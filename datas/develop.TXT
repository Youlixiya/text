岗位职责1、负责公司大数据平台相关产品的功能开发、文档撰写和项目改进；2、参与公司相关产品的技术选型、技术调研、大数据平台架构设计以及业务功能设计等；3、负责优化公司大数据产品的模块结构和流程逻辑，能够持续跟进大数据相关技术的发展趋势并能应用于实践；技能要求1、具有两年及以上大数据相关工作经验；2、熟练掌握Java、Scala语言，数据结构和算法等基础扎实，熟练掌握IO、多线程、MQ等技术；3、熟练掌握分布式消息队列Kafka；4、熟练掌握大数据分布式数据处理技术（1-2两种），Flink、Hive、Spark等，并有集群和分布式计算架构设计和实现经验（有Flink开发经验者优先）；5、熟练掌握大数据存储组件（1-2种）：Hive、Hbase、ES等；6、熟练掌握MPP数据库（1-2种）：GaussDB、PostgreSQL、GBase 8a等；7、具备优秀的数据敏感性；8、优秀的分析问题和解决问题能力，勇于解决难题；强烈的上进心和求知欲，较强的沟通表达能力，爱与他人讨论分享；9、对数据治理、数据挖掘、数据中台有一定的理解（加分项）；10、有华为FusionInsight HD大数据产品使用经验者优先；
智能供应链Y事业部定价管理研发部，致力于运用大数据和机器学习等人工智能技术，专注于供应链方面的智慧定价、智慧促销、供应链优化系统的打造，持续提升商品定价的决策效率，实现精准化比价跟价，解决用户行为分析、客户服务水平、市场渗透等电商领域内的业务问题；同时开放其技术能力，赋能商家与品牌商。岗位职责:参与京东零售智能供应链Y事业部定价促销项目中大数据方面的开发工作：1、负责大数据平台的设计以及开发工作，包括平台组件选型及搭建、平台服务开发；2、负责离线/实时的数据存储和加工处理，保证数据质量，负责数据监体系的建立和维护；3、负责海量数据的清洗、处理和挖掘工作，支持数据分析师和算法工程师的数据需求；4、对数据敏感，基于海量数据进行业务分析，灵活运用可视化工具，参与产品与应用的数据研发，分析数据成因，发掘数据商业价值；5、研究前沿技术，解决实际场景中的业务问题，优化离线/实时大数据计算任务的性能；岗位要求:1、计算机或相关专业本科及以上学历，三年以上大数据开发经验；2、熟悉Linux/Unix开发环境，精通python/java/shell，扎实的数据结构和算法功底；3、具有丰富的数据加工处理经验，对数据处理、数据清洗，数据建模、数据分析等有深刻认识和实战经验；4、熟练使用mapreduce、hive、spark等进行数据加工；熟悉hive和spark的编写和性能调优；5、熟悉常用的开源分布式系统，对Hadoop/Hive/Spark/Storm/Flink/HBase中的一项或多项有深入了解;能够独立排查及解决分布式系统的问题；6、清晰的逻辑分析和表达能力，热爱技术，乐于分享，对行业和技术的发展有自己的见解；7、良好的团队精神和合作意识，强烈的责任心，对工作有激情，良好的沟通能力；
岗位职责：1、负责大数据平台架构的设计和性能调优，支持海量数据的离线和实时分析，对数据敏感；2、参与大数据平台的搭建与维护，保证数据平台的稳定和可靠；3、保证大规模的离线、实时任务正常的平稳运行；4、设计并完成ETL等大数据处理任务；5、负责数据仓库的设计与开发。岗位要求：1、有大数据处理分析经验，熟悉Spark、Hive、Flink等大数据处理平台；2、熟悉主流开源数据组件，包括但不限于YARN、HBase、ClickHouse、Kafka、Oozie等相关技术；3、熟悉Linux开发环境，熟悉基础命令操作和shell脚本的编写，熟悉大数据平台组件部署思路；4、熟悉java、scala、python等任一开发语言，有3年及以上相关开发经验；5、熟悉大数据平台设计，熟悉OLAP引擎架构设计；6、参与过大型复杂分布式系统的设计与开发者优先。
工作职责1、负责公司研发工具数据运营分析，设计开发数据采集、数据处理、数据可视化、数据建模及数据质量等管理工具，构筑研发工具领域自己的大数据技术体系；2、规划设计研发工具服务主题模型，包括需求、设计、代码、检查、构建、软件仓库、测试、部署和运营运维等各个领域，以规范公司研发工具服务的数据架构设计；3、制定研发工具在数据采集、数据处理、数据服务、数据安全、数据质量等方面的管理规范，保证研发过程数据的可追溯；4、负责可信软件E2E可追溯服务的设计和开发。任职要求专业知识要求：1、熟悉数据架构设计和数据分析；2、熟练掌握常用Python数据包、Hadoop、Spark、SparkStreaming、Flink、ElasticSearch、Kafka、MongoDB等大数据相关技术；3、熟悉SQL，HiveSQL的使用;4、熟练掌握Java、Python、Scala任意一种编程语言；5、熟悉数据驱动需求理论，数据建模理论，具备数据加工处理ETL的实施经验优先；6、熟悉DevOps工具链经验的尤佳 7、 熟悉研发工具运营理论为加分项，必优先考虑
工作内容:1、负责公司大数据平台的建设;2、基于业务逻辑和业务数据的关系,设计相关数据结构,完成阅读数据模型的落地;3、根据相关数据规范和标准,实现业务底层数据ETL抽取逻辑,实现各项数据指标的计算,并基于相关指标开发监管类和业务类报表;4、负责公司大数据平台的运行维护、性能调优和日常技术支持。任职要求:1.具有扎实的java或python，shell语言基础知识，扎实的数据结构和算法知识，有web后端开发经验；2.熟悉常用开源组件如hadoop，hive，kafka，hbase，flume，spark的使用；3.对大数据处理有热情，对数据质量极致追求，热衷通过更优秀的数据建模和设计来提升数据处理效率；4.熟悉数据仓库，对分布式大数据处理有实践经验的优先；5.有创新思考，有数据分析背景或数据产品开发经验的优先；6.有阿里云大数据平台使用经验优先；
岗位职责：1.   负责数仓基础特征开发2.   负责数据平台相关模块的建设3． 负责大数据基础设施和平台改进，解决生产环境可用性和性能优化问题；4． 参与数据底层的工具、平台和部署流程等研发工作。岗位要求：1.   熟练使用Java 或scala 编程语言1． 熟悉etl架构，有一定的etl开发经验，了解日常作业的部署和调度；2． 较强的数据平台架构设计能力，能够主导分析客户业务需求，进行规划和设计3． 熟悉Hadoop、Hive、Kafka、Spark、Es、Flume等大数据相关技术栈，知晓底层原理和实现4． 精通 SQL，有较好的 SQL 性能调优经验5． 熟悉Linux操作系统及常用命令语句。6． 跨团队沟通能力。有以下经验的优先考虑：1． 有较好的产品意识，沟通能力强的优先考虑2． 阅读过大数据相关组件源码优先考虑
岗位描述1、负责海量数据的分析、抽样以及评估平台的研发2、对每天百亿广告数据、媒体数据进行分析处理，解决广告的推荐、用户画像、垃圾识别等一系列有挑战问题。 【任职要求】1.扎实的算法和数据结构功底，熟练掌握Java、Scala中至少一门编程语言；2.掌握海量数据处理技术，有使用Hadoop/Hive以及Map-Reduce计算模式，能熟练进行ETL处理TB级别数据，有Spark，Kafka，Elasticsearch，Hbase，Clickhouse等分析、存储海量数据的能力和经验。3.对数据仓库有深入了解，熟悉mysql、hive、redis等常用数据库。 4.有Flink开发经验者优先。 5.对分布式存储有较深了解，具有大规模集群高负载高并发工作经验者优先。6.有数据分析经验者优先。
职责描述：1.负责项目后台的架构设计和代码开发，包括高性能API接口实现，后台数据处理等；2.负责主流大数据开源组件的预研及落地；3.负责数据治理体系建设，包括元数据管理、数据生命周期管理、血缘管理等；4.负责数据ETL处理（采集/提取/清洗等），算法模型的工程化实现，包括算法服务封装以及接口设计开发等工作。任职要求：1.本科以上学历，具有计算机科学、信息技术、通信、数学、物理、统计等专业背景；2.具备扎实的编程能力，熟悉数据结构和常用算法等，熟练掌握Python语言，熟悉django、flask等web框架，熟悉JAVA/Scala/Go中的至少一种语言；3.熟悉Hadoop/Spark/Hive/Hbase /Flink等大数据基础组件的使用，熟练使用MySQL、PostgreSQL等数据库；4. 有快速上手新的大数据开源组件的能力；5.有持续的学习态度与自我提升意愿，有良好的工作执行力、沟通能力以及团队协作能力。
岗位职责：1、负责大数据平台ETL任务开发和维护；2、负责BI指标体系建设以及相关报表数据的开发；3、负责数据服务接口的设计及开发；4、负责离线数仓数据模型设计及落地；任职资格：1、本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业，3年及以上大数据平台开发工作经验；2、熟练使用java、scala、python等开发语言中的一种； 3、有hadoop和hive、spark、flink实际开发经验。了解大数据组件的使用限制和应用场景，如hdfs,yarn,hbase,hive,flume,kafka,zk,impala,kylin,kudu,ES,Storm、MongoDB等。4、熟悉mysql、oracle、ElasticSearch、Redis等关系型或NoSQL数据库，了解应用场景和使用限制；5、熟悉linux操作系统及常用命令；6、熟悉HDFS分布式文件系统架构，熟练掌握Hadoop/Hive/hbase的运维和调优方法； 7、熟练使用过azkaban、airflow、dolphinscheduler等开源调度工具。
职位描述1、负责离线与实时数据仓库构建；2、负责数据模型的设计，ETL实施，ETL性能优化，ETL数据监控以及相关技术问题的解决；3、深入业务，理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；4、参与大数据应用规划，为数据产品、挖掘团队提供应用指导；5、 参与数据治理工作，提升数据易用性及数据质量。职位要求1、熟悉数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；2、熟悉hadoop，hive，spark，flink，doris等大数据框架，有大规模数据处理经验；3、熟悉Java、Scala、Python、SQL等编程语言，具备较强的编码能力；4、对数据敏感，认真细致，善于从数据中发现疑点，具备优秀的技术与业务结合能力；5、有过支持算法相关的大数据工程问题，了解特征挖掘和机器学习算法优先
职位描述1.负责各个业务线数据仓库建设；2.定义并开发业务核心指标数据；3.根据具体问题，设计并实现合适的可视化展示，构建数据持续观测平台；4.参与数据平台的搭建，优化数据处理流程具体工作；5.参与数据收集,数据质量监控，任务调度，数据存储&查询优化，等全流程工作6.参与公司内数据流通规则等数据生态相关工作任职要求1.计算机相关专业，本科1年以上工作经验；2.了解掌握hive，kafka，spark，hbase，flink等任意两种技术，有脚本开发和SQL优化相关经验；3.熟悉掌握数据仓库建设方法和ETL相关技术，对于数仓的设计有自己独特的思考，具备优秀的数学思维和建模思维；4.很强的学习、发现、定位、分析和解决问题能力，良好的团队意识和协作精神，有较强的内外沟通能力。remind：简历与实际不符者，立即中断面试流程
工作职责:1. 负责数据仓库的设计、开发和优化工作；2. 负责数据平台和数据仓库开发建设，保证数据平台稳定可靠运行；3. 负责数据平台结构化数据和异构数据的规范化和数据清洗、关联、统计；4. 根据业务部门数据分析需求进行数据相关的开发、加工、分析，并持续跟进直至业务目标实现；5. 参与需求调研、分析及梳理任职资格:1. 211本科或以上学历，计算机、软件工程相关专业；2. 两年以上数据仓库领域工作经验，对数据仓库系统架构具有良好的认识，熟悉数据仓库相关技术，如数据建模、ETL、报表开发等；3. 熟悉hivesql、spark，了解Hadoop生态圈，有sql调优经验者优先;4. 具有MySQL等至少一种关系型数据库的开发经验；5. 熟悉Java、Python、scala 其中一种或多种开发语言；6. 具有较强的业务理解能力，具有较强的沟通和解决问题的能力，能承担一定的工作压力；7. 熟练掌握百度系edap、sugar等大数据产品加分
岗位职责1、构建数据分析体系，负责数据的分类汇总、分析研究、有效利用；2、根据业务需求和产品设计，完成相关数据处理、统计及分析工作；3、对项目数据采集、存储、处理及可视化应用等涉及的数据治理流程进行监控管理；4、协助开展业务数据调研、业务流程及数据规范梳理等工作，完成调研分析报告；5、负责数据产品的交付实施；6、运用SQL协助处理项目数据统计需求、支撑项目产品功能数据核对工作。任职要求：1、本科或以上学历（学信网可查），有相关数据处理相关岗位的工作经验，对贴紧业务做分析有浓厚兴趣；2、了解数据分析和处理工具，能够进行海量数据处理和挖掘，熟练使用Python/R等数据工具；3、数据敏感、善于创新、思维敏捷、精力充沛、沟通能力强，具备较强的团队合作精神；4、熟练使用SQL/Hive等语句，具备Hadoop/Spark等海量数据处理经验；5、具备计算机软件、硬件、网络、数据库等知识基础，熟练使用EXCEL、PPT等办公软件；6、熟练使用常见的开源ETL工具，如Kettle等，并对其工作机制有所了解。7、熟悉华为云、阿里云的优先考虑。8、参与B端、G端的项目优先考虑。
【岗位职责】1.负责业务相关的数据需求以及基础数据体系化建设，不限于数仓建设，数据质量，指标体系，数据治理，实时计算，用户画像，线上数据应用开发等；2.基于对客户服务、体验优化相关的理解，开展符合运营侧的拉新、留存、促活等体系的数据模型设计以及报表开发，为提升用户在平台的活跃度及忠诚度提供数据支持。3.设计并实现业务系统数据需求，能够独立完成建模及数据分析，数据线上应用等工作；4.负责离线数据的ETL的实施、清洗、归档、生命周期管理以及运营核心指标的开发工作；5. 跨部门协作，协同分析并解决数据，业务问题，深入数据挖掘和数据分析；6. 负责数据基础工具及数据仓库建设，核心业务指标可视化及监控，制定并实施数据规范；7. 根据海量的数据建立完善的指标体系和数据分析挖掘方法，支撑业务运营需求。 【任职要求】1.计算机相关专业本科以上学历，两年以上互联网数据开发工作经验；2.具备扎实的编程基础，熟悉SQL/Java/scala/Python等两门及以上语言；3.熟悉数据仓库架构及原理，具备大型数据仓库架构设计、模型设计和处理性能调优等相关经验；4.熟悉Linux系统原理、熟练运用Linux命令与脚本5.熟悉Hadoop, Hive，Spark，Flink，Kafka，ElasticSearch、HBase等大数据框架原理及应用；6.善于交流，有良好的团队合作精神和协调沟通能力，有与产品、客户端等多方密切配合的经验和意识。 【优先考虑】1.有互联网数仓开发经验；2.有用户主题数据建设经验；3.具有良好的数据质量管理意识；4.用过用户供给侧数据开发项目经验优先。
工作内容：IC开发流程自动化工具开发：—包括机器数据ETL，业务逻辑开发，前端页面开发IC ML/AI 大数据平台开发：职位要求：熟悉python ，PHP，javascript，HTML等语言有web开发经验是加分项有大数据处理，挖掘经验是加分项有机器学习算法开发经验是加分项
1、负责字节跳动电商相关业务数据仓库的开发与优化，建设电商数据中台；2、基于Hive/Flink等平台建设数据仓库，实时数仓建设，进行ETL开发；3、负责大数据能力在产品功能上的落地，推动产品数据化和智能化，为业务赋能；4、抽象业务逻辑，构建行业领先的大数据中台。岗位要求1、熟悉大数据相关技术：Kafka/Flink/Hadoop/Druid/HBase/Hive 等；2、熟练使用 Java、Go、Python语言中的一种或者多种；3、具备数据库系统理论知识，掌握主流数据库管理和应用，精通SQL；
岗位职责：1、参与银行数据类项目的需求调研，对业务需求部门进行数据支持；2、具备系统设计、编码开发能力，具备评审详细设计及查找定位bug的能力；3、能够理解业务需求，编写相应的需求文档并对交付结果负责，保证交付成果质量达标；4、数据映射的编写，ETL开发及数据验证，数据分析类工作。任职资格：1、大学本科以上，计算机或金融类专业优先；3、 熟知数据结构，数据库4、具备模型分析开发能力，如参与数仓中间层/应用层的设计建设5、 熟悉数据库工作原理，具备数据脚本调优能力6、熟练使用linux操作环境7、沟通能力良好，能独立完成需求对接开发
1、参与数据处理引擎开发；2、参与大数据中台的ETL数据处理；3、参与大数据中台的应用开发；4、参与系统自动化运维工具开发；5、参与辅助数据分析的代码开发；6、参与数据质量校验的代码开发；7、参与互联网数据采集的代码开发；技能要求：1、须满1年以上python开发工作经验；2、统招本科及以上学历，有扎实的数学基础和计算机基础；3、熟悉python语言做各种文件处理，例如：CSV文件处理、word文件处理、excel文件处理；4、熟练使用python做数据分析；5、熟练掌握python程序的调试、单元测试，性能分析；6、熟悉oracle数据库优先；7、熟练掌握linux开发环境；熟练操作shell脚本者优先；8、具备高效的理解能力；9、良好的沟通与表达能力、思路清晰，较强的动手能力与逻辑分析能力；10、较强的团队协作精神、优秀的学习能力与创新能力。
岗位职责：1、负责公司安防数据仓库的规划、设计；2、负责大数据基础平台的开发与优化；3、负责大数据相关技术的预研、选型、技术框架设计；4、负责数据的清洗，ETL实施，ETL性能优化。任职要求：1、计算机或相关专业统招本科（或以上）学历，具有3年以上Hadoop生态系统开发、调优经验；2、深入理解大数据平台架构，能够及时发现并解决重大故障以及性能瓶颈；3、精通大数据相关技术：Kafka/Flink/Hadoop/Yarn/HBase/Hive/ElasticSearch 等；4、熟悉java开发语言，能够熟练使用SQL；5、了解统计以及数据挖掘、机器学习、人工智能技术，会使用关联分析、分类预测、聚类分析等常用分析方法；6、具有良好责任心，团队合作意识，具有良好的沟通能力和客户服务意识。 团队缺口人数：2人早九晚六 餐补20/天  转正后享有交补和通讯补助200/150  六险一金 社保公积金全额缴纳可接受出差（差旅报销）
"岗位职责：1.	基于公司数据建设需要，完成数据平台构建、数据内容开发等工作。包括：数据平台基础设施建设、数据采集、ETL、数仓及数据集市、数据应用产品等开发工作；2.	充分理解需求文档，基于此进行自测，交付高质量的开发代码和数据内容；3.	工作中对数据平台基础设施、数据内容建设等工作主动深度思考，提升效能并积极建言、促进组织和系统发展。任职要求：1.	具备BI项目的需求分析和设计能力 2.	理解数据仓库和ETL领域的理论和方法 ，熟悉ETL架构，有一定的ETL开发经验，了解日常作业的部署和调度3.	精通主流ETL工具使用，如：DataStage、kettle、Informatica等；4.	精通Oralce、MySql、Sql Server等至少一种主流数据库的使用，精通 SQL，具有丰富的数据库开发和SQL优化经验；5.	熟练使用linux平台，以及python/shell命令编写，并且熟知docker相关知识；6.	熟悉阿里云base平台开发，并有阿里云平台开发工作经验，能够熟练使用大数据产品，持有ACP证书者优先 ；7.	熟悉大数据平台相关原理，能够进行云平台相关运维工作，保障平台出现问题能够及时处理。"
北京-大数据研发工程师工作职责：-负责构建大数据分析平台以及数据分析和挖掘工作-负责基于百度数据的离线和实时流分析-参与支撑业务的数据模型建设及数据指标的计算和分析-参与海量数据的存储、查询和运营数据分析体系搭建-运用Hadoop、Spark、ES等分布式计算和存储平台要求：-计算机相关专业应届毕业生-对Spark及Hadoop技术有深入了解-熟悉Python/Java/Scala/Php等编程语言，熟练使用SQL，有良好的编码习惯，对分布式有深刻理解-了解Windows、Unix、Linux等主流操作系统原理，熟练运用系统层支持应用开发-技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识，勇于解决难题-善于沟通和逻辑表达，拥有优秀的分析问题和解决问题的能力，良好的团队合作精神和积极主动的沟通意识-有激情，具有自我驱动力，追求卓越具有以下条件者优先：-计算机领域相关的编程大赛获奖、专业期刊发表文章或者有发明专利等-具备大数据云平台、计算存储平台、可视化开发平台经验，熟悉软件工程开发流程-具备专业领域的计算机知识和技能： Storm/Hive/Hbase/Storm/Kafka等
【职位描述】* 负责大数据中间件产品研发* 负责大数据分析平台软件的研究和开发* 负责数据仓库产品的研究和开发【任职资格】* 计算机科学、应用数学、统计学、经济学、物理学、天文学、商业分析、信息系统、数据科学或相关专业本科或以上学历* 优秀的学习能力与发现、分析并解决问题的能力* 良好的团队合作精神与沟通能力【技能要求】* 具备良好的口头表达能力* JAVA基础扎实，有相关开发或者实习经验，熟悉IO、多线程、MQ、数据结构与设计模式等* 精通Hadoop/Hive/Hbase，对Hadoop、Hive、Storm、Spark等源码有研究者优先* 有分布式监控、搜索、调度、部暑其中一项经验优先* 熟悉分布式、缓存、消息机制，常用的DAL/ORM框架和设计模式【公司介绍】：-麦肯锡和华为惠普联合团队• 由多位前麦肯锡合伙人以及华为惠普核心工程高管联合创立，打造精品管理咨询传承与科技创新品牌• 同时拥有优质咨询项目资源、丰富咨询经验，及数字化赋能的精尖技术能力，建立从咨询建议到产品/解决方案的全面商业服务模式• 约600位咨询顾问、数据科学家、软硬件工程师常驻北京上海和成都-多行业多商业领域覆盖•主要服务于企业客户，通过结合管理咨询、大数据分析、算法建模与工程落地的能力帮助企业客户实现业务增长•行业覆盖消费品、零售、金融、互联网、医疗与媒体等•与多行业领先企业深度合作，建立长期合作关系，如沃尔玛（获沃尔玛年度最佳供应商称号）、欧莱雅、联合利华、中国农业银行、腾讯、京东、美团等-精尖的数据分析/算法/工程师团队• 具备数据清洗与挖掘、算法模型和语义分析方面行业领先技术水平与能力• 具备根据客户业务方向搭建中台/后台的工程技术能力与丰富的项目经验• 具备广受行业认可的成熟产品（含已申请专利技术），帮助客户实现数据驱动的效率提升-富有竞争力的职业发展与薪酬福利保障•注重人才培养，提供定期培训分享及深度参与项目机会，加入团队的年轻小伙伴们再也不用担心自己沦为职场“小螺丝钉”•注重员工成长空间，每年二次全员review，半年即有机会享受升职加薪•注重福利保障，包括：五险一金、全额理赔商业补充医保、超长带薪年假、超长带薪病假、书费报销、打车报销、无限量零食饮料畅吃、国内外团建旅游等
岗位职责：1、数据开发及脚本开发；任职要求：1、2年以上数据开发经验、熟悉sql及类sql数据开发；2、熟练使用Python脚本进行数据处理及完成其他功能，具备shell脚本能力；3、熟悉电商行业、社交平台数据开发及相关分析方法论；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力；5、有大数据业务开发经验，熟悉Hadoop、Spark、Flink 等流批数据处理大数据开发产品优先；6、统招本科以上学历，熟悉大数据及云计算产品优先；
1. 从事大数据计算和存储平台的技术方案设计、平台搭建和应用研发协作及持续改进系统性能； 2. 负责AI及网络智能化相关平台大数据架构设计开发； 3. 参与代码评审、设计评审等开发过程相关工作，培养团队新人。职位要求: 学历及专业： 硕士及以上，计算机科学与技术、软件工程、通信工程或其他相关专业 专业技能： 1. 具备5年以上软件平台的研发及架构设计经验，具备良好的行业内技术积累,能独立负责技术架构规划与架构演进； 2. 熟悉开源分布式系统，对 Hadoop/Hive/Spark/Flink/HBase/Druid /kafka中的某项或多项有深入了解及实际的开发经验; 3. 从事过多年的JAVA或者Python开发语言的经验，并且基础知识扎实，理解io、多线程等基础内容及常用的开源框架，可以深入代码一线； 4. 熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制，掌握多线程及高性能的设计与编码及性能调优，有高并发应用开发具备以下经验者优先： 1. 具备5年以上的大数据软件开发和设计经验。 2. 有以下经验者任一可优先: a) 熟悉大数据、网络通信、云计算等领域主要调度系统的架构、算法、实现、以及设计理念，有大型或运营商网管领域项目的开发和架构设计经验者优先。 b) 运营或者参与过开源项目，熟悉开源项目运作，对开源和商业之间的关系以及联动发展有自己深入独到的理解者优先。从事过软件研发架构，有大数据高并发商用系统的开发经验者优先。 c) 具备数据挖掘、机器学习、自然语言处理相关开发经验者优先。
岗位职责：1、参与数据原理研究、处理模型验证、相关数据挖掘算法、统计分析方法、数据处理应用开发工作2、参与数据资源的收集规整、格式转换、交互共享3、参与数据可视化相关开发工作4、协助公司数据服务平台的大数据分析平台建设及运行维护任职资格：1、熟悉常用数据处理编程语言：Python、R等，有一定的代码编程经验2、掌握统计学数学知识，有一定的数据处理、数据分析和挖掘经验项目经验3、熟悉常用文档编辑工具的使用，精通EXCEL4、良好的沟通、学习、团队协作能力5、有民航领域相关工作经验优先6、英文能力较好者优先
1、至少3年以上实时流计算数据开发经验、熟悉Java,Scala，有持续学习新技术能力；2、具备大规模实时计算、大数据平台设计、数据仓库建模能力，有大数据业务应用场景经验的优先；3、深入理解Flink/Blink/Spark/storm/Hadoop/Hive/Clickhouse/等大数据技术框架，并有丰富的开发经验。4、熟悉图计算/Hbase/OSS/OTS/Beam/Yarn/Airflow等技术栈，熟悉基于实时数据的在线预测、累积计算、搜索推荐等应用场景的优先；5、有实际的大数据工程平台建设实践经验者优先；
职位描述：1、参与公司大数据项目应用开发与维护，协助完成项目需求的整理与设计工作；2、参与并负责系统架构的优化及性能的提升，解决关键问题与技术难题； 3、及时分析并解决线上系统的各类疑难问题。职位要求：1、全日制统招本科（含）以上学历，计算机或相关专业，6年以上大数据开发相关经验；2、熟悉shell、python、R、Scala等一种以上语言；3、熟悉大数据处理相关技术，包括但不限于Hadoop、Hive、Hbase、Impala、Spark、Kafka、Flume、Storm、Redis、Kylin，数据仓库等，并且有实践经验，能解决应用中的复杂问题；4、熟悉大数据领域的解决方案，具备该领域全面的技术积累，思维清晰敏捷，逻辑分析能力强，有独立软件设计和解决问题能力；6、具备良好的沟通能力、项目控制和协调能力、团队合作能力。
1.有汽车领域或互联网经验（离线数据方向）能够理解业务需求并制定技术方案，具备独立解决问题的能力2.熟悉Java技术栈，对springboot微服务有实践经验3.熟悉Hadoop生态，不限于hive hbase Doris hdfs spark atlas flink es sqoop iceberg等，至少掌握3种4.对开源调度系统airflow dolphinscheduler oozie azkaban 有实践经验，理解底层源码逻辑的优先5.参与过数据平台项目优先，离线方向不限于调度、元数据管理、同步工具、指标管理、bi、数据质量、ad-hoc等6.数据基础算法数据结构，能够熟练使用SQL，了解MySQL基本原理7.有过数据存储/计算引擎调优经验或开源社区贡献经历者优先8.有互联网大厂、车企、985、211优先
关于京东Y事业部京东Y事业部定位是以服务无界零售为核心，着重智慧供应链能力的打造，核心使命是用技术创新让供应链迈向卓越。Y事业部正在京东集团未来十二年战略转型的指引下，全面探索和应用大数据挖掘、人工智能、区块链、物联网等一系列技术，持续推动供应链管理创新与应用，携手合作伙伴链接世界，智创未来。 岗位职责：1、基于spark对数据进行实时/离线分析。2、通过数据分析，为线下店赋能。任职要求:1、深入了解 Spark原理，阅读过源码者优先2、熟悉Hadoop、Hive、Hbase、kafka等大数据技术3、精通Python、Java、Scala中至少1-2种开发语言4、具备实际的大数据业务开发经验以及良好的项目沟通和协调能力5、有互联网行业经验者优先。
岗位职责：1、负责理解项目需求、结合业务，参加数仓项目的设计开发；2、负责数仓项目的底层数据结构、数据模型设计，包括主题宽表、多维模型的设计；3、负责数据仓库实时数据统计模块开发及大数据工具类的开发。岗位要求：1、负责大数据接入、存储、分析、监控等系统的开发工作；2、负责Hive、Spark、HBase、Kafka等组件的性能优化工作；3、负责实时工业数据流计算应用程序的开发工作。有数据治理、团队管理经验者优先！
职位职责：1、负责广告数据流 实时数据计算、存储2、针对海量数据处理和查询需求，设计适应业务变化的合理的多维数据分析系统架构，满足多样性的需求。3、海量日志清洗加工，并抽象出可以多业务复用的数据模型。职位要求：1、计算机相关专业本科及以上学历,有扎实的编程语言基础，熟练掌握Java、Scala、Python、Shell2、熟练服务开发（Spring Boot、Spring Cloud、Dubbo服务框架等）3、有Hadoop stack（包括hadoop、hive、spark等）经验者优先4、熟悉spark、flink等大数据处理框架，理解流式处理概念者优5、有大数据查询系统（包括Impala、Kylin、clickhouse等）经验者优先5. 有BI开发（包括Spark SQL、Hive SQL）经验者优先6、有数仓经验者优先。7、善于沟通，工作积极主动，责任心强，具备良好的团队协作能力。8、具备良好的问题分析与解决能力，有较强学习能力和逻辑思维能力。
职位描述1、负责数据管理平台技术架构搭建、设计、开发与维护； 2、负责广告投放中的用户行为日志采集、大数据建模分析、业务系统数据展示工作； 3、为公司运营部门提供数据分析支持。任职要求1、3年以上大数据相关开发经验； 2、熟悉分布式系统的原理，了解常用分布式系统（HDFS，Hbase，Storm，Kafka，yarn，k8s）的设计与架构；3、熟练使用常用大数据框架 MR/streamming/hive/spark/flink； 4、熟练使用golang，java，python中任意一门语言；5、熟悉Linux下开发, 能用shell/python等做常规的数据处理和分析；6、针对业务系统数据需求, 能够设计合理的数据收集, 处理，存储，查询方案。 加分项： 1、有大规模数据收集,日志处理经验； 2、有关系型数据库, 数据建模经验； 3、深入研究过大数据框架的运行机制、实现原理、源码。4、了解常用的OLAP数据引擎，诸如clickhouse，presto，impala等
岗位职责： 1.负责小米集团质量相关数据的基础架构建设与维护2.参与小米大数据部数据产品的建设和研发工作岗位要求： 1.计算机相关专业，三年以上相关工作经验，有大型互联网公司工作经验者优先2.具备扎实的编程功底，熟悉数据结构和算法，至少熟悉Java/Scala中一种编程语言。3.具备快速学习能力、沟通协调能力及团队精神，有较强的责任心和学习积极性。4.熟练掌握大数据技术栈，包括Hadoop生态圈、隐私计算等技术架构，如Hive/Spark/ElasticSearch/HBase/Kafka/Flume/Flink等
1、负责数据中台融合建设，相关系统架构设计，资源环境规划2、负责大规模集群管理，架构优化，资源优化3、负责部分平台接口设计和研发、标准和规范制定任职资格1、专科以及以上学历，计算机相关专业五年以上大数据开发经验2、熟悉主流开源大数据技术，如Hadoop, Spark, Hive,Tez, Presto, Hbase等3、java/ scale编程背景，有丰富的进程间通信/多线程/高迸发等研发经验4、熟悉Linux等底层操作系统，能独立管理快速搭建大数据运行环境5、有大规模集群管理，运维，优化迁移者优先6、参与Apache来源社区技术共建，有源码贡献者优先
工作职责：1、搭建商业化数据处理平台，包含数据规模化计算、系统全链路数据建模&监控&诊断、算法模型生命周期管理。2、推进业务数据的沉淀，构建商业领域数据仓库，提升数据的准确性和可靠性。3、面向业务提供可靠、实时数据能力，包括但不限于特征平台、定向中心、索引更新平台等。任职资格：1、有两年以上的Java或Scala开发经验，编程基础扎实，熟悉常见的面向对象设计模式和常用的开源框架,如SpringBoot等;2、熟悉一种以上大数据计算引擎框架，如spark/hadoop/flink/storm等，理解数据仓库、数据湖等建模方法3、有大型服务框架开发研发经验，高并发、低时延系统设计与研发经验，具备良好的系统分析/构建能力，有稳定性架构经验者优先；4、有商业化业务背景，标签画像/索引更新/特征中心方面经验者优先。
工作职责负责车辆相关数据业务开发工作，不限于数据中台开发、数仓建设等开发方向；负责相关业务的数据应用梳理以及流程优化，完善数据应用系统的建设，为产品迭代提供数据化分析的方法论以及数据能力支撑；工作要求计算机、通信、数学相关专业毕业，大学本科以上学历；熟悉Java，Python、SQL等常用开发语言；了解Hadoop，Spark，Storm，Flink，Kafka，Elasticsearch，Druid等大数据相关平台和组件；扎实的计算机基础及编程能力，熟悉常用算法和设计模式；对数据驱动业务有一定理解，对数据与业务方面有足够的敏感性，有较强的逻辑分析能力，有较强的独立思考能力；具有强烈的责任心以及团队合作精神，具有较强沟通能力，积极向上。
阿里妈妈(北京)年前紧急招人啦，年前面试年后入职，我们是阿里妈妈广告数据平台团队，目前5-8都可以招。职位描述1.负责广告数据计算平台设计和开发，支持万亿级数据的交互式圈人、洞察、归因场景。2.负责广告定向数据产品研发，能提供架构设计和优化方案，并从技术上推进产品的快速迭代。3.负责数据应用产品开发。职位要求1.熟练掌握C++、多线程、网络通信、高性能优化，或者熟练掌握Java开发和调优、并发编程模式，有丰富Unix/Linux环境开发经验。2.具备丰富的数据开发经验，熟悉Hadoop、Hive、Spark等体系结构，并有实际开发经验。3.熟悉Impala/Presto/GreenPlum等MPP数据库，对各数据库的优劣和适用场景有深入理解，有实践经验者优先。4.熟悉分布式技术并有实践经验（rpc框架， nosql存储），对kafka等消息中间件有深入了解。
1.负责智能汽车行业大数据平台的规划和建设，包括离线、实时平台维护；2.利用大数据生态技术设计并实现车辆实时数据采集、归集和存储相关系统，包括车机CAN总线数据、ADAS数据、GPS、自动驾驶等相关数据；3.负责车机CAN总线数据、雷达数据的数据分析，为自动驾驶提供数据支撑；4.基于公司的智能汽车、出行等全面的IoT大数据，积极探索深度学习等人工智能技术的应用，实现大数据在智能汽车行业的商业价值。1.计算机、数学、统计学等相关专业本科及以上学位，3年以上的大数据建模、分析和软件开发经验；2.掌握常见分布式计算框架和技术原理，如Hadoop、MapReduce、Yarn、Hbase、Flink、Spark、TiSpark、WaterDrop等；3.掌握Druid/Kylin/ElasticSearch/Impala/ClickHouse等一种或者多种OLAP工具，熟悉其原理和运行机制；4.精通Java/Scala、其他主流开发语言；熟悉常用的Java类库以及框架，如Spring等；5.具备扎实的数学知识，至少在以下某一领域有深入的研究：统计学、深度学习；6.性格积极乐观、诚信，能自我驱动，有较强的语言表达能力；7.具有智能交通、车联网、互联网行业经验优先考虑。
岗位职责：1.参与数据中台建设，承担相关大数据平台研发、架构设计等工作，包括数据采集、传输、存储、处理、分析、治理等环节；2.工作范围涉及大数据开发平台、统一资产治理平台、数据服务平台、元数据中心、数仓建模工具等，探索创新方案和新领域，包括数据湖、流批一体等；3.负责数据中台产品的稳定性、性能、易用性优化；4.负责大数据能力在业务上的落地，推动数据化、服务化。职位要求：1.熟悉Linux系统，熟悉Java/python语言，熟悉常见的数据结构和算法，扎实的编码能力和工程实践能力；2.参与或主导过数据平台建设项目，对数据工作有深刻理解，熟悉数据仓库、数据建模理论，对平台建设有一定的见解和把控能力；3.熟悉常用的大数据技术并有实践经验，如Hadoop\Hive\Spark\Flink\Kafka\Impala\Oozie\Atlas\Elk等，对源码有研究者优先；4.具备TCP/IP网络协议分析能力，熟悉TCP协议相关原理例如：连接建立、拆除、启动、重传等，能够熟练运用Wireshark等工具进行协议分析，例如：ARP、HTTP、DNS等；5.有自研平台经验者优先，包括但不限于离线开发平台、数据质量中心、元数据管理、数据资产管理、日志埋点平台、实时流平台等。6.了解应用层协议识别、DPI原理，有过网络流量分析实战经验优先。
岗位职责：1.支持Hadoop集群底座的运维故障分析、解决、性能优化；大数据集相关组件主要包括：Yarn、HDFS、ZooKeeper、Storm、Kafka、Hbase、Hive、Spark、Kerberos、Spark、Flink、Flume、MySQL等组件运维；2.开展Yarn性能优化，提升集群资源利用率和任务响应速度；队列优化和维护；优化调度器性能；3.及时关注Apache官方网站、论坛，针对Patch提出升级建议、方案，并组织实施；4.配合开展HDFS存储、Hive元数据治理优化，建立并完善存储治理方案；5.配合开展Hive、Spark作业优化，对业务侧提出优化建议。如：作业小文件问题、数据倾斜治理方案等；6.提出集群优化建设方案，配合建设和优化大规模分布式集群的自动化运维、监控等工具和管理平台。任职要求：1.全日制本科及以上学历，通信/计算机等相关专业，具有良好的学习能力、沟通能力、团队合作能力及一定的抗压能力；2.熟悉Hadoop、Hive、Hbase、Spark等开源项目，理解组件架构及原理；3.对大数据运维开发有浓厚兴趣，熟悉Apache Hadoop部署、性能调优；4.能阅读/理解Hadoop等相关开源组件源码；5.对HQL、SparkSQL等有较深入的研究，能解决实际业务性能问题；6.熟练掌握LDAP、Kerberos等安全认证体系；7.熟练掌握Linux命令与工具进行问题定位，熟悉常规的互联网技术架构；8.具备一定的Java开发能力；9.擅长Linux Shell、Python脚本编写，有DevOPS/自动化运维经验工作者优先考虑。
岗位职责：1、参与大型数据中心系统的研发和建设工作；2、参与Flink、Hive、HDFS、YARN、ES、Kafka、CK等大数据平台组件核心技术的开发工作；3、参与数据汇聚、数据预处理、数据融合、数据治理、数据服务等面向业务中台的工具、系统的开发工作；4、参与大数据相关产品的架构规划、产品研发工作，包括产品使用文档、技术材料的编写等；5、参与团队所属项目的支撑工作，及时处理线上的问题，并优化产品功能；6、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景。任职资格：1、计算机相关专业或自学计算机技术，熟练掌握计算机基础理论知识；2、熟悉数据结构、设计模式以及算法；3、至少掌握Java/C/C++中的一种开发语言，能熟练进行开发，包括不限于多线程、网络通信等，了解调优原理，如JVM优化等；4、熟悉Linux系统，能熟练进行操作和部署，了解Shell，会进行常用命令的编程；5、对Hadoop生态圈相关组件（包括不限于HDFS、Hive、Kafka、Spark、Flink、Flume等）源代码有研究者优先；6、踏实肯干，责任心强，具有很强的学习能力，能很快融入项目组；7、较强的沟通能力，较强的逻辑思维，学习能力强，计划性强；8、对技术有浓厚兴趣，喜欢挑战。
岗位职责：1. 负责银行业金融客户AI项目系统实施的需求分析和任务开发设计和工程化；2. 负责项目现场客户IT环境的对接、数据需求和数据处理模块的开发、测试、上线交付；3. 负责项目现场AI系统实施过程中各种故障定位和解决落地，能够进行系统调优；4. 负责项目现场AI任务流的工程化、调度、测试、上线、交付文档编写，对系统稳定性负责。任职资格：1. 本科及以上学历，3～5年工作经验，计算机、通信、自动化等信息相关专业；2. 熟悉HDFS/Yarn/Hive的原理和架构，对Hbase/Kafka/Flume等相关技术要有一定的了解；3. 深入掌握Spark内核原理，对PySpark的计算资源和任务执行原理；4. 对数据治理和数据处理要有一定的了解和使用，熟练掌握SQL的开发；5. 熟悉Java，能够熟练使用Shell/Python等脚本语言进行开发；6. 掌握Mysql/Mongo/Redis/Oracle/Neo4j两种以上的使用；7. 思路清晰，自学能力强，能独立分析和解决问题；责任心强，吃苦耐劳，能够接受出差和驻场开发；8. 有如下一项或多项者优先考虑：(1): 有过银行或金融科技工作经验的优先考虑；(2): 有过AI模型和系统交付落地经验的优先考虑；(3): 有AI机器学习知识背景的优先考虑；
【寻找优秀的你】觉得自己的潜力没有被挖掘？想要拥有无限的发展空间？希望通过自己的努力取得进步、获得高薪？寻找一个释放光彩的机会？千易云教育，为你提供实现梦想的平台，见证你的成长，助你走向人生巅峰！ 岗位职责1. 负责面授课程的教学工作，向学员进行知识的输出，按进度完成教学任务；2. 负责学生自习时间的作业安排，学习成果验收；3. 联动助教、班主任关注、解决班级问题学员；4. 负责教学资源建设（包括教学大纲、教学PPT、教学用书、教学案例、教学视频等）5.​整理开发项目转换为课程6. 关注行业动态，参与学时交流与讨论，根据市场需求优化课程；7. 热爱教师职业，对工作充满热情，责任心强； 任职要求1. 计算机等相关专业，理论基础扎实，有5年以上java开发经验；2. 熟练使用MySQL、Oracle、DB2等一种或以上主流数据库；3.​精通linux操作系统并能进行shell脚本编程3. 具备Linux/Unix环境开发经验，熟悉脚本编程的优先；4. 深入了解大数据相关框架，对以下技术有过应用或相关开发教学经验，至少掌握其中三种，hadoop框架、spark、hbase、hive、scala、flume、kafka、storm、ELK；5. 有大数据培训课程讲师经验者优先；6. 语言表达流畅，有良好的人际沟通能力和学习能力。
一、技能要求1 精通python程序设计，熟悉flask,django等至少一种框架。2 熟悉linux操作系统，熟练使用nginx,git,redis,docker等与开发相关的依赖工具。3 熟悉数据库理论与操作，熟悉mongodb优先。4 熟悉搜索引擎的原理与使用，熟悉elasticsearch优先。5 掌握http协议，熟悉html,dom,xpath正则表达式等常见的数据处理技术。6 有实际爬虫开发实例者优先录用二、任职要求1 应届应聘者，要求第一学历为国内985或211高校计算机、通信、电子、信息、数学专业统招全日制本科或硕士毕业生。2 985.211硕士3 愿意扎实深入业务，深入一线，有较强的沟通协调能力，勇于承担压力和责任，较好的团队合作精神。
1、计算机专业本科及以上学历，学信网可查2、5年以上数据类项目工作经验3、负责数据从业务系统(数据源) 抽取/转换/加载到数据仓库，负责数据仓库的整体搭建及架构设计4、负责数据从仓库到前台报表的展现，负责开发数据个性化展示用户画像、日志抽取系统等数据应用服务5、负责数据治理项目的落地实施，包括数据采集数据治理数据质量及稳定性保障6、有金融保险行业数据项目经验优先
工作地点：北京（不定期出差济南）岗位职责: 1、根据产品和项目需求完成公司数据中台大数据相关技术和功能开发工作；2、负责大数据相关技术与公司产品融合的研究、规划、编制方案、开发落地； 任职要求: 1、本科及以上学历，5年以上大数据开发经验；有过实际大型数仓、数据中台、数据湖等项目或产品的设计与开发经验优先； 2、必须有Flink实时计算开发经验； 3、掌握或了解 kafka \ hbase \ es \ clickhouse等实时数仓相关技术栈； 4、了解Datax \ Sqoop \ Hive\ 调度管理等相关技术栈； 5、工作细致，责任心强；对数据有一定的敏感度。
职位描述 1． 参与实时处理与分析，搭建和维护分布式数据存储平台，保障交易链条等相关数据的准确性与及时性 2． 设计良好的数据流、调度系统、查询引擎，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值；职位要求 1．计算机、通信、数学、统计相关专业本科及以上学历，大数据存储平台 2 年以上经验或者clickhouse 数据处理一年以上经验2. 熟悉 Python/Java/Scala 语言的一种或多种编程语言，熟悉 Shell 编程3. 熟悉大数据相关开源框架的原理：包括但不限于 Kafka、Clickhouse等，有 Kafka、Clickhouse集群管理、使用经验4. 有 Flink 应用开发经验优先，了解 HDFS、ElasticSearch 者优先；有 Kubernetes 部署、使用开发经验者优先；了解 c++者优先；5. 具备良好的沟通和团队协作能力，做事主动积极，有技术热情和激情面对挑战
（百度外包）本科及以上学历，计算机、数学、统计学及相关专业。熟练使用SQL，至少熟练使用一门python/java/c++等编程语言。熟悉hadoop，spark等大数据处理相关框架。
teg广告数据平台部，北京新组建团队，各种级别职位都有，机会不容错过。工作内容1、负责持续集成平台开发和维护。2、负责大数据平台运维和工具开发。3、负责研发效率相关平台和工具的开发和维护。任职要求1、至少熟悉一种开发语言，语言不限，Java和Python最优。2、有研发效能和持续集成相关经验优先。3、熟悉大数据技术栈。
岗位职责：1、Hadoop大数据平台架构及组件的优化；2、数据分析平台的开发和优化；3、数据展示系统的开发和优化；4、大数据集群的监控、管理、性能优化；5、数据计算性能瓶颈的定位及优化。这样的你是我们的理想型：1、国家统招本科及以上学历；2、熟练使用C/C++/Java；3、熟练掌握计算机数据结构和算法;4、熟悉Hadoop架构，有大数据、分布式存储及计算等相关经验者优先。
负责进行大数据相关技术整体解决方案
1、开发，设计和落地商业化数据管理平台（DMP），用户数据服务(User Data Service) ；2、负责广告投放中用户画像建设，包括标签管理、人群管理、用户分析等功能；3、负责广告投放中用户行为数据采集，汇总，提供用户数据服务；4、紧密地和跨功能团队合作，工程，数据科学家，数据分析，产品，策略等，理解需求，并能提出自己的想法，高效地沟通，前瞻性的提供和落地技术方案；5、持续地和团队共同维护一个和谐，高效，结果导向的工作氛围。不断地提高自身和团队的技术能力以及标准。
1.负责海量物流数据的数据仓库建设和研究，建设PB级数据仓库，负责数据仓库设计、建模、研发等工作2.负责与业务方进行沟通，完成需求调研和需求挖掘，并进行解决方案级的产品价值设计、规划和输出，规划大数据解决方案，推动团队（如产品经理、研发、运营等）进行方案落地3.帮助进行信息化业务分析、业务建模及技术分析、数据建模，有针对性提出大数据解决方案
了解机器学习，文本挖掘等，能够对海量数据挖掘提炼核心结果了解大数据处理比如hive.sql.spark等相关数据提取工具熟悉图论，了解图数据库等相关
设计良好的代码结构，不断迭代重构
需要去银行驻场！需要去银行驻场！负责公司大数据应用产品的开发学习并研究大数据技术、最新动向以满足产品、项目的迭代需求负责公司大数据平台相关功能模块的设计、开发等工作岗位要求计算机/软件相关专业，本科及以上学历精于Java、Python、Scala语言中的一种或者多种熟悉linux操作系统，掌握基本的shell编程技能熟悉HDFS、Hive、Hbase熟悉SparkStreaming、Flink、Storm等至少一种开源实时计算框架，了解其原理和机制熟练掌握Kafka熟悉Solr、ElasticSearch、ClickHouse、MongoDB等分布式存储框架优先有Docker、k8s等容器使用经验优先工作积极主动，认真负责，具备团队合作精神对大数据有浓厚兴趣有智慧医疗相关经验者优先
实习岗位1.从事大数据系统架构设计开发2.开发智慧政务，智慧医疗，智慧公安，智慧养老，智慧军营等系统
负责集团数据计算平台建设负责公共平台的研发
岗位职责：1、负责大数据场景下数据应用的建设。 2、负责微博视频业务的数据挖掘和探索，帮助业务成功。 3、大数据新技术探索,技术攻坚。任职要求： 1、具备扎实的Java开发能力。良好的工程素养，优秀的编码能力。 2、具备中大型系统架构设计的实际经验和能力，且具备一定的深度。 3、熟悉Hadoop、Hive、Spark、Storm，Flink，Hbase，Kafka 等大数据技术体系中的一种或多种技术，对某个技术方向有独到深入的见解，有开源项目代码贡献者优先。 4、具备线上系统性能优化经验，生产系统快速 trouble-shooting 的能力，擅长分析更接近本质的原因。 5、良好的人际沟通和团队协作能力，有责任心。 6、追求极致自驱，对解决挑战性的问题充满激情。7、大学本科及以上学历
团队介绍-负责阿里巴巴高德地图产品公共交通核心系统/模块研发-深入理解业务，主导架构设计及核心开发工作，推动技术不断升级，解决系统问题-负责业务系统设计、实现和线上代码调优职位描述-3年以上Java研发经验，熟悉Java技术架构、并发编程、JVM-具有大型Web系统的开发经验，精通B/S架构开发-精通spring，hibernate，ibatis等常用开发框架-精通算法设计/数据结构，有系统分析和设计的项目经验-精通linux操作系统，熟练使用shell语言编写脚本-熟练掌握MySql、Oracle等数据库，熟练掌握sql语言-有强烈的上进心和求知欲，善于学习新事物-有很强的分析问题和解决问题的能力，追求技术创新并有践行经验者优先职位类型  技术-地图-业务平台工作地点  北京  工作年限要求  三年以上
岗位要求：能够通过数据分析栈（如Gauss数据库存储过程，Clickhouse, ETL, Hadoop等）对数据进行提取、清洗、加工，形成数字化报告支撑业务分析。1、掌握MySQL, Oracle主流数据库，并能熟练进行存储过程开发，API接口开发；且精通主流SQL查询语言，能熟练的对SQL进行调优；2、熟悉大数据分析技术栈：Hadoop、Flink、Hbase等，并能够针对业务场景进行实际应用；3、熟悉机器学习各种分类算法，聚类算法，深度学习和NLP自然语言处理等。专业知识要求：1、软件工程，计算机，应用统计，数学，大数据技术等相关专业；2、至少掌握一种编程语言工具：Python、Java、SQL；大数据处理框架：Hadoop、Storm、Spark
岗位职责1、负责大数据系统建设（采集，同步，建模，监控，权限）等2、负责大数据业务开发，包括ETL开发和相关技术问题3、产业链平台以及知识图谱建设任职资格1、本科以上，计算机相关专业，3年以上开发经验2、熟悉java服务端开发3、熟悉Python，shell语言4、熟悉hadoop生态、包括但不限于hive，hbase，flink/spark等组件5、熟悉es、clickhouse等使用和优化经验6、有图数据库相关经验优先
工作职责1、负责数据仓库架构设计、建模和ETL开发，服务于全公司的各个用户产品线； 2、制定和推行全公司的统一数据规范，负责数据质量，元数据的监控，整合； 3、理解并合理抽象不同业务需求，做较通用和系统性的支持。任职资格1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景； 2、具备强悍的编码能力，熟悉hive，spark，kafka，flink, storm中的多项，有至少PB以上级大数据处理经验； 3、对数据敏感，善于从数据中发现疑点，有用户行为分析经验者优先；
职位描述1、负责字节跳动中台业务的数据仓库架构设计、建模和ETL开发；2、参与数据治理工作，提升数据易用性及数据质量，与数据工具团队紧密合作；3、理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；4、总结抽象适用于业务的科学的数据研究方法论，并推进方法论在业务场景的实践。职位要求1、精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；2、具备较强的编码能力，熟悉sql，python，hive，spark，kafka，flink中的多项，有至少TB以上级大数据处理经验；3、熟练掌握批计算相关技术栈，了解流计算相关技术，有HTAP/HSAP相关实践经验优先；4、善于沟通，具备优秀的技术与业务结合能力；5、有中台业务/安全领域数据工作经验优先；6、有较好的业务和数据sense。
"岗位职责：	1. 负责大型智能视频图像处理平台产品的大数据计算、分析相关的研发工作。参与完整数据链路，包括基于视图的聚类技术开发、视图数据ETL开发等；2. 支撑智能视频图像大数据处理平台相关的项目落地工作，包括大数据应用相关的解决方案设计，解决复杂技术问题；任职要求：1. 熟练使用python/java/scala中的一种或多种开发语言；2. 具备分布式大数据处理系统、数据仓库的开发经验及海量数据处理经验者优先；3. 熟悉大数据平台生态圈，包括但不限于flink/spark/kafka/cassandra/clickhouse/nebulagraph/hadoop等第三方组件，以及k8s/docker等容器技术；4. 具备快速学习能力、较强的沟通表达能力、抽象总结能力、跨团队协调能力。善于分析复杂问题，逻辑清晰；5. 自驱力好，善于发现问题和解决问题。"
岗位职责：1 负责苏宁集团视频公司业务（包括PP视频，聚精彩等）数据仓库及数据应用开发工作。2 负责离线和实时计算开发，执行，维护，技术方案设计，技术对接等工作。3 负责推荐系统，搜索系统机器学习算法开发和优化工作。4 对接苏宁科技集团数据平台和管理部门，完成集团技术合规要求的相关工作。职位要求：1. 扎实的数据仓库理论基础，熟悉数据仓库模型设计，应用层建设有实践经验。2. 熟悉掌大数据领域相关技术栈知识，例如：SQL，Hive，Hbase, Hadoop/Spark，SparkStreaming, Flink，8等。3. 掌握数据库开发技术，具备海量数据加工处理（ETL）相关经验，有数据库建模经验，灵活运用SQL实现数据ETL加工处理4. 具备代码开发能力，熟练掌握Java、Scala、Python语言。5. 掌握机器学习算法，数据挖掘知识，基于SparkML实现算法。6. 有互联网行业数据开发经验者优先。
岗位职责1.  负责数据仓库逻辑模型和物理模型设计，对上游数据进清洗、清理、加工、转换、加载至目标数据库。2.  负责数据ETL开发、数据平台建设，解决各种数据库问题。例如：调优、异常处理等。3.  对接相关业务团队进行数据梳理，清洗并协助分析完成务数据化管理的目标。4.  对业务团队进行数据能力输出，并且负责与业务平台进数据对接。岗位要求：1.  计算机、软件相关专业，本科及以上学历。2.  一年以上主流数据上(Mysql、 DB2、 Oracle、 SQL Server等) ETL设计、3.  具备大型数据仓库逻辑模型物理模型设计经验，精通SQL，有较好的SQl性能调优经验。4.  熟悉Hadoop生态圈，精通Hive，Sqoop，熟悉Spark，Hbase开发优先。5.  熟悉Unix/Linux常规命令与工具，至少熟练使用Shell、Python、Perl等 脚本语言之一。6.  至少掌握一种ETL工具(Kettle,DataX,Informatic等)相关经验者优先。7.  了解实时数据库(influxdb等)和图数据库(Neo4j等)的优先。8.  银行项目经验优先。
岗位职责：1、负责离线数仓架构设计及ETL任务开发和维护；2、负责提升基于HIve、Hbase数据存储集群的高可用性、高性能、高扩展特性；3、负责设计和建立基于Flink或Spark实时数据处理框架；4、研究Hadoop/Spark/Hbase/Hive/Flink等开源项目，对线上任务进行调优，并开发通用组件；5、负责数据接口服务的设计及开发；6、负责技术攻关和创新技术引用，开发具有数据分析、数据挖掘能力的创新型产品；任职资格：1、本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业，3年以上大数据相关工作经验；2、熟练使用java、scala、python等开发语言中的一种； 3、有hadoop和spark、hive、flink实际开发经验。了解大数据组件的使用限制和应用场景，如hdfs,yarn,hbase,hive,flume,kafka,zk,impala,kylin,kudu,ES,Storm、MongoDB等。4、熟悉mysql、oracle、ElasticSearch、Redis等关系型或NoSQL数据库，了解应用场景和使用限制；5、熟悉linux操作系统及常用命令；6、熟悉HDFS分布式文件系统架构，熟练掌握Hadoop/Hive/hbase的运维和调优方法； 7、熟练使用过azkaban、airflow、apache dolphin等开源调度工具优先。
大数据开发工程师岗位职责1. 构建基于开源组件的离线/在线分析存储系统；2. 负责大数据平台优化及数据仓库建模、优化；3. 参与数据中台架构搭建，提升业务架构稳定性与可扩展性；4. 负责服务端创新探索，优化代码逻辑，提高其易维护性、稳定性、可用性、吞吐量和效率等。 任职要求1. 有一定的安全大数据业务处理经验，有过一种安全大数据产品开发经验；2. 编程基础扎实，熟悉 Java/Python/Go 等至少一种语言，熟练掌握 Linux 操作系统；3. 了解大数据知识体系，熟悉ETL、调度、数据仓库理论；4. 熟悉hadoop生态系统内常见项目的使用（hdfs、hive、hbase、spark、zookeeper,yarn等），具有MapReduce开发经验，有实际大数据项目经验；5. 掌握HBase、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；6. 拥有良好的编码习惯, 喜欢创新挑战, 自我驱动能力强, 具备良好的沟通能力和团队协作精神。
岗位职责：1.基于业界常用的大数据相关开源组件，包括调度、计算、存储、查询等，构建云原生的大数据平台。 2.提供统一的异构数据源接入集成，数据离线、实时计算，元数据管理和数据服务等全链路智能数据构建与管理的大数据能力，服务于京东物流内部业务和供应链垂直领域的外部商家。 3.持续对大数据系统技术架构进行优化，降低成本，提升系统的性能和用户体验，打造面向未来的批流一体的计算和存储，提升技术影响力。 4.开发商品推荐系统、英文分级系统、统计分析系统，为公司零售平台提供技术保障。 5.完成部门领导交予的其他工作。任职要求：1.计算机、通信、数学等相关专业，具备良好的计算机技术基础。2.熟悉java/python/Scala等至少两种编程语言，具备扎实的数据结构和算法基础。 3.具备良好的沟通和团队协作能力，做事主动积极，有技术激情和激情面对挑战。 4.有相关的大数据任务调度系统使用、调优经验者优先，如Azkaban等。 5.有相关的OLAP引擎使用、调优经验者优先，如Kylin等。 6.熟悉Hbase、HDFS、Yarn、Hive、Spark、Flink、ETL等大数据技术栈。
1. 结合银行对公户交易行为、贷前预审尽调和评级、贷中、贷后预警和全面检查等各场景数据，实现风控相关评分卡、回检、财务监控和预警等业务模型;2. 熟悉企业客户信用风险评价体系，了解传统评级和企业征信和银行外部数据;3. 研发完整的对公客户画像系统和营销获客、信贷产品解决方案，包括离线数据处理、风险标签挖掘、外部数据评级评分、供应链数据挖掘、企业现金流预测、债项违约预估、集团关联谱系挖掘、风险传导等业务模型。   职位要求:   1, 全日制统招本科及以上学历，信息技术相关专业，熟悉常见的数据挖掘和机器学习算法比如LR,RF,GBDT,XGboost等，并能根据业务场景快速完成ETL和模型的加工和服务上线，有较强的算法分析和实现能力;   2,熟悉大数据系统Spark/Hive等数据读取、存储，熟练Java、Scala、Python、Shell中至少两种编程语言;   3, 精通资本市场或者银行对公场景的风控或者营销挖掘模型设计，熟悉wind、中债、企业工商等相应企业信息披露数据加工方式者优先；   4, 5年以上参与过银行等金融机构数据模型加工处理经验，熟悉银行、券商、基金资管行业其中的核心业务者优先;   5,逻辑思维缜密，具备深度思考能力和问题抽象能力，能够快速响应建模需求。
1. 负责大数据相关平台的搭建、开发、维护、优化；2. 负责大数据相关推荐系统/广告系统的研发，相关算法研发；3. 负责数据ETL开发；4. 负责数据处理、数据建模、模型选取与优化、模型验证等工作；5. 负责实现与支持业务部门的数据分析需求。
职位描述1、负责公司主营电商项目数据仓库的开发与优化；2、基于Hive/Flink等平台建设数据仓库，实时数仓建设；3、负责数据模型的设计，etl实施，etl性能优化以及相关技术问题的解决；职位要求1、熟悉大数据相关技术：Kafka/Flink/Hadoop/Druid/HBase/Hive 等；2、熟练使用 Java、Go、Python语言中的一种或者多种；3、具备数据库系统理论知识，掌握主流数据库管理和应用，精通SQL；4、了解统计以及数据挖掘、机器学习、人工智能技术，会使用关联分析、分类预测、聚类分析等常用分析方法；5、有电商行业经验优先。
工作职责: 1. 负责开发大数据工具, 如报表平台/多维度分析工具/ETL平台 2. 负责数据仓库的建设, 数据接入/数据建模/数据服务等工作 3. 负责大数据平台核心问题的攻关, 解决项目中出现的技术难题 任职资格: 1. 重点大学本科及以上学历，具备扎实的计算机专业知识, 极强的问题解决能力 2. 掌握大数据生态技术栈, 具备较丰富的Hadoop/Hbase/Hive/Flink等大数据工具的应用和开发经验 3. 熟悉Linux系统, 具备Java/Python/Scala一种或几种语言开发能力 3. 扎实的SQL功底, 了解不同框架下SQL执行的原理, 熟悉大数据结构化及非结构化分析工具, 有比较丰富的实战经验, 4. 优秀的业务理解能力和良好的沟通协调能力, 有大数据或者数据仓库项目经验优先
岗位职责：1、负责公司安防数据仓库的规划、设计；2、负责大数据基础平台的开发与优化；3、负责大数据相关技术的预研、选型、技术框架设计；4、负责数据的清洗，ETL实施，ETL性能优化。任职要求：1、计算机或相关专业统招本科（或以上）学历，具有3年以上Hadoop生态系统开发、调优经验；2、深入理解大数据平台架构，能够及时发现并解决重大故障以及性能瓶颈；3、精通大数据相关技术：Kafka/Flink/Hadoop/Yarn/HBase/Hive/ElasticSearch 等；4、熟悉java开发语言，能够熟练使用SQL；5、了解统计以及数据挖掘、机器学习、人工智能技术，会使用关联分析、分类预测、聚类分析等常用分析方法；6、具有良好责任心，团队合作意识，具有良好的沟通能力和客户服务意识。 团队缺口人数：2人早九晚六 餐补20/天  转正后享有交补和通讯补助200/150  六险一金 社保公积金全额缴纳可接受出差（差旅报销）
1、参与BOSS直聘数据中台建设、构建：包括数据采集、传输平台，存储、离线/实时计算以及分布式调度系统、高可用高并发的数据服务等一些列大数据生态系统的建设与维护。任职要求:1、专业本科及以上学历，计算机及相关专业2、熟练Linux环境及shell脚本，掌握linux环境下多线程及网络编程,深入理解Hadoop MapReduce、HDFS、Hbase、Hive、Spark、Flink等大数据生态系统中间件原理。3、精通Java语言，具有扎实的面向对象开发经验，熟悉分布式系统和相关性能调优思想； 熟练掌握设计模式包括J2EE、MVC、Spring微服务、Dubbo等； 4、对操作系统、内存管理、存储技术等基础设施有相当的了解；5. 精通数据库体系架构，对于高性能计算、分布式架构、数据同步、数据缓存技术有丰富的经验6、具有丰富的数据开发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验7、业务理解力强，对数据、新技术敏感，对云计算、大数据技术充满热情8、积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神
工作职责：1、负责设计与实现数据仓库；2、确保数据指标完备性和正确性；3、根据具体的业务需求构建业务分析模型，对海量数据进行分析，利用数据分析模型对产品与运营做出指导；4、负责业务建模和数据分析方向前沿技术的调研。岗位要求：1、计算机、数学或其他相关专业，本科及以上学历；2、熟悉Hadoop，有数据仓库的开发经验；3、熟悉Linux开发环境，具有良好的编程基础，掌握C/C++/Java/Python/PHP等至少一门高级编程语言；4、熟悉常用的数据结构和算法，了解各种建模方法，熟悉MySQL等关系型数据库；5、有大数据分析工作经验优先；6、对数据敏感，具有较强的逻辑思维能力和分析解决问题能力；7、具备良好沟通能力和团队合作精神，工作认真细致，责任心强。
1.支持算法模型的特征构建、样本生成等工作，为业务提供高效可靠的数据保障 2.支持业务的统计分析、数据挖掘等相关工作，完成对业务数据的分析并产生洞见  任职要求 1.统招本科及以上学历，计算机或数据相关专业，两年及以上大数据相关工作经验；2.熟悉Linux环境，熟练掌握Python、Java等至少一门常用编程语言； 3.熟悉Hadoop/Hive/Spark/Flink等大数据生态，能对海量数据进行高效分析和处理；能够熟悉运用Hive SQL； 4.有推荐、机器学习、数据挖掘等相关经验者优先 5.责任心强，思维开阔，有良好的团队合作意识
1、负责数据系统开发、上线、维护、完善，完成数据采集、复杂数据清洗、存储等开发工作；2、基于分布式集群环境进行数据加工、汇集、IDMAPPING、处理等工作；3、配合产品同学，了解业务需求，对业务部门的数据分析、加工、处理需求给予实现与支持；4、负责客户营销业务基础数据功能模块开发工作，对数据治理、安全等全生命周期进行跟进，结合市场营销产品和业务需求设计数据分析场景，并形成后台实现方案，提高整个平台的计算能力和效率；5、优化Hadoop yarn/Storm/Spark/Clickhouse等系统参数，实现系统调优，满足行业应用的实时大数据处理需求。
岗位职责1. 数据中台一站式开发平台的设计和研发，涉及数据采集、作业调度、数据质量、元数据管理、指标管理等模块；2. 大数据平台服务组件的搭建和维护，能够持续优化并改进现有的技术框架，保证高可用、稳定、低延迟的优质服务体验；3. 设计和研发AI训练框架和工具体系，提高算法开发优化效率。岗位要求1. 具备大数据项目开发经验或数据中台产品研发经验；2. 掌握Hadoop、Spark、Hive、Flink、Kafka、ES等主流的大数据技术；熟练掌握Java，有Scala或Python语言开发经验；有数据采集、作业调度、监控告警、数据治理等设计和开发经验的优先。3. 擅于沟通和解决问题，乐于总结分享，有想法，有冲劲，有团队精神和主人翁意识和责任感。
"职位描述：    负责图计算平台实时数据产品化技术建设，技术难点攻坚以及平台研发工作。岗位要求：1.	计算机相关专业本科及以上学历，5年以上互联网行业研发经验；2.	熟练掌握开发语言java，熟悉scala，c++，python一种或多种。3.	熟练掌握大数据hadoop，hbase，hive，spark，flink等技术的使用及原理，有实时大数据相关落地经验。4.	责任心强，很强自驱能力和独立解决问题的能力，良好的沟通能力和团队合作意识。5.   熟悉图计算，图数据库graphx，gelly，janusgraph，nebulagrpah等相关技术者优先"
工作职责1、负责公司各条业务线数据仓库设计建模、报表开发、数据分析；2、与产品运营团队配合，参与公司用户精细化运营，广告归因、用户画像、人群包、反作弊、流量分级等开发；3、数据平台建设、数据资产管理、工具框架开发;任职要求1、熟悉主流大数据开发组件（包括但不限于Hive、Hadoop、Spark、HBase、Druid、ES、Kafka、Flume等）；2、熟练掌握Scala、Java、Python、Shell等语言2种以上；3、有在线广告、地理信息、用户画像相关经验优先，1年以上开发经验；4、本科及以上，计算机及数学相关专业，良好的数学基础和英语功底，要求看懂英文文献，文档书写能力扎实；
1.为系统的AI、BI功能提供大数据技术开发支持；2.负责大数据离线计算功能设计与开发；3.负责大数据实时/准实时计算功能设计与开发；4.负责图数据库的构建与计算功能设计与开发。 任职要求：1. 计算机、数学相关专业本科及以上学历，原则上年龄不超过33周岁；2. 熟悉Hadoop、Hive、Spark、Elasticsearch等大数据技术，具有相关使用和开发经验；3. 掌握Flink、Neo4j、JanusGraph、TigerGraph、GraphX等相关技术；4. 具备优秀的数据敏感性，对大数据处理和分析技术有丰富的经验和强烈热情；5. 优秀的分析问题和解决问题的能力，勇于解决难题；强烈的上进心和求知欲，较强的沟通表达能力与协作推进能力；6. 有银行风险业务背景知识者优先，有开源社区贡献经验的开发者优先。
工作内容包括但不限于：海量数据的离线以及实时数据流处理，大型作业的优化。要求如下：1. 精通java开发语言2. 熟悉Hadoop生态3. 精通spark, flink或者其他计算处理引擎，有源码级别的优化者优先4. 参与过广告， 信息流推荐，或者画像相关开发经验者优先5. 工作有热情，有责任心，执着于高质量的交付
（重点：能接受出差）岗位职责：1、根据业务需求研发大数据程序及业务团队框架管理2、解决大数据组件常见问题3、与大数据相关的周边服务和工作岗位要求：1、熟悉linux, 会shell和java编程, 会python 或scala 编程。2、熟悉大数据生态圈相关组件(hadoop、spark、hbase、hive、kafka、storm，cdh, elk)等。3、熟悉常见数据结构和算法，计算机基础知识扎实。4、思维敏捷，有独立分析和解决问题的能力; 有团队精神和表达沟通能力。5、8年以上大数据技术工作经验。
工作职责:1参与公司级统一的大数据平台研发，服务于公司所有业务线2参与一站式的实时计算平台的设计与研发3对平台各基础服务进行优化迭代，提升系统稳定性和性能任职资格:1计算机相关专业本科以上学历，、2年以上相关工作经验；2了解大数据基本原理，做过spark,kafka或者flink, druid, clickhouse等类似大数据系统项目3有较强的Java编码能力，理解IO、多线程等基础框架，熟悉linux环境
岗位职责1.负责大数据平台实时数据集成、清洗、加工及业务逻辑的设计与开发。2.负责对实时大数据平台性能和稳定性进行优化。3.参与实时计算平台的架构设计、开发、运维等工作。4.参与公司大数据处理方向的技术拓展。任职资格1.三年以上java开发经验，两年以上基于Hadoop/Kafka/Spark/Flink等应用开发经验。2.熟悉Hadoop技术体系，对分布式计算有较为深刻的理解。3.熟悉Java/Scala，熟练掌握离线/实时计算以及数据分析相关的开发。4.熟悉Linux/Unix，熟悉Python/Shell等脚本语言开发。5.勤奋好学，踏实肯干，良好的沟通能力和团队精神6.本科以上学历(必须)，计算机及相关专业。
大数据工程师职位要求 1. 本科以及以上学历， 5年以上大数据平台开发经验。2. 熟悉Linux系统，有大数据基础知识、大数据平台以及工具的知识3. 熟悉Hadoop、zookpeer、kafka、Hbase、spark等大数据工具的使用，并且在参与的实际案例中使用过4. 熟悉mysql5. 熟练使用python、Java、scala等语言6. 就个人参与过的大数据相关项目、使用过大数据相关工具的项目，能从架构、工具、逻辑上分析清楚。
岗位职责：1、负责规划和研究现有结构化和非结构化数据，探索数据在实际业务中的应用；2、基于现有海量数据，建立数据挖掘及数据治理体系；3、负责大数据基础平台建设方案的设计和技术选型；4、基于Hadoop、Spark等平台，实现算法的工程落地及迭代优化。任职要求：1、有成功数据分析经历的优先，掌握机器学习、数据分析相关算法；2、精通Java、C/C++、Python、Matlab之一；3、对分布式系统原理有较深的理解，熟悉hadoop，hbase，kafka，es，kudu，dubbo，spark等技术；4、学习能力强，对技术有追求，具备良好的沟通和协作能力；5、特别优秀的可放宽要求。
工作内容：1、负责流程行业大数据云平台的系统搭建；2、负责大数据的采集、存储及加工；3、负责数据服务的开发。任职要求：1、计算机、软件工程、应用数学相关专业背景，3年以上工作经验；2、精通Oracle、Mysql、HBase等数据库，掌握SQL语言；3、精通Hadoop、Hive、Spark、flink等大数据平台/工具，有相关实践经验；4、熟悉常见的数据模型，有较好的开发习惯和编程规范；5、有Java或Python开发经验，会使用常用的开发框架；6、有报表、BI等相关开发经验优先；7、工作认真负责有责任心，有很强的主动学习能力、理解能力，有大数据项目经验者优先。
工作职责：1.负责Flink,Spark数据开发。2.负责大数据平台开发及Ambari+HDP平台二次开发。3.负责大数据平台容器化部署运维和优化。职位要求1.计算机及相关专业，熟练掌握一种或多种语言Scala,Java,Python等2.具有3年以上大数据开发经验，有数据开发，集群运维经验。3.熟悉Ambari+HDP部署及二次开发，了解Docker,kubernetes优先。4.熟悉Hadoop生态组件，包括但不限于Flink,Spark,Hadoop,Hive,Hbase,Elasticsearch等。5.有Flink实时数仓建设经验和数据仓库模型设计经验，有Flink+数据湖经验更佳。6.参与或主导过数据中台的建设，有大数据平台开发经验，熟悉数据中台原理，7.分析问题逻辑清晰，善于解决疑难问题，有较好的抗压能力。
职位描述（985/211优先考虑）：1. 负责数据仓库搭建、推荐系统等开发工作;2. 参与大数据平台的设计与开发，解决海量数据面临的挑战；3. 协助组内同学建立数据模型，对数据进行挖掘、优化及统计。4. 负责数据处理流程和算法的优化，选择合理的算法提升推荐效果5. 参与需求沟通、架构设计、产品方案沟通、代码review等关键的团队工作;优先考虑：1、熟悉数据结构,熟悉数据挖掘和机器学习算法等常用算法,并对机器学习算法和理论有较深入的研究（如对熟悉决策树、聚类、逻辑回归，序列标注,关联分析、SVM，贝叶斯等数据挖掘算法有较深理解和实践经验）；2、熟悉文本挖掘分析方法及分布式数据分析工具使用；任职资格：1.国家211重点大学本科生及以上学历2. 5-10年及以上互联网系统或者其他企业应用系统开发相关经验，3.其中要有3年以上数据仓库或推荐系统的实际开发经验；4. 精通Hadoop/HBase/Spark/flink/Hive/impal/kudu；5. 具备Java、scala开发经验，编程基础扎实，6. 熟练使用spring boot, spark core,spark sql,flink 等框架编程；7. 数据控，善于发现问题、解决问题,具备良好的分析和解决问题的能力，具备一定的钻研精神和持续学习的意愿，强烈的责任感和团队感，对负有挑战性的工作充满热情。
岗位职责：1、参与建设/维护基于Hadoop/Spark生态的大数据离线/实时处理平台；2、参与大数据平台业务日志数据的抽取、转储、清洗等相关工作；3、参与数据仓库建设、标签开发工作；4、根据项目需求使用SQL完成数仓表数据处理工作；5、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景；任职要求：1、3年以上大数据处理经验，有实时处理数据项目交付经验者加分；2、熟悉大数据开源技术，包含（不限于）Hadoop/Spark/Hive/Hbase/Flume/Kafka等相关技术,并有一定的Hadoop生态系统维护经验；3、掌握Java或Scala一种开发语言，掌握SQL、SparkSQL数据开发，有较好的SQL性能调优经验；4、优秀的分析、解决问题能力，充分的数据敏感度，有一定的高性能支撑经验和故障排除能力；5、具备强烈的工作责任感，喜欢钻研，态度乐观，团队意识强；
岗位职责:（1）基于数据平台，完成数据采集、复杂数据清洗、存储等开发工作；（2）基于数据进行数据建模统计查询以及数据报表分析；（3）精通sql，对业务部门的数据分析需求给予实现与支持；（4）负责应急业务的大数据开发工作，对数据治理全生命周期进行跟进，结合应急业务需求设计数据分析场景，并形成后台实现方案，提高整个平台的计算能力和效率；（5）优化Hadoop yarn/Storm/Spark 参数，实现系统调优，满足行业应用的实时大数据处理需求；（6）完成领导交办的其他工作。任职条件：（1）大学本科及以上学历，计算机、软件工程、通信工程、自动化等相关专业，条件优秀可适当放宽学历限制；（2）精通计算机原理，熟练掌握Java/scala/python等开发语言，熟悉常用设计模式；（3）精通离线数据分析，熟练掌握Hadoop、Hive、flume、SparkCore、SparkSql、Sqoop、Azkaban等技术并具有相关项目经验；（4）精通SQL语法，并具备SQL分析调优能力；（5）熟悉实时数据计算，熟练掌握Kafka、SparkStreaming/Flink、Kudu、Impala、Hbase等技术框架；（6）熟悉shell/python等脚本语言；熟悉flink开发以及对scala有深度理解，有实时数仓经验者优先。
· 参与技术体系的规划建设，包括采集平台、数据质量及监控系统，大数据产品平台等建设；· 整合业务场景、业务流程对于数据的需求，响应业务需求，设计、开发、优化、迭代、维护大数据平台，构建统一的数据系统；任职要求：· 本科以上学历，计算机相关专业，有大型互联网公司相关经验者优先；· 精通 Java / Python / Scala 其中的一种或几种编程语言；·  对大数据平台的构建和实现机制有深刻的理解，有大数据平台运维和开发经验；·  熟悉数据仓库产品，理解数据仓库的概念和原理，对数据处理、维度建模等有深刻认识和实战经验，如Hadoop/Hive，Storm/Spark，Impala，MPP等的数据应用开发；· 具备扎实的数据结构及算法功底，精通设计模式、设计原则、面向对象编程开发，精通可扩展分布式编程经验，优秀的工程实现能力，良好代码编写习惯；· 具备较强的逻辑思维能力，很强的学习、分析问题能力，良好的团队意识和协作精神，有技术热情和好奇心，愿意学习接触新技术
【学历】         本科及以上【招聘岗位】         大数据开发/设计工程师        【工作地点】         北京、西安、南京        【岗位职责】负责大数据平台系统的需求分析、方案设计、特性开发、自动构建（CI/DI）、版本测试、维护等工作1、构筑领先业界一代的智能化、高吞吐、高弹性的实时流计算、离线批计算框架2、实现一站式的数据编排平台，将集成、流、批、策略、AI、模型驱动开发整合；增强数据治理能力，构筑运营商数据中台。3、构建统一的数据访问层，通过实现标准SQL的JDBC驱动，构筑数据分析开放生态4、开发大数据云服务，满足企业混合云和边缘计算场景下的数据应用需求。【专业知识要求】1、  熟悉C/C++、JAVA、Python、JS中的至少一种，掌握常见的数据结构、算法，了解软件工程、敏捷开发等知识，熟悉常用设计模式；2、  熟悉大数据开发框架，熟悉Hadoop/Spark/Hbase/MPP DB及业界主流流处理平台如Storm/Flink/Spark Streaming之一;3、  了解SOA、微服务、中间件等PaaS相关的关键理念与技术，并对其有广泛的实践与应用经验者优先。
职责：1.负责建设、维护、优化基于Hadoop生态技术的大数据集群和计算框架；2.通过提供平台化的计算框架，支撑海量数据分析、数据挖掘、机器学习工作；3.负责数据产品平台的设计、开发；4.关注开源技术动态，预研、评测大数据生态新技术，引进新的技术框架，满足业务需求并不断提高工作效率及质量；岗位要求:1. 计算机、信息系统、数学或相近专业本科以上学历，4年以上大数据研发经验；2. 精通java/scala，精通Hadoop生态并有实战经验，包括但不限于hadoop/flink/hive/spark/impala/hbase/kafka等；3. 有大规模集群维护经验，能够快速处理hadoop或spark等相关技术栈的问题；4. 熟悉大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化，能够设计、开发平台化数据产品；5. 有优秀的业务理解能力，对数据敏感，对金融风控有较深入的认识；6. 有关键技术攻关的决心和能力，能够适应和享受高压力的工作；7. 有OLAP产品开发经验优先。
【字节跳动】大数据研发实习生-商业化技术-北京（无转正，应届慎重投递）职位描述1、负责公司广告大数据的离线和实时数据流；2、为公司广告策略产品提供大数据存储、分析、计算支持。3、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；4、构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值；职位要求1、计算机相关专业，至少熟练Python，Java，C/C++等语言的一种；2、使用过Hadoop/Storm/Spark/Hive/Kafka等分布式开源项目的优先；3、使用过ES/Druid/Superset等开源产品的优先；请按照“数仓实习+学校年级+姓名+实习时长+每周可出勤天数”格式为简历标题
"岗位职责：	1、整合公司全域海量数据，建设公司核心中台数据资产。	2、通过数仓模型、实时\离线数据开发、数据服务等方式建设全站的数据能力，以数据+产品的方式提供丰富、稳定的数据服务赋能业务，探索数据本身的增量价值。	3、深入理解业务场景，了解业务痛点，为各业务线提供数据驱动解决方案。岗位要求：	1、有较为丰富的数据仓库研发经验，熟悉数据仓库、数据体系和数据价值的建设及优化；。	2、熟悉大数据架构，具备实时或离线数据研发能力，熟悉Hive，Kafka，Spark，Storm，Hbase，Flink等相关技术并有相关开发经验；	3、具备快速学习能力、跨团队沟通协作能力，有较强的逻辑思维能力和解决问题能力；    4、本科及以上学历，3年以上数据研发经验，有AWS或阿里云等云平台使用经验者优先，有数据质量管理，元数据管理等数据治理实施经验者优先，有游戏行业背景优先"
帮团队在北京招聘一个高级大数据工程师，对标公司25级，除了技术要求，还需要候选人有良好的英语口语和书面沟通能力，可以和同事用英语无障碍交流。具体要求如下： Have experience working in Big data system (Spark/Hadoop/Hive)• Have experience with Java/Scala and Python• Have experience and passion in business support or issue handling.• Strong in problem solving with team spirit, passionate for unlocking the power into business• Have basic knowledge of SQL, database and Linux shell• Good communication skills. Have ability to synthesize information and tracking work with documentation• Have experience with predicative modeling, data mining and analytical tool is a big plus.• Work effectively and independently in a remote report line across different time zones.Basic Qualifications• Bachelor’s degree in computer science/engineering or quantitative field with 5+ year professional work experience. Or Master’s degree in an engineering or quantitative field with 3+ year professional work experience• Fluent in English, both written and oral.
大数据开发   1-3年 15-30K*14【上班地点】：东三环 十号线团结湖/六号线呼家楼 （靠近三里屯）【上班时间】：10：00-7:00 弹性上班 不打卡（避开早晚高峰），双休【福利待遇】：年14薪，足额七险一金， 年假10+n，每月带薪病假一天不累计（无需提供医院证明），免费提供午餐、晚餐、零食、水果、饮料等 ， 年度免费体检，家人可享受团购价，定期团建和周年庆活动、滑雪、篮球、羽毛球等兴趣小组活动 ，贴心的节假日活动和礼品 。【岗位描述】1、负责大数据服务平台接口的迭代开发，构建离线&实时的数据仓库平台2、基于hadoop、spark、hive、hbase、flink等开源技术构建解决方案满足业务方需求3、负责公司级的Hadoop集群日常维护和扩容升级工作，服务于公司各个业务线；4、构建设计良好的数据仓库、调度系统、查询引擎，数据服务、分析系统等，保证系统稳定高效运行，以实现数据的最大价值。  【我们期望】1、具有分布式系统架构开发能力。熟练使用flink、spark hbase者优先；2、具有扎实的java编程基础,强悍的编码能力，生产环境快速troubleshooting能力，对新技术有强烈的学习热情；3、对业务和数据敏感，有用户行为分析系统、用户画像系统等相关经验者优先；4、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值。
￼职位详情大数据开发工程师（23应届，急招，外卖）应届-校园招聘北京市、上海市、成都市岗位职责美团拥有涵盖吃喝玩乐住行的全链条大数据，公司非常注重数据价值，数据是美团的核心资产，同时也是下一代新能源，数据的高效管理和价值挖掘是各公司业务发展的基础和保障，公司的核心经营决策、百万外卖小哥的调度、广告、搜索、推荐等用户产品的正常运转等都不离不开数据，数据就像血液一样渗透到美团的方方面面。在本岗位上，你将参与： 1.数据仓库的建设、组织和管理，沉淀数据资产； 2.数据建设过程的各项工具研发，如数据安全、数据质量、数据开发的工具链等；3.数据应用的研发，如商业智能、挖掘、分析报告、数据可视化等；4.其他服务于业务各环节的数据运营工作。任职要求1.计算机、信息技术相关专业本科及以上学历，对数据技术感兴趣；2.熟练掌握至少一种编程语言（包括但不限于Python、Java、C++等），熟练掌握算法数据结构，有编程实践经验；3.掌握数据库基本原理和知识，熟练使用SQL。具备以下经验者优先1.具备相关行业互联网公司核心项目实习经验；2.发表过相关技术方向国际顶会或核心期刊一作论文；3.对大型开源软件项目有核心开发贡献； 4.熟悉大数据技术（Hadoop、Spark、Storm等）。岗位亮点DT时代什么最重要？是数据！在这里，你将成为数据价值的驱动者！ 在这里，你将利用前沿的大数据技术(Hadoop/Hive/NoSQL)，处理PB级数据，并通过数据仓库建模、元数据、数据治理等技术手段使数据的生产适应互联网产品的快速迭代； 在这里，你将与优秀的工程师、产品经理、数据分析师，共同实践数据驱动产品的Growth Hacking； 在这里，你将伴随O2O业务的快速发展，发掘千亿生活服务数据的价值，为广大网民带来更多便利！
岗位职责1、全面主持技术开发团队的各项工作，监控项目进展，协调研发内部相关资源；2、负责参与产品的业务梳理、业务分析，策划解决方案；3、负责与上级指定合理的项目开发任务并指定计划，定期汇报研发情况，协调跨项目资源；4、负责主导项目架构设计、研发与测试、部署、安全策略；任职要求：1、具备3年以上企业应用或者互联网产品的一线开发经验。2、具备扎实的Java编程基础，有多线程开发经验。3、熟练运用mybatis、spring/spring mvc、spring boot开发框架构。4、熟悉微服务架构，具备spring cloud或者dubbo开发经验。5、具备Maven使用经验，可熟练使用Maven构建项目；可熟练使用Git、SVN等版本管理工具。6、.熟练使用Oracle、MySQL进行应用开发、并具备一定数据库调优能力。7、熟悉Redis、monogDB有相关使用经验。8、熟悉至少一种消息中间件kafka、RabbitMq。9、.熟悉Docker生态体系并有实际项目经验者优先，有ElasticSearch使用经验者优先。10、有工业领域软件开发背景优先。
岗位要求：1. 有大数据相关研究经验，包括：机器学习、数学建模、数据分析、数据挖掘、信息检索等；2. 熟悉C/C++/JAVA语言，并至少熟练使用以下语言中的一种：Python/Perl/Shell等编程语言及脚本语言；3. 严谨认真、责任心强，有较强的执行力和团队意识，能与他人进行良好合作；4. 计算机、电子、通信、数学、人工智能等领域本硕及以上学历岗位职责：1. 结合业务数据、行业数据、人群数据等进行建模、数据分析和数据挖掘，设计实现相应算法，能够衡量、预判并评估产品痛点、人群分布、特性趋势变化等； 2. 对用户场景与用户行为进行分析，构建不同人群的行为模型，进行差异化分析，给产品改进提供输入，以提高终端产品质量和用户体验； 3. 研究人工智能算法和前沿理论，构建并持续完善大数据能力。
JAVA后台大数据开发1、负责大数据离线、实时分析处理，为业务提供数据服务及支持工作；2、参与大数据处理系统或应用的设计、开发、维护；岗位要求 1，本科及以上学历，计算机相关专业。2，2年及以上java开发经验。3，熟悉java技术，熟悉JVM、分布式缓存、消息队列、消息中间件、RPC框架、负载均衡等；4，熟悉面向对象和设计模式，熟悉主流开源应用框架，如Spring、MyBatis、SpringMVC等应用框架并熟悉实现原理，掌握Maven、git等代码管理工具；5，熟悉分布式、多线程、高并发及高可用、设计、编码和调优；熟悉常用的网络通信协议原理；6、熟练主流数据库MySql/NoSQL如Redis、MongoDB，具备优秀的数据建模能力和数据库分库分表设计能；7、熟悉HTML、JavaScript、Ajax、CSS、HTML5、ES6、CSS3等web开发技术，掌握主流前端开发框架jquery、vue等；8，有较好的沟通能力，工作责任心，自驱力和主动性，有在一定范围内独立驱动，负责，承担，解决相关问题的强烈意愿和能力。
大数据开发相关工作，有同行业工作经验者优先
岗位职责：1、负责项目有关大数据核心模块的代码开发实现，并按项目管理规范编写相应的技术文档；2、参与并负责大数据相关系统架构的设计、优化及性能的提升，解决关键问题与技术难题；3、为系统的有关大数据功能提供大数据技术开发支持；4、负责大数据离线计算功能设计与开发；5、负责大数据实时/准实时计算功能设计与开发。任职要求：1、        985、211、双一流或世界排名前100海外高校硕士及以上学历，计算机科学、软件工程、数学统计学、金融学等专业；2、        深入理解常用的数据建模理论，可独立把控数据仓库各层级的设计；3、        三年及以上建模开发经验，有财务、供应链、电力生产、投资管理系统相关建模经验的优先；4、        精通阿里云体系，熟悉dataworks/maxcompute/datahub/hologres/flink/kafka/oss开发及调优，熟悉传统和大数据数仓架构，了解关系型数据库，对离线大数据有自己的了解；5、        熟悉其他开源等大数据生态技术栈，具备良好的数据敏感度，具备海量数据开发和调优的能力。
职责描述负责离线数据、实时数仓的建模、开发，用户行为数据的分析；负责公司消息平台的搭建；参与埋点页面结构的梳理，辅助数据埋点工作；负责会员和商城相关业务的数据支持；参与行为数据指标体系好构建数据分析体系的建设；参与分析报表等数据应用开发；岗位要求计算机、数学、统计学相关专业本科及以上学历，3年大数据相关开发经验，其中1年以上大数据数仓相关经验；有医学、教育培训信息化和大数据工作背景，To B工作背景的优先；熟悉大数据相关计算引擎，有2年以上数仓开发设计经验；理解关系型数据库以及文件存储数据库，熟练掌握各类SQL语句；有研发背景，熟悉java、python语言；有优秀的逻辑思维能力，顶层设计何家沟思维，能快速理解业务；深度关注业务，且有意愿探索新技术；
"岗位职责：1.负责大数据系统相关模块的研发工作2.依据业务场景、分析需求提供技术、业务解决方案并加以实现；3.与技术部门对接，解决数据建模、报表和报告在系统开发遇到的问题；任职资格：1.本科及以上学历，计算机、统计学、应用数学等相关专业优先2. 熟悉Hadoop平台,2年以上hive、sqoop开发经验；3.了解BI系统，有数据管理经验，有维度建模相关经验者优先；4.2年以上相关工作经验，有行业分析经验者优先；5.熟悉DB2、Oracle等数据库及sql数据查询，熟悉hadoop者优先；6.熟悉Linux开发环境和shell脚本；7.具备银行项目设计、开发、优化等经验者加分；8.优秀的业务理解能力、逻辑性和沟通能力，能跨部门合作沟通业务背景	华为云Stack服务于全球150+国家和地区，4000+客户：600+政务云、65%中国省级医保、中国5大行、全部12家中国股份制银行、TOP5中国保险机构、全球超过300+金融机构、20个智慧机场、29省高速公路自由流，为政企量身定制云解决方案；	过去，我们连续三年蝉联中国政务云市场与运管平台领军者位置、连续五年位居中国云系统软件以及桌面云市场第一；未来，期待您的加入！"
参与公司数据处理逻辑、数据模型的设计和优化；3年以上的TB级别数据平台开发经验，至少2种分布式计算引擎的实现原理。名校毕业或高学历者优先、有开源社区贡献如 apache Committer 优先、有海量数据处理经验优先。
职位描述：1、负责数据清洗；2、负责大数据平台系统设计和开发；3、负责大数据平台持续集成相关工具平台的架构设计与产品开发等；                         4、参与数据平台的监控、维护与优化；                                                     5、参与项目技术难点攻关以及核心代码的编写；                                                                                                                  6、协助上级完成团队制定其他后端开发任务。任职要求：1、熟练掌握Java开发，1年以上Hadoop/hive相关开发经验；                                                                                           2、对基于Hadoop的大数据处理体系有深入认识，具备相关（MapReduce/hdfs/hive/hbase）项目应用研发经验；     3、掌握flink相关理论及开发技能,有实际项目经验；                                                                 4、熟练掌握sql，能根据需求快速编写sql准确返回结果；                                                                               5、具有良好的沟通及项目协调能力，优秀的分析问题和解决问题的能力，具备强烈的进取心和良好的团队合作精神。
岗位职责：1、负责大数据核心业务组件的开发与维护。2、负责数据处理的设计、实现与优化。任职资格：1、熟练掌握Java、Scala、python中至少一种开发语言。2、精通掌握mysql、oracle等数据库集群。3、具有夯实的数据仓库和元数据构建能力。4、有较强的数据和业务结合能力。5、有较强的独立、主动学习能力、良好的沟通表达能力。6、硕士研究生及以上学历，计算机相关专业。
岗位职责：1、参与大数据业务需求调研、分析、设计2、负责大数据业务的开发建设，包括：数据采集、处理、存储以及挖掘分析的功能实现3、配合项目团队完成系统功能交付；任职要求：1、本科及以上学历，计算机和数学相关专业；2、熟悉Flink开发，熟悉kafka，具备2年以上Flink开发经验；3、熟练掌握Mysql、ES等数据库的使用；4、熟悉逻辑常用算法，有一定建模能力，具有数据分析思维；
工作职责1.负责大数据中台的管理、维护和优化：包括调度系统、计算引擎、资源管理系统等大数据分布式系统的优化以及更新迭代，不断降本增效；负责集群的监控和运维；2.负责多业务数仓的建设：数据管道的调优，数据集成和清洗，以及数据集市的开发，服务多业务日益增长的业务需求，方便数据分析师等同事的使用。3.负责BI服务的维护和优化，与数据分析师、产运团队、算法团队深度合作，满足用户增长、运营、产品等需求，致力于数据赋能业务；4.负责新组件的调研、应用、调优。任职资格1. 有业务思维和良好的沟通能力，力争为业务创造价值。2. 计算机或相关专业一本及以上学历，有过5年以上大数据开发经验。3.掌握数据仓库体系架构、数据建模方法、数据治理等知识；对数据价值探索充满热情，较强的业务理解和抽象能力。4. 熟练使用java、shell、python、hive sql。5. 精通主流大数据和流式数据处理技术，如hadoop、Flink、Storm、Flume、Kafka等大数据计算及运维经验；同时熟悉阿里云和AWS。
健康检查 数据库瘦身 安全策略调，熟悉使用套Oracel，SQL Server，My Sql
岗位职责： 1、参与大数据相关存储系统的开发，负责存储产品和系统相关功能的设计、开发，交付和维护； 2、负责公司大数据存储，对象存储，冷存储等相关系统的设计，开发，上线和维护；3、持续不断优化存储效率，降低成本，提升性能。岗位要求：1、统招本科及以上，1年及以上相关工作经验，精通Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境 ；2、熟悉常用开源分布式系统，熟悉Hadoop HDFS，OZone，熟悉源码者优先 ；3、熟悉存储系统原理，存储介质，压缩算法，列存储格式等技术方向优先；4、具有良好的沟通协作能力，具有较强成本意识和效率意识； 5、对Druid、Kylin、Impala、ElasticSearch等系统（其中一种）有深入使用和底层研究者优先。
需要一本以上学校毕业（学信网可查），计算机相关专业，211以上学校或研究生优先。基本条件：1、有软件开发或数据库技术背景，对技术钻研有浓厚兴趣；2、有较强的自主研发能力和开拓能力，分析解决问题能力强，技术触觉敏锐（最近在研发微服务化的智能运维系统）；3、微服务架构，高并发，负载均衡等企业应用（门类广泛，难以列举全面，跟上社区主流玩法，逻辑清晰最要紧）。4，熟悉Python Tornado、Redis、Nginx、RabbitMQ、Docker-compose等开发技术。5，负责大数据分析项目开发，ETL处理和基本机器学习项目算法等。
岗位职责:1.基于TB级别数据，进行相关大数据应用开发。2.参与开发业务相关的数据接口、通用开放计算平台设计、开发。3.参与金融数据业务的大数据产品架构、设计以及实现。4.结合金融行业特点，优化大数据平台的性能，提高稳定性。任职要求:1、2年以上Hadoop或HBase的Java开发经验，有金融行业开发经验。2、熟悉Hadoop、HBase、Hive、Spark等组件，.熟练掌握Java、Scala、C++中至少一种语言。3、熟悉Lucene，ElastiSearch、solr框架优先。4、有shell、perl开发经验优先。5、熟悉数据仓库，具有相关ETL开发经验优先。
岗位职责：1、对业务数据进行清洗，产出准确稳定的风控数据； 2、根据业务需求对风控数据进行抽象和建模，设计建设风控数仓。 岗位要求： 1、计算机及相关专业，本科及以上学历，3 年及以上工作经验，具有风控反作弊从业经验者优先； 2、熟悉 ETL、Hive、Spark、ES、任务调度等数据处理相关技术，对原理有较为深入的了解，能够根据需求进行合理选型；3、熟悉数仓理论，具备数仓架构设计、模型设计和性能调优能力； 4、良好的沟通能力和团队合作精神。
【岗位职责】1. 能独立完成实时项目的系统分析、设计，并主导完成详细设计和编码的任务，确保项目的进度和质量；2. 参与公司数据平台建设，支持产品、运营数据需求。【任职要求】1. 本科及以上学历，计算机或相关专业；2. 熟悉Linux，精通Java/Scala语言中的一种或多种，熟练应用python、shell；3. 掌握并且熟练应用主流实时计算框架，如Spark、Flink（必备其中一项）；4. 熟悉ETL流程，熟悉大数据领域技术栈，如Hadoop、Hive、Impala，熟悉Dataworks、Maxcompute(加分项）等；5. 有良好的执行能力、学习能力、适应能力，对技术有热情。
岗位职责1. 数据中台一站式开发平台的设计和研发，涉及数据采集、作业调度、数据质量、元数据管理、指标管理等模块；2. 大数据平台服务组件的搭建和维护，能够持续优化并改进现有的技术框架，保证高可用、稳定、低延迟的优质服务体验；3. 设计和研发AI训练框架和工具体系，提高算法开发优化效率。岗位要求1. 具备大数据项目开发经验或数据中台产品研发经验；2. 掌握Hadoop、Spark、Hive、Flink、Kafka、ES等主流的大数据技术；熟练掌握Java，有Scala或Python语言开发经验；有数据采集、作业调度、监控告警、数据治理等设计和开发经验的优先。3. 擅于沟通和解决问题，乐于总结分享，有想法，有冲劲，有团队精神和主人翁意识和责任感。
工作职责1、负责公司各条业务线数据仓库设计建模、报表开发、数据分析；2、与产品运营团队配合，参与公司用户精细化运营，广告归因、用户画像、人群包、反作弊、流量分级等开发；3、数据平台建设、数据资产管理、工具框架开发;任职要求1、熟悉主流大数据开发组件（包括但不限于Hive、Hadoop、Spark、HBase、Druid、ES、Kafka、Flume等）；2、熟练掌握Scala、Java、Python、Shell等语言2种以上；3、有在线广告、地理信息、用户画像相关经验优先，1年以上开发经验；4、本科及以上，计算机及数学相关专业，良好的数学基础和英语功底，要求看懂英文文献，文档书写能力扎实；
岗位职责:（1）基于数据平台，完成数据采集、复杂数据清洗、存储等开发工作；（2）基于数据进行数据建模统计查询以及数据报表分析；（3）精通sql，对业务部门的数据分析需求给予实现与支持；（4）负责应急业务的大数据开发工作，对数据治理全生命周期进行跟进，结合应急业务需求设计数据分析场景，并形成后台实现方案，提高整个平台的计算能力和效率；（5）优化Hadoop yarn/Storm/Spark 参数，实现系统调优，满足行业应用的实时大数据处理需求；（6）完成领导交办的其他工作。任职条件：（1）大学本科及以上学历，计算机、软件工程、通信工程、自动化等相关专业，条件优秀可适当放宽学历限制；（2）精通计算机原理，熟练掌握Java/scala/python等开发语言，熟悉常用设计模式；（3）精通离线数据分析，熟练掌握Hadoop、Hive、flume、SparkCore、SparkSql、Sqoop、Azkaban等技术并具有相关项目经验；（4）精通SQL语法，并具备SQL分析调优能力；（5）熟悉实时数据计算，熟练掌握Kafka、SparkStreaming/Flink、Kudu、Impala、Hbase等技术框架；（6）熟悉shell/python等脚本语言；熟悉flink开发以及对scala有深度理解，有实时数仓经验者优先。
· 参与技术体系的规划建设，包括采集平台、数据质量及监控系统，大数据产品平台等建设；· 整合业务场景、业务流程对于数据的需求，响应业务需求，设计、开发、优化、迭代、维护大数据平台，构建统一的数据系统；任职要求：· 本科以上学历，计算机相关专业，有大型互联网公司相关经验者优先；· 精通 Java / Python / Scala 其中的一种或几种编程语言；·  对大数据平台的构建和实现机制有深刻的理解，有大数据平台运维和开发经验；·  熟悉数据仓库产品，理解数据仓库的概念和原理，对数据处理、维度建模等有深刻认识和实战经验，如Hadoop/Hive，Storm/Spark，Impala，MPP等的数据应用开发；· 具备扎实的数据结构及算法功底，精通设计模式、设计原则、面向对象编程开发，精通可扩展分布式编程经验，优秀的工程实现能力，良好代码编写习惯；· 具备较强的逻辑思维能力，很强的学习、分析问题能力，良好的团队意识和协作精神，有技术热情和好奇心，愿意学习接触新技术
【学历】         本科及以上【招聘岗位】         大数据开发/设计工程师        【工作地点】         北京、西安、南京        【岗位职责】负责大数据平台系统的需求分析、方案设计、特性开发、自动构建（CI/DI）、版本测试、维护等工作1、构筑领先业界一代的智能化、高吞吐、高弹性的实时流计算、离线批计算框架2、实现一站式的数据编排平台，将集成、流、批、策略、AI、模型驱动开发整合；增强数据治理能力，构筑运营商数据中台。3、构建统一的数据访问层，通过实现标准SQL的JDBC驱动，构筑数据分析开放生态4、开发大数据云服务，满足企业混合云和边缘计算场景下的数据应用需求。【专业知识要求】1、  熟悉C/C++、JAVA、Python、JS中的至少一种，掌握常见的数据结构、算法，了解软件工程、敏捷开发等知识，熟悉常用设计模式；2、  熟悉大数据开发框架，熟悉Hadoop/Spark/Hbase/MPP DB及业界主流流处理平台如Storm/Flink/Spark Streaming之一;3、  了解SOA、微服务、中间件等PaaS相关的关键理念与技术，并对其有广泛的实践与应用经验者优先。
职责：1.负责建设、维护、优化基于Hadoop生态技术的大数据集群和计算框架；2.通过提供平台化的计算框架，支撑海量数据分析、数据挖掘、机器学习工作；3.负责数据产品平台的设计、开发；4.关注开源技术动态，预研、评测大数据生态新技术，引进新的技术框架，满足业务需求并不断提高工作效率及质量；岗位要求:1. 计算机、信息系统、数学或相近专业本科以上学历，4年以上大数据研发经验；2. 精通java/scala，精通Hadoop生态并有实战经验，包括但不限于hadoop/flink/hive/spark/impala/hbase/kafka等；3. 有大规模集群维护经验，能够快速处理hadoop或spark等相关技术栈的问题；4. 熟悉大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化，能够设计、开发平台化数据产品；5. 有优秀的业务理解能力，对数据敏感，对金融风控有较深入的认识；6. 有关键技术攻关的决心和能力，能够适应和享受高压力的工作；7. 有OLAP产品开发经验优先。
【字节跳动】大数据研发实习生-商业化技术-北京（无转正，应届慎重投递）职位描述1、负责公司广告大数据的离线和实时数据流；2、为公司广告策略产品提供大数据存储、分析、计算支持。3、为大数据的全生命周期提供服务，覆盖数据产生，传输，建模，统计分析，实验评估，可视化的全流程；4、构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具/产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值；职位要求1、计算机相关专业，至少熟练Python，Java，C/C++等语言的一种；2、使用过Hadoop/Storm/Spark/Hive/Kafka等分布式开源项目的优先；3、使用过ES/Druid/Superset等开源产品的优先；请按照“数仓实习+学校年级+姓名+实习时长+每周可出勤天数”格式为简历标题
职位描述：1、负责整车软件数据的汇聚与接入；2、负责整车数据平台数据链路建设和数据开发规范建设；3、建设数据质量体系，形成完整的数据监控和数据校验机制；4、负责相关数据需求的开发，能独立设计方案、把控需求、拆解细化并实施。职位要求：1、熟练运用Python、Java、Scala、Go等至少一门语言，对数据结构和算法设计有较为深刻的理解；2、熟悉MySQL/TiDB/MariaDB等至少一类数据库，熟悉常见的NoSQL存储；3、熟悉Hive数据仓库设计，了解数据仓库模型及思想、维度建模思想；4、丰富的大数据技术经验，熟练掌控至少2种大数据技术，包括不限于Hadoop、HBase、Spark、Kafka、Storm、Flink等；5、具有良好服务意识与数据sence，团队意识和协作精神；6、较强的内外沟通能力，有数仓开发经验者优先。
"岗位职责：	1、整合公司全域海量数据，建设公司核心中台数据资产。	2、通过数仓模型、实时\离线数据开发、数据服务等方式建设全站的数据能力，以数据+产品的方式提供丰富、稳定的数据服务赋能业务，探索数据本身的增量价值。	3、深入理解业务场景，了解业务痛点，为各业务线提供数据驱动解决方案。岗位要求：	1、有较为丰富的数据仓库研发经验，熟悉数据仓库、数据体系和数据价值的建设及优化；。	2、熟悉大数据架构，具备实时或离线数据研发能力，熟悉Hive，Kafka，Spark，Storm，Hbase，Flink等相关技术并有相关开发经验；	3、具备快速学习能力、跨团队沟通协作能力，有较强的逻辑思维能力和解决问题能力；    4、本科及以上学历，3年以上数据研发经验，有AWS或阿里云等云平台使用经验者优先，有数据质量管理，元数据管理等数据治理实施经验者优先，有游戏行业背景优先"
帮团队在北京招聘一个高级大数据工程师，对标公司25级，除了技术要求，还需要候选人有良好的英语口语和书面沟通能力，可以和同事用英语无障碍交流。具体要求如下： Have experience working in Big data system (Spark/Hadoop/Hive)• Have experience with Java/Scala and Python• Have experience and passion in business support or issue handling.• Strong in problem solving with team spirit, passionate for unlocking the power into business• Have basic knowledge of SQL, database and Linux shell• Good communication skills. Have ability to synthesize information and tracking work with documentation• Have experience with predicative modeling, data mining and analytical tool is a big plus.• Work effectively and independently in a remote report line across different time zones.Basic Qualifications• Bachelor’s degree in computer science/engineering or quantitative field with 5+ year professional work experience. Or Master’s degree in an engineering or quantitative field with 3+ year professional work experience• Fluent in English, both written and oral.
大数据开发   1-3年 15-30K*14【上班地点】：东三环 十号线团结湖/六号线呼家楼 （靠近三里屯）【上班时间】：10：00-7:00 弹性上班 不打卡（避开早晚高峰），双休【福利待遇】：年14薪，足额七险一金， 年假10+n，每月带薪病假一天不累计（无需提供医院证明），免费提供午餐、晚餐、零食、水果、饮料等 ， 年度免费体检，家人可享受团购价，定期团建和周年庆活动、滑雪、篮球、羽毛球等兴趣小组活动 ，贴心的节假日活动和礼品 。【岗位描述】1、负责大数据服务平台接口的迭代开发，构建离线&实时的数据仓库平台2、基于hadoop、spark、hive、hbase、flink等开源技术构建解决方案满足业务方需求3、负责公司级的Hadoop集群日常维护和扩容升级工作，服务于公司各个业务线；4、构建设计良好的数据仓库、调度系统、查询引擎，数据服务、分析系统等，保证系统稳定高效运行，以实现数据的最大价值。  【我们期望】1、具有分布式系统架构开发能力。熟练使用flink、spark hbase者优先；2、具有扎实的java编程基础,强悍的编码能力，生产环境快速troubleshooting能力，对新技术有强烈的学习热情；3、对业务和数据敏感，有用户行为分析系统、用户画像系统等相关经验者优先；4、优秀的理解沟通能力，能快速理解业务背景，对数据敏感，崇尚数据说话，深信数据在驱动业务、支撑决策上的价值。
岗位要求：1. 有大数据相关研究经验，包括：机器学习、数学建模、数据分析、数据挖掘、信息检索等；2. 熟悉C/C++/JAVA语言，并至少熟练使用以下语言中的一种：Python/Perl/Shell等编程语言及脚本语言；3. 严谨认真、责任心强，有较强的执行力和团队意识，能与他人进行良好合作；4. 计算机、电子、通信、数学、人工智能等领域本硕及以上学历岗位职责：1. 结合业务数据、行业数据、人群数据等进行建模、数据分析和数据挖掘，设计实现相应算法，能够衡量、预判并评估产品痛点、人群分布、特性趋势变化等； 2. 对用户场景与用户行为进行分析，构建不同人群的行为模型，进行差异化分析，给产品改进提供输入，以提高终端产品质量和用户体验； 3. 研究人工智能算法和前沿理论，构建并持续完善大数据能力。
JAVA后台大数据开发1、负责大数据离线、实时分析处理，为业务提供数据服务及支持工作；2、参与大数据处理系统或应用的设计、开发、维护；岗位要求 1，本科及以上学历，计算机相关专业。2，2年及以上java开发经验。3，熟悉java技术，熟悉JVM、分布式缓存、消息队列、消息中间件、RPC框架、负载均衡等；4，熟悉面向对象和设计模式，熟悉主流开源应用框架，如Spring、MyBatis、SpringMVC等应用框架并熟悉实现原理，掌握Maven、git等代码管理工具；5，熟悉分布式、多线程、高并发及高可用、设计、编码和调优；熟悉常用的网络通信协议原理；6、熟练主流数据库MySql/NoSQL如Redis、MongoDB，具备优秀的数据建模能力和数据库分库分表设计能；7、熟悉HTML、JavaScript、Ajax、CSS、HTML5、ES6、CSS3等web开发技术，掌握主流前端开发框架jquery、vue等；8，有较好的沟通能力，工作责任心，自驱力和主动性，有在一定范围内独立驱动，负责，承担，解决相关问题的强烈意愿和能力。
大数据开发相关工作，有同行业工作经验者优先
岗位职责：1、负责项目有关大数据核心模块的代码开发实现，并按项目管理规范编写相应的技术文档；2、参与并负责大数据相关系统架构的设计、优化及性能的提升，解决关键问题与技术难题；3、为系统的有关大数据功能提供大数据技术开发支持；4、负责大数据离线计算功能设计与开发；5、负责大数据实时/准实时计算功能设计与开发。任职要求：1、        985、211、双一流或世界排名前100海外高校硕士及以上学历，计算机科学、软件工程、数学统计学、金融学等专业；2、        深入理解常用的数据建模理论，可独立把控数据仓库各层级的设计；3、        三年及以上建模开发经验，有财务、供应链、电力生产、投资管理系统相关建模经验的优先；4、        精通阿里云体系，熟悉dataworks/maxcompute/datahub/hologres/flink/kafka/oss开发及调优，熟悉传统和大数据数仓架构，了解关系型数据库，对离线大数据有自己的了解；5、        熟悉其他开源等大数据生态技术栈，具备良好的数据敏感度，具备海量数据开发和调优的能力。
职责描述负责离线数据、实时数仓的建模、开发，用户行为数据的分析；负责公司消息平台的搭建；参与埋点页面结构的梳理，辅助数据埋点工作；负责会员和商城相关业务的数据支持；参与行为数据指标体系好构建数据分析体系的建设；参与分析报表等数据应用开发；岗位要求计算机、数学、统计学相关专业本科及以上学历，3年大数据相关开发经验，其中1年以上大数据数仓相关经验；有医学、教育培训信息化和大数据工作背景，To B工作背景的优先；熟悉大数据相关计算引擎，有2年以上数仓开发设计经验；理解关系型数据库以及文件存储数据库，熟练掌握各类SQL语句；有研发背景，熟悉java、python语言；有优秀的逻辑思维能力，顶层设计何家沟思维，能快速理解业务；深度关注业务，且有意愿探索新技术；
"岗位职责：1.负责大数据系统相关模块的研发工作2.依据业务场景、分析需求提供技术、业务解决方案并加以实现；3.与技术部门对接，解决数据建模、报表和报告在系统开发遇到的问题；任职资格：1.本科及以上学历，计算机、统计学、应用数学等相关专业优先2. 熟悉Hadoop平台,2年以上hive、sqoop开发经验；3.了解BI系统，有数据管理经验，有维度建模相关经验者优先；4.2年以上相关工作经验，有行业分析经验者优先；5.熟悉DB2、Oracle等数据库及sql数据查询，熟悉hadoop者优先；6.熟悉Linux开发环境和shell脚本；7.具备银行项目设计、开发、优化等经验者加分；8.优秀的业务理解能力、逻辑性和沟通能力，能跨部门合作沟通业务背景	华为云Stack服务于全球150+国家和地区，4000+客户：600+政务云、65%中国省级医保、中国5大行、全部12家中国股份制银行、TOP5中国保险机构、全球超过300+金融机构、20个智慧机场、29省高速公路自由流，为政企量身定制云解决方案；	过去，我们连续三年蝉联中国政务云市场与运管平台领军者位置、连续五年位居中国云系统软件以及桌面云市场第一；未来，期待您的加入！"
参与公司数据处理逻辑、数据模型的设计和优化；3年以上的TB级别数据平台开发经验，至少2种分布式计算引擎的实现原理。名校毕业或高学历者优先、有开源社区贡献如 apache Committer 优先、有海量数据处理经验优先。
职位描述：1、负责数据清洗；2、负责大数据平台系统设计和开发；3、负责大数据平台持续集成相关工具平台的架构设计与产品开发等；                         4、参与数据平台的监控、维护与优化；                                                     5、参与项目技术难点攻关以及核心代码的编写；                                                                                                                  6、协助上级完成团队制定其他后端开发任务。任职要求：1、熟练掌握Java开发，1年以上Hadoop/hive相关开发经验；                                                                                           2、对基于Hadoop的大数据处理体系有深入认识，具备相关（MapReduce/hdfs/hive/hbase）项目应用研发经验；     3、掌握flink相关理论及开发技能,有实际项目经验；                                                                 4、熟练掌握sql，能根据需求快速编写sql准确返回结果；                                                                               5、具有良好的沟通及项目协调能力，优秀的分析问题和解决问题的能力，具备强烈的进取心和良好的团队合作精神。
岗位职责：1、Hadoop大数据平台架构及组件的优化；2、数据分析平台和展示系统的开发和优化；3、大数据集群的监控、管理、性能优化；4、数据计算性能瓶颈的定位及优化。[此岗位偏数据内核，负责组件的二次开发，非数仓方向]这样的你是我们的理想型：1、国家统招本科及以上学历；2、熟练使用C/C++/Java；3、熟练掌握计算机数据结构和算法;4、熟悉Hadoop架构，有大数据、分布式存储及计算等相关经验者优先。
岗位职责：1、负责大数据核心业务组件的开发与维护。2、负责数据处理的设计、实现与优化。任职资格：1、熟练掌握Java、Scala、python中至少一种开发语言。2、精通掌握mysql、oracle等数据库集群。3、具有夯实的数据仓库和元数据构建能力。4、有较强的数据和业务结合能力。5、有较强的独立、主动学习能力、良好的沟通表达能力。6、硕士研究生及以上学历，计算机相关专业。
岗位职责：1、参与大数据业务需求调研、分析、设计2、负责大数据业务的开发建设，包括：数据采集、处理、存储以及挖掘分析的功能实现3、配合项目团队完成系统功能交付；任职要求：1、本科及以上学历，计算机和数学相关专业；2、熟悉Flink开发，熟悉kafka，具备2年以上Flink开发经验；3、熟练掌握Mysql、ES等数据库的使用；4、熟悉逻辑常用算法，有一定建模能力，具有数据分析思维；
工作职责1.负责大数据中台的管理、维护和优化：包括调度系统、计算引擎、资源管理系统等大数据分布式系统的优化以及更新迭代，不断降本增效；负责集群的监控和运维；2.负责多业务数仓的建设：数据管道的调优，数据集成和清洗，以及数据集市的开发，服务多业务日益增长的业务需求，方便数据分析师等同事的使用。3.负责BI服务的维护和优化，与数据分析师、产运团队、算法团队深度合作，满足用户增长、运营、产品等需求，致力于数据赋能业务；4.负责新组件的调研、应用、调优。任职资格1. 有业务思维和良好的沟通能力，力争为业务创造价值。2. 计算机或相关专业一本及以上学历，有过5年以上大数据开发经验。3.掌握数据仓库体系架构、数据建模方法、数据治理等知识；对数据价值探索充满热情，较强的业务理解和抽象能力。4. 熟练使用java、shell、python、hive sql。5. 精通主流大数据和流式数据处理技术，如hadoop、Flink、Storm、Flume、Kafka等大数据计算及运维经验；同时熟悉阿里云和AWS。
健康检查 数据库瘦身 安全策略调，熟悉使用套Oracel，SQL Server，My Sql
岗位职责： 1、参与大数据相关存储系统的开发，负责存储产品和系统相关功能的设计、开发，交付和维护； 2、负责公司大数据存储，对象存储，冷存储等相关系统的设计，开发，上线和维护；3、持续不断优化存储效率，降低成本，提升性能。岗位要求：1、统招本科及以上，1年及以上相关工作经验，精通Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境 ；2、熟悉常用开源分布式系统，熟悉Hadoop HDFS，OZone，熟悉源码者优先 ；3、熟悉存储系统原理，存储介质，压缩算法，列存储格式等技术方向优先；4、具有良好的沟通协作能力，具有较强成本意识和效率意识； 5、对Druid、Kylin、Impala、ElasticSearch等系统（其中一种）有深入使用和底层研究者优先。
岗位职责1、负责公司大数据平台相关产品的功能开发、文档撰写和项目改进；2、参与公司相关产品的技术选型、技术调研、大数据平台架构设计以及业务功能设计等；3、负责优化公司大数据产品的模块结构和流程逻辑，能够持续跟进大数据相关技术的发展趋势并能应用于实践；技能要求1、具有两年及以上大数据相关工作经验；2、熟练掌握Java、Scala语言，数据结构和算法等基础扎实，熟练掌握IO、多线程、MQ等技术；3、熟练掌握分布式消息队列Kafka；4、熟练掌握大数据分布式数据处理技术（1-2两种），Flink、Hive、Spark等，并有集群和分布式计算架构设计和实现经验（有Flink开发经验者优先）；5、熟练掌握大数据存储组件（1-2种）：Hive、Hbase、ES等；6、熟练掌握MPP数据库（1-2种）：GaussDB、PostgreSQL、GBase 8a等；7、具备优秀的数据敏感性；8、优秀的分析问题和解决问题能力，勇于解决难题；强烈的上进心和求知欲，较强的沟通表达能力，爱与他人讨论分享；9、对数据治理、数据挖掘、数据中台有一定的理解（加分项）；10、有华为FusionInsight HD大数据产品使用经验者优先；
岗位职责：1、负责大数据平台架构的设计和性能调优，支持海量数据的离线和实时分析，对数据敏感；2、参与大数据平台的搭建与维护，保证数据平台的稳定和可靠；3、保证大规模的离线、实时任务正常的平稳运行；4、设计并完成ETL等大数据处理任务；5、负责数据仓库的设计与开发。岗位要求：1、有大数据处理分析经验，熟悉Spark、Hive、Flink等大数据处理平台；2、熟悉主流开源数据组件，包括但不限于YARN、HBase、ClickHouse、Kafka、Oozie等相关技术；3、熟悉Linux开发环境，熟悉基础命令操作和shell脚本的编写，熟悉大数据平台组件部署思路；4、熟悉java、scala、python等任一开发语言，有3年及以上相关开发经验；5、熟悉大数据平台设计，熟悉OLAP引擎架构设计；6、参与过大型复杂分布式系统的设计与开发者优先。
工作内容:1、负责公司大数据平台的建设;2、基于业务逻辑和业务数据的关系,设计相关数据结构,完成阅读数据模型的落地;3、根据相关数据规范和标准,实现业务底层数据ETL抽取逻辑,实现各项数据指标的计算,并基于相关指标开发监管类和业务类报表;4、负责公司大数据平台的运行维护、性能调优和日常技术支持。任职要求:1.具有扎实的java或python，shell语言基础知识，扎实的数据结构和算法知识，有web后端开发经验；2.熟悉常用开源组件如hadoop，hive，kafka，hbase，flume，spark的使用；3.对大数据处理有热情，对数据质量极致追求，热衷通过更优秀的数据建模和设计来提升数据处理效率；4.熟悉数据仓库，对分布式大数据处理有实践经验的优先；5.有创新思考，有数据分析背景或数据产品开发经验的优先；6.有阿里云大数据平台使用经验优先；
岗位职责：1.   负责数仓基础特征开发2.   负责数据平台相关模块的建设3． 负责大数据基础设施和平台改进，解决生产环境可用性和性能优化问题；4． 参与数据底层的工具、平台和部署流程等研发工作。岗位要求：1.   熟练使用Java 或scala 编程语言1． 熟悉etl架构，有一定的etl开发经验，了解日常作业的部署和调度；2． 较强的数据平台架构设计能力，能够主导分析客户业务需求，进行规划和设计3． 熟悉Hadoop、Hive、Kafka、Spark、Es、Flume等大数据相关技术栈，知晓底层原理和实现4． 精通 SQL，有较好的 SQL 性能调优经验5． 熟悉Linux操作系统及常用命令语句。6． 跨团队沟通能力。有以下经验的优先考虑：1． 有较好的产品意识，沟通能力强的优先考虑2． 阅读过大数据相关组件源码优先考虑
岗位描述1、负责海量数据的分析、抽样以及评估平台的研发2、对每天百亿广告数据、媒体数据进行分析处理，解决广告的推荐、用户画像、垃圾识别等一系列有挑战问题。 【任职要求】1.扎实的算法和数据结构功底，熟练掌握Java、Scala中至少一门编程语言；2.掌握海量数据处理技术，有使用Hadoop/Hive以及Map-Reduce计算模式，能熟练进行ETL处理TB级别数据，有Spark，Kafka，Elasticsearch，Hbase，Clickhouse等分析、存储海量数据的能力和经验。3.对数据仓库有深入了解，熟悉mysql、hive、redis等常用数据库。 4.有Flink开发经验者优先。 5.对分布式存储有较深了解，具有大规模集群高负载高并发工作经验者优先。6.有数据分析经验者优先。
职位描述1、负责离线与实时数据仓库构建；2、负责数据模型的设计，ETL实施，ETL性能优化，ETL数据监控以及相关技术问题的解决；3、深入业务，理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；4、参与大数据应用规划，为数据产品、挖掘团队提供应用指导；5、 参与数据治理工作，提升数据易用性及数据质量。职位要求1、熟悉数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；2、熟悉hadoop，hive，spark，flink，doris等大数据框架，有大规模数据处理经验；3、熟悉Java、Scala、Python、SQL等编程语言，具备较强的编码能力；4、对数据敏感，认真细致，善于从数据中发现疑点，具备优秀的技术与业务结合能力；5、有过支持算法相关的大数据工程问题，了解特征挖掘和机器学习算法优先
岗位职责：1、负责大数据平台ETL任务开发和维护；2、负责BI指标体系建设以及相关报表数据的开发；3、负责数据服务接口的设计及开发；4、负责离线数仓数据模型设计及落地；任职资格：1、本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业，3年及以上大数据平台开发工作经验；2、熟练使用java、scala、python等开发语言中的一种； 3、有hadoop和hive、spark、flink实际开发经验。了解大数据组件的使用限制和应用场景，如hdfs,yarn,hbase,hive,flume,kafka,zk,impala,kylin,kudu,ES,Storm、MongoDB等。4、熟悉mysql、oracle、ElasticSearch、Redis等关系型或NoSQL数据库，了解应用场景和使用限制；5、熟悉linux操作系统及常用命令；6、熟悉HDFS分布式文件系统架构，熟练掌握Hadoop/Hive/hbase的运维和调优方法； 7、熟练使用过azkaban、airflow、dolphinscheduler等开源调度工具。
工作职责:1. 负责数据仓库的设计、开发和优化工作；2. 负责数据平台和数据仓库开发建设，保证数据平台稳定可靠运行；3. 负责数据平台结构化数据和异构数据的规范化和数据清洗、关联、统计；4. 根据业务部门数据分析需求进行数据相关的开发、加工、分析，并持续跟进直至业务目标实现；5. 参与需求调研、分析及梳理任职资格:1. 211本科或以上学历，计算机、软件工程相关专业；2. 两年以上数据仓库领域工作经验，对数据仓库系统架构具有良好的认识，熟悉数据仓库相关技术，如数据建模、ETL、报表开发等；3. 熟悉hivesql、spark，了解Hadoop生态圈，有sql调优经验者优先;4. 具有MySQL等至少一种关系型数据库的开发经验；5. 熟悉Java、Python、scala 其中一种或多种开发语言；6. 具有较强的业务理解能力，具有较强的沟通和解决问题的能力，能承担一定的工作压力；7. 熟练掌握百度系edap、sugar等大数据产品加分
岗位职责1、构建数据分析体系，负责数据的分类汇总、分析研究、有效利用；2、根据业务需求和产品设计，完成相关数据处理、统计及分析工作；3、对项目数据采集、存储、处理及可视化应用等涉及的数据治理流程进行监控管理；4、协助开展业务数据调研、业务流程及数据规范梳理等工作，完成调研分析报告；5、负责数据产品的交付实施；6、运用SQL协助处理项目数据统计需求、支撑项目产品功能数据核对工作。任职要求：1、本科或以上学历（学信网可查），有相关数据处理相关岗位的工作经验，对贴紧业务做分析有浓厚兴趣；2、了解数据分析和处理工具，能够进行海量数据处理和挖掘，熟练使用Python/R等数据工具；3、数据敏感、善于创新、思维敏捷、精力充沛、沟通能力强，具备较强的团队合作精神；4、熟练使用SQL/Hive等语句，具备Hadoop/Spark等海量数据处理经验；5、具备计算机软件、硬件、网络、数据库等知识基础，熟练使用EXCEL、PPT等办公软件；6、熟练使用常见的开源ETL工具，如Kettle等，并对其工作机制有所了解。7、熟悉华为云、阿里云的优先考虑。8、参与B端、G端的项目优先考虑。
【岗位职责】1.负责业务相关的数据需求以及基础数据体系化建设，不限于数仓建设，数据质量，指标体系，数据治理，实时计算，用户画像，线上数据应用开发等；2.基于对客户服务、体验优化相关的理解，开展符合运营侧的拉新、留存、促活等体系的数据模型设计以及报表开发，为提升用户在平台的活跃度及忠诚度提供数据支持。3.设计并实现业务系统数据需求，能够独立完成建模及数据分析，数据线上应用等工作；4.负责离线数据的ETL的实施、清洗、归档、生命周期管理以及运营核心指标的开发工作；5. 跨部门协作，协同分析并解决数据，业务问题，深入数据挖掘和数据分析；6. 负责数据基础工具及数据仓库建设，核心业务指标可视化及监控，制定并实施数据规范；7. 根据海量的数据建立完善的指标体系和数据分析挖掘方法，支撑业务运营需求。 【任职要求】1.计算机相关专业本科以上学历，两年以上互联网数据开发工作经验；2.具备扎实的编程基础，熟悉SQL/Java/scala/Python等两门及以上语言；3.熟悉数据仓库架构及原理，具备大型数据仓库架构设计、模型设计和处理性能调优等相关经验；4.熟悉Linux系统原理、熟练运用Linux命令与脚本5.熟悉Hadoop, Hive，Spark，Flink，Kafka，ElasticSearch、HBase等大数据框架原理及应用；6.善于交流，有良好的团队合作精神和协调沟通能力，有与产品、客户端等多方密切配合的经验和意识。 【优先考虑】1.有互联网数仓开发经验；2.有用户主题数据建设经验；3.具有良好的数据质量管理意识；4.用过用户供给侧数据开发项目经验优先。
工作内容：IC开发流程自动化工具开发：—包括机器数据ETL，业务逻辑开发，前端页面开发IC ML/AI 大数据平台开发：职位要求：熟悉python ，PHP，javascript，HTML等语言有web开发经验是加分项有大数据处理，挖掘经验是加分项有机器学习算法开发经验是加分项
岗位职责：1、参与银行数据类项目的需求调研，对业务需求部门进行数据支持；2、具备系统设计、编码开发能力，具备评审详细设计及查找定位bug的能力；3、能够理解业务需求，编写相应的需求文档并对交付结果负责，保证交付成果质量达标；4、数据映射的编写，ETL开发及数据验证，数据分析类工作。任职资格：1、大学本科以上，计算机或金融类专业优先；3、 熟知数据结构，数据库4、具备模型分析开发能力，如参与数仓中间层/应用层的设计建设5、 熟悉数据库工作原理，具备数据脚本调优能力6、熟练使用linux操作环境7、沟通能力良好，能独立完成需求对接开发
1、参与数据处理引擎开发；2、参与大数据中台的ETL数据处理；3、参与大数据中台的应用开发；4、参与系统自动化运维工具开发；5、参与辅助数据分析的代码开发；6、参与数据质量校验的代码开发；7、参与互联网数据采集的代码开发；技能要求：1、须满1年以上python开发工作经验；2、统招本科及以上学历，有扎实的数学基础和计算机基础；3、熟悉python语言做各种文件处理，例如：CSV文件处理、word文件处理、excel文件处理；4、熟练使用python做数据分析；5、熟练掌握python程序的调试、单元测试，性能分析；6、熟悉oracle数据库优先；7、熟练掌握linux开发环境；熟练操作shell脚本者优先；8、具备高效的理解能力；9、良好的沟通与表达能力、思路清晰，较强的动手能力与逻辑分析能力；10、较强的团队协作精神、优秀的学习能力与创新能力。
岗位职责：1、负责公司安防数据仓库的规划、设计；2、负责大数据基础平台的开发与优化；3、负责大数据相关技术的预研、选型、技术框架设计；4、负责数据的清洗，ETL实施，ETL性能优化。任职要求：1、计算机或相关专业统招本科（或以上）学历，具有3年以上Hadoop生态系统开发、调优经验；2、深入理解大数据平台架构，能够及时发现并解决重大故障以及性能瓶颈；3、精通大数据相关技术：Kafka/Flink/Hadoop/Yarn/HBase/Hive/ElasticSearch 等；4、熟悉java开发语言，能够熟练使用SQL；5、了解统计以及数据挖掘、机器学习、人工智能技术，会使用关联分析、分类预测、聚类分析等常用分析方法；6、具有良好责任心，团队合作意识，具有良好的沟通能力和客户服务意识。 团队缺口人数：2人早九晚六 餐补20/天  转正后享有交补和通讯补助200/150  六险一金 社保公积金全额缴纳可接受出差（差旅报销）
"岗位职责：1.	基于公司数据建设需要，完成数据平台构建、数据内容开发等工作。包括：数据平台基础设施建设、数据采集、ETL、数仓及数据集市、数据应用产品等开发工作；2.	充分理解需求文档，基于此进行自测，交付高质量的开发代码和数据内容；3.	工作中对数据平台基础设施、数据内容建设等工作主动深度思考，提升效能并积极建言、促进组织和系统发展。任职要求：1.	具备BI项目的需求分析和设计能力 2.	理解数据仓库和ETL领域的理论和方法 ，熟悉ETL架构，有一定的ETL开发经验，了解日常作业的部署和调度3.	精通主流ETL工具使用，如：DataStage、kettle、Informatica等；4.	精通Oralce、MySql、Sql Server等至少一种主流数据库的使用，精通 SQL，具有丰富的数据库开发和SQL优化经验；5.	熟练使用linux平台，以及python/shell命令编写，并且熟知docker相关知识；6.	熟悉阿里云base平台开发，并有阿里云平台开发工作经验，能够熟练使用大数据产品，持有ACP证书者优先 ；7.	熟悉大数据平台相关原理，能够进行云平台相关运维工作，保障平台出现问题能够及时处理。"
【职位描述】* 负责大数据中间件产品研发* 负责大数据分析平台软件的研究和开发* 负责数据仓库产品的研究和开发【任职资格】* 计算机科学、应用数学、统计学、经济学、物理学、天文学、商业分析、信息系统、数据科学或相关专业本科或以上学历* 优秀的学习能力与发现、分析并解决问题的能力* 良好的团队合作精神与沟通能力【技能要求】* 具备良好的口头表达能力* JAVA基础扎实，有相关开发或者实习经验，熟悉IO、多线程、MQ、数据结构与设计模式等* 精通Hadoop/Hive/Hbase，对Hadoop、Hive、Storm、Spark等源码有研究者优先* 有分布式监控、搜索、调度、部暑其中一项经验优先* 熟悉分布式、缓存、消息机制，常用的DAL/ORM框架和设计模式【公司介绍】：-麦肯锡和华为惠普联合团队• 由多位前麦肯锡合伙人以及华为惠普核心工程高管联合创立，打造精品管理咨询传承与科技创新品牌• 同时拥有优质咨询项目资源、丰富咨询经验，及数字化赋能的精尖技术能力，建立从咨询建议到产品/解决方案的全面商业服务模式• 约600位咨询顾问、数据科学家、软硬件工程师常驻北京上海和成都-多行业多商业领域覆盖•主要服务于企业客户，通过结合管理咨询、大数据分析、算法建模与工程落地的能力帮助企业客户实现业务增长•行业覆盖消费品、零售、金融、互联网、医疗与媒体等•与多行业领先企业深度合作，建立长期合作关系，如沃尔玛（获沃尔玛年度最佳供应商称号）、欧莱雅、联合利华、中国农业银行、腾讯、京东、美团等-精尖的数据分析/算法/工程师团队• 具备数据清洗与挖掘、算法模型和语义分析方面行业领先技术水平与能力• 具备根据客户业务方向搭建中台/后台的工程技术能力与丰富的项目经验• 具备广受行业认可的成熟产品（含已申请专利技术），帮助客户实现数据驱动的效率提升-富有竞争力的职业发展与薪酬福利保障•注重人才培养，提供定期培训分享及深度参与项目机会，加入团队的年轻小伙伴们再也不用担心自己沦为职场“小螺丝钉”•注重员工成长空间，每年二次全员review，半年即有机会享受升职加薪•注重福利保障，包括：五险一金、全额理赔商业补充医保、超长带薪年假、超长带薪病假、书费报销、打车报销、无限量零食饮料畅吃、国内外团建旅游等
岗位职责：1、数据开发及脚本开发；任职要求：1、2年以上数据开发经验、熟悉sql及类sql数据开发；2、熟练使用Python脚本进行数据处理及完成其他功能，具备shell脚本能力；3、熟悉电商行业、社交平台数据开发及相关分析方法论；4、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力；5、有大数据业务开发经验，熟悉Hadoop、Spark、Flink 等流批数据处理大数据开发产品优先；6、统招本科以上学历，熟悉大数据及云计算产品优先；
1. 从事大数据计算和存储平台的技术方案设计、平台搭建和应用研发协作及持续改进系统性能； 2. 负责AI及网络智能化相关平台大数据架构设计开发； 3. 参与代码评审、设计评审等开发过程相关工作，培养团队新人。职位要求: 学历及专业： 硕士及以上，计算机科学与技术、软件工程、通信工程或其他相关专业 专业技能： 1. 具备5年以上软件平台的研发及架构设计经验，具备良好的行业内技术积累,能独立负责技术架构规划与架构演进； 2. 熟悉开源分布式系统，对 Hadoop/Hive/Spark/Flink/HBase/Druid /kafka中的某项或多项有深入了解及实际的开发经验; 3. 从事过多年的JAVA或者Python开发语言的经验，并且基础知识扎实，理解io、多线程等基础内容及常用的开源框架，可以深入代码一线； 4. 熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制，掌握多线程及高性能的设计与编码及性能调优，有高并发应用开发具备以下经验者优先： 1. 具备5年以上的大数据软件开发和设计经验。 2. 有以下经验者任一可优先: a) 熟悉大数据、网络通信、云计算等领域主要调度系统的架构、算法、实现、以及设计理念，有大型或运营商网管领域项目的开发和架构设计经验者优先。 b) 运营或者参与过开源项目，熟悉开源项目运作，对开源和商业之间的关系以及联动发展有自己深入独到的理解者优先。从事过软件研发架构，有大数据高并发商用系统的开发经验者优先。 c) 具备数据挖掘、机器学习、自然语言处理相关开发经验者优先。
岗位职责：1、参与数据原理研究、处理模型验证、相关数据挖掘算法、统计分析方法、数据处理应用开发工作2、参与数据资源的收集规整、格式转换、交互共享3、参与数据可视化相关开发工作4、协助公司数据服务平台的大数据分析平台建设及运行维护任职资格：1、熟悉常用数据处理编程语言：Python、R等，有一定的代码编程经验2、掌握统计学数学知识，有一定的数据处理、数据分析和挖掘经验项目经验3、熟悉常用文档编辑工具的使用，精通EXCEL4、良好的沟通、学习、团队协作能力5、有民航领域相关工作经验优先6、英文能力较好者优先
1、至少3年以上实时流计算数据开发经验、熟悉Java,Scala，有持续学习新技术能力；2、具备大规模实时计算、大数据平台设计、数据仓库建模能力，有大数据业务应用场景经验的优先；3、深入理解Flink/Blink/Spark/storm/Hadoop/Hive/Clickhouse/等大数据技术框架，并有丰富的开发经验。4、熟悉图计算/Hbase/OSS/OTS/Beam/Yarn/Airflow等技术栈，熟悉基于实时数据的在线预测、累积计算、搜索推荐等应用场景的优先；5、有实际的大数据工程平台建设实践经验者优先；
岗位职责：1、负责理解项目需求、结合业务，参加数仓项目的设计开发；2、负责数仓项目的底层数据结构、数据模型设计，包括主题宽表、多维模型的设计；3、负责数据仓库实时数据统计模块开发及大数据工具类的开发。岗位要求：1、负责大数据接入、存储、分析、监控等系统的开发工作；2、负责Hive、Spark、HBase、Kafka等组件的性能优化工作；3、负责实时工业数据流计算应用程序的开发工作。有数据治理、团队管理经验者优先！
职位描述：1、参与公司大数据项目应用开发与维护，协助完成项目需求的整理与设计工作；2、参与并负责系统架构的优化及性能的提升，解决关键问题与技术难题； 3、及时分析并解决线上系统的各类疑难问题。职位要求：1、全日制统招本科（含）以上学历，计算机或相关专业，6年以上大数据开发相关经验；2、熟悉shell、python、R、Scala等一种以上语言；3、熟悉大数据处理相关技术，包括但不限于Hadoop、Hive、Hbase、Impala、Spark、Kafka、Flume、Storm、Redis、Kylin，数据仓库等，并且有实践经验，能解决应用中的复杂问题；4、熟悉大数据领域的解决方案，具备该领域全面的技术积累，思维清晰敏捷，逻辑分析能力强，有独立软件设计和解决问题能力；6、具备良好的沟通能力、项目控制和协调能力、团队合作能力。
职位职责：1、负责广告数据流 实时数据计算、存储2、针对海量数据处理和查询需求，设计适应业务变化的合理的多维数据分析系统架构，满足多样性的需求。3、海量日志清洗加工，并抽象出可以多业务复用的数据模型。职位要求：1、计算机相关专业本科及以上学历,有扎实的编程语言基础，熟练掌握Java、Scala、Python、Shell2、熟练服务开发（Spring Boot、Spring Cloud、Dubbo服务框架等）3、有Hadoop stack（包括hadoop、hive、spark等）经验者优先4、熟悉spark、flink等大数据处理框架，理解流式处理概念者优5、有大数据查询系统（包括Impala、Kylin、clickhouse等）经验者优先5. 有BI开发（包括Spark SQL、Hive SQL）经验者优先6、有数仓经验者优先。7、善于沟通，工作积极主动，责任心强，具备良好的团队协作能力。8、具备良好的问题分析与解决能力，有较强学习能力和逻辑思维能力。
职位描述1、负责数据管理平台技术架构搭建、设计、开发与维护； 2、负责广告投放中的用户行为日志采集、大数据建模分析、业务系统数据展示工作； 3、为公司运营部门提供数据分析支持。任职要求1、3年以上大数据相关开发经验； 2、熟悉分布式系统的原理，了解常用分布式系统（HDFS，Hbase，Storm，Kafka，yarn，k8s）的设计与架构；3、熟练使用常用大数据框架 MR/streamming/hive/spark/flink； 4、熟练使用golang，java，python中任意一门语言；5、熟悉Linux下开发, 能用shell/python等做常规的数据处理和分析；6、针对业务系统数据需求, 能够设计合理的数据收集, 处理，存储，查询方案。 加分项： 1、有大规模数据收集,日志处理经验； 2、有关系型数据库, 数据建模经验； 3、深入研究过大数据框架的运行机制、实现原理、源码。4、了解常用的OLAP数据引擎，诸如clickhouse，presto，impala等
岗位职责：1. 负责银行业金融客户AI项目系统实施的需求分析和任务开发设计和工程化；2. 负责项目现场客户IT环境的对接、数据需求和数据处理模块的开发、测试、上线交付；3. 负责项目现场AI系统实施过程中各种故障定位和解决落地，能够进行系统调优；4. 负责项目现场AI任务流的工程化、调度、测试、上线、交付文档编写，对系统稳定性负责。任职资格：1. 本科及以上学历，3～5年工作经验，计算机、通信、自动化等信息相关专业；2. 熟悉HDFS/Yarn/Hive的原理和架构，对Hbase/Kafka/Flume等相关技术要有一定的了解；3. 深入掌握Spark内核原理，对PySpark的计算资源和任务执行原理；4. 对数据治理和数据处理要有一定的了解和使用，熟练掌握SQL的开发；5. 熟悉Java，能够熟练使用Shell/Python等脚本语言进行开发；6. 掌握Mysql/Mongo/Redis/Oracle/Neo4j两种以上的使用；7. 思路清晰，自学能力强，能独立分析和解决问题；责任心强，吃苦耐劳，能够接受出差和驻场开发；8. 有如下一项或多项者优先考虑：(1): 有过银行或金融科技工作经验的优先考虑；(2): 有过AI模型和系统交付落地经验的优先考虑；(3): 有AI机器学习知识背景的优先考虑；
1、负责数据中台融合建设，相关系统架构设计，资源环境规划2、负责大规模集群管理，架构优化，资源优化3、负责部分平台接口设计和研发、标准和规范制定任职资格1、专科以及以上学历，计算机相关专业五年以上大数据开发经验2、熟悉主流开源大数据技术，如Hadoop, Spark, Hive,Tez, Presto, Hbase等3、java/ scale编程背景，有丰富的进程间通信/多线程/高迸发等研发经验4、熟悉Linux等底层操作系统，能独立管理快速搭建大数据运行环境5、有大规模集群管理，运维，优化迁移者优先6、参与Apache来源社区技术共建，有源码贡献者优先
工作职责：1、搭建商业化数据处理平台，包含数据规模化计算、系统全链路数据建模&监控&诊断、算法模型生命周期管理。2、推进业务数据的沉淀，构建商业领域数据仓库，提升数据的准确性和可靠性。3、面向业务提供可靠、实时数据能力，包括但不限于特征平台、定向中心、索引更新平台等。任职资格：1、有两年以上的Java或Scala开发经验，编程基础扎实，熟悉常见的面向对象设计模式和常用的开源框架,如SpringBoot等;2、熟悉一种以上大数据计算引擎框架，如spark/hadoop/flink/storm等，理解数据仓库、数据湖等建模方法3、有大型服务框架开发研发经验，高并发、低时延系统设计与研发经验，具备良好的系统分析/构建能力，有稳定性架构经验者优先；4、有商业化业务背景，标签画像/索引更新/特征中心方面经验者优先。
工作职责负责车辆相关数据业务开发工作，不限于数据中台开发、数仓建设等开发方向；负责相关业务的数据应用梳理以及流程优化，完善数据应用系统的建设，为产品迭代提供数据化分析的方法论以及数据能力支撑；工作要求计算机、通信、数学相关专业毕业，大学本科以上学历；熟悉Java，Python、SQL等常用开发语言；了解Hadoop，Spark，Storm，Flink，Kafka，Elasticsearch，Druid等大数据相关平台和组件；扎实的计算机基础及编程能力，熟悉常用算法和设计模式；对数据驱动业务有一定理解，对数据与业务方面有足够的敏感性，有较强的逻辑分析能力，有较强的独立思考能力；具有强烈的责任心以及团队合作精神，具有较强沟通能力，积极向上。
岗位职责：1.参与数据中台建设，承担相关大数据平台研发、架构设计等工作，包括数据采集、传输、存储、处理、分析、治理等环节；2.工作范围涉及大数据开发平台、统一资产治理平台、数据服务平台、元数据中心、数仓建模工具等，探索创新方案和新领域，包括数据湖、流批一体等；3.负责数据中台产品的稳定性、性能、易用性优化；4.负责大数据能力在业务上的落地，推动数据化、服务化。职位要求：1.熟悉Linux系统，熟悉Java/python语言，熟悉常见的数据结构和算法，扎实的编码能力和工程实践能力；2.参与或主导过数据平台建设项目，对数据工作有深刻理解，熟悉数据仓库、数据建模理论，对平台建设有一定的见解和把控能力；3.熟悉常用的大数据技术并有实践经验，如Hadoop\Hive\Spark\Flink\Kafka\Impala\Oozie\Atlas\Elk等，对源码有研究者优先；4.具备TCP/IP网络协议分析能力，熟悉TCP协议相关原理例如：连接建立、拆除、启动、重传等，能够熟练运用Wireshark等工具进行协议分析，例如：ARP、HTTP、DNS等；5.有自研平台经验者优先，包括但不限于离线开发平台、数据质量中心、元数据管理、数据资产管理、日志埋点平台、实时流平台等。6.了解应用层协议识别、DPI原理，有过网络流量分析实战经验优先。
【寻找优秀的你】觉得自己的潜力没有被挖掘？想要拥有无限的发展空间？希望通过自己的努力取得进步、获得高薪？寻找一个释放光彩的机会？千易云教育，为你提供实现梦想的平台，见证你的成长，助你走向人生巅峰！ 岗位职责1. 负责面授课程的教学工作，向学员进行知识的输出，按进度完成教学任务；2. 负责学生自习时间的作业安排，学习成果验收；3. 联动助教、班主任关注、解决班级问题学员；4. 负责教学资源建设（包括教学大纲、教学PPT、教学用书、教学案例、教学视频等）5.​整理开发项目转换为课程6. 关注行业动态，参与学时交流与讨论，根据市场需求优化课程；7. 热爱教师职业，对工作充满热情，责任心强； 任职要求1. 计算机等相关专业，理论基础扎实，有5年以上java开发经验；2. 熟练使用MySQL、Oracle、DB2等一种或以上主流数据库；3.​精通linux操作系统并能进行shell脚本编程3. 具备Linux/Unix环境开发经验，熟悉脚本编程的优先；4. 深入了解大数据相关框架，对以下技术有过应用或相关开发教学经验，至少掌握其中三种，hadoop框架、spark、hbase、hive、scala、flume、kafka、storm、ELK；5. 有大数据培训课程讲师经验者优先；6. 语言表达流畅，有良好的人际沟通能力和学习能力。
一、技能要求1 精通python程序设计，熟悉flask,django等至少一种框架。2 熟悉linux操作系统，熟练使用nginx,git,redis,docker等与开发相关的依赖工具。3 熟悉数据库理论与操作，熟悉mongodb优先。4 熟悉搜索引擎的原理与使用，熟悉elasticsearch优先。5 掌握http协议，熟悉html,dom,xpath正则表达式等常见的数据处理技术。6 有实际爬虫开发实例者优先录用二、任职要求1 应届应聘者，要求第一学历为国内985或211高校计算机、通信、电子、信息、数学专业统招全日制本科或硕士毕业生。2 985.211硕士3 愿意扎实深入业务，深入一线，有较强的沟通协调能力，勇于承担压力和责任，较好的团队合作精神。
1、计算机专业本科及以上学历，学信网可查2、5年以上数据类项目工作经验3、负责数据从业务系统(数据源) 抽取/转换/加载到数据仓库，负责数据仓库的整体搭建及架构设计4、负责数据从仓库到前台报表的展现，负责开发数据个性化展示用户画像、日志抽取系统等数据应用服务5、负责数据治理项目的落地实施，包括数据采集数据治理数据质量及稳定性保障6、有金融保险行业数据项目经验优先
工作地点：北京（不定期出差济南）岗位职责: 1、根据产品和项目需求完成公司数据中台大数据相关技术和功能开发工作；2、负责大数据相关技术与公司产品融合的研究、规划、编制方案、开发落地； 任职要求: 1、本科及以上学历，5年以上大数据开发经验；有过实际大型数仓、数据中台、数据湖等项目或产品的设计与开发经验优先； 2、必须有Flink实时计算开发经验； 3、掌握或了解 kafka \ hbase \ es \ clickhouse等实时数仓相关技术栈； 4、了解Datax \ Sqoop \ Hive\ 调度管理等相关技术栈； 5、工作细致，责任心强；对数据有一定的敏感度。
职位描述 1． 参与实时处理与分析，搭建和维护分布式数据存储平台，保障交易链条等相关数据的准确性与及时性 2． 设计良好的数据流、调度系统、查询引擎，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的最大价值；职位要求 1．计算机、通信、数学、统计相关专业本科及以上学历，大数据存储平台 2 年以上经验或者clickhouse 数据处理一年以上经验2. 熟悉 Python/Java/Scala 语言的一种或多种编程语言，熟悉 Shell 编程3. 熟悉大数据相关开源框架的原理：包括但不限于 Kafka、Clickhouse等，有 Kafka、Clickhouse集群管理、使用经验4. 有 Flink 应用开发经验优先，了解 HDFS、ElasticSearch 者优先；有 Kubernetes 部署、使用开发经验者优先；了解 c++者优先；5. 具备良好的沟通和团队协作能力，做事主动积极，有技术热情和激情面对挑战
负责进行大数据相关技术整体解决方案
职位要求：1、3年大数据开发经验，熟练使用DataWorks、Maxcompute、DI进行数据开发、调度配置、任务发布和运维。2、熟悉mysql、GBase、oracle等关系型数据库，可异构开发sql脚本，精通sql语法、数据类型和函数的使用。3、了解数据分析、维度建模、数据统计相关知识。4、有大数据sql调优经验、国网项目经验优先。工作内容：负责网上国网目前上线的数据产品模型共计9个，其中能效账单、关爱码、能效走访、用电排名、碳效账单、用能分析、银电互动、居家疫情码等8个数据产品业务，用以支撑网上国网部分前端数据展示；行业用电排名产品用以支撑运管平台上业务场景展示。负责网上国网运管报表后端数据库开发、数据运营。
岗位职责：1.负责深度学习系统工具链的开发和优化，实现模型训练、量化、转换、测试的端到端自动化工作流，加速算法从研究到落地的转化；2.负责数据标注平台相关工具开发，包括数据标注、数据管理等软件的后端开发工作，实现大规模的自动化数据标注；3.持续提升深度学习相关组件的使用效率和稳定性，负责相关文档的撰写和更新。任职要求：1.熟悉Node.js, Golang, C++, Java, Rust 其中一种编程语言；2.熟悉常用的架构和设计模式，具备一定的系统软件架构能力；3.具备良好的编程风格习惯、文档撰写能力、团队协作和沟通表达能力。
1.需要出差银川4-7月2.需要能搭建大数据框架及相关技能3.需要对数据治理，数据仓库数据4.需要你热爱技术，能够以客户至上
【工作职责】1、 研发安全运营平台，包含日志收入、数据处理、自动化响应等；2、 负责安全运营平台需求模块设计、接口设计、代码开发及验证；3、 支撑平台在攻防对抗中的应用和迭代；【任职要求】业务技能要求：1、具备良好的计算机、软件工程领域知识，熟悉软件系统设计、开发、测试等研发领域的流程、工程方法和工具；2、良好的学习能力、团队协作性好，沟通协调能力强；3、有研发工具模块设计、接口设计、开发经验优先。专业知识要求：1、熟悉C/C++、JAVA、Python、PHP中的至少一种，掌握常见的数据结构、算法；2、了解软件工程、敏捷开发等知识，熟悉常用设计模式；3、具备云化、服务化等相关知识并能熟练运用。
1.负责业务建模及数据化运营平台的搭建、运维,对业务流程与大数据的结合提出建议和解决方案;2.负责大数据平台架构的整体设计,承担数据抽取、清洗、转化( ETL )等数据处理程序开发;3.负责基于大数据平台项目的开发、实施和维护工作;4.负责解决大数据平台建设过程中的技术难点和性能调优工作;5.负责数据治理、数据统计、数据可视化等方面操作流程和文档的组织管理;任职要求;1、全日制本科及以上学历,5年以上大数据分析工作经验,精通数据模型相关能力2、熟悉 Python / Java / Scala 等相关语言3、熟练掌握 Kylin , Hive 、 Spark 、 Flink 、 RocketMq 、 Redis , mysql 、 SpringBoot 等大数据通用技术栈开发经验,有数据中台、大数据数仓建设经验。4.熟悉常用的数据建模理论,可独立把控数据仓库的各层级设计优先。
大数据开发工程师（知识图谱方向）岗位职责：  1.  参与大数据平台、知识图谱等项目落地过程中的数据治理、数据清洗、数据准备、提升数据质量等开发工作，包括参与数据链路架构、数据存储、数据计算、数据工具的完善和优化工作，解决计算中性能和功能等多方面的各种挑战（例如ETL的性能优化）；以及负责海量数据接入采集、数据质量、数据规范、数据监控、数据降本增效等工作。  2.  负责知识图谱构建中实体和关系的识别、抽取、对齐等开发工作，将业务数据转化为易用的数据资产。3、为项目提供大数据分析任务的方案设计及文档编写的工作。4、与建模人员及应用开发人员协作，支撑数据分析、挖掘工作对于基础数据的加工。将数据分析及开发结果应用到相关业务场景。5、为团队分享相关技术知识，帮助团队提升整体技术水平。 任职要求：  1.  计算机相关专业，全日制大学本科及以上学历，6年以上工作经验，至少参与过5个金融项目的实施。  2.  有大型项目的经验，精通Spark（Spark SQL、Spark GraphX），熟练掌握Hadoop、Hive、Hbase等开源技术；熟悉NoSQL数据库；熟悉Scala、Java等语言，  3.  对数据挖掘、关系网络分析、图表示学习和推理有深入研究或者丰富的项目经验；  4.  熟练Neo4j图数据库，有知识图谱产品或项目经验；有银行零售或对公业务图谱项目经验适当加分；  5.  学习能力强、善于沟通、对技术创新充满激情，善于分析和解决问题，良好的团队合作精神。
工作职责：1、主导AI云服务的亿级别数据建设，包括但不限于分布式存储、数据ETL、数仓建设、数据BI产品等；2、主导新业务和行业的数据商业化探索和数据价值挖掘。任职资格：1、精通分布式存储，熟悉数据仓库产品，对数据处理、维度建模、数据分析等有深刻认识和实战经验，如HBase，ClickHouse，Hadoop/Hive，Storm/Spark，Impala，MPP等的数据应用开发； 2、对大数据平台的构建和实现机制有深刻的理解，有大数据平台运维和开发经验； 3、对大数据、云计算、开源软件、传统数据仓库类产品有一定的深度和广度； 4、有较强的编程能力和编程经验，至少熟悉Java/C++其中一门编程语言，有较强的分布式存储及计算基础和算法工程能力； 5、具备优秀的学习能力，具有较好沟通协调能力，主动建立与业务的紧密合作，推动业务升级；6、985院校毕业优先、硕士学历优先、大厂经验者优先。
工作职责-负责企业数据产品相关数据产品建设-根据业务需求，提供大数据计算应用服务，并持续优化改进-负责大规模海量数据的特征提取、统计计算、数据分析和数据挖掘任职要求-数据相关工作经验5年-熟悉Shell&Hive SQL，熟悉Java、Python，对数据结构和算法设计有较为深刻的理解-熟悉大数据编程技术包括但不限于：Hadoop、Hive、Spark等-熟悉数据仓库理论方法及ETL相关技术，对于数据的架构和设计有一定的思考，具备良好的数学思维和建模思维-熟悉分布式计算框架，掌握分布式计算的设计与优化能力-有强烈的上进心和求知欲，善于学习新事物，有很强的学习、分析和解决问题的能力，良好的团队合作意识，较强的沟通能力
职位描述1.大数据平台数据端需求开发，包括位置大数据、智能感知数据的接入、处理及分析等；2.大数据ETL、计算任务等开发、维护及调优；任职要求1.计算机、数学，电子，通信，软件工程等相关专业，扎实的计算机基础知识，2年以上工作经验；2.熟练使用python、java、c++中至少一门语言；3.熟悉Kafka，Flink，HadoopMR，HBase，ElasticSearch等，有一定的数据分析能力；4.了解实时计算框架及理论Flink/JStorm/Spark Streaming等实时计算框架；5.了解离线计算框架及理论HadoopMR/Spark等批处理计算框架；6.了解数据仓库建设过程以及ETL过程；7.能承受一定的工作压力，有责任心和上进心，能通过持续学习完善自身，有担当，执行力强，乐于分享。
职位描述：【工作职责】：1. 维护部门内数仓，优化存储、计算效率；2. 跟踪业务线数据需求，完成数据ETL、数仓建模、任务调度流程优化；3. 配合分析师完成用户画像、安全画像等业务方向的数据分析工作。【任职要求】：1. 计算机相关专业本科及以上学历，有良好的数据结构、算法基础，熟悉Linux基本操作；2. 熟练掌握Java 语言，了解Shell、Python、PHP以及Golang等常用编程语言，有良好的代码习惯；3. 具备良好的学习能力、分析能力和解决问题的能力；4. 了解大数据相关框架：Hadoop、Hive、Spark、Flink、HBASE、Sqoop、Kafka 等；5. 熟悉机器学习、数据挖掘、数据分析、分布式计算至少某一方面，有较深的理论研究和实践经验优先；6. 有用户画像、业务风控（帐号／互动／资金等）项目经验优先。
岗位职责: 1.负责保险行业数据应用的业务需求沟通及分析，数据类项目方案的设计。2.负责数据应用（报表数据产品）的数据探查，数据分析、数据清洗、标签加工，开发（ETL）。3.数据平台服务需求开发设计，编写设计文档，提交设计评审，开发测试，部署上线以及相应维护工作；4.深入理解保险业务（寿险），善于与客户深入沟通交流，挖掘业务需求。岗位要求：1、2年及以上数据开发经验，了解保险行业相关业务，有实际项目经验2、具备大数据的处理能力，掌握大数据相关的开源组件,如Hadoop、Hbase、Hive、ES、Kafka、Spark等，要求会python3、具有海量数据建模实践经验，有BI架构体系建设经验者优先考虑4、熟练使用sql语句且具备优化能力5、具备良好的沟通能力、逻辑思维能力、团队合作能力
岗位工作职责：1.按需完成各数据主题的数仓搭建，设计和开发对应的数据服务，ETL开发和优化工作2.基于公司业务数据，理解分析需求，建设数据仓库模型，开发数据报表3.优化数仓模型和SQL性能，开展数据治理及数据运维工作，确保数据服务质量4.按照业务需求提取所需数据，满足业务临时看数需要岗位任职要求：1.具有3年以上数据仓库（DW）、商务智能（BI）、大数据等方面的软件或项目开发经验2.精通SQL编程，熟练使用python，熟悉Shell3.熟悉数据仓库理论，有实际搭建公司层级数仓的经验，有数据仓库性能优化的实战经验4.熟悉大数据周边产品，具备Hadoop/Hive/Spark/Flink/Kafka等大数据工具应用和开发经验5.数学、计算机等相关专业，优秀的业务理解能力和良好的沟通协调能力6.能够独立负责相关的模块，有数据治理实践经验者优先
岗位职责：1、负责大数据实时、离线分析处理；2、面向业务目标，从数据模型、数据分布、数据传输、数据存储等方面进行大数据系统的开发；3、负责数据仓库建设、设计、优化和落地；4、负责数据ETL开发、数据平台建设、ETL数据准确性验证及ETL任务的优化；5、数据仓库需求调研和需求分析。任职要求：1、统招本科及以上学历，计算机相关专业；2、熟悉常用开源分布式系统，精通Hadoop/Hive/Spark/Storm/Hbase/Kafka/Flume组件中的至少四个以上；3、参与过完整的数据采集、数据清洗整理、分析和建模等工作；4、有大规模分布式系统开发、维护经验，有故障处理能力，源码级开发能力；5、熟悉Linux开发环境，熟练掌握至少一种编程语言（Java / Python / SHELL / Scala）；6、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题；7、有数据分析工具平台的开发经验者优先；8、具有良好的学习能力、时间和流程意识、沟通协作能力；
岗位职责：负责大数据平台的搭建和研发；负责数据接入和存储，保障数据通道的可靠性、一致性；负责数据平台的大数据基础架构规划、运维保障、数据监控等，为海量数据和业务系统提供可靠的基础设施；参与大数据生态相关技术的前瞻性研究和调研落地，持续扩充大数据能力，优化大数据服务的性能和效率 。参与大数据相关业务的业务建模和开发；岗位要求：全日制正规院校本科及以上学历，计算机、软件、通信、信息等相关专业；3年及以上大数据相关技术背景；熟练进行Java的代码编写，良好的代码编写素养，良好的数据结构算法技能；熟悉Java/Python/Shell等语言，具备良好的编程能力、数据结构算法技能、集群优化改造能力；有数据平台开发经验，包括但不限于离线开发平台、数据质量中心、元数据管理、数据资产管理，实时流平台等；熟悉开源大数据组件如Hadoop、Hive、HBase、Phoenix、ES、Druid.io、Sentry/Ranger、Spark、Flink等，有实际的报表平台、多维度分析工具、ETL平台、调度平台中至少一种工具的实际建设经验；面对开发目标自我驱动及管理能力强，有激情和责任心，优秀的团队沟通和协作能力，以开放性思维，谦逊和积极乐观的态度对待工作和同事；优先条件：有知名互联网公司从业经验者；
1. 掌握数据库领域主流开源技术及行业动态，预研各种大数据框架下数据仓库的最新技术架构和方案，能够运用到现有的业务数据分析中2. 负责公司大数据产品规划,大数据处理分析平台的架构设计3. 公司数据仓库的建模，ETL流程设计和数据仓库的日常开发4. 能够利用内部业务数据和外部数据进行特征工程抽取，对用户进行分层和画像，支持金融风控模型和反欺诈模型岗位要求：1. 正规院校本科及以上学历，软件、计算机、通信、信息安全、网络工程等相关专业；2. 熟悉Linux，熟练使用Java/Python，等语言进行开发（至少熟练掌握一种），有高效、高可靠代码开发经验；3. 熟悉常用数据仓库，如Hive/MySQL等的架构，能够熟练进行ETL开发、SQL优化、集群部署、数据同步等工作；4. 熟悉大数据处理平台，如Hadoop,MapReduce,Hive等，熟悉分布式平台工作原理；
学历： 本科工作经验： 3-5年职位描述：1. 构建基于开源组件的离线/在线分析存储系统；2. 设计并构建安全大数据分析体系；3. 对大数据技术敏感，保持相关领域的钻研，能从海量安全数据中挖掘潜在有价值的信息；4. 负责服务端创新探索，优化代码逻辑，提高其易维护性、稳定性、可用性、吞吐量和效率等。职位要求：1. 有一定的安全大数据业务处理经验，有过一种安全大数据产品开发经验；2. 编程基础扎实，熟悉 Java、Python、Go 等语言，熟练掌握 Linux 操作系统；3. 熟悉Hadoop、Flink、Spark、kafka、kubenetes等常用的大数据处理/分析技术，擅长Flink者优先，并能结合不同的业务场景深入使用；4. 对大数据治理有比较系统的实践，有分布式计算或海量数据应用经验；5. 拥有良好的编码习惯, 喜欢创新挑战, 自我驱动能力强, 具备良好的沟通能力和团队协作精神。
岗位职责：1. 对大数据基础服务进行能力化封装和云化部署；2. 参与数据治理方案设计(元数据、数据标准、数据模型、数据质量、数据安全、数据资产目录等)；3. 参与公司数据治理平台的设计和研发，主导对应的落地实施；4. 持续优化数据治理平台的数据架构和任务流程, 保证系统、任务的性能与稳定性。任职要求：1. 计算机相关专业统招本科或硕士以上学历，三年以上大数据相关开发经验；2. 有责任心，工作热情、踏实、严谨，有团队合作精神，具备较强的动手能力和一定的抗压能力；3. 精通Hadoop生态系统常用组件（Hadoop、Hive、Spark、Hbase、Impala等）并能够独立搭建高可用Hadoop平台；4. 熟悉Flink、SparkStreaming、Storm；5. 精通数据仓库建模, 掌握常用数仓建模方式(如维度建模), 并在实际业务中有所应用；6. 熟悉敏捷开发、DevOps开发过程，具备良好的软件工程素养，熟悉Git等开发、构建、版本控制工具；7. 精通Python语言，熟悉Java语言或Scala语言；8. 熟练使用Linux操作系统，能进行shell脚本编程；9. 有数据治理、数据产品研发或云计算等经验者优先；10.有从事财经金融行业大数据处理经验者优先。
1. 3年以上数据仓库相关工作经验；2. 懂Java开发语言，熟悉Spring、MyBatis等开发框架，具备独立平台开发能力；3. 熟悉hadoop/spark/flink等分布式计算技术(尤其spark)，熟悉其运行机制和体系结构；4. 了解Mysql/ElasticSearch/Presto等存储引擎的数据存储及使用方法，以及不同场景下的olap技术选型；5. 良好的开发习惯、沟通表达能力和跨团队协调能力，乐于寻求挑战和突破自我；6. 懂业务善思考，对数据敏感，有实际数据驱动业务的工作经验。
岗位要求：1、对数据处理、数据建模、数据分析等有深刻认识和实战经验；2、熟悉Hadoop/Spark/Hive等大数据工具；3、精通SQL/HQL，熟悉常用的关系型数据库、非关系性数据库和数据仓库，具有SQL性能优化经验；4、熟悉Linux系统；5、思维敏捷，对新技术敏感，有较强的钻研学习能力；6、有银行数据业务模型者优先。工作内容：1、根据业务进行数据模型分析及数据探查。   2、编写SparkSQL脚本处理报表数据。 3、协助核对报表数据。
1.参与数仓和数据平台开发2.基于现有数据仓库完成报表产出；任职要求：1.本科及以上学历，2年以上大数据相关工作经验；2.熟练掌握SQL、Java、Scala等，基本了解数据结构；3.熟悉大数据生态圈，熟练掌握HDFS、Hive、Spark等,有Flink实操经验更优；5.有地理空间大数据处理经验者优先；6.掌握ClickHouse、PostgreSQL优先；
岗位职责：1. hadoop大数据平台建设、维护；2. hadoop平台下应用设计、开发；3. 根据业务需要进行算法设计及实现。岗位要求：1. 计算机相关专业及统招本科以上学历;2. 部署、调试、优化、验证Hadoop及相关框架。包括hbase、spark、hive、hawq等；3. 熟练使用storm、kafka、sqoop、flume、mysql等框架和产品，熟练java、python编程；4. 熟练spark进行数据处理开发；5. 1年以上相关框架、工具、产品的实际工作经历；6. 有hadoop相关技术、框架的产品研发经验优先。
岗位职责：负责公司大数据相关项目研发工作；任职要求：（数据量非常大，集群PB级别，日增数据几十T，业务需要熟练使用spark）1、统招本科及以上学历，计算机相关专业，3年左右工作经验；2、掌握hadoop、hbase、spark、MR等大数据相关知识，熟练使用spark相关组件；3、熟练使用svn、git等版本控制工具，熟练使用maven等项目管理工具；4、深入理解面向对象编程思想，具备扎实的Java编程基础，良好的编码习惯；5、良好沟通能力和团队协作能力，具有较强的工作责任心，快速学习能力，乐观积极进取。
【大数据开发中级岗位职责】：1.负责数据分析相关系统的设计、开发工作；2.负责数据处理、分析、开发、调优等工作；3.支持业务需求、完成数据的采集、清洗、入库、计算、展示等工作。4.负责参与构建、配合数据仓库构建等方面工作。【职位要求】：1、3年以上hadoop、spark相关生产环境开发工作经验；2、熟悉hadoop、spark、hive、clickhouse原理等，对hadoop、spark等源码有研究者优先；3、了解有相关（HDFS、Hive、Hbase、Sqoop、Spark、Flume、Zookeeper、ES、Kafka、Clickhouse）的运维及开发经验者优先；4、工程能力强，基础扎实，熟悉java、scala、python、shell等其中一种语言；5、对技术有持续追求，强烈的责任心；6、优秀的分析问题和解决问题的能力，对解决挑战性问题充满热情。7、参与大项目工程整体设计流程和实现者优先。8、本科学历以上要求。
大数据开发工程师1、参与数据中台建设、构建：包括数据采集、传输平台，存储、离线/实时计算以及分布式调度系统、高可用高并发的数据服务等一些列大数据生态系统的工程化化的建设与维护。任职要求:1、计算机相关专业本科及以上学历，4年以上工作经验；2、熟练Linux环境及shell脚本，掌握linux环境下多线程及网络编程,深入理解Hadoop MapReduce、HDFS、Hbase、Hive、Spark、Flink等大数据生态系统中间件原理；3、精通Java语言，具有扎实的面向对象开发经验，熟悉分布式系统和相关性能调优思想； 熟练掌握设计模式包括J2EE、MVC、Spring微服务、Dubbo等；4、精通数据库体系架构，对于高性能计算、分布式架构、数据同步、数据缓存技术有丰富的经验；6、具有丰富的数据开发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验。
岗位职责及工作内容：1.负责平台日志的数据治理开发工作；2.负责大数据平台建设方案设计等工作；3.负责公司大数据平台相关功能模块的设计、开发等工作。其他要求：1 本科及以上学历，计算机相关专业，有五年以上的工作经验，三年以上从事大数据开发相关工作经验。2 熟练使用Java、Python、scale语言中的一种或者多种，具有独立开展大数据开发项目的能力。3 熟悉数据结构与算法，有较强的数据建模能力。4 熟悉多项大数据领域的开源框架，如Hadoop、HBase、ES、MPP、Spark、Flink、Flume等，熟悉其中一种或多种框架。5 熟悉数据仓库模型设计，熟悉数据建模理论，熟悉数据挖掘和机器学习等相关算法和技术。6 熟悉分布式基本原理，对高可靠，高并发，高吞吐系统特性有一定理解。7 具有较强的逻辑思维、清晰的沟通表达、项目管理及组织协调能力。
【职位描述】       负责公安行业AI产品的的规划和架构工作，主导系统的架构设计和核心模块开发，确保项目质量和关键性能指标达成；负责面向PB量级的数据查询、数据计算、数据存储以及数据模型与管理的总体架构与优化，提升数据查询的响应效率；负责研发技术发展方向，新技术领域的探索，将新技术应用到项目；参与技术团队建设和学习成长，为团队整体的知识积累，技能提升做贡献；【任职资格】计算机相关专业211本科以上，3年以上大数据开发经验，5年以上技术研发经验；计算机功底扎实，掌握一定的数据结构、算法、技术架构方法；精通大数据技术栈，熟悉大数据处理引擎，例如Hadoop、Storm、Spark、Flink等；三年以上平台产品设计和开发经验，具备优秀的编程能力和良好的开发习惯。熟悉Linux平台上的Java、Scala编程；国内一线互联网公司或企业级服务公司从业者优先;
"岗位职责1、	负责大数据平台、数据中台的研发，满足海量数据的高效管理和分析计算需求；严格遵循产品开发计划，按时提交高质量的代码，完成开发任务；2、负责设计和开发存算新引擎，提供高效的数据查询和处理服务；3、负责跟进大数据组件的新特性，结合业务需求引入并落地，有效提升平台效益；4、负责大数据平台的性能优化、技术故障诊断与处置。任职要求1、本科及以上学历，计算机软件相关专业，具备扎实的计算机科学功底，良好的工程素养，高效的问题解决能力；2、Hadoop及大数据开发经验，熟悉HDFS/YARN/Spark/Hive/Flink/Impala/Kafka等多个组件的内部原理，并具有生产项目的优化经验；熟练掌握Spark/Flink的开发以及HiveSQL/SparkSQL的编写与调优；3、掌握Java/Scala编程语言，熟悉常见的设计模式、数据结构和算法；具有良好的文档编写能力和较强的语言沟通能力；4、熟悉CDH/Ambari等大数据平台，熟悉平台及组件的部署架构；5、熟悉ClickHouse/StarRocks/Kylin/Ozone并具有项目落地经验者优先考虑。"
【工作内容】1、 负责针对银行业务数据需求场景，分析整理数据集市需求，并进行数据集市设计研发；2、 基于数据集市实现报表等数据可视化研发；3、 负责银行数据分析和数据挖掘工作，包括数据模型的需求分析、模型开发和结果分析，为银行提供深入的业务分析服务，根据业务需求进行数据统计、分析，撰写分析报告。4、负责银行相关数据系统项目的数据需求调研、数据分析和数据挖掘模型等相关项目的实施过程。【职位要求】1、具备计算机、数学、统计学、数据挖掘相关专业本科或研究生学历。2、熟悉数据挖掘和数据仓库相关的理论原理，精通挖掘算法，了解最新算法应用，熟悉数据挖掘建模流程，熟练掌握SQL/Hadoop/Hive/Hbase/Spark等大数据工具。 3、具有2年以上数据仓库或大数据挖掘相关工作经验，具备利用数据挖掘技术解决银行客户分析、营销等相关业务问题的经验和能力，熟悉银行业务各种统计指标口径。4、具备良好的客户需求理解能力、良好的沟通和表达能力。
高级大数据开发工程师岗位职责1) 负责基于Spark与Hadoop，进行海量数据模型设计开发；2) 负责分布式数据平台框架下的数据架构设计与开发，以及新数据应用开发；3) 参与大数据平台的基础数据服务接口开发，包括数据提取、分析与结果整理；4) 参与数据分析模型体系构建及数据主题设计和开发职责；任职要求：1) 本科及以上学历，计算机、通信、电子、航空航天等相关专业毕业，从事相关行业三年以上；2) 熟练掌握Java、C++、python等主流开发语言的一种，熟练掌握常用的软件架构模式，并能熟练使用基本的编程编译工具；3) 熟练使用Hadoop分布式平台，能使用Java、Scala或其他语言进行大数据处理；4) 熟悉Hadoop或Spark分布式数据开发技术，熟练掌握数据库技术；5) 熟悉数据分析平台进行设计、开发分布式计算业务以及海量数据系统开发；6) 具备良好的沟通协调能力、团队合作精神以及高度的责任心和良好的工作态度；
岗位职责：1、负责大数据产品开发、数据采集及治理。2、可视化界面集成，性能优化。3、各项文档编写。4、熟悉IPD、CMMI和敏捷开发，落实产品开发计划。任职要求：1.三年以上工作经验，扎实的计算机基础，具备良好的系统分析能力、逻辑思维能力和独立分析解决问题能力；2.精通Java语言、设计模式、面向对象编程思想，熟悉常见框架技术，对多线程、网络编程、事务、反射、IO、锁等有一定理解；3.熟悉分布式开发，有高可用、高并发等开发经验；有相关的运维经验；4.精通spark架构原理和机制，熟悉列式存储组件；熟悉实时开发流程，有相关项目经验者优先考虑；5.主动性强，自学能力强，善于钻研；6.有python语言基础者优先；7.有数据结构、算法相关知识者优先。
任职资格1、熟练掌握linux基本操作和运维管理； 2、熟练运用SQL,熟悉ORACLE、MySQL等主流数据库； 3、熟练运用JAVA、Python、Shel1Shell等语言开发： 4、具备ansible、Jenkins或主流商用运维平台系统的建设维护经验 5、精通大数据生态相关组件（HDFS、HBase、Hive、Spark、Kafka、Flink、ElasticSearch等），具备Hadoop集群维护运营经验 。6、有大数据平台管理和运维经验，熟悉CDH、HDP或CDP其中一种平台。7、有微服务实际项目开发经验优先。岗位职责 1、负责实验室平台系统的需求管理、功能分析工作 2、负责实验室平台系统运维规划、建设及实施工作 3、负责实验室平台日常技术支持4、负责实验室项目数据采集、展示模块开发。5、负责实验室平台数据治理相关组件开发工作。
1. 参与相关产品技术方案研讨； 2. 按照团队分工，进行相关产品的技术选型、技术调研、大数据平台架构设计、API接口设计、平台构建、代码编写等开发工作； 3. 对代码进行自测，保证代码质量； 4. 与其他团队技术对接，跟进问题的处理和反馈； 5. 编写相关产品技术文档； 6. 持续跟进大数据平台技术发展趋势并能应用于实践； 7. 其他相关支持性工作。  任职资格： 1．本科以上（含）学历，计算机相关专业； 2．扎实的编程能力，熟练掌握Java、Python、Scala等语言中的两种及以上，熟练掌握IO、多线程、MQ等相关技术； 3．熟练掌握大数据生态技术组件，如Hadoop、Hive、Hbase、Kafka、Spark、ZooKeeper、Flink、ES等，并有集群和分布式计算架构设计和实现经验； 4．扎实的计算机基础，对数据治理、数据挖掘、数据中台等有一定的理解； 5．具有很强的学习能力、逻辑分析能力，有良好的技术视野，可以作为独立的项目组成员； 6．具有很强的责任心、协同意识、沟通能力、自我驱动力及工作主动性。
承担建设基于Hadoop/Spark生态的大数据离线/实时处理平台构建数据中台的基础设施，实现数据治理和分析挖掘，建设标签体系，用户画像等，支撑数据化运营任职资格：1. 5年以上大型分布式系统研发经验，有分析解决分布式计算或者服务系统性能问题的经验或案例2. 熟悉分布式一致性协议以及数据完整性解决方案3. 编程能力优秀，C/C++/Java/Python/Go语言至少掌握两种以上4. 有人工智能，包括但不限于机器学习、计算机视觉、语音、自然语言处理等领域全球领先企业的工作经验者优先考虑；5. 有大数据平台研发经验者优先考虑6. 有互联网金融领域工作经验的优先考虑7. 热衷于技术创新，对于把人工智能技术应用到实际业务场景产生商业价值具有强烈的热情；8. 自驱主动有担当，具有很好的表达能力和团队合作能力
用工方式：项目聘用/劳务派遣简历接收邮箱：*****岗位职责：1、参与大数据平台产品的设计、研发工作2、参与大数据项目的设计、开发、测试工作岗位要求：1、计算机等相关专业，硕士及以上学历；2、熟练掌握Hadoop、Spark、Hive、Hbase、Solr、ElasticSearch、Kylin、neo4j等大数据技术，具有丰富的大数据开发经验；3、熟练掌握Linux操作系统常用命令、掌握Shell编程；熟练使用Scala，Java中的一种，具备良好的编码习惯； 4、有一定的创新能力，在以往的数据分析、挖掘工作中有自己独特的见解，有数据清洗经验优先； 5、具有较强的逻辑思维能力、数据洞察能力和沟通协调能力，拥有强烈的责任心和团队合作精神；
岗位招聘信息:岗位内容：1、参与公司PB级数据处理框架设计及数据仓库和数据中台建设。2、时空大数据模型算法设计、优化和开发3、基于覆盖全国亿级移动用户的实时数据进行公司自有旅游大数据产品的开发任职要求：1、1-3年相关工作经验，统招本科及以上学历。2、熟悉Linux系统，了解常用的服务器配置及命令行工作3、掌握java或者Scala开发语言。具备以下条件者优先：1、熟悉Hadoop计算框架及核心组件的使用，有spark项目开发经验者。2、有位置数据处理经验者（包括基站位置数据，GPS位置数据）工作环境：1、团队技术氛围浓厚，施行导师制，文旅行业业务专家和时空大数据技术权威传帮带，可快速提高个人专业能力。2、基于覆盖全国10亿级移动用户时空数据及文旅行业核心业务，沉浸式大数据产品开发，并鼓励畅想和创新实践。
大数据应用开发工程师JD工作职责：-负责保险业务日常数据分析工作；-支撑保险数据中台需求的日常迭代和系统升级；-深刻理解现有业务以及负责系统业务难题攻关；职位要求：1.本科及以上学历，计算机相关专业，2年以上大数据处理经验；2.能熟练使用大数据组件，包括但不限于(MapReduce,hive,spark,flink),了解部分原理，有一定的优化性能能力，能处理常见问题；3.能熟练使用其中一种或者几种存储引擎，包括但不限于(mysql,gp,hbase,hdfs),了解部分原理，有一定的性能优化能力;4.掌握常用的数据建模方法,熟练掌握模型分层原理,能独立的搭建数据仓库；5.熟悉java或者python语言,熟练使用spring框架系列；6.精通SQL语句，有一定的SQL性能优化能力；7.具备良好的沟通能力，协调能力、推动能力，思维活跃，学习能力强；8.具备较好的数据质量意识；  大数据平台高级开发工程师JD工作职责：-主要负责业务系统的技术难题攻关和技术架构；-支撑数据中台需求的日常迭代和系统升级；职位要求：1.本科及以上学历，计算机相关专业，3-5年大数据处理经验；2.深入理解包括但不限于（MapReduce,spark家族,hive ,flink）大数据处理原理，能独立的建设数据仓库，具有排查问题和解决问题的能力；3.熟悉包括但不限于（kafka,redis,zk,presto,es,hdfs,gp）使用方法，能应用于业务场景，解决业务问题；4.具备较好的数据结构和算法基础；5.精通java或者python语言；包括但不限于精通spring boot,spring cloud系列,mybatis等；6.具备良好的沟通能力，协调能力、推动能力，思维活跃，学习能力强；7.具备一定的系统技术架构能力，能通过技术解决业务问题；
大数据开发工程师职责：1、负责产品功能底层大数据开发，负责大数据清洗、存储、处理、分析等场景的开发；2、参与软件研发过程中的文档撰写；3、负责和参与公司大数据基础架构平台的运维，保障数据平台服务的稳定性和可用性；4、负责和参与超大规模数据存储与计算任务的精细化设计，选型和开发。 条件：1、计算机以及相关专业，本科及以上学历；2、扎实的算法和数据结构基础；3、熟悉 Java Scala 至少一门编程语言，较强的编码实现能力；熟悉 Python、Perl、Bash shell 脚本语言中的一种；熟悉 HiveQL 以及常用的 UDF；4、掌握 Hadoop、Kafka、Zookeeper、HBase、Spark 中任意3个的运行机制；5、有良好的问题分析及故障排除能力。
岗位职责：1、负责集团级实时/离线/调度等数据计算平台建设；2、负责集团级公共基础数据流、公共平台的研发；3、参与海量数据处理和高性能分布式计算的架构设计，负责数据处理流程的设计和代码开发，撰写相关文档；4、设计及研发PaaS平台的关键组件；5、负责研发资源调度框架、数据库、缓存、存储、检索等相关中间件的二次开发优化工作；6、参与集群运维工作，支持Hadoop集群底座的运维故障分析、解决、性能优化；任职要求：1.本科及以上学历，通信/计算机等相关专业。2、熟悉大数据相关组件二次开发、搭建、应用、优化，如：Hadoop/Spark/Yarn/Hive/Kafka/Hbase/Kerberos/Flink/Mysql等。3、扎实的计算机基础，掌握常用的数据结构及算法，熟练掌握Java/Golang/Scala/Python中的一项或多项；4、愿意承担部分运维职责，熟悉Apache Hadoop部署、性能调优。5、能阅读/理解Hadoop等相关开源组件源码。6、较强的人际关系能力，有团队精神、较强的执行与推动能力，有一定抗压力。
岗位职责：负责数仓建设工作：a)数据清洗：检测数据质量、统一数据标准b)维度建模：数据分层落地，包括离线数仓、实时数仓；c)业务模型：抽象各业务模型，建立信息层；d)数据可视化：BI报表展现；e)接口服务：数据可视化服务接口开发；f)任务调度：常规作业调度和维护；g)业务开发：报表业务、指标统计、邮件报警等以及大数据业务支撑工具的开发；任职要求1.本科及以上学历，计算机相关专业，三年或以上相关工作经验，研究生、985，211院校优先；2.思维活跃，喜欢数据，对数据敏感；3.能够从数据中发现问题，追溯根源。；4.喜欢钻研，对大数据技术有浓厚的兴趣爱好；5.熟练操作CDH集群，了解hadoop生态圈spark技术栈的相关工作原理与机制。6.熟练使用hiveSQL/mysql/HBase /redis/ES等OLAP存储中间件，熟练使用oozie配置任务调度，懂spring boot服务开发，了解VUE前端框架技术，hbase、hive大数据开发,能够熟练使用HUE，自主完成hive支持业务数据需求；7.懂Shell\java；8.有良好的沟通能力，乐于接受挑战，能承受工作压力。
p6-8北京上海杭州三地任选智能风险技术专家团队介绍：我们隶属于蚂蚁集团数字金融线，大部门拥有花呗、余额宝、蚂蚁基金、相互宝等众多海量用户规模和资金体量的国民级金融业务，巨大的系统部署规模和数据体量、频繁的功能变更、错综复杂的资金流、信息流给稳定性保障带来了巨大的挑战，传统加自动化保障方式急需破局。数字金融智能风险团队致力于以大数据和算法驱动的方式保障金融级系统的稳定性，我们需要面对的挑战包括而不限于：面对全面的数据需求如何从JVM字节码等底层角度去探索解决方案、面对业务的海量数据如何做到低延迟高并发、面对复杂的稳定性要求如何定义问题探索解题方案、技术风险全新前沿智能化领域的探索与开创。职位描述:1、进行数字金融业务技术风险行业领域分析和建模，设计搭建核心风险防控系统，守护资金资产安全；2、主导技术风险防控数据分析与设计、算法工程落地工作，承担系统核心功能代码开发，维护系统公用核心模块；3、持续在风险数据智能平台、高可用、资金数据等方面沉淀，并能实际运用到金融业务中。职位要求:1. 计算机、软件工程、电子信息等相关专业背景，3年+工作经验；2. 扎实的java编程基础，熟悉设计模式、Java EE、Spring等相关技术；4. 熟悉分布式、多线程及高性能的设计与编码及性能调优，考虑综合技术成本(开发、运行、维护、可靠性)；3. 熟悉Hadoop，MapReduce等分布式并行处理技术，具备 Storm、Flink、Spark、Kafka、Elastic Search等大数据开发实施经验5. 熟悉至少一种关系型数据库如Oracle、Mysql，具备数据存储优化、查询优化经验和能力；6. 有很强的分析问题和解决问题的能力，有很强的架构设计与优化能力；7. 较强的表达和沟通能力，较强的学习能力，对技术有热情，工作认真、严谨、敬业。有很强的分析问题和解决问题的能力，有强烈的责任心。8. 有创新精神，乐于和热于技术钻研。思维严谨，逻辑清晰，具备批判性思维能力和习惯；9. 特殊说明：结合具体岗位特性，符合如下条件之一的可优先考虑；有经典机器学习、深度学习、自然语言处理或运筹优化等领域算法研发经验；有动态/静态系统（代码）脆弱性分析、健壮性测试、系统性能分析，或对内的渗透测试或业务风险攻击研发经验；有数据、算法产品及运营经验或相关研发经验
国研大数据研究院由国研科技集团全资设立，是在国务院发展研究中心大数据应用研究与指导委员会和宏观决策大数据实验室直接指导下，开展创新型研究和数据增值服务，是中心利用大数据实现研究方式创新的重要平台。研究院以“让决策更早更好”为使命，致力于运用大数据、人工智能等方法开展经济社会行为认知与计算研究，对经济社会运行提供实时预报、监测预警、智能预测和分析研判，为各级政府、企事业单位的决策提供支持服务，不断提升大数据时代决策科学性和精准性。作为推进学科交叉融合和开放合作研究的平台，下设多个研究方向和多条业务线，与政府、企业、高校、科研机构和国际组织开展多领域合作。岗位描述：1. 参与数据仓库架构设计，规范落地，数据主题/模型的建设。2. 负责大数据平台运维开发工作，维护和升级现有技术框架，保障系统稳定性和性能。3. 理解业务逻辑，整合需求，为算法、业务提供系统化、可持续化的数据解决方案。任职条件：1. 统招本科及以上学历，计算机相关专业，3年及以上工作经验。2. 深入理解常用的数仓建模理论，可独立把控数据仓库各层级的设计，有数仓相关设计开发经验者优先。3. 熟练掌握SQL开发，复杂SQL优化，熟练使用mysql等关系型数据库。4. 熟悉Hadoop生态圈架构，掌握Hive、Spark、Flink等大数据开发工具。5. 掌握Linux开发环境，掌握Java，Scala等开发语言中一种或几种，掌握Shell或Python脚本语言，有图数据库开发工作经验优先。6. 具备快速学习能力、沟通协调能力及团队精神，有较强的责任心及学习积极性，善于学习探索新兴大数据技术。(待遇面议）
岗位职责1.负责数据字段整理程序的开发、维护；2.负责电池数据模型的开发、维护；3.参与数据产品的数据治理工作；4.处理日常数据处理及程序开发。任职要求：1.985、211等本科以上学历；2.熟悉常用数据挖掘、机器学习算法，有相关的数据模型开发实践经验；3.精通大数据技术各模块功能，能灵活运用；4.精通Java 或Scala 开发，python语言，深刻理解J2EE规范和相关技术；5.拥有扎实编程能力，熟练掌握常见数据结构，熟练掌握常用框架思想；6.具有良好的人际沟通能力和责任心，思维敏捷、严谨，能够及时发现问题并找出解决方案。
1、大数据基础平台的搭建与优化；2、石油化工行业的工厂数据采集，搭建大数据库，便于技术部门的调取使用；3、研发基于大数据平台的数据仓库平台产品；4、参与大数据平台的容量规划、持续交付、业务监控、应急响应，保证平台正常运行；5、利用大数据相关技术实现对数据的加工、分析、挖掘、处理、及数据可视化等相关工作；6、最好能够独立组建数据库开发的团队，以自己为核心带队承担起公司相关的工作安排；7、熟练使用python。
职位描述：1. 负责产品的需求分析、概要设计，技术文档编写；2. 根据开发进度和任务分配，完成后端系统的设计与开发；3. 参与数据库设计和维护；4. 维护线上系统，使其保持稳定性和可用性。任职要求：1. 统招本科以上学历， 3年以上研发经验；2. 熟练使用Mybatis、Spring Boot、Dubbo、SpringMVC等常用框架；3. 对于多线程并发有一定的掌握和应用经验；4. 熟练使用SQL， 熟悉PostgresSQL、MySQL等主流数据库的应用；5. 熟悉Memcached/Redis；6. 熟悉Flink、scala、ES、HBase、Doris、StarRocks者优先；7. 有责任心，善于沟通，具备一定的抗压能力和良好的学习能力、有较好的团队合作精神。
岗位职责：1、负责公司的各类数据处理任务有数据仓库的使用和架构经验。2、负责配合算法团队，一起开发相应的大数据分析平台。3、负责大数据集群搭建、优化。岗位要求：1、计算机或相关专业本科以上学历,2年以上java开发经验，1年以上大数据工作经验。2、熟悉Linux平台上的开发环境，熟悉常用脚本语言。3、至少掌握一种计算框架Hadoop/Spark等。4、至少掌握一种分布式存储技术HBase/Cassandra等。5、至少掌握一种大数据ETL工具Hive/Spark等。6、善于学习新的知识，对解决具有挑战性问题充满激情。
岗位职责：（1）负责行业应用的计算平台开发与应用； （2）负责行业应用相关的数据接入、采集、加工、清洗、处理程序的开发； （3）参与大数据平台的搭建、开发、维护、优化； （4）对业务部门的数据分析需求给予实现与支持；（5）不断解决规模增长带来的技术和业务问题，构造高度稳定可用的大数据分布式系统，支撑海量数据分析、数据挖掘、机器学习等场景。任职要求：（1）计算机相关专业，本科及以上学历，3年左右Java或Python开发工作经验，学习能力突出；（2）熟悉Linux/Unix系统环境下的操作，熟悉云计算集群环境，了解分布式任务调度，高可用和网络优化；（3）熟悉Hadoop生态系统内常见项目的使用（HDFS、Hive、HBase、Spark、ZooKeeper、yarn等），熟悉使用Python/Java 进行数据聚合清洗，数据分析ETL等的开发经验，熟悉Kafka/EMQ等消息队列和中间件，熟悉API接口开发，有实际大数据项目经验优先； 熟练掌握高性能数据仓库ClickHouse，内存数据库（Ignite）和其他主流数据库（MySQL/Oracle）的操作，包括数据的导出导入，集群同步，SQL的增删改查和各种查询优化等等；（4）能够独立开发设计数据仓库、ETL设计、Cube建模、OLAP开发、报表开发等；一定的应用系统分析与设计能力，有良好、规范的编程习惯和文档编写习惯； （5）熟练Python进行数据处理，网页爬取；（6）有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术、新理论、新开发实践的学习和实践。
岗位职责：1、负责设计研发大数据平台相关产品，包括但不限于实时计算平台，用户行为分析平台等。2、负责实时数据的ETL开发，收集，清洗，计算。3、负责实时数据的数据仓库建设。任职要求：1、java基础扎实,熟悉基于spring的web开发。2、熟悉分布式文件系统hadoop、alluxio等。3、熟悉流式计算引擎flink、spark等。4、熟悉sql大数据组件hive、presto等。5、熟悉消息中间件kafka等。6、精通sql语句，擅长优化hivesql。7、2-4项大数据组件一个或多个即可。8、善于思考,沟通能力强,能主动发现问题,并提出解决方案者佳。
技术要求：1.熟练Python、SQL开发；2.熟练掌握CDH、Hadoop、Hbase、Hive、Spark、Kafka等组件或技术，熟悉复杂数据查询性能调优;3.熟练掌握Spark流批一体的计算框架，具有spark streaming的实时数据处理经验，并有实际项?;4. 熟练使用Dezebium，sqoop等etl工具；5. 精通数据建模并有数据仓库；有数据湖建设、元数据管理等经验优先;6. 具有3年以上的数据开发经验；认证资格要求：通用胜任力素质要求：1. 有扎实的编程能力，思路清晰，善于思考，能独立分析和解决问题；2. 责任心强，具备良好的团队合作精神和抗压能力；
岗位职责：1.基于Hive， Spark，Hadoop的计算架构，进行大数据开发工作；2.在分布式集群上进行Hive和Spark数据开发；3.能够定位数据计算任务的瓶颈并进行性能优化；4.能够针对具体的业务场景，实现一些机器学习运算。任职要求：1.计算机相关本科及以上学历，有强烈的责任心和团队合作精神、具备良好的沟通能力以及快速学习的能力，有独立项目开发经验，优秀应届毕业生可酌情考虑；2.熟悉数据库、数据仓库建模方法论，熟悉数据建模；3.精通SQL语言，至少熟练掌握以下一种大数据开发技能，Hive开发，MR开发，Spark开发；4.有ETL性能调优经验者优先；5.熟练掌握MR、Spark编程模式，有数据计算性能调优经验；
岗位职责:1、负责数据治理、数据建模、数据ETL、中台产品化等核心模块设计与开发；2、参与制定大数据平台、数据中台相关技术规范和使用规范；3、负责数据中台web系统后台的Java支持性开发。任职要求:1. 本科及以上学历，计算机、软件工程、信息通信、数学等相关专业；2. 具有5年以上大数据开发、分析、挖掘等相关工作经验；3. 精通java/python等编程语言，具备离线数仓开发和实时数仓开发能力;4. 熟练掌握Hadoop和Spark、Kafka、CDH;熟练掌握XXL-JOB、DataX；熟练掌握Hive离线数仓、熟练掌握SparkSQL和Flink相关计算引擎；5. 精通大数据组件中的3-5种(Flume、Kafka、Hive、HDFS、spark、Flink、ES、HBase、Kudu、Impala、Azkaban、XXL-JOB、Sqoop、DataX)；6. 有良好的思维逻辑与沟通能力；熟悉数据仓库模型设计方法论，并有实际模型设计及ETL开发经验；7、有负责或参与大数据平台、数据中台产品开发经验者优先；8、具备一定规模团队管理经验，担任过数据平台、数据建模分析等相关数据类项目的项目经理优先；
1.负责行业应用的计算平台开发与应用；2.负责行业应用相关的数据接入、采集、加工、清洗、处理程序的开发；3.参与大数据平台的搭建、开发、维护、优化；4.对业务部门的数据分析需求给予实现与支持；5.不断解决规模增长带来的技术和业务问题，构造高度稳定可用的大数据分布式系统，支撑海量数据分析、数据挖掘、机器学习等场景。1.计算机相关专业，本科及以上学历，三年以上开发经验；2.负责业务线数据仓库基础平台的建设和维护，数据ETL的设计、开发与性能优化3.具备较强的编码能力，对代码风格自我要求严格，熟练掌握Java、Shell、Python等至少其中一门语言4.熟练掌握高性能数据仓库ClickHouse和关系型数据库MySQL的操作5.熟悉大数据的存储/计算相关技术：Hadoop/Hive/Spark/ElasticSearch/HBase/Kafka/Flume/Flink等大数据生态圈常用组件。6.良好的语言沟通与表达能力，自我驱动动力7.能主动发掘业务需求，解决业务问题，提升团队技术影响力8、优秀的学习、分析和解决问题能力，责任心强，具备良好的沟通能力和团队合作精神；9.有实际数据平台项目经验优先
职位职责：1、负责整体大数据平台的建设工作，包括平台搭建、挖掘、治理、服务等；2、负责流式数据的实时传递，清洗，转换，计算，并对外提供查询服务；3、负责相同数据集的批处理功能。职位要求：1、计算机或数学相关专业毕业，有扎实的数据结构和算法基础；2、编程基础扎实，熟练使用至少一种常用的编程语言，包括但不限于C++、Python、Scala、Go、Java；3、有学习热情，关注业界前沿技术。4、有至少2年以上大数据处理经验，或有数据仓库、数据分析的工作经验；5、熟悉数据仓库模型设计 ，掌握常用数据建模方法，具备大数据平台优化经验和能力；6、熟悉大数据处理工具/框架中的一项或多项，包括但不限于Hadoop,Mapreduce,Hive,Spark,Storm,kafka,hbase,canal等，并对其架构有一定的理解；7、精通SQL语言和ETL工具，有hive或sparkSQL开发经验；8、掌握数据仓库理论、数据建模方法、ETL开发相关技术；9、熟悉各类数据分析统计方法，较强的数据推理及分析能力，并具有一定的解决业务问题的实践经验。
岗位职责（工作地点南湖实验室，嘉兴市南湖区七星街道香湖别墅29幢）：1、参与大数据架构的规划设计，参与业务建模及数据化运营平台建设；2、负责数据仓库整体架构，包括元数据管理、ETL调度、OLAP等子系统的设计和开发；3、基于Hadoop和Spark生态进行离线、准实时任务开发、优化、和维护工作；4、负责实时日志采集、数据同步及数据仓库构建，参与大数据平台技术、产品规划；5、负责数据分析和报表产出；6、负责解决大数据平台建设过程中的技术难点和性能调优工作;任职要求：1、本科或以上学历，计算机、数学、通信等相关专业,精通数据仓库和数据挖掘的相关技术，3年以上大数据工作经验；2、熟悉大数据组件及其原理，精通MapReduce设计方法，Strom、Spark计算框架、对NoSQL，Hadoop、Hbase、Hive、Kafaka、Flume等大数据处理相关技术有充分的了解，并且有实践经验，能解决应用中的复杂问题;3、熟悉Kimball、Inmon等主流数据仓库建模方法论，精通数据仓库数据分层架构设计4、精通Java编程，扎实的数据结构及算法功底，熟悉Shell、Python等一种以上语言;5、熟练掌握SQL开发，能对复杂SQL进行优化，有海量数据处理经验者优先6、熟练掌握Airflow,Azkaban,Oozie等至少一个工作流调度系统
岗位职责：【重要：必须是统招全日制公办本科学历，培训机构出来的、毕业年份造假的请勿投递，谢谢】1.负责大数据平台、数据中台项目数据开发和大数据处理模块架构设计、代码开发和数据校验；2.负责数据模型设计、数据采集、数据清洗、数据加工、数据推送、数据分析等开发工作；3.负责大数据平台数据模型设计，包括数据分层、数据域设计、分类、汇总拆分等过程设计；4.负责数据采集、加工、处理、分析工作，能够进行项目数据开发、模型建构和数据处理工作；5.负责优化大数据平台数据模型和ETL性能、调度任务优化，参与数据治理，确保数据质量；6.负责编写相关的设计及开发、测试文档。岗位要求：1.本科及以上学历，3年以上数据架构及数据开发相关经验，具备优秀的数据开发、模型开发能力；2.熟悉主流大数据开发平台，如阿里DataWorks、阿里Dataphin、华为FusionInsight等，熟悉Oracle、MySQL等传统主流数据库，精通SQL及存储过程编写，了解数据挖掘和机器学习等相关算法和技术；3.熟悉开源大数据生态，熟悉Hadoop、Hive、Spark、Hbase、Flink、Kafka等大数据和相关技术；4.熟悉数据中台，数据One Data方法论，熟悉范式、维度等建模方法论，具备较强的需求分析、文档编写能力；5.熟悉Linux平台，熟练使用Hive、SQL、Java、Python编程语言，编码基本功扎实；6.有很强的分析复杂问题和解决复杂问题的能力，有强烈的责任心和使命感，具有良好的沟通能力。
1、参与数据中台建设，负责承担数据资产建设，通过将业务数字化，赋能业务，提升数据价值；2、深入理解业务、产品，制定数据资产架构的规划建设，包括数据采集、资产管理、数据产品、数据质量及稳定性保障体系等；3、深度参与到BU层面业务的重点项目和战役，通过数据技术和数据产品给业务带来增量；4、能为团队引入创新的技术和方案，用创新的思路解决问题，能对现存或未来系统进行宏观的思考，规划形成统一的框架、平台或组件。任职资格：1、计算机或相关专业，985/211本科及以上学历，从事数据仓库领域工作至少2年以上，熟悉数据仓库模型设计方法论，并有实际模型设计及ETL开发经验；2、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验，包括Hdfs、Mapreduce、Hive、Hbase等；3、熟悉数据仓库领域知识和技能，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理；4、了解实时计算，有使用过Storm、Spark Streaming、Flink等开源实时流引擎的优先；5、有一定系统架构设计经验，熟悉常见的技术架构，能够将技术与业务做很好的结合；6、对数据技术有很强的兴趣，不断自我学习，对新技术热衷热爱；7、良好的思维逻辑性、语言表达能力；有较好英语口语能力尤佳；强烈的自我驱动力。
大数据开发（1人）岗位要求：1、计算机或相关专业本科及以上学历2、具备良好的沟通能力、适应能力和理解能力3、有大数据项目落地、数仓建模验者优先岗位技能1、熟练掌握python2、熟悉linux操作系统及常用命令3、熟悉数据结构及算法4、熟悉Oracle、mysql等OLTP数据库5、熟悉大数据相关技术，如Hadoop,Hive,Hbase,Kafka,Flume,Sqoop,Flink，ES工作职责：1、参与大数据平台建设及优化2、ETL数据预处理开发与维护3、数据仓库开发与维护
岗位职责：1、负责基于大数据技术框架下的相关数据产品的设计、开发、实施、优化等工作；2、负责分析数据采集需求，全局设计数据处理、数据质量的技术流程和规范；3、负责数据中台中的大数据技术应用，包括数据采集，数据接入，数据处理等；4、深入理解业务，从数据视角洞察业务，主导数据处理、查询，统计和分析工作；5、负责大数据项目的开发工作。任职要求：1、有HADOOP、HIVE、HBASE等大数据平台开发经验；2、熟悉数据仓库理论，具备有一定的ETL开发工作经验；3、熟悉SQL和NoSQL数据库的设计和开发，如：Oracle/Mysql/Hbase/Mongodb/Redis等；4、熟悉大数据相关组件搭建、应用、优化。
职位职责：1、负责基于HIVE/SPARKSQL数据仓库的开发与优化2、负责数仓计算任务的开发和调度，维表、宽表的建设和调优3、负责数据模型的设计，etl实施，etl性能优化以及相关技术问题的解决4、负责面向业务的olap，报表，数据提取工具等开发工作职位要求：1、计算机相关专业毕业，本科以上学历，3年以上工作经验。2、熟悉Hadoop、HIVE、HBASE 等开源工具；了解数据仓库建设的基本思路。 3、精通Hive sql，有丰富的Hive sql性能调优经验。 4、熟悉Linux，掌握SQL开发和调优，掌握Python或JAVA等一门或者多门语言。5、具备出色的需求分析能力及快速学习能力，能深入理解复杂的业务逻辑。 6、具备良好的团队合作精神，具备出色的沟通能力。
职责1.负责涉及多种数据源的开发工作，包括数据过滤、清洗和分析等2.参与大型分布式应用系统数据流和数据仓库的设计与实现3.参与数据相关的前沿技术预研4.有会员、营销相关数据产品开发工作经验者优先。要求1.计算机相关专业本科及以上学历，3年以上工作经验，2年以上ETL/DataFlow/BI项目经验2.熟悉SQL和至少一种常用数据库语言(Oracle/MySQL/PG等)，有基于Kettle/Nifi/Airflow等平台的开发经验3.熟练使用Linux系统，至少熟悉Python/Shell/JavaScript中的一种脚本语言4.深刻理解数据处理等相关技术和实现方法5.积极主动、学习能力强、沟通能力强、肯吃苦耐劳6.对数据敏感，有数据分析、数据挖掘经验者优先7.有分布式数据处理、BI、数据仓库开发实施经验者优先
岗位职责：1、负责设计和开发分布式大数据分析和应用系统；2、基于业务需求，对分布式系统进行持续性能优化；3、预研新的新技术和组件，应用于产品技术平台；任职资格：1.本科及以上学历，3年以上大数据软件开发相关经验；2.精通Java，熟悉Linux平台上的开发技能，熟悉shell、python等开发语言；3.熟悉ELK/Hadoop/Spark/Flink等大数据技术，有实际项目架构经验，开源项目贡献者优先；4.良好的逻辑能力和沟通能力，具有很强的问题分析和解决能力，对工作具有充满激情；
掌握Linux、Hadoop、Spark、Hbase、Hive、Storm、Kafka。掌握数据仓库的建模流程与规范掌握搜索引擎、推荐系统、BI报表、用户画像、风控模型。熟悉常见的机器学习算法。熟悉深度学习框架TensorFlow，并项目落地经验(语音识别和NLP)。掌握Java语言，掌握微服务架构SpringCloud
工作职责岗位职责：1. 根据广告业务规划，建设广告离线和实时数据体系，支撑业务需求；2. 搭建和维护广告DMP系统，设计和开发人群圈选、透视和lookalike功能；3. 负责广告数据分析平台建设；任职资格"岗位要求：1、本科以上学历，计算机相关专业背景，有3年以上大数据开发经验；2、有良好的数据结构、算法基础和扎实的编程能力；3、熟悉大数据生态相关技术，具备hive,spark和flink开发经验，对数仓建模有较好理解；4、熟悉广告系统和DMP业务优先；5、自驱力强，对技术有追求；6、善于团队沟通、合作；
大数据开发工程师岗位职责1、负责公司整个集团的数据应用和产品需求的设计、开发和维护等工作； 2、参与系统架构设计工作，完成需求开发以及底层架构的升级优化；3、构建强大的OLAP系统，提供实时、离线的分析数据； 4、关键词：大数据、分布式、OLAP、高可用、ADHOC、服务治理、数据展示； 5、服务用户：运营中心，产品团队、高层决策等；任职要求(以下满足2项以上即可)： 1、有扎实的编程语言基础，熟练掌握Java/Python/Shell 等至少一项；  2、有Hadoop stack（包括Hadoop、Hive、Spark等）经验者优先； 3、有大数据系统及相关生态，包括Kylin、HBase、ElasticSearch等经验者优先； 4、有BI开发（包括Spark SQL、Hive SQL、大数据DBA 等）经验者优先； 5、有后台服务开发（Spring Boot、Spring Cloud、Dubbo服务框架等）经验者优先；
职位描述：1. 负责用户画像系统的的架构设计与开发；2. 负责大数据在线服务的架构设计与开发；3. 负责实时特征处理系统的架构设计与开发；4. 负责机器学习模型服务的架构设计与开发；岗位要求：1、计算机或相关专业本科以上学历优先，3年以上工作经验;2、具备扎实的Java语言编程基础，具备良好的编程习惯，较强独立解决问题的能力；掌握Spring等常用的开发框架；3、有丰富的工作经验，参与过大型复杂分布式系统的设计、架构者优先；4、有Hadoop、Spark、Flink、ES、Kafka等框架开发经验者优先；5、熟悉多线程编程和JVM性能调优，有高并发、高吞吐量服务开发经验者优先；6、做事严谨踏实，责任心强；具有良好的沟通能力和团队意识；7、有机器学习模型开发经验者优先；
大数据开发工程师岗位描述:从0到1参与海外内容电商平台的数仓建设，为推荐、搜索业务提供数据和技术支撑；职位要求:1. 熟悉Java/Scala。2、熟悉maxCompute3. 熟悉Hadoop生态圈，能从0到1搭建Hive，Spark，Flink，ElasticSearch，ClickHouse，Hbase等组件,，并且可以基于spark和flink进行数据开发。4. 可以使用Spring Boot框架进行常规开发。5. 积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神。
岗位职责:1. 云警-数据中台建设、维护及优化；2. 云警数据类相关功能开发及性能优化；任职资格：1. 3年大数据研发相关从业经验，熟练掌握Java或Scala语言开发基本技能； 2. 熟悉Hadoop、Spark、Flink等大数据开源框架及其生态； 3. 熟练使用Kafka、Mongodb、ElasticSearch、Redis、Hbase等开源工具，熟练掌握常用中间件调优技巧； 4. 具备DataOps、AIops、机器学习、运维自动化相关从业经验者优先； 5. 具有云业务运维监控系统相关开发经验者优先；
【岗位职责】1、负责公司业务系统的数据加工、分析、处理工作；2、按照业务侧的要求加工数据，生成业务需要的分析数据，用于系统使用的用户标签数据；3、对业务数据进行优化，提升数据分析处理的效率；【岗位要求】1、精通Java/python/go其中一个语言及相关框架，能熟练掌握常用数据结构和算法；2、有实际的Hadoop生态系统HBbase/Hive/MP开发经验；3、熟悉Spark、Flink、Storm、Impala等计算和数据处理引擎的环境搭建、开发和管理；4、熟悉消息队列的原理，熟练使用Kafka、Activemq、Rabbitmq等常用的消息队列；5、掌握数据分析的基本流程，擅长数据采集、清洗、分析等环节，；6、具有较强的业务理解能力，并能快速应用于数据分析各阶段；7、工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战；加分项：广告行业数仓经验
工作职责：1、基于深演云平台（包括不限于hadoop、storm、spark、Hbase、Presto等框架），参与各产品线的开发和优化；2、通过数据分析和数据挖掘，支撑精细化运营及决策；3、承担每天300亿+数据增量的系统可靠性、高效性优化工作；4、参与人工智能算法在大数据平台的工程化、产品化、标准化工作。任职资格：1、本科及以上学历，计算机相关专业；2、良好的编程基础、数据结构基础、数据库基础；3、熟练使用至少一种常见程序语言，如Java/Python/Scala/C/C++/Go；4、有Hadoop等大数据实习经验者优先；5、优秀的学习能力，具备良好的团队意识，积极主动，对大数处理充满热情。职位招聘1-5人
岗位职责：1、大数据平台相关产品的开发；2、负责大数据场景下的数据分析和数仓建设工作；3、熟悉大数据相关组件，并应用大数据技术组件做二次开发；4、负责大数据中台产品的日常部署和维护；任职资格：1、统招硕士或以上学历，3年以上开发经验，熟悉 Hadoop、Flink、Hive、Spark、kafka等分布式开源组件；2、精通 Java 等面向对象编程，熟悉springboot 前后端分离的开发经验；3、有至少一种以上 MySQL 、 Oracle 、 hive 、 mpp 等数据仓库项目研发经验；5、具备一定的前端能力，如vue 、antd-desgin等；6、具备对 Hadoop 生态组件优化与性能调优能力者优先；7、熟悉智慧交通业务者优先；8、能积极主动学习，快速接收业务相关知识和大数据相关技术，完成分配到开发和分析需求。
职位描述-负责大数据平台的开发建设，已上线项目的运维工作;-设计并实现业务系统分析设计，能够独立完成建模工作;-跨部门协作，协同分析并解决数据问题;-核心业务逻辑编写及算法编写。 职责要求:-熟练使用Java/Scala/Python等语言进行开发（至少熟练掌握一种），有高效、高可靠代码开发经验;-有扎实的算法基础，熟悉常见的数据结构，了解分布式算法和分布式系统;-熟悉常见的开源分布式计算/存储相关技术，包括Spark, Kafka、Redis、Mysql、Influxdb等;-熟悉Linux环境及shell脚本;-对机器学习有一定的了解，熟悉常见的机器学习算法,如线性回归、逻辑回归、决策树、随机森林等；-学习能力强，喜欢钻研新技术，有团队观念，具备独立归纳问题，分析问题，解决问题能力；-5年以上大数据工作经验。
岗位职责：1、独立完成大数据领域定制需求的设计和开发工作；2、大数据风控项目现场实施。任职资格业务技能要求：1、有大数据需求分析、方案设计、应用开发经验，具备一定的业务沟通能力；2、能够深入理解产品的业务场景和关键需求，参加过大数据量离线应用开发；3、业务能力强，对技术有激情，喜欢钻研，能够快速接受和掌握新技术，有较强的独立，主动的学习能力。岗位要求：1、计算机相关专业本科及以上学历；2、熟悉Java、Scala的至少一种，掌握常见的数据结构、算法；3、熟悉大数据开发框架，熟悉Hadoop/Spark/Hbase/Rdis/ES DB及业界主流流处理平台如Storm/Flink/Spark Streaming之一；4、Java方向的，能深刻理解IO，多线程等基础框架，熟悉JVM的原理和性能调优；5、对Spark大数据应用开发有成功实践经验，有亿级大数据优化经验者。
岗位职责：1. 熟悉sql开发语言，熟悉hive数仓工具，熟悉数仓建模理论于实际应用。2. 熟悉zookeeper协调工具，kafka消息中间件，以及hbase列式存储数据库。3. 熟悉大数据hadoop框架， 熟悉hdfs、yarn的工作原理以及调优。4. 熟悉Javase开发，熟悉大数据生态的Scala语言。 5. 熟悉spark计算引擎基本原理，熟悉sparksql以及sparkstreaming流式处理计算。6. 熟悉Flink datatream api的使用，flinkcdc、flinkcep的使用7. 熟悉linux系统的安装及使用，熟悉shell脚本编写上班时间：早8.15晚5.15，不同项目组可能涉及调班，九点开始的就往后延，双休，加满8小时可换工作日调休。工作地点：北京朝阳区华润时代中心A座11层
岗位职责:1、负责海量数据离线、实时处理需求的开发；2、负责数据产品相关的功能开发；3、负责数据处理任务的性能优化，并能及时找到问题和解决办法；4、负责大数据相关组件在不同业务场景下的调研任职要求:1、3年及以上大数据开发经验，计算机基础和算法数据结构功底扎实，并能灵活运用解决实际问题；2、具备扎实的java语言基础，掌握scala/python/shell任意一门脚本语言，对技术有热情，愿意尝试新技术；3、熟练掌握Flink主流实时大数据计算系统原理，阅读过源码或是commiter者优先；4、熟悉Spark、Hadoop、hive、HBase、clickhouse等数据平台的基本原理和开发、使用经验；5、具备良好沟通能力和团队合作精神，工作认真细致，责任心强加分项：1、熟悉数仓模型，有离线和实时数仓建设实战经验者优先；2、有互联网产品BI开发经验，有网站数据、用户数据、电商、点击流、精准营销等相关经验优先。
"1.	负责大数据平台规划、部署、优化和维护，保证平台稳定可靠高效运行、熟练掌握并使用cdh、hdp、华为云等大数据管理平台2.	熟练掌握hadoop、hive、hbase、spark、kafka、es、oozie、azkaban、flink等分布式组件的工作原理及应用场景，能够独立应用相关组件独立开发项目3.	深入理解大数据平台架构以及适用场景，有较强的自主分析解决问题的能力4.	熟练使用java、python、scala、shell等开发语言5.	深入理解mysql、oracle任一数据库存储原理、有较强的sql能力6.	熟悉linux环境，有过服务器运维经验者优先7.	从事过spark mlib、spark graphx、neo4j、tigergraph、kudu、impala、Phoenix、tez相关项目开发者优先8.  有过真实日增TB级数据量项目开发经验者优先9.  有过两年以上后端开发经验者优先"
职位描述：1、参与大数据项目的需求分析，实现软件研发;2、根据项目需求，分析并给出性价较高的解决方案。任职要求：1. 熟悉统计学原理和数据挖掘算法；2.计算机相关专业，本科及以上学历，1年以上数据相关工作经验，学习能力突出；3.熟悉hadoop生态组件HDFS/Yarn/Hive/Spark/Flink/Hive/Hbase/Kafka/Sqoop Redis/ClickHouse/Presto/Impala，具有SparkSQL\SparkStreaming\Flink项目开发经验，有实际CDH或HDP集群搭建及调优经验；4.熟练掌握MySQL, Oracle 等主流数据库5.精通Java, Scala, Python 至少两种编程语言，有较强的分布式计算基础和软件工程能力；加分项：1.熟悉机器学习、数据挖掘、分布式计算；2.熟悉工厂SPC、YMS、MES等系统；3.基础能力+学习能力特别优秀者。
岗位职责1、参数数据中台建设，承担相关大数据平台开发，包括数据采集、传输、存储、处理、分析、治理等环节；2、负责数据仓库（离线、实时）的架构设计、数据模型设计及实施落地；3、负责大数据能力在业务上的落地，推进数据化、服务化；任职要求1、精通SQL，有较好的SQL性能调优经验。2、熟悉Linux操作系统，至少熟练使用Java、Scala、Python、Shell语言之一。3、掌握分布式计算框架Flink、HDFS、Spark、Hive、HBase、Kudu、Elasticsearch等至少一项。4、熟悉至少一种OLAP引擎，Impala/Presto，有OLAP引擎调优经验者优先5、有较强的逻辑思维能力，善于分析、归纳、快速定位并解决问题。6、从事游戏行业，或有机器学习、用户画像相关项目经验优先。
工作内容：   1.负责数据服务功能技术设计文档的编写；   2.负责业务数据的分析、集成、清洗、加工程序的开发；   3.负责数据仓库的设计、开发、优化工作；   4.负责为公司各部门的数据应用提供指导和支持。岗位要求：   1.本科5年(硕士3年)以上的大数据开发经验，熟悉大数据、数据仓库、分布式架构技术理论，具有系统架构设计和实战经验，熟悉CDH、HDP、TDH至少一款大数据产品  2.熟悉大数据组件的开发、搭建、维护及性能优化；  3.具有较强的开发能力，能熟练使用shell、sql等开发语音，熟悉大数据生态、关系型数据库和NOSQL数据库等相关知识，能够独立完成并知道初级开发人员完成大数据相关的开发和优化工作；  4.熟悉hadoop、hbase、hive、zk等技术和组件；  5.熟练掌握spark、flink、mr任意一种计算框架；  6.具有一定的机器学习、人工智能、数据分析工作的经验者优先
岗位职责：1、负责公司数据仓库的搭建以及快速并行化查询需求的支持2、负责公司的数据处理、数据统计以及数据挖掘的开发工作 3、负责公司后台日志统计分析系统的具体开发工作  4、利用hadoop、spark等框架做数据的实时及离线分析  岗位要求：1、本科以上学历，java基本功扎实，熟悉Scala的优先2、熟悉分布式计算和存储技术，熟悉Hadoop、MapReduce、Spark等3、熟悉MYSQL、ORACLE等关系数据库3、熟悉Mongo、HBase等NOSQL数据库。 4、熟悉大数据的统计分析和挖掘，了解常用的数据统计方法和挖掘算法。5、熟悉Linux 操作系统, 可以自行部署开发环境  加分项：1、对程序开发有浓厚热情的，愿意深入学习的；2、有写博客习惯或能提供github地址的3、了解股票，期货和其他金融衍生品的知识者优先
岗位职责：1、参与公司大数据平台的设计和优化，提高平台易用性；2、精通各类大数据技术和产品，能够引入并实施，包括Hadoop、Spark、ClickHouse和、Flink生态圈的各种主流技术，熟练掌握HBase、Hive、Flink、ClickHouse、MySQL等数据库技术，实现数据平台的搭建、完善和开发；3、负责数据基础架构和数据处理体系的开发升级和优化，不断提升系统的稳定性和效率，为公司的业务提供大数据底层平台的支持和保证；4、设计并实现数据产品开发、算法开发的系统性支持，并规划元数据、数据质量等数据治理体系；5、研究未来数据模型和计算框架的创新与落地，参与制定并实践团队的技术发展路线；6、针对产品、项目需求，组织制定系统优化方案并进行系统开发；7、参与大数据平台通用工具的设计，负责大数据平台的性能参数调整和优化。任职资格：1、大学统招本科以上学历，3年及以上工作经验；2、熟悉hadoop、hive、hdfs、hbase基本原理；3、熟悉Spark、flume、kafka、Flink、ClickHouse等相关技术；4、扎实的Java编程基础和开发经验，熟悉J2EE及开发模式；5、有高并发、高可用大数据平台开发经验者优先；6、熟悉数据仓库基本原理者优先。
数据职位描述1、承接各业务条线的数据指标解耦类需求，以及产品化落地；2、负责离线和实时数据模型、数据服务API等功能的设计、开发和优化；3、实习地点为北京亦庄总部，时间3个月起，实习薪资可面议，表现良好的同学有毕业转正机会。职位要求1、高校在读硕士研究生。2、有大数据分布式计算平台开发经验，熟悉Mapreduce原理，熟悉使用Hive开发，有一定的hive调优经验。3、熟悉spark、hive、flink等大数据框架，OLAP存储相关技术，如MySQL、Doris、ElasticSearch、Clickhouse等；4、了解数据仓库各类建模理论，以及数据仓库数据层级关系，熟悉多维数据模型设计，具备一定大型数据仓库架构设计、模型设计和处理性能调优等相关能力；5、了解JAVA技术栈，如Spring、Mybatis等基本框架，具备工程开发基本功。
工作职责：1.搭建存储海量金融数据的分布式数据仓库。2.搭建公司的大数据平台，包括：调度系统、数据监控、数据处理流程、平台权限管控等，实现高可靠、高效率、高扩展的金融数据处理。3.开发实时数据处理系统和平台，实现实时数据处理、传输的自动化流程。4.和其他同事一起设计开发不同业务数据的自动化处理流程。5.基于大数据平台开发相关衍生数据的计算模块和流程。职位要求：1.全国统招本科及以上学历，具有计算机、电子、自动化等相关专业背景。2.对数据仓库体系架构有深刻的理解，能熟练进行数据系统的设计和开发。3.熟悉大数据处理方法，熟练使用hadoop、hive、hbase、spark、flink等分布式应用工具。4.有知名互联网公司的大数据平台建设经验和大数据开发经验，能够独立搭建数据仓库和数据平台。5.有金融领域的大数据平台工作经验，有处理海量金融数据的能力。6.具有Linux系统环境下的开发经验，具有编写shell脚本的能力，精通Python、R、Scala等开发语言。7.熟练使用常见的数据库，例如：MySQL、PostgeSQL、MongoDb、Redis等。8.具有ZeroMQ、RabbitMQ、Kafka等消息中间件的数据开发经验。9.具有优秀的团队沟通和协作能力、责任心强，善于学习，有较强的自我驱动，具有独立分析并解决问题的能力。
岗位职责：1、负责数据治理调研，数据治理全过程；2、负责公司数据质量产品实施；3、 负责数据分析，抽取，数据检查、核对及数据整合技术文档编写；4、负责对实施提供的客户需求进行分析、根据需求编写数据报表、图表需要的 sql 脚本；任职要求：1、五年以上相关工作经验，计算机相关专业，本科及以上学历；2. 熟悉数据管理标准、元数据管理、数据质量管理；3. 熟悉PG数据库，能够通过PL/SQL或脚本(Python, R，SHELL)等方式实现业务需求，完成数据分析、挖掘、加工处理;4. 参与数据仓库和大数据平台的环境搭建、架构设计和数据开发;5. 熟悉hadoop生态圈，包括但不限于hive、hdfs、hbase、sqoop、spark、scala 等
岗位职责:1、负责数据中台、AI中台相关的软件产品规划、设计、评估、检验，支撑产品在技术选型、架构规划、产品设计等方面的前瞻性；2、负责数据抽取、智能调度、元数据管理、数据质量管理、数据资产、API服务管理、各种指标统计等功能模块的设计与研发工作；3、负责数据平台实时计算/分布式计算的架构设计\代码编写，及开源技术组件的二次开发；4、负责数据中台、AI中台相关软件产品售前技术支持，给客户制定个性化的方案并领导实施；5、具备Java,SQL开发经验，性能调测，开源代码商业化，底层基础架构搭建；6、积极关注业界在数据中台领域的发展动态，持续打造具有国际一流的产品和服务；任职资格:1、全日制统招本科以上学历（硬性要求），三年以上相关工作经验；2、2年以上基于Hadoop/Spark/Hbase/Hive/Flink/Kafka/Clickhouse等分布式技术的产品开发经验；3、熟练掌握大数据分布式计算开源软件设计原理，并能够组织实施基于开源软件进行的二次研发；4、熟悉Oracle、Mysql、SQLServer等至少一种大型数据库，熟悉SQL；5、熟悉常见的数据挖掘、机器学习及深度学习算法，有相关项目经验者优先；6、具有较强的工作责任心，良好的沟通和协调能力7、严谨、细致、踏实的工作作风和积极主动的工作态度；
1. 数据仓库建设2. 大数据计算程序开发3. flink计算程序开发4. 金融数据（期货、股票等）相关行情数据及行业数据处理5. 数据采集、处理、发布流程开发
岗位职责：1、负责公司产品的后端框架设计与开发工作，满足各种复杂业务场景下的产品需求；2、与产品、运营部门一起探讨，设计、实现产品的新功能及改进；3、数据驱动，不断通过产品和技术数据进行改进，并完成快速迭代；4、能够独立完成核心模块的技术攻关以及开发工作；5、学习和研究新技术以更好的满足产品的需求。任职要求：1. 5年以上开发经验，担任核心开发角色；2. java基础扎实，掌握设计模式及应用场景，有良好的代码风格，能够编写高质量代码；3. 熟练使用主流java技术框架并有深入理解，如springboot、springcloud、nacos、sentinel、mybatis等；4. 至少熟练使用一种关系型数据库，如Mysql、Oracle、SqlServer、Postgresql等。能写出高性能sql语句；5. 有大数据开发经验，有百亿级以上结构化、非结构化数据检索系统开发调优经验；6. 有大型分布式系统的开发经验，能够设计出高并发、高可用的系统；7. 熟练使用kafka、redis；熟悉ElasticSearch ；8. 熟悉Linux操作系统，对于Linux的基本命令要很熟，能够做到将自己的项目部署到Linux服务器上，并查看程序运行的日志；9. 熟悉容器技术，包括Docker，Swarm，k8s等。
岗位职责1、负责支撑业务中台、数据中台、能源大数据中心等项目的应用架构、技术架构、数据架构设计；2、负责大数据平台的系统架构和风险评估、性能优化；3、遵循公司技术标准、规范，高质量完成设计、开发任务；4、负责配合制订信息化发展路线及相关规划，基于阿里云数据中台相关产品出具整体解决方案。岗位要求1、全日制本科以上学历，计算机相关专业，要求学信网可查，3年以上相关工作经验；2、熟悉阿里云大数据产品组件，如dataworks、maxcompute、datahub、quickbi、blink、rds、adb等；3、熟悉数据集成、基于多产品的组合应用的数据链路设计，熟练掌握基于dataworks的离线数据开发或基于blink的流计算开发；有一定python/java开发能力，能编写一定复杂程度的udf；4、熟悉数仓建模理论，了解ER建模及维度建模理论，熟悉常见的数仓分层方法、原则、规范；5、具备一定业务敏感度，能够结合业务问题进行业务调研、总结、抽象，简单设计数据应用原型；6、逻辑思维清晰，沟通表达流畅，具备一定的领导力和项目组织能力，能够进行团队技术总控。
工作职责：1.主要负责实时数据接入、查询中心、大数据资产管理等相关数据化产品设计、研发2.增强、完善大数据到数据价值应用的桥接功能3.提升数据对业务的价值产出和创新能力职位要求：1.精通java(必须)，熟悉阿里云/hadoop大数据生态相关框架2.对开源框架Spring、kafka、zk、Hbase、mongo等有实际应用经验，并能熟练使用4.有BI平台、交互式查询平台实际项目研发经验优先5.能够自驱，有创新意识，对数据价值应用思路清晰，能够主导项目研发
大数据开发工程师    岗位职责：    1、建设量化交易系统的数据仓库；    2、从国内外交易所,数据供应商以及互联网获取各类的金融数据；    3、负责数据的收集, 聚合,清洗和分析；    4、确保数据质量,包括正确性,一致性,完备性,有效性,时效性等。    任职要求：    1、2年以上相关工作经验；    2、熟练掌握一种或多个开发语言，java\c++\python；   3、熟悉linux开发环境, 掌握常用算法和数据结构；    4、熟悉MySQL和NoSQL数据库,有很好的数据多维空间思维能力；   5、熟悉计算机原理,操作系统,计算机网络等基础理论；   6、有很强责任心,优秀的团队合作精神,能够承受较大的工作压力。
团队和业务简介公司团队骨干由互联网知名公司的各领域专家组成；管理架构扁平高效，结果导向, 崇尚狂热的技术氛围。目前产品涵盖：视频聚合、电子书、电商等领域业务面向千万日活，大数据平台覆盖多条产品线和多个子系统，提供如下服务：- 提供一站式数据服务平台, 帮助用户降低大数据使用门槛，提升团队开发协作效率- 提供多维度数据统计分析，为运营决策体系提供充足的决策数据支撑- 提供不同粒度的用户行为数据，为算法等线上业务提供高质量、高稳定度的数据输出职位职责1. 参与数据仓库架构设计和各个分层的开发2. 完成业务模型抽象、数据梳理，设计数据模型，提供统计、分析、报表展示服务3. 参与数据治理工作，提升数据易用性及数据质量4. 与业务团队紧密合作，理解并合理抽象业务需求，发挥数据价值，职位要求：1. 精通离线和实时数仓的常用开发技能，对HQL或SparkSQL有丰富实战经验2. 对Hive等查询语言的调优有较为深入的理解3. 精通数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景4. 熟悉大数据生态圈相关组件，比如Hadoop/Sqoop/Impala/Clickhouse/Presto/Kylin等5. 良好的沟通能力，抽象能力，具备优秀的技术与业务结合能力6. 目标导向，敢于通过挑战更大的难度，获得自我提升
岗位职责1、基于业务需求对数据进行数据治理与规范，确保数据的准确性、及时性、可靠性 ；2、参与数据平台的设计、开发、维护 ；3、支撑业务部门的数据需求；4、调研新兴工具与方法，提高数据平台的效率。任职要求1、1年以上工作经验，有数据相关经验者优先；2、熟练编写SQL代码，可优化其查询性能；3、具备较强的编程能力和经验、熟练使用 Python/Java/Go（一种或多种）；4、具有数据管道编排工具xxljob、Airflow的开发和使用经验.
公司介绍：面向青年学子的数字化职业成长平台，通过连接在校生与真实的工作世界， 帮助用户明确职业理想、严选推荐个性化成长资源与工作机会， 赋能亿万青年！数据分析师职位描述* 以公司大量自有数据、外部导入数据为基础，跟踪高等人才素质教育动态，开展相关研究，定期输出行业报告；* 负责公司数据模型的优化与迭代，不断提升数据模型准确度，并迭代模型策略；* 规划和设计业务数据报表，提供决策支持，推动业务数据化运营职位要求；* 本科及以上学历，统计/数学/运筹/管理科学等理工科优先；* 三年以上相关数据分析工作经验；* 熟练使用SQL、Python等语言和各种数据分析工具，熟悉 Excel；* 对数据分析工作感兴趣，工作认真细致，有极强的责任心；* 具备出色的数据分析、商业分析能力、逻辑思维能力。
学历须！！！！！学信网可查！！！！至少毕业满足2年！！！岗位职责大数据环境下shell脚本开发，Hive SQL，impala SQL开发1、熟练使用shell脚本开发2、熟练Hive SQL、impala SQL的编写3、使用过大数据相关组件（hive、impala、CDH、hue）任职要求1、本科学历，须学信网可查。计算机专业。2、2年以上数据架构开发等工作经验（不包含实习)，对主流大数据计算引擎和存储架构有深刻的理解3、有扎实的计算机基础，较强的产品架构设计能力，优秀的数据库设计和优化能力4、学习能力强，具有优秀的逻辑思维能力5、富有责任心，具备良好的团队合作精神和承受压力的能力
工作职责：参与公司数据处理逻辑的设计和优化；参与公司各种数据模型的设计和优化；负责公司大数据基础架构平台的规划、设计。岗位要求：熟悉HDFS、MapReduce和HBase的实现原理；熟悉至少2种分布式计算引擎的实现原理，具备故障定位、以及性能调优能力；熟练使用Java与Scala语言进行开发；具备3年以上的TB级别数据平台开发经验；良好的工作习惯、沟通能力和学习能力。
岗位职责•  优化和迭代数据仓库，统一数据指标，完善建模，分层等；•  数据源集成，数据采集，数据分发；•  ETL全流程的研发和部署，会使用Airflow，Azkaban等调度工具；•  使用即席查询和BI工具，制作看板和进行异常监控，数据分析和数据挖掘；任职要求•  本科及以上学历，计算机/数学/统计等相关专业；•  1年以上数据方向大型项目相关经验；•  熟练使用SQL，以及Python和Shell等脚本语言；•  熟悉Spark，Imapala，Flink等大数据处理框架；•  有一定的业务思维，具有数据敏感度
岗位职责1.负责大数据分析需求设计和开发 ，承担数据抽取、清洗、转换等数据处理应用的开发；2.负责资源库题库系统的各个场景下推荐算法及优化；3.负责数据流的优化和监控；4.负责研究大数据前沿技术，架构调整和性能调优。岗位要求：1.计算机相关专业，本科及以上学历，3年以上大数据开发经验或推荐系统开发经验；2.熟悉Spark、Hadoop、Hive、Hbase、Flink、Elasticsearch等技术；3.熟悉常见的推荐和排序算法，比如协同过滤，逻辑回归，决策树模型，双塔模型等；4.熟悉JavaEE开源框架，SpringBoot，SpringCloud 等 ； 熟悉Linux环境，掌握Python或Shell等脚本语言5. 有数据采集、作业调度、监控告警、数据治理等平台设计和开发经验的优先；5. 有用户画像、排序优化、知识库建设等经验优先；6. 有教育资源库，题库项目经验者优先。
1.熟悉ETL流程及开发2.熟悉Hadoop，hive，hbase，spark，kafka，mapreduce等框架和工具的原理并能熟练运用3.掌握微服务框架和开发技巧4.精通oracle/mysql/NCC等主流数据库的配置、存储过程开发和性能调优5.精通java/scala语言并能进行企业级开发6.熟悉ES、数据标签和人员画像者优先考虑7.数据类项目三年以上工作经验8.大学计算机相关专业，本科以上学历9.意向在北京长期工作。
1、参与分布式大数据处理系统和数据服务基础设施的架构设计和开发；2、负责ETL关键任务的优化设计，协助解决开发过程中的技术难题；3、负责通过数据分析和挖掘，支撑业务团队数据需求。任职要求：1、对未知世界充满好奇，善于思考，热爱编程，能够独立解决问题；2、精通Java、python语言，了解语言的原理、能够编写高质量的代码；3、熟悉常用分布式系统相关理论基础，有一定的分布式系统开发经验；4、具备Spring Cloud等微服务设计和开发经验和能力；5、熟悉大数据技术栈,对Flink、Hadoop、Hive、Spark、Hbase、Kafka、Flume、等开源组件；6、了解分布式、微服务、传统关系型数据库、常用NoSQL开源系统、RESTful、基本的信息安全领域知识7、如果了解一些基本的数据挖掘相关知识者优先 8、985/211学校毕业生优先
职位描述：1、基于HBase/Hive/Spark/Flink等平台建设数据仓库，在线海量数据分析平台的开发;2、负责数据模型的设计，etl实施，etl性能优化以及相关技术问题的解决；3、参与大数据的采集、存储、处理，分析等开发4、参与数据挖掘算法的设计、对海量数据进行挖掘分析和发掘数据价值及算法学习及实现。任职要求：1、2年及以上大数据项目架构/开发/调优经验2、熟悉Linux/Unix系统，熟悉至少一门编程语言PHP/Python/Java等，有高性能分布式平台开发经验3、具备数据库系统理论知识，掌握主流数据库管理和应用，精通SQL；4、熟悉常见的算法和数据结构，熟练设计数据模型、ETL设计、Cube多维建模、OLAP开发等；5、熟练使用大数据处理框架（Hadoop/Hive/Spark/Flink）相关技术；6、熟悉流式计算引擎，对相关框架(Kafka/SparkStreaming/Flink)熟悉了解，有实际应用经验优先；7、了解统计以及数据挖掘、机器学习、人工智能技术，会使用关联分析、分类预测、聚类分析等常用分析方法；8、沟通主动，有较强的工作激情和抗压能力，能组织协同团队开发。
1.计算机及相关专业本科以上学历，三年以上大数据经验；2.具备引导客户需求的能力，具备良好的交流沟通能力；3.深入理解数据治理的方法，包括数据清洗、ETL、质量监控和评估等实施经验； 4.熟悉基于HIVE的数据仓库的搭建与性能调优。5.具备基本的数据仓库建模能力，能够准确表达需求和设计并对对数据的可视化有深入认识和理解。6.熟练掌握JAVA语言，熟悉Linux操作系统，熟练编写及使用shell脚本。7.掌握Sqoop、Spark、Hive、HBase、Zookeeper、Hadoop、Elasticsearch等大数据框架，并有过实际项目搭建经验。8.有海量数据处理经验者优先；有大数据框架调优经验者优先；有数据挖掘、数据分析算法者优先；有Python 爬虫反爬经验者优先；
职位描述：1、负责公司反欺诈系统的离线或实时计算的开发任务2、负责公司数据平台的开发工作，包括数据平台开发，数仓建设，数据统计分析等3、负责相关业务的数据应⽤梳理以及流程优化，完善数据应⽤系统的建设，为产品迭代提供数据化分析的⽅法论以及数据能⼒⽀撑4、线上系统的技术支持职位要求：1、扎实的编程能力，熟练掌握Java/Scala/Python编程2、有良好的数据结构、算法基础和扎实的编程能力3、具有3年以上大数据系统的搭建及调优经验4、熟悉大数据生态相关技术，具有hadoop,hive,spark,hbase,es,OLAP,flink等开发经验5、工作细致、责任心强，具备较强的学习能力及理解能力，有良好的沟通能力和团队协作能力6、加分项: 熟悉广告系统
岗位职责：1、技术开发：技术研究、技术选型、环境部署、技术验证、技术培训2、产品开发：开发大数据基础平台支撑各类产品的研发工作3、项目实施：架构设计、大数据接入、接口服务、计算、数据处理4、日常运维：算法提炼、知识库、工具库、培训5、售前支持：大数据技术相关方案编制6、完成上级领导交办的其他工作。 任职要求：1、4年以上软件行业工作经验；2年以上大数据相关工作经验，精通java语言开发2、精通Hadoop系统，对HDFS、HBASE、HIVE以及Map reduce框架计算有深入的研究和实践；能独立进行Map reduce算法设计3、熟悉STORM、SPARK、Flume、kafka、redis、memecahed等产品，有相关开发经验4、熟悉主流WEB开发框架（Spring、Hibernate、Struts2、ibatis等），熟知不同流行框架的优缺点5、精通java语言，熟悉jvm核心工作原理；拥有3年以上基于海量数据的大型分布式系统应用开发经验6、具有大数据处理平台架构设计经验，熟悉智慧城市数据模型、数据标准、数据质量、元数据、主数据等数据治理相关领域的技术者优先7、学习能力强,有良好的沟通能力,具有强烈的团队合作精神，积极肯干，吃苦耐劳，责任心强。
工作职责：1、负责公司数据服务及产品交付的实施工作；2、负责与客户技术沟通以及团队指导协调工作；3、与公司其他部门或其他项目组保持良好协作,确保项目良好运转；任职要求：1、本科或以上学历,计算机、软件、数学等相关专业,3-5年以上工作经验；2、熟悉数据仓库各类模型建模理论,了解数据仓库数据分层架构,了解主数据、元数据及数据集中、清洗转换与质量检测；3、熟悉Oracle数据仓库组件,熟练运用 SQL、PL-SQL程序语言；4、熟悉BI产品BO,具有实施经验；5、熟练使用常见 ETL工具如ODI、Kettle或类似产品；6、具有医疗、电力等行业BI数据仓库建设经验者优先；7、有DBA工作经验者优先,有OCP、OCM认证者优先；8、工作态度严谨认真,有敬业精神,并具一定团队管理能力以及良好的团队合作精神,有浓厚的钻研学习能力；9、能接一定程度的出差。
工作内容及职责：1. 负责平台实时数据、离线数据的接收、清洗、存储；2. 负责业务相关数据指标的统计分析、计算挖掘；3. 负责公司内部数据平台的设计和开发；4. 负责数据仓库的设计和开发；5. 负责大数据框架搭建和维护。任职资格：1）掌握hadoop生态环境，熟悉Java、scala编程；2）掌握spark、impala、storm、hive、hbase等；3）有较强的性能优化及问题排查、解决能力；对开源技术非常感兴趣并具有一定的研究能力。
1、深入了解 Spark原理，阅读过源码者优先2、熟悉Hadoop、Hive、Hbase、kafka等大数据技术3、精通Python、Java、Scala中至少1-2种开发语言4、具备实际的大数据业务开发经验以及良好的项目沟通和协调能力5、有制造行业经验者优先。6、具备扎实的专业基础，良好的沟通能力和团队合作，主动积极，乐于面对挑战；7、参与过数据处理、分析、挖掘等相关项目更好；
spark，flink精通，人靠谱，热爱技术，目标清晰，简单可依赖，有金融信贷优先，无金融项目经验勿扰。
岗位要求：1、统招本科及以上学历；2、熟悉Linux操作系统、熟悉Shell，有一定解决系统问题的能力；3、熟练掌握HBase、Hive、MongoDB、Redis等组件，具备Hbase性能调优经验优先4、熟练使用Hbase进行分布式存储，熟悉其读写流程，可根据实际业务进行Rowkey的设计和优化；5、熟练使用Hive 语法，精通SQL编写与优化；5、优秀的设计和编码能力：针对具体的业务场景问题，快速设计和实现解决方案；对工程质量有很高的自我要求；
"岗位职责：1.	负责公司大数据分析产品的技术选型、设计、研发和维护，参与产品从立项到交付的全生命周期工作，负责公司产品研发过程中的技术架构及数据处理逻辑文档的沉淀与积累。2.	负责基础大数据框架搭建，包括数据仓库、数据集市的模型设计与开发、ETL数据准确性验证及ETL任务的优化；3.	负责数据质量、稳定性等数据管理工作，促进数据标准规范化、数据获取高效化；4.	负责数据分析平台的可用性、容量、性能及安全等数据运维管理工作；5.	负责数据平台组件的优化和改造工作，参与核心代码设计以及开发，带领数据团队攻克项目开发中的技术难点；6.	参与用户调研，提出对重点业务的数据分析&洞见，提炼数据产品需求，沉淀分析思路与框架，与团队协作进行产品规划及设计讨论，促进数据平台产品不断优化、迭代升级。任职要求：1.	5年以上分布式大数据处理和离线数据仓库相关设计经验，有过GreenPlum、gbase等MPP项目的相关实施经验，有BI项目实施经验；2.	熟练掌握数据仓库、数据集市的设计及开发流程，有实际模型设计、性能调优及ETL开发经验，对数据治理的理论和实践能够结合思考、相互印证；3.	具有熟练的数据建模经验，能够基于建模理论进行熟练的数据模型设计，具备2-3个标准数仓模型建设经验者优先；4.	熟悉Linux平台，熟练使用Shell、Python等脚本语言其中一种；5.	具备根据业务需求进行高效数据建模的能力，可输出合理的数据建设解决方案，对数据的应用建设有比较丰富的经验；6.	熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量管理、数据平台性能调优等；7.	熟练应用并深刻理解大数据相关组件，包括但不限于HDFS、HBase、Yarn、Zookeeper、Spark、Hive、Kafka、Elasticsearch、Solr等；8.	具备良好的抗压能力、沟通能力和团队精神，具有独立开展分析研究项目能力，具备跨部门协调获取资源的能力。9.	全日制大学本科及以上学历，计算机、信息管理、统计学、数学类专业。"
1、负责公司大数据平台/数据中台搭建、数据标准建立、数据建模、元数据管、ETL开发与维护等工作。2、对上游数据进行清洗、清理、加工、转换、加载至目标数据库，组织协调数据整改。3、关注前沿技术，通过新技术服务团队和业务。4、在理解开发流程的基础上，结合实际建立或优化提升工作效率的流程和工具。岗位要求：1、计算机、软件相关专业本科及以上学历；2、具有金融行业系统软件开发经验者优先考虑；3、Java基础扎实，掌握JVM、并发编程、网络编程、数据库编程、单元测试等基础知识，熟悉Web开发，深入理解HTTP协议；4、熟悉数据仓库方法论、理解维度建模，有ETL相关开发工作经验，能够完成数据仓库和数据报表开发相关工作;或者熟悉大数据算法模型、分布式存储、大规模分布式计算、实时计算、跨平台资源调度、大规模分布式算法平台等5、掌握常见分布式计算框架和技术原理，如Hadoop、MapReduce、Yarn、Hbase、Flink、Spark等;6、熟悉Linux操作系统和Shell编程，熟悉SQL编程以及性能调优；7、熟悉SVN，Git等版本管理工具；8、熟悉数据标准/数据治理/元数据管理相关工作；9、具有一定项目管理能力，了解基本项目管理知识，有实际项目管理经验更佳；
Responsibilities1. 负责字节跳动大规模基础研发资源大数据体系建设，构建系统数据中台，赋能业务； 2. 负责研发资源数据规范的制定、数据模型的设计、ETL实施、性能优化以及相关技术问题的解决； 3. 持续数据治理，构建全链路质量监控体系，保障数据时效性和准确度，并支持数据回溯及问题快速定位； 4. 理解并合理抽象业务需求，探索数据应用场景，支撑运营策略； 岗位亮点： 1. 海量设备数据实时分析的实践经历； 2. 有机会深刻理解基础设施管理相关业务特性并对复杂设备运行态制定评估标准； 3. 参与运营决策，支撑运营策略；Qualifications 1、具备实际的大数据业务开发经验，熟练使用Hadoop、Hive、Spark、Flink等一种或者几种大数据离线或实时计算相关框架，并深入知晓原理； 2、有数据统计系统或熟悉BI/DW原理和实施，数据仓库、数据集成、多维数据仓库设计、开发、架构经验者优先； 3、熟练使用 Java、Go、Python语言中的一种或者多种； 4、具备数据库系统理论知识，掌握主流数据库管理和应用，精通SQL, 对数据结构和算法设计有较为深刻的理解； 5、有传统IDC、云基础设施相关经验优先。
岗位描述深入理解相关业务及数据应用需求；负责数据整合与数据仓库模型的建立、维护和优化；了解、监控应用需求及数据源的变化，并评估对数据仓库模型的影响；设计数据模型的ETL实现，参与团队ETL流程的优化以及相关技术问题的解决。任职要求熟悉数据仓库建设生命周期流程规范,并掌握主题建模、维度建模理论；熟悉SQL/HQL，有较好的SQL性能调优经验；熟悉 java/Python/Shell等至少一种脚本语言，有较强的编程能力和编程经验；有大规模数据/日志处理经验，熟悉Hadoop/Hive熟悉Hadoop/Hive/hbase/storm/flink 一种以上者优先具有ETL设计与开发、数据建模、数据质量保障、元数据管理、指标体系建设等项目实践经验优先；工作认真、踏实、负责，有良好的团队合作精神，良好的分析能力、沟通技巧；有互联网经验优先
岗位描述：1、参与构建京东集团toB业务数据仓库，支持各条业务线数据需求2、参与实施数据仓库开发3、参与数据仓库OLAP体系搭建，建设灵活的在线分析应用4、调研和实践热门数据仓库组件和技术任职资格：1.计算机等相关专业本科以上学历；2. 5年以上数据仓库/商业智能/数据统计相关工作3.熟悉数仓建设方法论 1)熟悉etl分层建设方法 2）熟悉主题建设方法，能独立抽象主题，建设主题，并且物理化和性能调优 3）熟悉常用的BI系统建设方法，理解实现原理，理解各个工具使用场景4.熟悉掌握sql和调优；5.熟悉掌握java/python中至少一种编程语言
1、熟悉大数据开源产品的架构和技术细节，具有以下Spark(Streaming/MLlib)、Hadoop、Hbase、YARN、Flume、Kafka平台的项目开发经验，平台运营维护经验，参与过开源Hadoop社区贡献最好；2、熟练掌握至少一种编程语言，Java、Scala；3、研究过Spark(Streaming/MLlib)、Hadoop、Hbase、YARN、Flume、Kafka等源代码者优先；4、工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战。5、能接受短期出差
在这里，你将与业界大数据专家一起工作，有机会与来自全球的大数据领域牛人交流，参与华为业界领先的大数据平台的核心产品设计、研发、交付。你将会：1、深度参与到华为大数据Hadoop、Yarn、Spark、Hive、HBase、Kafka、Zookeeper、Flume、AI平台等组件的研发、交付及解决方案支撑；2、探索云服务化实现的前沿技术，并负责华为云大数据服务的架构设计、开发、测试及运维。
岗位职责1.参与数据平台的设计开发，构建高效、健壮的数据计算系统，保证高可用、稳定、低延迟的优质服务体验，2.承担大数据平台服务组件的搭建和维护，优化现有的技术框架，形成配置化、可复用的数据技术能力；3.通过数据模型跟踪和分析业务效果，为业务提出优化解决方案。岗位要求：1.本科及以上学历，2年及以上大数据项目开发经验或数据中台产品研发经验；2. 精通Java/Python/Scala等一门语言，精通SQL，熟悉Hadoop、Spark、Hive、Flink、Kafka、ES等主流的大数据技术；3. 有数据采集、作业调度、监控告警、数据治理等平台设计和开发经验的优先；4. 有BI系统开发经验、熟悉Dashboard、 标注工具等开源项目者优先；5. 擅于沟通和解决问题，对于业务可以进行抽象总结，推动并优化业务发展。
岗位职责：1.支持Hadoop集群底座的运维故障分析、解决、性能优化；大数据集相关组件主要包括：Yarn、HDFS、ZooKeeper、Storm、Kafka、Hbase、Hive、Spark、Kerberos、Spark、Flink、Flume、MySQL等组件运维；2.开展Yarn性能优化，提升集群资源利用率和任务响应速度；队列优化和维护；优化调度器性能；3.及时关注Apache官方网站、论坛，针对Patch提出升级建议、方案，并组织实施；4.配合开展HDFS存储、Hive元数据治理优化，建立并完善存储治理方案；5.配合开展Hive、Spark作业优化，对业务侧提出优化建议。如：作业小文件问题、数据倾斜治理方案等；6.提出集群优化建设方案，配合建设和优化大规模分布式集群的自动化运维、监控等工具和管理平台。任职要求：1.全日制本科及以上学历，通信/计算机等相关专业，具有良好的学习能力、沟通能力、团队合作能力及一定的抗压能力；2.熟悉Hadoop、Hive、Hbase、Spark等开源项目，理解组件架构及原理；3.对大数据运维开发有浓厚兴趣，熟悉Apache Hadoop部署、性能调优；4.能阅读/理解Hadoop等相关开源组件源码；5.对HQL、SparkSQL等有较深入的研究，能解决实际业务性能问题；6.熟练掌握LDAP、Kerberos等安全认证体系；7.熟练掌握Linux命令与工具进行问题定位，熟悉常规的互联网技术架构；8.具备一定的Java开发能力；9.擅长Linux Shell、Python脚本编写，有DevOPS/自动化运维经验工作者优先考虑。
岗位职责：1、负责华为大数据存算分离方案的设计、演进、技术推广、POC测试和客户支撑；2、负责维护线上大数据解决方案的SLA，基于用户的体验和数据持续优化，对解决方案质量负责。岗位要求：1、熟悉大数据或媒资或分布式存储，有解决方案设计经验；2、掌握计算机基础知识，熟悉Linux基本操作以及Shell/python脚本使用；3、具备良好的沟通能力，对业界技术敏感，喜欢专研，能够快速接受和掌握新技术，善于团队合作，责任心和主动性强。有以下相关经验、技能者优先考虑：1、有公有云微服务、分布式系统研发和大数据经验者优先；2、熟悉hadoop生态，有使用、开发和设计经验者；3、熟悉Kafka/Pulsar等开源流式处理平台者优先4、对大并发业务场景了解者优先。
负责字节跳动商业化方向数据仓库开发工作，包括但不限于数据建模，数据开发，和数据治理，数据质量等。负责与业务进行需求对接，抽象数据沉淀数据建模，结合产品矩阵灵活把控技术方案，高质量交付需求。参与商业化数据治理工作，提升数据稳定性，易用性和数据质量。
职位：银行大数据开发工程师/架构师人数：3人工作职责：面向信贷管理场景，负责新一代风险数据集市及数据资产化系统组件的规划、设计、开发及系统建设落地，平台化支撑客户风险管理数智化及公司的风险预警产品服务。任职要求：1. 统招本科及以上学历，计算机相关专业背景2. 至少3年以上银行数仓/集市/数据平台开发经验3. 具备扎实的编码能力、软件规范及质量深度实践4. 良好的大数据系统工程框架及组件化拆解整合能力5. 逻辑清晰，良好的需求分析、问题沟通解决能力6. 技术视野，至少非常熟悉银行数仓、治理、集市、信贷系统、大数据风控、数据智能处理、1104、ECIF等相关系统平台的技术栈其中之一7. 熟悉信贷场景及风控前中后台风险管理者优先
岗位职责：1、负责大数据平台架构的设计和性能调优，支持海量数据的离线和实时分析，对数据敏感；2、参与大数据平台的搭建与维护，保证数据平台的稳定和可靠；3、保证大规模的离线、实时任务正常的平稳运行；4、设计并完成ETL等大数据处理任务；5、负责数据仓库的设计与开发。岗位要求：1、有大数据处理分析经验，熟悉Spark、Hive、Flink等大数据处理平台；2、熟悉主流开源数据组件，包括但不限于YARN、HBase、ClickHouse、Kafka、Oozie等相关技术；3、熟悉Linux开发环境，熟悉基础命令操作和shell脚本的编写，熟悉大数据平台组件部署思路；4、熟悉java、scala、python等任一开发语言，有3年及以上相关开发经验；5、熟悉大数据平台设计，熟悉OLAP引擎架构设计；6、参与过大型复杂分布式系统的设计与开发者优先。
北京-大数据研发工程师工作职责：-负责构建大数据分析平台以及数据分析和挖掘工作-负责基于百度数据的离线和实时流分析-参与支撑业务的数据模型建设及数据指标的计算和分析-参与海量数据的存储、查询和运营数据分析体系搭建-运用Hadoop、Spark、ES等分布式计算和存储平台要求：-计算机相关专业应届毕业生-对Spark及Hadoop技术有深入了解-熟悉Python/Java/Scala/Php等编程语言，熟练使用SQL，有良好的编码习惯，对分布式有深刻理解-了解Windows、Unix、Linux等主流操作系统原理，熟练运用系统层支持应用开发-技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识，勇于解决难题-善于沟通和逻辑表达，拥有优秀的分析问题和解决问题的能力，良好的团队合作精神和积极主动的沟通意识-有激情，具有自我驱动力，追求卓越具有以下条件者优先：-计算机领域相关的编程大赛获奖、专业期刊发表文章或者有发明专利等-具备大数据云平台、计算存储平台、可视化开发平台经验，熟悉软件工程开发流程-具备专业领域的计算机知识和技能： Storm/Hive/Hbase/Storm/Kafka等
岗位描述：1. 负责构建Spark/HDFS大数据处理架构, 基于Spark技术的海量数据的自动化分析处理和统计工作； 2. 基于Spark框架大数据架构的设计、开发和维护； 3. 根据相关需求使用Spark Streaming、SQL进行数据处理、查询和统计等工作； 招聘要求：1. 要求2年经验以上，本科以上学历，数学基础、统计学、概率论基础扎实，条件优异者可适度放宽；2. 熟悉Spark相关技术，如：Spark Streaming和Spark SQL，有MLlib/mahout开发经验者优先； 3. 具备大规模系统的故障诊断与性能优化能力优先；4. 具备银行、基金、证券保险等相关项目工作经验优先。
岗位职责： 1.负责大数据组件产品服务平台（如智能监控，智能诊断等）建设； 2.负责大数据组件产品场景化（如一键迁移平台，实时计算等）建设； 3.负责大数据组件产品中组件（如hbase, spark）等的优化。岗位要求： 1.计算机、通信等相关专业，本科及以上学历，3年以上大型互联网产品或分布式系统开发设计经验； 2.扎实的java编程基础，熟悉Spring等开源框架，熟悉Java内存模型、多线程、NIO、类加载等； 3.有Hadoop、hbase、Storm、spark、TensorFlow等使用经验者优先，有大数据产品研发经验的优先； 4.对企业级或云厂商大数据组件平台有比较多了解，有相关开发管理经验者优先。
工作职责：1.大数据分析系统的开发和维护2.根据业务需求进行数据挖掘和统计分析3.海量数据的收集、存储和处理的优化任职要求：1.计算机相关专业，本科及以上学历2.3年以上大数据场景的开发经验3.熟练掌握python/c++/java至少一种编程语言4.精通Hadoop/Spark/Hive/Kafka/Flink等大数据生态，了解其工作原理，有丰富的相关研发经验5.有数据处理，ETL流程优化实战经验, 熟悉kettle/informatica等抽取工具6.了解分布式系统的设计与开发、负载均衡技术，系统容灾设计，高可用系统等知识7.全面、扎实的软件知识结构，掌握操作系统、数据结构、网络等专业知识8.熟悉基于Linux系统的程序开发流程及工具9.具备高效的独立开发能力，同时乐于团队协作并善于沟通
负责数据产品需求分析、数据建模，主导完成相关设计及编码
职位描述：1、负责传音离线数据和实时数仓的设计、建模、开发与维护，实现数据驱动业务增长2、深入了解业务，抽象数据模型，构建面向主题业务的数据模型体系3、通过数据仓库的建设，实现数据产品化，能够针对业务场景探索提供大数据解决方案职位要求：1、计算机相关专业本科及以上学历，3年及以上数据开发经验；有实际主题模型设计和开发经验优先2、熟悉Hadoop、Spark、Hive、Kafka、Flink、AirFlow、Dataworks、MaxCompute、QuickBi等大数据相关技术及组件3、精通SQL,具备SQL性能调优经验优先4、熟悉Java、Scala、Shell、Python等多种脚本语言，具备一定的开发能力5、熟练大型数据仓库架构设计、模型设计、ETL相关经验6、善于沟通，工作积极主动，责任心强，具备良好的团队协作能力
工作职责：1、负责数据模型建设和ETL开发、优化、技术攻关，BI报表开发2、负责大数据基础架构、产品技术的规划建设，包括数据总线、数据资产、数据产品、数据质量及稳定性保障体系建设。任职条件：1、计算机相关专业本科及以上学历，3年以上相关工作经历2、熟悉Java、Scala、Python中的一种3、熟悉OneData大数据建模方法论，熟练使用HiveQL4、具备体系化的数据质量与数据治理相关经验5、熟悉Hadoop、Spark、Flink、ClickHouse、Presto、Kafka、Debezium、DataX、Griffin、Atlas等大数据相关技术，深入了解其背后的实现原理并能够调优6、有数据挖掘经验，具备基础机器学习算法知识者优先7、有自动驾驶或互联网大厂工作经验优先考虑
岗位职责：1. 参与支持hadoop、mpp类大数据平台或数据仓库实施项目，负责技术验证、架构设计、ETL代码开发工作；2. 参与支持大数据平台、数据仓库等售前方案编写、POC技术验证等工作；3. 参与金融行业Hadoop大数据平台架构设计和软件技术选型方案研究及相关标准制定等工作；4. 研究大数据技术发展动态，研究新型计算框架，并能够提出优化解决方案。 职位要求：1. 本科及以上学历，具备3年以上大数据相关工作经验；2. 熟练JAVA语言3. 熟练掌握SQL及linux shell开发技能；熟练主流关系数据库中的一种（如Oracle、MySQL、PostgreSQL）4. 熟悉Hadoop，熟练掌握HDFS、HBase、Hive、Spark等开发技能，并具备2年以上开发经验5. 强烈责任心，善于协作，具有团队合作精神；6. 能接受短期出差工作安排
工作内容∶1. 参与数据产品、数据平台的架构设计，及其相关技术研发；2. 负责业务需求的理解与满足，数据价值的探查和挖掘，及相关数据开发；3. 负责企业级数据仓库、数据湖的建设，数据ETL的设计、开发与性能优化。任职要求∶1. 本科及以上学历；2. 3年以上实际大数据开发经验，熟练Java/Scala编程语言，有良好的编程习惯；3. 熟悉Hadoop/Spark/Flink/Kafka/HBase等大数据组件并深入理解其原理；4. 熟悉主流开源OLAP引擎ClickHouse/Doris/StarRocks等，或优先；5. 熟悉主流数据湖解决方案Delta/Hudi/Iceberg者优先；6. 有线上调优、源码阅读经验者优先，社区贡献者更佳。
岗位职责：1、负责构建分布式大数据服务平台, 包含大数据存储, 离线/实时计算, 实时查询, 大数据系统运维等工作2、基于大数据平台完成各类统计和开发任务,承担数据抽取、清洗、转化等数据处理3、熟悉业务形态，参与需求分析和方案设计4、协助承担架构性体系工作，配合技术实施方案、交流材料的编写岗位要求：1、1年以上Hadoop、Hive平台开发与服务经验2、Java/scala语言基础扎实，有一定java/scala程序设计语言开发能力3、精通Linux平台日常shell命令操作，可以熟练使用shell脚本程序开发，如熟悉python程序语言则更好4、掌握并精通内存的计算引擎spark和海量存储集并行计算引擎mapreduce的ETL 数据采集与SQL加工转换、汇总计算作业脚本程序开发5、熟悉与灵活运用HDFS分布式文件系统、hive数仓、YARN、spark计算引擎、Kafka消息队列、HBase等Hadoop各类服务组件
学历要求最高学历本科需211及以上高校最高学历研究生，无学校要求工作地点在上海任职要求1.熟练掌握SQL语言，熟悉Teradata、Greenplum、oracle、mysql中至少一种数据库2.熟悉大数据开发框架，熟悉Hive、spark、flink、hbase、impala、kylin、Kafka中两种以上大数据主流工具技术、对大数据基础架构和平台有深刻理解3.熟悉python、java、Scala等开发语言中的一种或多种，熟悉Linux操作系统和shell编程4.具有2年以上大数据平台、数据仓库相关领域项目开发实施经验，有丰富的数据建模、ETL架构与开发经验，深入了解相关技术者优先考虑5.熟悉金融业主题数据模型、中间层模型理论以及多维模型设计，有银行业IT系统开发经验者优先考虑6.热爱技术，能够主动研究相关新技术，具有较强的学习能力
工作职责：1、负责搭建永辉超市数据中台，推送永辉零售业务快速发展2、负责永辉超市大数据平台数据仓库（离线、实时）的模型设计和搭建3、参与具体项目负责数据开发工作4、负责数据平台对外数据接口设计和开发5、与业务需求方、系统技术方沟通，梳理数据加工逻辑任职要求1、从事数据仓库领域至少3年以上工作经验，精通数据仓库模型架构设计与ETL开发经验，掌握维度建模设计方法，具备海量数据处理经验;2、精通掌握分布式计算框架Flink、HDFS、Mapreduce、Spark、Hive等其中一项, 有Flink经验者优先;3、熟练掌握数据库技术，包括Druid、HBase、Redis、Mysql等，有实际调优经验者优先;4、熟练掌握Scala、Python、Java、Shell等编程语言的其中一项;5、熟练掌握Azkaban、Airflow、Datax、Sqoop等开源ETL调度、同步工具;6、有实际的企业级数据仓库优化经验及较强的Trouble Shooting能力优先;7、能够快速融入团队，具备良好的语言沟通能力与表达能力;8、具备良好的自驱力，对技术有追求和激情，研究前沿技术
工作职责1. 根据不同场景，构建业务指标体系，能够持续挖掘日常业务数据，及时、准确披露产品整体的运作情况；2. 通过数据分析为运营决策等提供数据支持；3. 通过数据收集/计算/分析，监控产品关键指标，及时发现异常波动并推动解决；4. 通过对产品数据进行深入分析，建立有效的数据运营体系，推动产品数据化运营；5. 负责产品运营报表开发维护，提供多层面数据支持；6. 通过大数据挖掘用户群体行为和属性特征，帮助更好的理解客户，作用精准化运营体系； 任职资格1、本科以上学历，计算机、数理统计相关专业；2、3年以上相关工作经验；3、精通SQL，数据仓库的ETL开发，拥有极好的数据分析能力；4、有Hadoop集群相关组件的开发、调优、监控等工作经验，负责过大规模Hadoop集群的规划、部署、自动化运维者优先；5、熟悉大数据生态相关技术，包括HDFS、MapReduce、Yarn、Spark、Hive、HBase、Flink等，对分布式存储和计算架构熟悉者优先。
1. 负责数据研发工作，针对业务诉求和实际数据情况，能独立完成项目的系统分析，根据开发规范和数据模型设计实现数据开发任务，保证数据质量；2. 基于阿里云自主研发离线计算MaxCompute平台与实时计算Blink平台，进行海量数据模型设计、数据ETL开发，整合和处理海量数据；3.数据系统建设和构建数据应用，包括数据采集、提取、分析与数据产品化，以及模型架构设计及优化工作；4. 同产品、BI等团队协作深度挖掘数据商业价值，建设公共数据服务，实现高质量数据共享，推动部门数据应用能力；职位要求：具有丰富的数据研发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验。较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验；有从事分布式数据存储与计算平台应用开发经验，有Hadoop、Spark、Flink 等离线计算、实时计算数据研发经验，对Flink有一定了解者优先。具备较扎实的理论基础和工程能力，具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；责任心强，做事细致，具备较强的沟通协作能力和快速学习能力
工作职责：1、自动化ETL平台的设计与开发，包括自动化数据模型设计与代码生成、ETL流程的监控自动化、数据资产管理工具、维度管理工具等将传统数仓操作自动化的工具；2、数据仓库ETL流程的优化及解决ETL相关技术问题；3、负责携程国际业务数据治理方案并落地，制定和持续更新数据仓库规范，并通过代码进行监控，落地为数据质量分；4、数据仓库元数据的维护和分析，挖掘数仓中存在的问题并加以改进，包括数据安全、数据质量、性能优化等问题；任职要求：1、计算机、软件工程、电子信息等专业，本科以上学历； 2、精通数据仓库建模和ETL开发，熟悉数据仓库主题域和分层方法；3、JAVA基础扎实，熟悉io、多线程、集合等基础框架，熟悉分布式、缓存、消息、搜索等机制优先。熟悉Python、Shell等一种或多种语言。有编写UDF函数经验。4、精通SQL语言，熟悉Hive/Spark SQL调优；5、有企业级数据中台工作相关经验。熟悉数据血缘追踪，数据质量监控等数仓元数据和平台的概念和使用；6、熟悉批量离线式分布式并行计算技术（如Hadoop、MapReduce、Hive、Spark等）；7、熟悉MySQL、Oracle等一种或一种以上关系型数据库；熟悉TiDB、Clickhouse、Kudu等一种或一种以上分布式数据库；了解Redis、HBase等非关系型数据库；8、有较强逻辑思考能力强，问题分析能力，思维缜密；9、勤奋好学，良好的表达沟通能力、团队合作及文档交付能力；10、忠诚、勤奋，对工作有责任感和团队精神，能够在压力下工作。
了解hadoop生态，有etl经验，大数据工作经验1-3年。能接受出差岗位是外包岗位
1、有ETL、数据仓库、数据集市、大数据、BI等相关开发经验，精通SQL 2、熟悉掌握主流数据库系统中的一种或多种，Oracle、DB2、MY SQL、SQL Server 等3、熟悉Hadoop、Hive、Kafka等相关技术并有相关实践经验 4、熟练使用数据ETL开发工具，如Informatica PWX/PWC/PI等 5、熟悉保险行业相关业务知识6、具备良好的领导、沟通、团队协作和创新能力，有强烈的责任心
1.   本科以上学历。2.    3-5年及以上工作经验；有资产管理优先3．有金融保险行业相关工作经验者优先； 4．思维活跃、善于学习、有较高的工作积极性和主动性．熟悉两种及以上主流数据库（Oracle、Sybase等）；2．精通Informatica、datastage等ETL工具； 3．能熟练进行SQL查询优化，熟练使用存储过程、有海量数据处理经验优先； 4．熟悉Linux shell脚本者优先；5.  熟练的文档读写能力；
1、本科及以上学历，计算机及相关专业毕业(专业优先计算机、数学相关，能力突出的可放宽)2、1年以上互联网ETL及数据仓库全流程(抽数，清洗，建模)开发经验，精通hadoop组件（不限于sqoop hive hdfs kafka等）3、熟悉Hadoop生态系统，精通HIVE,精通MapReduce计算算框架，有海量处理，运维及调优经验4、能够根据业务部门的数据分析需求给予实现与支撑5、负责建立业务系统数据模型，对数据进行分析，展示6、熟悉HANA,Oracle,高斯,Mysql等主流数据库，精通SQL，有较好的SQL性能调优经验7、熟悉存储过程开发优先8、就别良好的沟通能力、有较强的责任心、具有良好的学习能力、沟通能力、有一定的抗压能力
职位诱惑：平台良好,高成长性职位描述：*职位信息：1、参与数据仓库项目的技术架构及其实施，具体包括数据仓库的数据模型设计、ETL设计开发、元数据管理、数据质量管理、报表平台等方面的工作;2、参与数据仓库的运维工作，保障系统的运行稳定；3、参与规划数据仓库的技术框架，进行前瞻性技术研究；* 任职要求：1、本科及以上学历，3年及以上工作经验；2、熟练使用HIVE SQL，能独立处理SQL性能问题；3、对数据仓库系统架构具有良好的认识，参与过大型的数据仓库项目实施优先；4、具备较好的数据仓库建模设计、ETL设计能力；5、良好团队协作和沟通能力
负责交通领域的大数据分析和建模：1、负责数据分析和建模项目的需求分析和技术实现等；2、对应用中的数据模型进行跟踪、调整和优化；3、承担建设基于Hadoop/Spark生态的大数据离线/实时处理平台；4、参与业务数据、生产日志的抽取、转储、检索等相关工作；5、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景；6、211,985学校优先。7、应届生请走官网校招通道，不再做单独回复，谢谢。
工作职责：1、参与和完善基于大数据平台的量化投研平台的建设；2、根据业务需求对于数据进行实时处理和指标运算；3、调研大数据平台方向的新技术；4、负责自建数据平台稳定运行、数据跑批稳定；5、参与部门数据规划和硬件规划工作；6、其他数据分析需求、数据可视化的支持。任职资格：1、硕士（含）以上学历；计算机及相关专业；2、三年及以上工作经验，其中至少有二年（含）以上大数据相关工作经验；熟练掌握相关大数据分析处理机制；具备证券、期货等行情数据处理经验；3、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Clickhouse）等。熟悉Java/Python等语言，能够熟练的进行开发。具有主流数据库开发或运维经验。具有编写sql脚本的能力；4、熟悉docker容器、k8s集群者优先，对任务调度熟悉者优先；5、具有量化同业及交易厂商大数据相关经验优先考虑。
岗位职责在这里，你将深度参与大型企业数字化转型过程，与业界最优秀的专家共同见证华为管理体系的数字化变革：1、管理客户需求、产品定义、架构设计、开发测试、运营运维全生命周期的产品数据管理。2、负责研发域信息架构设计、产品主数据管理、产品配置E2E解决方案设计与交付。3、负责集团级的数据分析/数据管理平台建设，数据服务交付，支撑公司数字化转型。岗位要求专业知识要求：1、数据科学、信息管理、信息学/情报学、电子信息、工业自动化、数学及计算机相关专业本科及以上学历；2、有较强的业务理解力，具备良好的数据思维、数据建模能力；3、至少掌握一种编程语言或工具：Python、Java、SQL等；熟悉hadoop，HDFS、Hive、Sqoop等大数据平台；4、具有优秀的大数据分析能力和实践经验；用户行为分析能力、具有自然语言处理、搜索与推荐、知识图谱等专业背景或实践经验；5、具备团队合作工作能力和解决问题的能力、善于沟通、乐于合作、热衷新技术、善于总结分享、喜欢动手实践；6、优选条件： （1）有PLM/ERP/其它信息管理、或大数据平台建设实践与经验； （2）熟练掌握范式建模及维度建模方法，熟悉Erwin、PowerDesigner等设计工具，有数据仓库开发、行业数据模型设计经验优先
大数据产品开发工程师熟悉hudi技术原理，熟练掌握spark hdfs hbase等技术具备0-1大数据平台建设经验精通java原理与应用编程了解python语言
岗位描述1. 负责广告部大规模机器学习离线样本数据流的开发和维护，提高离线特征抽取计算的复用性，2. 负责广告部大规模机器学习离线特征的存储组件选型和开发，避免特征数据重复存储，提高存储效率3. 负责广告部大规模机器学习离线数据流平台的开发和维护，提高算法离线特征调研迭代效率4. 构建机器学习数据质量体系，持续提升数据质量和及时发现数据问题5. 跟踪和调研前沿的数据处理和分析、存储技术，不断提升计算和存储效率岗位要求1. 对数据处理相关技术如hadoop、spark、flink等有一定的了解2. 对Java、Python有一定的理解3. 对hbase等列式存储系统有实际使用经验4. 有机器学习、大型电商系统、互联网广告、数据挖掘、流计算相关经验者优先
【岗位职责】1、负责存储大数据存算分离 、数据湖、流式存储 特性的设计、代码开发，测试验证及运维工作，保证系统可靠性，可伸缩性和高性能；2、负责交付特性/子系统设计文档和接口，主导特性交付；3、参与在实现中验证设计的工作，完成设计问题分析和预防的工作。【岗位要求】1.掌握C/C++/Java/Scala/Python语言，熟悉Linux操作系统；2、熟悉oracle、mysql等主流数据库技术中的一种，有在中大型项目中的实际应用经验。3、熟悉大数据相关组件Hadoop/Flink/HBase/Spark/Sqoop/Oozie/Flume/Kafka/Storm/Hive/Elasticsearch/Presto/CarbonData/Hudi/ClickHouse内核源码，系统性能调优和分布式架构经验优先；
岗位职责-对接算法落地流程，开发算法平台与特征平台。-负责基于海量数据的分布式模型训练框架开发-负责海量数据的离线与在线数据处理。任职要求-计算机，统计学等相关专业，本科及以上学历，至少3年以上相关大数据开发经验-精通hive/mysql等数据库、精通sql语言，对数据库优化、sql优化等有相关经验-掌握spark、flink等一种或多种数据处理框架，并对其架构有深入理解，有源码经验尤佳-熟练掌握JAVA/Scala之一，对数据结构和设计模式有较为深刻的理解-有机器学习特征平台以及机器学习训练平台开发经验优先-有较强的学习、分析和解决问题能力，良好的团队意识和协作精神以及沟通能力
岗位职责：1、根据项目需求，分析，设计，并实现系统功能。使系统功能具有合理性和可扩展性2、参与代码的实现，并编写技术文档，对通用技术实现复用技能要求：1、熟悉Hadoop底层文件系统，熟悉Hadoop分布式计算框架（HDFS、Hbase、Hive、Mapreduce、Spark、Storm、Flink等2、精通Java, Scala, Python 至少两种编程语言，有较强的分布式计算基础3、熟悉业界有影响力数据仓库和大数据领域的产品、解决方案形态和技术4、熟悉OLAP、OLTP引擎和DB，熟悉主流数据整合、治理技术和工具
1，有丰富的数仓理论知识和实践，对数仓分层有深刻了解。2，熟练掌握sql语法和各种函数，能基于sql实践经验做一些性能优化，能基于sql处理数据3，熟练使用spark/flink等分布式计算框架，深入了解原理，并有相关处理大批量数据的实践经验，可以做一些性能调优4，至少熟练掌握一门编程语言，如java/scala/python5，有较强责任心，保持学习，积极主动
职责；1、负责数据接入、数据提取、数据清洗、底层重构、业务主题建模等工作；2、参与数据集市开发，用户画像标签开发，用户ID打通；3、负责接口平台、自助分析平台、客户经营平台等系统的建设和维护；4、针对具体大数据应用场景，提供有效解决方案，并针对具体模型落地实施要求；1、大专及以上学历、计算机相关专业，3年以上开发经验；2、精通SQL，至少熟悉Oracle/Mysql/Posgresql中的一种。3、熟悉HADOOP生态相关技术，至少熟悉Hive、Hbase、Spark组件的中的一种，能对其进行故障分析、性能调优；4、了解linux系统，能够熟练使用常用的shell脚本命令；5、大型互联网工作经验者，处理高性能、高并发实践经验者、精通Scala、Python,JAVA者优先考虑。6、具备良好的学习能力、分析和解决问题能力；7、具有高度的责任心和团队合作精神。
岗位职责：1、负责基于Hadoop、Spark平台的海量数据处理、数据计算、数据开发。2、负责高并发、高可用性、高可扩展性的线上数据系统开发。3、负责大数据项目的相关开发支持。4、负责Hadoop集群、Kafka集群的维护和性能调优。任职要求：1、计算机及相关专业本科及以上学历，5年以上工作经验。2、精通java和scala开发技术，熟练掌握多进程/多线程开发，熟悉常用设计模式。3、熟练掌握ElasticSearch、Hadoop、Spark、Sqoop、Flink、Kafka、HBase、Impala、Kudu等大数据开发技术，进行过大数据项目实践。4、熟练掌握Mysql、Redis、MongoDB等常用数据库。5、有机器学习、数据挖掘、特征变量库的经验者优先。6、具有分布式计算后台开发经验者优先。7、对技术有激情、有追求；富于技术创新精神，勇于解决技术难题。
岗位职责：1、优化现有大数据集群的架构和性能；保证系统的安全、稳定、高效运行；2、负责大数据产品（如CDP等）的架构设计和开发，以及对外数据服务的开发工作；3、与产品经理、测试工程师等其他团队沟通合作，保证大数据产品研发工作的质量和进度；4、参与新技术的技术难题的攻关，带动团队年轻成员共同成长。岗位要求：1、计算机、数学相关专业全日制本科以上学历；2、至少5年以上大数据应用系统的开发和设计经验；有知名互联网公司、零售或电商行业工作经验优先；3、熟悉Hadoop，熟练掌握ElasticSearch、HBase、Hive、Flume、Kafka、Flink等大数据技术；4、熟悉实时计算引擎，具有丰富的Spark、Spark Streaming的开发经验；5、精通Linux环境，精通Java/ Scala开发；具备分布式系统或数据库系统的理论基础，熟悉分布式计算系统的工作机制；6、善于表达，思维活跃，性格开朗，责任感强。
招聘岗位：大数据工程师（3名）  薪酬待遇：13K-25K年龄：25-50岁学历要求：硕士及以上(特别优秀，学历可放宽至本科)工作地点：上海市奉贤区奉浦大道123号（上海商学院）作息时间：周末双休、寒假（1个月）、暑假（2个月）【寒暑假薪酬正常标准发放】。工作就餐：学校食堂就餐，费用非常低。岗位职责：1、负责、参与大数据相关专业培养方案的制定与完善；2、负责、参与大数据相关专业课程建设，包括教学大纲、教材、教学案例、教案、讲稿、多媒体课件等；3、负责大数据相关专业课程的日常授课工作；4、负责大学生双创教育（创新创业教育）指导工作；5、调研大数据人才市场需求发展趋势，研究最新大数据相关技术，更新人才培养方案及课程授课内容； 6、能够根据大数据项目开发需求，编写相关售前方案和大数据项目开发。任职要求：1、计算机、数学等大数据相关专业硕士及以上学历；2、熟练掌握Python、Java、Hadoop、Hive、HBase、Zookeeper、Spark、Storm等工具的使用；3、熟练掌握大数据处理技术的典型应用场景；4、具备良好的语言表达能力，有较强的责任心和团队协作意识；5、有3年及以上大数据相关项目开发工作经验；6、有数据挖掘、数据分析、数据仓库、推荐算法等开发经验者优先；7、有大数据业务培训授课经验者优先；8、具备较好的文字功底，能够独立编写方案。
职责： 1、数据清洗入库：将日志数据解析入库到oracle、hive等数据库。2、数据报表统计：利用Hadoop yarn Hive/Storm/Spark进行开发、存储、分布式计算应用的代码实现。3、算法模型实现：对所给的算法模型进行开发实现。4、数据实时平台开发与维护5、大数据处理平台应用的开发工作，对外提供数据接口。6、使用永洪/帆软做报表开发，为业务方提供图形化数据展现要求1、计算机相关专业，专科以上学历，有较好的英文阅读能力；2、3年以上Hadoop/Storm/Spark/Hive开发经验，对分布式、并行计算理论有深刻理解;3、熟悉hadoop,linux等环境，精通java/perl/python 优先4、熟悉主流数据库技术，如oracle、Sql server、mysql、hive、hbase等；5、熟悉数据开发流程，了解日常作业的部署和调度6、有很好的技术敏感性，良好的学习能力和吃苦耐劳能力。
"大数据(高级)研发工程师：上海/北京/杭州职位描述	1、负责头条系产品短视频用户体验的持续优化；	2、构建短视频相关数据仓库，分析和报表系统；	3、设计并优化视频播放QoS数据上报机制，构建面向用户体验的APM系统；	4、通过建设实时数据分析，构建智能播放调度策略和自动报警归因系统； 职位要求	1、本科及以上学历，计算机、通信等相关专业，两年及以上全职工作经验；	2、有扎实的编程能力，有优秀的设计和代码品位，有独立的代码实现能力 ；	3、深刻理解计算机原理，有良好的数据结构和算法基础；	4、熟悉数据采集、清洗入库、统计计算、Web展示核心要点，可实现指标计算需求；	5、熟悉至少一个分布式框架，如 Hadoop/YARN、Hive、Spark、Storm、Kafka 等，有Flink实时处理经验优先；	6、优秀的理解沟通能力，能快速理解业务背景，责任心强，具有良好的团队沟通与协作能力；；	7、有大数据处理、数据平台、数据仓库经验者或数据挖掘算法优先;"
上海农商银行业务处理中心（来安路1045号）学信网本科完成产品大数据相关内容开发 完成产品与大数据之间的对接工作 对大数据产品代码的编写、调试、测试及优化任职要求： 具有2年以上的Hadoop及java开发经验  熟练linux操作系统的基本命令，精通java开发技能  能够独立完成hadop平台的搭建，对CDH、FI、Hortonworks其中一个有了解 熟悉各个大数据组件，尤其对HBase，Hive，Spark，HDFS、Yarn,solr等能够熟练编写代码，对大数据各个组件原理有清晰深刻理解 对spark、hive、hbase,sorl有较强的优化能力，了解MapReduce运行原理，能够熟练编写MapReduce 有阅读源代码的能力，根据阅读源代码能够发现问题解决问题的能力 具有很强的团队意识、沟通能力和独立解决问题的能力，学习能力和主动性强，具有钻研精神，充满激情，乐于接受挑战
岗位职责：1、参与快递大数据的开发，实现数据驱动业务，降低营运成本，提升公司效率；2、根据业务需求进行数据模型的调研、设计、开发及验证工作，并持续进行模型的优化；3、负责数据模型架构的构建，建立数据抽取、清洗、校验等数据加工流程规范及OLAP多维数据分析模型；4、持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。岗位要求：1、大专及以上学历，计算机相关专业，深入理解数据建模及业务抽象；2、熟悉数据管理标准、元数据管理、数据质量管理；3、3年以上的基于Hadoop架构DW/BI项目实施和开发经验；熟悉Hadoop Hive, Spark sql等；6、良好的沟通能力和团队精神，具备创新意识。
职位描述：1、大数据领域软件开发，包括算法开发、测试等相关工作；2、工业设备数据的存储、处理与分析；3、工艺设计、生产控制和设备匹配等工业流程的自动化实现；4、协助Web端服务的开发与维护；5、完成相关技术文档的起草、整理和管理工作。 岗位要求：1、扎实的计算机系统和算法基础知识，有良好的操作系统、数据结构和软件编程算法功底； 2、熟练运用C++、Python、Java、VBA语言中的一种或多种；3、熟悉Oracle, MySQL, PostgreSQL, NoSQL DB和Hive, GreenPlum等数据管理技术中的一种或几种；4、熟悉UG、CAD等软件二次开发者优先；5、熟悉Hadoop, Hive, HBase, Spark, Flink, ElasticSearch, Kafka, Kylin等常见大数据组件者优先6、英语良好，可以顺畅地阅读与理解英文技术资料；7、能够适应短期的出差和现场调试。
职责描述1、利用大数据相关组件实现海量的搜集和存储；2、利用大数据相关组件实现数据清洗，转换等工作；3、利用大数据相关组件实现数据可视化以及海量数据下的多维钻取分析；4、整合大数据相关组件，构建数据沙盒 ，支撑多租户的数据分析5、组件性能调优；理想的求职者1、 5年以上相关工作经验，至少熟练掌握 Java Scala Python中的一种或多种；2、熟悉 Spark Flink Mapreduce等分布式计算框架。3、熟悉 Storm SparkStreaming等流处理框架。4、熟悉 MPP和搜索引擎，例如 Impala Presto Elasticsearch等；5、熟悉熟悉分布式存储系统，例如 HDFS Ceph等。6、熟悉 NoSQL存储，例如 Hbase MongoDB CouchDB等；7、了解 PowerBI Tableau等任一一款可视化工具优先考虑；8、有大数据相关组件性能调优经验或机器学习经验优先考虑；
"1、参与公司大数据平台整体架构的规划和设计； 2、参与大数据平台技术框架的选型和开发； 3、参与大数据平台的搭建，完成系统调试、集成与实施； 4、参与项目开发过程中的技术攻关及核心代码编写； 5、参与大数据应用开发，提供数据应用项目技术支持，参与数据应用类项目任职资格： 1、	本科及以上学历，计算机相关专业，具有2年及以上的大数据平台搭建、架构和研发经验; 至少参与过一个完整的大数据开发项目； 2、	熟悉kimball数据维度模型，数据仓库分层模型3、	熟悉Linux系统，熟悉shell编程，在操作系统、计算机网络和安全方面具备系统知识和相关经验 4、	熟练掌握Java/Scala，熟悉大数据离线计算生态体系，对Hadoop、HDFS、HBase、MapReduce、Kafka、Yarn、Hive、Spark等开源组件有研究，有海量数据处理经验； 5、	熟悉日志采集传输、消息队列相关技术，对Kafka、Flume、Fluentd等开源组件有深入研究 6、	至少熟悉一种编程语言（Python/Java/scala）。7、	精通离线和实时数据处理流程，掌握离线数据处理框架，掌握实时数据处理常用技术工具等，有Flink项目经验； 8、	有数据仓库开发经验/BI系统开发经验者优先；"
岗位职责：1、参与多维数据分析平台开发，从数据接入到查询应用的开发，提供离线数仓与实时数仓的数据分析功能；2、参与建立数据标准化管理体系，构建数据知识图谱，沉淀企业级数据资产；3、参与大数据平台工具开发，提供数据传输、数据计算、数据分析、数据存储能力，为内部基础平台、应用系统提供支持；4、参与大数据平台的架构设计、搭建、管理、运维，及本地化中台部署；5、不断探索行业内最新的大数据解决方案，提升算力、降低成本、拓展多元数据服务能力，如批流一体、数据湖等；任职资格：1、熟悉Linux操作系统，熟悉常用脚本语言Shell，Python等；2、熟练JVM平台语言，包括Java、Scala、Kotlin，对分布式和调优有深刻理解，熟悉JVM原理，做过JVM调优者优先；3、熟悉开源大数据技术栈，包括但不限于Hadoop、MapReduce、Spark、Flink、Kafka、Kudu、Clickhouse、Druid、Iceberg、Hudi、Doris；4、熟练掌握SQL开发及调优，有Impala、Hive、Presto开发经验者优先；5、深入理解常用的数据建模理论，有大规模数据处理、分布式存储计算、数据仓库模型建设经验优先；6、熟练使用Redis、HBase、MySQL、HDFS、Kudu等存储并掌握其原理；7、有实时数仓开发经验优先；8、对数据敏感，具有较强的逻辑思维能力和分析解决问题能力，对大数据技术栈有热情，能够主动发现并研究新的大数据技术方向；9、具备出色的需求分析能力及快速学习能力，能深入理解复杂的业务逻辑;态度积极主动，具有主动思考并解决问题的能力;思维缜密，责任心强，具有较强的沟通能力及团队合作精神；
岗位需求：1、5~8年经验，在大数据平台上开发可扩展的数据湖/数据仓库。2、对SparkSQL/HiveSQL语言有丰富的知识和经验，了解Presto或其他MPP数据库。在气流或其他数据仓库调度工具方面有良好的经验。有良好的数据仓库建模经验。3、熟悉AWSS3、EMR、lambda和AWS组件或其他云计算上的类似技术堆栈。4、实时数据处理经验，流数据处理经验将较强有关于Python编程的经验。5、在产品和工程领域之间建立积极关系的强大技能。能够快速获取新的编程语言、技术和框架。6、有在敏捷和Scrum开发过程中的工作经验。7、英语读写能力
职责1.  负责Java+Springboot应用开发、测试、部署及维护2. 负责OLAP架构设计及实现3. 负责分布式架构应用设计及维护技能要求1. 熟悉主流OLAP平台基本原理及优缺点2. 至少熟悉一门编程语言，Java优先3. 熟悉Springboot应用及开发4. 熟练掌握SQL者优先5. 有Clickhouse调优经验者优先5. 有开源项目经验者优先
职位描述：1. 负责数据中心平台建设； 2. 根据业务需求优化升级现有平台功能，为业务分析和数据应用提供可行的解决方案 3. 调研和落地大数据平台相关新技术，实现技术分享和沉淀； 任职资格： 1. 3年及以上Java开发经验，有良好的 java 编码习惯和能力 2. 熟悉 linux，能使用 shell/python脚本处理工作 3. 熟悉 mysql 数据库，redis 缓存等 4. 对大数据组件（hdfs，hbase，hive，presto，kudu，impala，kerberos，sentry，altas，flink，storm 等）有一定了解或者使用经验者，优先考虑。
工作职责:1、负责离线和在线数据的采集、清洗和加载；2、负责通过专项分析，输出专项分析报告，为业务决策和监控提供数据支持；3、负责携程大量商户/用户数据的分析和提炼。任职资格:1、本科及以上学历，计算机相关专业；2、精通SQL，具备海量数据开发能力，至少熟悉一种主流数据库(比如MySQL/SQLServer/Oracle等)，有Hive使用经验者优先；3、熟练掌握Java，具有良好的编程能力和代码风格；4、具备快速学习能力、沟通协调能力及团队精神，有较强的责任心和学习积极性。
职位描述：1、负责Hadoop数据平台数据开发工作；2、基于Hive的数据仓库设计与性能优化；3、设计和实现数据收集模型、数据分析处理模型和数据汇总展现模型；4、基于Tableau，开发数据统计报表及BI工具；5、了解Hadoop生态圈其他组件；职位要求：1、全日制统招本科以上学历，至少2-3年以上Hadoop开发经验；2、熟悉Hive及其性能调优，熟练掌握数据仓库建模方法；3、熟练编写SQL语句；熟悉Java或Python，或有至少一门动态语言使用经验；4、对数据有着强烈兴趣，有部署大规模Hadoop集群的经验者优先；5、良好的学习能力，保持对新技术的敏感性；
1、负责字节跳动海量数据的处理，在分布式计算、存储平台基础上建立高效、稳定的数据链路，打造平台化工具和数据产品；2、与业务团队深度合作，应用数据开发、分析、挖掘等技术，为包括抖音、今日头条在内的所有字节跳动业务提供数据解决方案，挖掘数据价值，提升数据使用效率；3、深入底层系统与引擎，解决大规模生产环境集群可用性和性能优化问题；4、以上职责描述光谱较宽，覆盖“大数据工程师”的多个形态，具体岗位的工作可能涉及其中一种或多种。
有实际的大数据平台（Hadoop、Spark、Hive）开发经验；熟悉运用PySpark、Scala、Spark SQL、Hive SQL进行大数据任务开发工作；熟悉各种关系型数据库系统，熟练运用SQL；Cloudera平台经验；有实际的Azure云平台数据开发经验，Azure Databricks，Azure Synapse，Azure Data Factory等；熟练运用Kafka/Spark Streaming进行大数据任务开发工作；熟练运用Azkaban/Oozle等任务调度工具进行任务调度开发工作；熟练运用Informatica ETL开发工具；SQL SERVER数据库经验。派微软项目工作，工作地点为实际项目现场。
1. 计算机本科及以上学历;2. 熟练数据模型设计ETL设计精通数据仓库相关理论3. 拥有良好数据库设计和开发经验;4. 熟练使用SQL，Hive等技术，了解Hadoop工作原理5 .有Spark SQL、Pyhon等开发经验；6. 有Linux shell经验者、懂算法或流式等大数据应用技术优先7. 工作认真负责，有良好的团队合作精神，良好的分析能力与沟通技巧。
1.较为丰富的数据仓库及数据平台的架构经验，精通数据仓库建模及ETL设计开发；有海量数据性能处理经验；在大数据资产管理与治理有一定成功产品化经验；2.有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop、spark等生态相关技术并有相关开发经验，有Hive/Flink的开发经验尤佳；3.具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；4.良好的思维逻辑性、语言表达能力；有较好英语口语能力尤佳。5.有金融领域的工作经验优先。
职位描述1、参与数据中台的汇聚和采集ETL详细设计和开发工作；2、负责数据平台相关数据管理工作，如研发规范、质量规范、保障规范的制定与推动实施落地；3、负责数据分析需求的模型开发和实现；4、负责来自业务团队数据方面的研发需求。职位要求1、5年以上大数据开发经验，精通SQL语言，具备存储过程开发能力，能熟练进行SQL查询优化；2、熟悉Hive数据仓库设计，了解数据仓库模型及思想、维度建模思想，了解数据仓库、CDP者优先；3、熟悉Hadoop、Spark、Flink、Sqoop、DataX、Hive、Flume、Kafka等相关技术；4、熟练scala、python、java中至少一种语言；5、具有良好服务意识，抗压力和沟通能力强，有过toB行业服务经验优先。
职位描述岗位职责：1、参与数据平台的构建工作, 演进现有数据平台基础设施；2、参与数据部门的相关的数据清洗开发；3、负责或参与项目开发过程中的技术攻关和性能调优;4、负责数据研发工作，针对业务诉求和实际数据情况，能独立完成项目的系统分析，根据开发规范和数据模型设计实现数据开发任务，保证数据质量;任职要求：1、 本科学历，计算机等相关专业，具有2年及以上大数据（hive/spark）开发经验；2、 具有丰富的数据研发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验。2、 有Java开发经验，熟悉linux，熟悉Python；3、 对Hive/HDFS/Yarn/Spark/Hbase/Flink等有较深的认识, 熟悉大数据架构及解决方案，并有实际工作经验；4、 熟悉数据仓库建设，对平台建设、方法论、ETL、数据治理有较好的理解；5、善于学习，有较强的责任心，能够自我驱动；6、有算法及数据结构基础者优先；7、具备丰富的高性能大并发场景下开发及架构经验及性能调优经验优先。
工作职责- 负责基于 Hadoop 框架的海量数据平台建设；- 参与大数据平台的数据架构设计，完成从业务模型到数据模型的设计；- 基于海量数据的数据仓库，为业务搭建通用的查询和分析解决方案；- 管理并优化存储和计算资源利用效率、监控并维护例行 ETL 任务；- 梳理整体业务指标，可视化报表开发；- 对于开源项目进行二次开发。任职资格岗位要求- 本科及以上学历，计算机科学及相关专业优先；- 熟悉常用的数据结构和算法；- 熟悉大数据技术框架以及其生态的二次开发和使用经验（如 Hadoop / Cassandra / Spark / Flink / Presto / Hive / Kafka / Flume 等）；- 扎实的 Java 开发能力，能有 Python / Scala 经验尤佳，具备一些算法能力尤佳；- 业务理解力强，对数据敏感，有互联网行业产品数据分析经验者优先；- 具有良好的沟通能力和团队合作精神，优秀的分析问题和解决问题的能力，对技术有热情。
"大数据研发工程师岗位职责:1. 参与或负责规划建设优化流批一体的大数据计算和分析平台，保证系统的高可用和稳定2. 深入理解数据和业务逻辑，参与或负责私域电商数据仓库建设（数据建模，ETL 研发，性能优化，元数据管理等） 3. 与产品，运营等团队协作深度挖掘数据价值，推动数据产品，系统和方法论的演进 岗位要求:1、	计算机及相关专业本科以上学历，具有良好的数学、统计学、计算机相关知识2、	三年以上大数据开发经验，熟悉大数据生态体系，熟悉 Hadoop，Hive，HBase，ES，Clickhouse 等技术的基本原理，熟练掌握Spark或 Flink，有实时大数据研发经验者优先。3、	熟悉数据仓库理论和维度建模，有较丰富的离线或实时数仓建设和数据 ETL 设计开发的经验，对元数据管理、数据质量管理等有经验者优先。4、	扎实的Java/Scala编程基础，良好的沟通能力和团队协作能力，较强的学习能力和责任心。"
工作职责:1、负责搭建永辉云创新零售数据中台，推动永辉新零售业务的快速发展;2、负责云创大数据平台的架构设计、搭建;3、负责云创数据仓库（离线、实时）的架构设计、数据模型设计及实施落地;4、负责云创各类数据报表的落地;  任职资格:1、从事数据仓库领域至少4年以上工作经验，精通数据仓库模型架构设计与ETL开发经验，掌握维度建模设计方法，具备海量数据处理经验;2、精通掌握分布式计算框架Flink、HDFS、Mapreduce、Spark、Hive等其中一项, 有Flink经验者优先;3、熟练掌握数据库技术，包括Druid、HBase、Redis、Mysql等，有实际调优经验者优先;4、熟练掌握Scala、Python、Java、Shell等编程语言的其中一项;5、熟练掌握Azkaban、Airflow、Datax、Sqoop等开源ETL调度、同步工具;6、有实际的企业级数据仓库优化经验及较强的Trouble Shooting能力优先;7、能够快速融入团队，具备良好的语言沟通能力与表达能力;8、具备良好的自驱力，对技术有追求和激情，研究前沿技术;
大数据工程师岗位职责1、深入理解公司业务与技术架构，参与规划、建设房地产数据中台，包括数据仓库架构、数据模型设计、ETL开发等2、主动跟进新业务及业务发展，通过从业务到技术源系统、到数据指标的转换，发现并解决数据问题3、保障数据仓库数据质量，促进良好的数据治理，促进企业数据资产化任职资格：1、计算机或相关专业本科以上学历，具有扎实的编程基础理论知识2、精通数据仓库设计，精通常见数仓各垂直分层的逻辑设计、划分，以最优化的分层设计和功能复用，建立结构清晰的数据仓库层级结构，达成平衡存储与计算，满足数据一致性和高效分析；3、精通SQL，熟练掌握MySql、Oracle、PostgreSQL等至少一种主流关系数据库；有复杂存储过程和sql优化能力的优先4、具备良好的coding素养和习惯，熟悉Java/Python/Shell中的一种或多种；5、熟悉hadoop及生态（hdfs、hbase、hive等），理解背后工作原理；了解其他常用技术（spark, impala, GreenPlum，presto, Elasticsearch等)6、对元数据管理，数据质量管理有实施经验者优先。7、具备良好的团队协作精神，良好的沟通能力；
中级数据开发工程师 要求：    1. 本科以上学历、计算机专业毕业；    2. 2年以上数据库开发经验，熟练掌握至少一种数据库和etl工具使用，有Kettle、Infarmatic经验者优先考虑；    3. 能吃苦耐劳、愿意加班者优先；
岗位职责：1、基于主流ETL工具和技术实施数据采集、处理；2、使用HiveSQL/SparkSQL进行数据清洗和建模；任职要求：1、基础扎实，熟悉SQL语言；2、熟悉Linux操作系统3、熟悉Java与Python、Scala中至少一种编程语言，较强的独立开发能力，具备良好的代码风格；4、具备3年以上hadoop开发经验，熟悉Hive,Hbase等组件。5、有独立分析和解决问题的能力；6、有较强的学习能力，能够迅速掌握新技能；7、能够承担一定工作压力，具备创新思维、具备团队协作精神；
岗位职责：1）负责数据仓库的模型设计，业务需求口径的梳理确认；2）负责数据仓库开发工作：编写Hive\MySql代码、数据稽核、并通过有效的优化使流程稳定运行；3）深刻理解所负责的业务线，为产品优化、运营活动提供有效的数据支持；4）参与数据产品设计和评审，保障数据平台架构稳定；任职资格：1）至少3年以上DW/ETL项目经验；2）熟悉DW实施方法和常规ETL构架；3）熟悉Hadoop/Hive等分布式数据库，熟练编写SQL脚本并具备一定的SQL性能调优经验；4）熟悉Perl，Python，Shell等脚本语言之一；5）有大型互联网数据仓库项目经验者优先；
岗位职责：1、负责数据采集、清洗、加工、整合，并能够独立进行ETL开发和数据分析；2、参与数据仓库ETL流程优化及解决ETL相关技术问题；3、负责系统架构模型的设计和优化；任职要求：1、本科及以上学历，3年以上ETL工作经验；2、具备简单的ETL 相关的英文读写能力；3、熟悉DW/BI项目系统架构和基础知识，熟悉数据仓库、数据集市的建模理论；4、熟悉Oracle、SQLserver、Mysql等主流数据库开发，熟练掌握SQL及存储过程；5、具有AWS，aliyun平台及组件，有dataworks，dataphin平台开发经验优先；6、有ETL项目经验，参与过完整的BI项目并有过完整的BI项目ETL实施经验，精通帆软报表工具fine report或tableau报表工具，了解日常作业的部署和调度；7、有较强分析问题的能力、团队协作能力、优秀的沟通能力和高度工作责任心。
岗位职责：1、负责数据中台架构设计，数据中台数据架构设计，模型、指标及标签等设计；2、根据项目要求编写相关技术文档；3、参与需求、设计、审核和评审；4、完成领导交代的其他任务；任职资格：1、985或211高校本科及以上计算机、数学、金融相关专业毕业，海外高校需在QS世界大学排名前100以内；2、具有5年以上相关工作经验，3年以上大数据平台或数据中台开发经验；3、具备大数据或数据中台架构和数据模型设计经验，熟悉大数据平台开发流程4、精通MySQL、ORACLE、DB2、Teradata、Redis、MongoDB、HBASE等一种或多种数据库的使用和开发；5、熟练掌握基本的Linux操作系统和某种脚本语言编程（如Shell等）；6、熟练掌握一种ETL开发工具，如Kettle、datastage、informatica等；
1、统招本科以上学历，3年相关工作经验；2、熟悉flink/spark/hadoop/hbase/hive等分布式计算技术，熟悉其运行机制和体系结构；3、三年以上大型数据仓库架构和建模经验，熟悉大型互联网企业仓库架构解决方案者优先；
基于Hive， Spark，Hadoop的计算架构，进行大数据开发工作
主要职责：熟悉Azure的微服务架构、spring云、spring boot和spring云，参与微服务架构设计，了解微服务治理；熟悉Hadoop生态，在flink、spark、hbase、hive等大数据组件方面有实际项目经验；了解ServerLess，了解容器，有在生产环境中使用容器的经验者优先；熟悉kafka、RabbitMQ等主流消息中间件；对技术有热情，良好的团队合作和沟通能力。
工作职责1.负责中通实时/离线数据分析任务任职要求1.较强的数据库及SQL能力，熟悉MYSQL等开源数据库，对Hadoop技术体系有深入了解和研究；2.熟练hive、kylin、druid、es等数仓工具的使用和调优；3.熟练掌握java、scala中至少一种开发语言，熟练开发mr、spark、storm等计算程序；4. 5年以上大数据项目经历，有较强的开发调优能力；5.对数据敏感，有较强的逻辑分析能力，对(大)数据处理和分析技术有强烈热情；6.处理过日增亿级以上数据的系统优先考虑。
岗位职责：1、负责公司的大数据处理框架的研发设计工作；2、对现有系统的不足进行分析，难点攻关，找到目前系统的瓶颈，改进系统架构设计，提高系统性能3、根据用户行为分析，挖掘有价值的信息，指导公司运营和决策4、参与小组的产品设计讨论，共同讨论和设计产品。 任职要求：1、5年以上大数据开发经验；本科以上；2、精通Hadoop、Storm、Hbase、Hive、Spark、FLINK其中的一种或几种；3、精通JAVA编程语言，精通面向对象和设计模式，熟悉Linux平台，可以编写代码编程使用Hadoop和基于Hadoop开发大数据处理系统；4、拥有实际大数据项目经验。5、有ML/DL经验者优先6、熟悉flink者优先
岗位职责1.  灵活使用大数据相关的技术解决相关的业务问题；2.  开发并维护数据平台的产品和系统；3.  大数据平台的日常运维；4.  与业务部门密切配合，寻求数据层面的业务价值，利用数据分析结论推动产品优化；5.  研究大数据技术领域最新进展并结合业务需求进行合理的应用和实践。任职要求1.  全日制本科及以上学历，三年以上 Java 开发经验，扎实的 Java 基础，最好有 Scala 经验；2.  有 Hadoop 使用经验，了解 HDFS 运行机制；3.  有 Spark 使用经验，使用过 Spark SQL 和 Spark Streaming 并了解其原理，最好对 Storm 也有了解；4.  有 HBase 使用经验，了解 HBase 的各个模块以及大致的工作流程；5.  了解分布式系统的一些基本原理和协议；6.  有图数据库使用经验者优先；7.  使用过或了解过 Kafka/Flume/Hive/MongoDB/ZooKeeper/Sqoop/Kerberos/Presto 等大数据相关框架；8.  熟悉常用 Linux 命令；9.  良好的沟通和业务理解能力。
工作职责:1.    负责带领团队利用数据挖掘算法进行多维数据分析，服务外部客户2.    结合多样数据，可落地构建完整的用户生命周期行为数据体系3.    构建的支持数字经营和用户增长的数据分析产品4.    负责数据应用产品体系建设工作，帮助客户提升数据应用效率职位要求: 1.    计算机或相关专业本科及以上学历，3年以上工作经验。2.    熟悉Hadoop、Spark框架功能和原理，具备流批数据处理经验。3.    熟练掌握python语言，具备python产品开发经验。4.    具有较好的数据感知和分析能力，善于挖掘数据潜在价值。5.    工作积极主动，具有强烈的责任心，良好的团队合作精神。6.    有知识图谱、用户画像、推荐系统等相关经验者优先，有toB工作经验者优先7.    有营销行业经验优先；熟悉php语言优先。
工作职责：1、参与云平台大数据相关模块，技术验证、方案选型、架构设计。2、有Java/Scala 流式计算的开发经验，熟悉Flink,SparkStreaming。3、参与公司SaaS产品基础框架的设计讨论、研发和具体应用。任职要求：1、计算机相关专业本科及以上学历，4年以上工作经验，２年以上大中型软件产品的全生命周期开发经验。2、具备良好的面向对象编程基础，扎实的 Java 编程基础知识。3、熟悉Hadoop生态体系（HDFS, Yarn, MapReduce，Hive，HBase, Redis, Spark/Storm/Flink, Kafka, Flume, Sqoop等），精通Flink优先。4、熟悉数据仓库建模及分层理论，熟悉Hadoop、Hive、Doris、ES等大数据生态技术。5、熟悉大规模数据挖掘、机器学习、分布式计算等技术优先。6.熟悉Spring Cloud微服务架构及devops，具备Docker、K8S使用经验者优先。
岗位职责1、参与和负责大数据基础设施和平台的搭建、开发以及维护工作；2、负责大数据环境的部署、调优以及日常运维；3、设计合理数据采集任务，数据采集平台设计及开发4、负责大数据项目实施以及部分设计开发；5、负责大数据环境下的数据清洗、转换、建模、分析以及部分开发工作。任职要求1、硕士及以上学历，计算机相关专业，3年或以上大数据开发经验，计算机或相关专业2、精通Java、springboot、mybatis、SQL3、了解数据采集、存储、清洗、分析及挖掘等方面的相关技术4、了解大数据平台运行的环境配置及安装部署方式5、了解多项大数据处理/分析相关的工具/框架，如Hadoop、MapReduce、Hive、Storm、Spark、flink、kafka及HBase等经验；6、熟悉一般的数据采集方式，熟悉Kafka、Flume、Sqoop、MQ等，具备相关项目经验者优先。7、学习能力强，愿意尝试新技术8、对数据敏感，有较强数据分析和解决问题能力优先；有机器学习基础优先
"岗位职责：	1.根据产品设计要求，负责数据平台类生态应用快速迭代研发。2.通过框架、平台、工具、流程打造数据平台的智能解决方案。3.内部CICD建设、基于DevOps理念的工程实践在业务线推广、开源工具探索。4.完善知识库积累。任职要求：	1.本科及以上学历，计算机相关专业。2.至少3年以上大数据领域开发经历。3.熟悉多项大数据领域的开源框架及部署，如：Hadoop, Hive, Presto, Storm, Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch, Druid, FlinkCDC,etc.4.强悍的编码和解决问题的能力；5.乐于挑战没有明显答案的问题，对新技术有强烈的学习热情。6.熟悉DevOps体系及技术组件。8.熟悉高并发、高可用设计、动态配置等应用架构。9.具有较强的学习能力，能适应较大的工作压力，具备良好的团队精神和敬业精神。具备以下条件者优先：	1.对互联网及软件研发流程有深入认识，热衷于工程效率优化及关注前沿软件技术。2.熟悉研发全流程工具和框架，并有优化和集成经验，熟悉相应的管理工具。3.精通数据集成开发框架，有研发效率工具、私有云平台工具的开发经验。"
岗位职责：1.负责大数据服务总体设计与核心代码开发：应用系统架构设计、开发框架搭建、开发规范制定，核心算法编写，指导开发团队进行业务模块代码编写等。2.负责优化现有产品架构，设计新的架构，解决现有技术架构的瓶颈，解决现有业务产品优化升级的技术问题等。3.负责产品的创新迭代，站在业务角度负责信息技术应用与创新，产品升级迭代，解决技术难点攻克以及技术设计方案的落地。4.负责现有产品进行重构设计、功能改进、技术升级。负责国产化项目适配、改造及迁移的整体方案设计。任职资格：1.大学本科以上学历，5年以上工作经验,丰富的软件架构设计经验，实际完成并独立设计、改造的软件项目不少于3个，或大型项目1个。2.精通JAVA，扎实的Java编程基础，熟悉常用设计模式、多线程、JVM，包括内存模型、类加载机制以及性能优化，具有系统设计、系统架构能力。3.熟悉高性能、高并发、高可用性分布式系统设计，熟悉RPC、缓存、消息队列、负载均衡、分布式事务等，并能进行系统的调优和优化。4.熟练掌握SpringBoot框架，两年以上SpringCloud微服务框架开发经验,深刻理解微服务原理及运行机制，并对服务拆分、服务间调用、服务治理有独特见解。5. 熟悉SqlServer、Mysql、Oracle等数据库，有数据库调优经验，熟悉主流多种NoSQL数据库。6.熟悉flink,spark，有过大数据开发经验者，优先考虑！
工作职责：1. 负责食亨餐饮大数据平台相关的业务分析、系统架构设计工作，基于业务场景设计最优的系统级方案；2. 利用Hadoop、Spark等大数据技术对订单、菜品等海量历史数据进行预处理，支持预测模型、算法等工程化实现；3. 支持运营业务需求，提供数据驱动和决策的能力；4. 参与需求的确认、方案的研讨以及方案的实施；5. 对公司大数据产品进行优化 。职位要求：1. 统招本科或以上学历，计算机相关专业，2年以上工作经验、3年以上互联网行业经验;2. 具备较丰富的基于Hadoop或Spark等大数据处理项目经验，具备一定的数据挖掘经验;3. 熟悉linux操作系统、算法、数据库原理和并行处理技术，对大数据处理技术有深入的了解;4. 掌握大数据平台常用组件的原理，可熟练运用：Flume，Hive，HDFS，Hbase，Kafka、ES等等;5. 精通Java语言，掌握常用设计模式和开发框架，熟悉并发、分布式编程;6. 具有良好的需求分析、软件设计能力，良好的系统架构设计和分析能力;7. 有深入研究大数据框架的运行机制、实现原理、源码经验优先;
有大数据项目开发经验；熟悉JAVA/PYTHON；熟悉数据建模、数据平台开发规范等；
岗位职责：1.开发、实现和运维基于私有云和公有云的大数据基础设施2.参与大数据核心组件选型：时序数据库、数据仓库、实时和离线计算平台、数据分析平台、机器学习平台等；3.参与核心代码的开发工作，解决项目开发过程中的难点问题；4.及时跟进大数据领域新技术任职资格：1.本科及以上学历，计算机、数学、统计学、电子等专业本科以上学历；( 学历要求211/985 全日制)2.精通大数据Hadoop体系的相关技术： Hive、HBase、Storm、Kafka、Kylin等3.熟悉BI工具，具有大数据平台的开发运维经验4.了解主流云平台及其服务使用5.至少熟悉一门面向对象的编程语言6.熟悉Linux操作系统，Shell编程等；7.良好的沟通能力、团队合作精神和服务意识。8.具有互联网和（或）物联网相关大数据工作经验为加分项
岗位描述：1. 进行大数据计算框架的通用化、可视化开发。2. 进行通用化数据分析算法开发。3. 产品未来发展方向的技术预研以及当前使用的技术框架的升级看护。4. 进行通用数据处理插件开发，支撑新的数据接入和治理需求。5. 参与数据仓库和数据中台产品开发。任职资格：1、熟悉Oracle数据库故障分析解决，性能分析调优；2、熟悉Linux、Unix操作系统，熟悉shell编写；3、熟悉数据库集群搭建、备份、负载均衡等技术；4、熟悉weblogic、tomcat等中间件的日常运维和故障处理；
职责描述：1、负责公司大数据或人工智能相关应用设计、研发、项目落地；2、利用大数据或人工智能技术，提供快速、高效、准确的数据分析及智能化成果支撑；3、数据治理运转以及对接数据管控平台，确保数据治理成果包括数据标准管理、数据质量管理落地；任职要求：1.全日制大学硕士以上学历，国内985院校毕业，计算机、统计学、信息管理等相关专业；2.熟悉数据建模知识、数据挖掘理论，掌握数据分析体系方法，有一定数理统计基础，具备对各种现实业务场景，选择、建立数学模型的能力3.精通Excel或熟悉Python、Java、R等一种以上程序语言，熟悉大数据及人工智能领域主流开源工具和平台，熟悉使用人工智能相关工具包（库）；4.有较强逻辑推理能力、学习理解能力、沟通协调能力及一定的商业意识、创新能力；5.3年以上大数据技术生态开发应用、数据分析应用、数据治理或人工智能相关任一领域工作经验，具有金融证券行业背景者优先。
职位描述:分析用户群体行为和属性特征，帮助业务更好的理解用户，通过数据报告、分析系统推动业务部门的数据化运营。工作职责：- 负责业务数据分析，进行数据挖掘；- 根据业务数据分析的结果，提出改进建议；- 追踪业务动态，建立监测预警体系。职位要求：- 本科及以上学历，数学、统计等专业优先；- 了解常见的统计方法，具备数据分析、挖掘、统计等相关工作经验；- 了解大数据生态，有构建数据仓库相关经验；- 熟悉 ETL 及数据挖掘工具，如：SAS、SPSS、Tableau 等；- 良好的分析报告书写能力；- 工作细致、责任心强，具备较强的学习及理解能力，具备较好的沟通协调能力。
本科及以上学历，计算机、数学、统计学及相关专业
岗位职责：1.负责大数据平台的需求开发；2.负责大数据开发的需求评估及澄清；3.参与业务部门的问题排错；4.负责上级领导安排的其他事情。专业要求：1. 计算机或软件工程专科及以上学历，开发经验2年以上。2. 熟练掌握java开发；3. 掌握至少一种数据库，如mysql、oracle等；熟练hadoop。4. 有一定的linux基础，熟悉linux常见命令；5. 有较好的团队沟通合作能力，思路清晰、善于思考。
1. 负责大数据技术组件选型、测试、开发； 2. 负责大数据公共服务开发
1、计算机工程、软件工程、应用数学、信息工程等相关专业本科及以上学历；优秀的应届毕业生或2年以上分布式系统或基础软件框架研发经历； 2、熟练掌握C++/Java/Go中至少一种开发语言； 3、掌握多进程，多线程编程，网络编程等常用技术； 4、熟悉云原生相关技术：Docker、Kubernetes； 5、较强的英文阅读能力； 6、有良好的团队协作精神，工作积极主动，较强的学习能力。 工作内容：1、协助时空数据分布式系统专家，完成分布式系统的开发及测试和部署。2、协助时空数据分布式系统专家，参于技术预研和攻关，突破难点。3、参与设计文档编写。
高级大数据工程师\大数据研发专家工作职责 ：1、参与建设云计算数据体系，负责数据仓库方向、数据应用方向的开发工作;2、参与构建云计算各业务线数据仓库建设（数据接入、分层建设、元数据管理、任务调度、性能优化）;3、参与相关BI系统建设及解决方案落地；4、进行相关大数据新技术的调研以及引入；5、协助维护大数据平台，迅速解决相关问题，确保大数据平台的稳定。任职资格：1、全日制统招本科及以上学历，计算机、软件工程等相关专业优先；2、五年及以上软件研发经验，且有三年及以上大数据相关系统研发经验；3、熟练掌握一种或以上的开发语言，如Python、Java、Scala等；4、熟悉数据仓库建模理论，有丰富的实时、离线ETL处理经验；5、熟悉Hadoop生态圈（HDFS、HIVE、KAFKA、ZOOKEEPER、SPARK、FLINK等），深入理解HDFS、SPARK、FLINK原理及优化技巧，有研究过相关组件源代码者优先；6、具有运维系统的实时监控报警系统搭建的经验者优先；7、具有大型数据产品构建经验者优先；8、具备较强的工作责任心和团队合作意识，抗压能力强，具备良好的协调沟通能力；
职责描述：1.负责业务部门的基础离线数据需求及实时数据需求2.负责数据BI分析、加工、清理、处理程序的基础功能开发岗位要求：1.熟悉数据仓库模型设计和精通ETL开发2.熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Flink/Kafka等），对内部实现机制一定了解3.三年及以上大数据开发经验4.熟练掌握java,scala编程语言，有大型项目建设经验者优先5.熟悉数据仓库领域知识和技能者优先，包括但不局限于：数据开发测试工具与方法、数据质量等6.熟悉Linux系统常规shell处理命令7.熟悉常见数据结构和算法，计算机基础知识扎实
职位描述：1. 负责数据仓库的搭建与维护，针对日常数据分析需求进行数据模型的设计与开发，保证数据质量； 2. 参与集市元数据、主数据、数据质量、数据管控等系统的建设； 数据系统建设和构建数据应用，包括数据采集、提取、分析与数据产品化，以及模型架构设计及优化工作； 3. 和产品团队、数据分析团队合作，挖掘数据价值，建设公共数据服务，推动数据应用； 职位要求：1. 计算机、数学、统计等相关专业的本科或以上学历；2年以上工作经验； 2. 精通数据仓库建模及ETL设计开发，熟练使用hive，kafka，spark，hbase，flink等任意两种； 3. 精通SQL，具备Hive/Spark性能调优经验； 4. 责任心强，工作态度积极主动，有较好的团队合作和沟通能力。
1. 负责数据平台架构和规划；2. 基于数据驱动构建企业的数据模型EDW以及面向应用产品与分析的应用层模型设计开发。3. 参与数据平台的数据研发，发掘数据商业价值，打造极致体验的数据平台。岗位要求:1 从事数据仓库领域至少2年以上，熟悉数据仓库模型设计与ETL开发经验 ，掌握Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验2. 数据结构和Java知识扎实具有一定数据模型和数据架构基础，熟悉精通flink spark二者其一；3. 精通SQL，有一定的SQL性能调优经验，熟悉hive sql的开发；4. 具有良好的需求分析、系统分析与设计能力，熟悉EHR相关领域业务优先；5. 掌握相关大数据计算、挖掘、分析平台技术优先。6. 对数据敏感、对技术敏感，有研究的意识和直觉者更佳；7. 性格积极乐观，诚信，有较强的语言表达能力；具备强烈的进取心、求知欲及团队合作精神。
工作职责:1、负责基于分布式平台的数据仓库架构和建模工作；2、负责日志采集、数据接收、ETL、数据仓库建模中的一个或多个环节，完成数据仓库的建设开发，并确保数据质量；3、负责批计算、流计算的设计和研发及元数据管理工作；4、负责数据平台能力建设，大数据相关组件调研和使用；任职资格:1、计算机或相关专业本科以上学历，5年以上工作经验，有机器学习数据建模能力优先；2、精通SQL和Spark处理方法，具有一线coding的能力，至少3年的Spark(Core/Streaming/SQL)开发经验；3.对数据质量管理、元数据管理、数据权限管理、数据应用等有独到见解的优先；4、熟练掌握分布式存储相关技术，包括HDFS，Redis、Kafaka、Zookeeper、ElasticSearch等；5、有大数据项目实战经验，熟悉Hadoop、Hbase、flink, Druid等开源框架，并熟悉其工作原理；6、具有较强的内外沟通能力，良好的团队意识和协作精神；7、熟悉OLAP和OLTP技术，有大规模数据平台或数据仓库设计经验；
职责描述：1、负责从数据湖提取数据和进行数据分析，满足业务部门数据需求；2、根据业务目标进行数据建模、数据挖掘，抽取、编写ETL JOB,spark flink MR 任务，熟悉常见的OLAP presto等框架3、通过编写SQL等方式实现业务需求，完成数据建模处理加工；4、基于业务场景和数据理解进行数据库分层设计、开发和维护，具体包括DWD,DWB,DWS；5、数据埋点设计及入库跟踪提取；6、通过和业务沟通，抽象出业务逻辑。同时需要有数据敏感性，需要对数据的准确性负责；任职要求：1、计算机相关专业全日制本科及以上学历，3年以上大数据开发或分析经验；2、熟悉数据仓库建模开发、实时及离线计算、数据仓库方面有经验者优先；3、熟悉大数据生态包括不限于 Hadoop/Spark/Hive/Hbase等 并有相关项目开发经验；4、熟悉数据ETL的流程和每个过程的关键数据处理方法和技巧，对OLAP、报表及可视化深入的了解；5、数据敏感性强、良好的沟通表达能力和团队协作能力，对自己有较高的要求，有自驱力
职位描述1，负责蚂蚁金服基础数据平台的建设，包括基础的运维数据，资金数据，系统变更数据等。2，对全链路数据质量负责，进行实时监控，分析，最终提供保障数据的质量，包括低延时，高可用等指标。3，参与建设数据平台建设，满足实时数据流的上各种复杂计算需求，包括图计算，多流合并，以及各种常见transform计算。4，对接数据平台上的各种业务方，满足不断发展的业务需求。5，对接各类数据源系统，包括蚂蚁平台内部的各种queue，关系数据库，日志等系统。职位要求1，有ownership意识，追求实现自我价值。2，有ETL，ELK类业务的实际项目经验，掌握实时计算技术体系包括数据采集、计算引擎storm/spark/flink，对实时计算所涉及的事务、容错、可靠性有深入理解。了解背后的实现原理，并能够调优。3，对hadoop/yarn/hive等大数据工具有深入使用经验，熟悉大数据存储系统hbase/hdfs等，了解起背后的实现原理，并能够调优。4，精通C/C++，Java，Scala等其中一种，极佳的编程素养，有丰富的分布式开发经验。熟悉Linux系统，又一定的脚本开发能力。5，参与过超大规模数据项目，有百万级TPS数据处理经验者优先。6，有算法项目经验的优先。此岗位P6/7/8均有需求
1、有ORACLE存储过程开发经验； 2、有ETL开发经验； 3、对SQL调优有所了解；4、对数据仓库模型有所了解； 5、有基金行业监管报送经验或者财务报表开发经验者优先考虑。岗位描述1、对已有的ORACLE存储过程进行整合和调优； 2、日常数据ETL任务； 3、根据业务报表需求完成SQL脚本开发。其他：1、学历要求：本科及以上；2、相关工作经验：2年以上。
岗位职责  1、参与大规模数据快速查询系统的架构设计和开发；  2、大规模数据挖掘和机器学习算法的实现；  3、在线和离线海量数据分析平台的开发；  4、研究大数据前沿技术，提升系统的运维效率；  5、实现大数据基础架构平台的自动化运维。    职位要求：    1、计算机相关专业,具有3年以上大数据开发经验，熟悉Java,Linux；  2、熟悉Hadoop大数据处理系统的开发,搭建及部署者优先；  3、熟练地处理数据模型、数据ETL以及存储管理；  4、熟悉HDFS/Hive/MapReduce/Kylin/HBase，能独自进行Mapreduce程序开发者优先；  5、熟悉分布式系统概念、架构，有大规模分布式系统设计、实现、部署等经验；  6、有较强的书面与口头沟通表达能力，独立分析、解决问题的能力  7、熟悉SQL优化，熟悉用SQL进行数据处理和分析  8、了解调度系统和导数系统
岗位职责：1.辅助模型算法研究员对模型因子数据的数据清洗、分析等工作。2.能培养大数据开发工程师，并能领导一个小组及完成相关的开发任务。3.基于hadoop、spark/flink等构建数据分析平台，进行设计、开发分布式计算业务；4.辅助管理Hadoop集群运行，稳定提供平台服务。5.基于Spark/Flink技术的海量数据的处理、分析、统计和挖掘；6.基于Spark/Flink框架的数据仓库的设计、开发和维护；7.根据需求使用Spark Streaming和Spark SQL或者Flink进行数据处理、查询和统计等工作。岗位要求：1.正规本科及以上学历，计算机相关专业；2.3年及以上大数据开发经验；3.熟悉HDFS/HBase/Hive/MapReduce/spark/flink，有丰富的分布式编程经验；4.熟悉Spark Streaming和Spark SQL或Flink；5.熟练Scala编程；6.了解Core Java，熟悉Java IO, NIO, 多线程编程， 熟悉JVM运行机制和内存管理，网络协议；7.有过海量数据系统开发经验优先录取。
"The RoleWe are looking for a Data Engineer to be part of our Applications Engineering team. This person will design, develop, maintain and support our Enterprise Data Warehouse & BI platform within Tesla using various data & BI tools, this position offers unique opportunity to make significant impact to the entire organization in developing data tools and driving data driven culture.Responsibilities:•	Work in a time constrained environment to analyze, design, develop and deliver Enterprise Data Warehouse solutions for Tesla’s Sales, Delivery and Logistics Teams•	Create ETL pipelines using Python,  Airflow •	Create real time data streaming and processing using Open source technologies like Kafka , Spark etc•	Work on creating data pipelines to maintain Datalake in AWS or Azure Cloud•	Work with systems that handle sensitive data with strict SOX controls and change management processes•	Develop collaborative relationships with key business sponsors and IT resources for the efficient resolution of work requests.•	Provide timely and accurate estimates for newly proposed functionality enhancements•	critical situation•	Communicate technical and business topics, as appropriate, in a 360 degree fashion, when required; communicate using written, verbal and/or presentation materials as necessary.•	Develop, enforce, and recommend enhancements to Applications in the area of standards, methodologies, compliance, and quality assurance practices; participate in design and code walkthroughs.•	Utilize technical and domain knowledge to develop and implement effective solutions; provide hands on mentoring to team members through all phases of the Systems Development Life Cycle (SDLC) using Agile practices.Qualifications:Minimum Qualifications:•	3+ years of experience in Cloud Technologies like AWS or Azure•	3+ years of experience in creating data pipelines using Python•	3+ years of experience in Data Modelling •	Must have strong experience in Data Warehouse ETL design and development, methodologies, tools, processes and best practices•	Strong experience in stellar dashboards and reports creation for C-level executivesPreferred Qualifications:•	3+ years of development experience in Open Source technologies like Python, Java•	Experience in Big Data processing using Apache Hadoop/Spark ecosystem applications like Hadoop, Hive, Spark, Kafka and HDFS preferable•	Excellent query writing skill and communication skills•	Familiarity with common API’s: REST, SOAP"
工作职责：1.负责大数据平台的开发和性能优化工作；2.负责大数据采集、清洗、整合等工作；3.负责大数据平台文本挖掘分析等工作；4.负责BI、报表和驾驶舱的开发。5.负责针对业务人员在应用数据过程中提出的需求并进行功能设计与实现。 任职资格：1.熟练掌握 Java，熟悉 Shell，Python 等一门以上脚本语言，并灵活运用到实际工作中及解决技术问题 。2，熟悉大数据生态的处理工具和技术(ETL、Hadoop、Hive、Hbase、Kafka、Spark、Flink、ES等)， 有 MapReduce 程序的实战开发经验；有实际大数据分析处理项目经验 ；3、熟悉MySql、SqlServer、Oracle等常用数据库，熟悉数据库性能优化；4、熟悉分布式存储和NoSQL数据库技术（如MongoDB、Redis等）；5.参与过分布式高性能服务的设计开发过程，有大规模分布式系统的实践经验；6.熟悉Hadoop运行监控及调优技术；熟悉Hadoop生态相关的管理平台（如CDH等);7.计算机、软件工程及相关专业本科或以上学历，2年以上相关项目开发经验；8.具有较强的学习能力和分析、解决问题能力，具备良好的团队合作精神。
1、熟悉Hadoop、Spark生态圈，熟练使用多项大数据处理/分析相关的工具/框架，e.g.hive, hbase, kafak, flume, spark, flink等；2、熟练开发SQL，有数据库调优能力，熟练使用BI工具开发报表；3、3年以上的ETL开发、数据仓库、数据建模等相关经验；4、有Dataworks/Pentaho/Kettle/Informatica等ETL组件开发经验优先考虑；5、认真负责、工作踏实、有良好的合作与沟通能力；6、有汽车行业、CDP相关业务经验更佳。
1、3年以上的ETL开发、数据仓库、数据建模等相关经验，具备汽车行业相关业务经验更佳； 2、熟练开发SQL(MySql/Oracle/DB2/SQL Server等)，有较强的SQL调优、问题解决能力; 3、了解BI工具开发报表，如：Fine BI/Fine Report/PowerBI/Tableau等；4、熟悉hadoop、spark生态圈相关组件，hive/spark/flume/kafka/hbase等； 5、有Kettle/Informatica/Dataworks/Pentaho等ETL组件开发经验优先考虑； 6、学习能力强，认真且负责任。岗位要求1.理工科相关专业，专科及以上；2.熟悉 Spark 相关技术，3年以上 Spark 开发经验；3.熟悉 Spark Streaming 和 SparkSQL、SparkMllib；4.熟练使用 java、scala、python 语言等；5.有过海量数据系统开发经验者优先；6.具备一定的数据分析模型能力；7.良好的沟通能力，有较强的数据敏感度，能够快速熟悉业务。
非外包，不加班，8小时，弹性上班，双休，法定节假。主要技能点：1. Python / Scala2. PySpark，Spark SQL, Hudi, Presto，Clickhouse3. Django / Flask / Fastapi / Pandas / Scikit-learn4. MySQL /Redis / MongoDB / Elasticsearch5. ETL / Airbyte / Streamsets / Airflow / DolphinScheduler岗位职能：1. 负责数据体系化建设，负责数据处理体系搭建管理和维护2. 对接数据处理需求，制定开发计划并高效实施3. 负责挖掘现有数据，发现数据潜在价值，以数据指导业务4. 根据开发规范和数据模型设计实现数据开发任务，保证数据质量5. 参与数据仓库中 ETL 流程的优化以及数据仓库系统实施过程中 ETL 相关技术问题的解任职要求：1. 计算机相关专业，有三年以上数据开发经验，有数据处理、数据建模、数据开发数据资产管理经验2. 精通 Python 语言，精通 MySQL / Postgres 等主流关系型数据库和 Hbase 等非关系型数据库，有数据库调优经验3. 精通 Spark，Flink 等大数据组件，有 Spark 调优经验，有 Iceberg，Hudi 等湖仓经验4. 熟悉常见机器学习算法，了解深度学习框架，有自然语言处理优先考虑5. 有良好的编码习惯和文档编写能力，熟悉常见的设计模式和面向对象设计思想，熟悉并应用常见算法6. 熟悉 Linux 运维，有大数据系统搭建经验，熟悉主流容器化技术(Docker 、 k8s)7. 有激情和责任心，积极主动，具有良好的团队协作、对外沟通能力，有良好的自取能力。提供 Github 或者博客地址，有开源项目贡献者优先考虑
岗位职责1. 大数据基础平台、大数据能力开放平台、大数据交易平台的搭建与优化；2. 基于大数据平台(Hadoop)的数据仓库工具Hive/Spark/HBase, ETL调度工具，数据同步工具的开发、使用、集成和自动化运维，以及多租户与权限控制策略的实现；3. 研发基于大数据平台的数据仓库平台产品；4. 参与大数据平台的容量规划、持续交付、业务监控、应急响应，保证平台正常运行。5. 利用大数据相关技术实现对数据的加工、分析、挖掘、处理、及数据可视化等相关工作。岗位要求1. 全日制本科及以上学历，计算机相关专业，对数据处理、数据建模、数据分析等有深刻认识和实战经验2. 熟悉Hive SQL语言，熟悉shell, python等脚本语言3. 有hadoop、spark、flink等大数据平台的使用经验4. 有数据仓库建设、商业数据分析、增长项目经验5. 熟练掌握Hadoop及Map-Reduce应用开发，熟练掌握HBase、Hive、Storm、spark等大数据开发工具6. 熟悉至少一种实时计算引擎 Storm, Spark Streaming, Flink, 对hadoop生态其他组件有一定了解，比如 HBase， hadoop, Hive, Druid等7. 熟悉Hadoop/Spark/Hive/HBase等大数据工具，主导过大型数据平台建设者优先；8. 精通SQL，熟悉常用的关系型数据库、非关系性数据库和数据仓库，具有SQL性能优化经验；9. 了解微服务开发理念、实现技术，熟悉常见设计模式，熟练掌握SSH开发框架，熟练进行Java、Python代码编写，熟悉多线程编程10. 有Hadoop/Hive/Spark/Storm/Zookeeper 等相关开发经验或从事分布式相关系统的开发工作11. 熟悉Linux/Unix系统和丰富的Java开发经验，具备shell、python等脚本开发能力者优先12. 3年以上企业级数据仓库开发经验，有大规模集群应用开发经验优先13. 熟悉数据仓库理论，具备复杂业务需求梳理能力14. 学习能力强，喜欢研究开源新技术，有团队观念，具备独立解决问题的能力，具备扎实的计算机理论基础, 对数据结构及算法有较强的功底
职位描述： 1. 负责公司大数据平台(包括数据建模、数据架构、数据治理、数据管理、数据安全、数据运营等技术领域)的设计、开发、维护、优化 ；2. 构建公司数据中台服务体系，满足公司各级部门的敏捷化数据分析、挖掘需求，提供多场景、高效的数据支持服务；3、建设公司数据仓库，为公司离线批处理及实时流处理提供平台技术及数据支撑； 4、与包括执行，产品，数据和设计团队在内的利益相关方合作，为客户获取，运营效率和其他关键业务绩效指标提供可操作的见解，协助处理与数据相关的技术问题并支持其数据基础架构需求；5. 研究与跟踪大数据技术发展方向并推进技术演进&优化 ，大数据应用支持及大数据平台的扩容、集群安全等的实施及推进； 岗位要求：1、全日制统招本科及以上学历，计算机、应用数学、统计学等专业，具有4年及以上数据开发及大数据平台建设经验；2、精通主流数据库系统（如MySQL/SQL SERVER/Oracle/PostgralSQL等），有丰富的 SQL 编程经验及 ETL 流程设计开发经验，有MaxCompute /Hive/Spark SQL等相关开发经验;3、熟悉数据仓库各类建模理论以及数据仓库数据层级关系，具备大型数据仓库逻辑模型和物理模型设计经验； 4、熟练使用Python/Java/Scala/Shell等开发语言中的一种或多种；5、熟练使用阿里云DataWorks - 数据集成、数据开发及数据服务技术构建从各种数据源中优化提取，转换和加载数据所需的基础架构；6、熟悉Hadoop生态体系，了解HDFS、Hive、Spark、sqoop、HBase、MapReduce、Flume、kafka等开源项目原理和开发使用；7、 突出的分析问题和解决问题的能力，自我驱动、敢于担当、乐于沟通，具有良好的团队合作精神，积极主动，能承受一定的工作压力；以下为加分项：1、具有以下产品及咨询能力者优先，商业智能（BI）、数据治理、数据指标体系、标签库管理；2、 熟悉spark mlib、scikit-learn等机器学习框架，对常用机器学习算法，如逻辑回归、贝叶斯网络、决策树等，对于特征工程、算法选择和调优、测试评估有实战经验者优先。
岗位职责：1.参与公司自研大数据中台项目建设，工作地点：苏州虎丘 。2.面向银行、券商、公募基金等金融机构项目交付（非人力外包），短期差旅（1～3个月）。3.社保 base地 可选：上海 或 苏州 。4. 日常工作：ETL开发、数据模型设计、数据指标加工、数据可视化。任职要求：1.全日制本科，学信网可查，毕业证学位证齐全。2.熟悉Oracle、DB2等关系型数据库，熟练掌握 SQL ，能独立完成有难度的开发。3.掌握Linux 系统基本操作，能独立编写 Shell 脚本。4.掌握 ETL 工具，不限于 DataStage、Informatica、Kettle、Sqoop 5.能接受短期差旅，跟着大牛一起搞项目。加分项目：1.计算机、金融经济、数学统计类专业优先。2.有数据仓库、传统BI、报表项目经历，或银行、金融行业从业经验者优先。3.有面向官方文档编程，面向搜索引擎编程，面向报错信息编程能力者优先！！！   （某面试官留）4.熟悉Hadoop生态，Hive相关组件优先；5.有NoSQL、图数据库等非关系型数据库开发经验优先；福利待遇：1、补贴奖金:享受员工的餐补、项目补贴、出差补贴、项目奖金，年终绩效奖金。2、休假制度:周末双休、法定节假日正常休假，带薪年假，5-10天/年。3、带薪培训:系统化培训体系，新员工带薪培训。4、社会保险:按照规定足额缴纳五险一金。5、健康体检:每年享受年度员工体检。6、拓展旅游:定期员工拓展活动及旅游奖励。
岗位职责：1. 与Apache Kylin核心开发者一起，研发基于Apache Kylin的下一代智能大数据分析平台；2. 在增强分析，实时数仓，硬件加速，云原生计算存储架构等领域保持创新突破；3. 根据客户诊断信息，排查、定位、分析系统缺陷或性能瓶颈；4. 参与Apache Kylin开源项目，成为Apache Kylin核心贡献者；岗位要求：1. 计算机、软件工程等相关专业，本科及以上学历；2. 对 Hadoop / Spark / Impala / Flink / Druid / HBase 等任一常见大数据项目有代码级理解，具备二次开发经历更佳；3. 扎实的计算机基本知识，可靠的编码、设计、算法、调优、故障排查能力，编程语言不限；4. 过关的英文阅读能力，无障碍理解英语的技术材料；5. 有大数据平台开发和调优经验，数据中台建设经验者优先；6. 开源项目贡献者优先；
【岗位职责】1、负责存储大数据存算分离 、数据湖、流式存储 特性的设计、代码开发，测试验证及运维工作，保证系统可靠性，可伸缩性和高性能；2、负责交付特性/子系统设计文档和接口，主导特性交付；3、参与在实现中验证设计的工作，完成设计问题分析和预防的工作。【岗位要求】1.掌握C/C++/Java/Scala/Python语言，熟悉Linux操作系统；2、熟悉oracle、mysql等主流数据库技术中的一种，有在中大型项目中的实际应用经验。3、熟悉大数据相关组件Hadoop/Flink/HBase/Spark/Sqoop/Oozie/Flume/Kafka/Storm/Hive/Elasticsearch/Presto/CarbonData/Hudi/ClickHouse内核源码，系统性能调优和分布式架构经验优先；
急聘大数据相关开发人员。主要工作职责：1.根据业务侧需求进行数仓模型设计并进行PB级别的数据作业开发2.参与公司日常调度任务的监控和数据质量的监控3.参与公司数仓建设的设计与优化，代码优化等任职资格：1. 精通Hive，熟练使用HQL进行开发，并能根据场景进行调优2. 熟悉MapReduce底层原理，Hive底层原理3. 熟悉JAVA语言，可以单独实现UDF,UDAF等开发与使用4. 掌握数据仓库体系架构、数仓建模、数据治理等5. 有2年以上大数据开发经验，可以场景化数仓建模设计6. 熟练使用SparkSQL,Scala进行程序开发，调优7. 了解大数据技术栈，如Hadoop/Spark/KAFKA等8. 有实时处理，PB数据处理，用户画像等相关背景优先Ps:薪水，职级等根据面试结果定级定薪。薪资优渥，氛围活泼，欢迎各位老板加入哈。
1、本科及以上学历，计算机相关专业，优先考虑211及以上学校毕业生。3年以上JAVA开发经验、熟悉JAVA Web开发框架，JVM原理，包括内存模型、类加载机制以及性能优化；2、精通使用关系型数据库，熟练大数据相关技术如Hadoop、Spark、Hive、HBase、Kafka、Elasticsearch等，并有实际工作经验，对开源社区有贡献优先；3、了解任意一款 OLAP 数据库的设计、架构，熟悉缓存技术和分布式系统理论；4、具有良好的文档撰写能力和编码规范，熟悉软件开发规范与流程，有团队协作意识；5、具有较强的团队合作能力和责任心，能够主动高效的完成任务，性格开朗，乐于沟通，具有良好的学习能力，敢于创新和接受挑战；
岗位职责：1、负责公司大数据平台数据接入、清洗、管理等工作；2、负责公司spark、flink等程序开发；3、研究用户画像，构建营销相关模型；4、负责公司BI报表和数据可视化相关工作以及业务部门日常数据需求和任务；5、负责上级交办的其他相关工作。基本要求：1、熟练掌握java/python/scala之中至少一种开发语言；2、熟悉常用的关系型数据库mysql，oracle等，熟悉非关系型数据库如redis,mongoDB,es,HBase等；3、熟悉linux操作系统以及常用命令，能在linux上完成开发、和调试工作；4、能够熟练应用spark、storm、flink、hive等大数据并行计算框架，完成实际项目开发需求；5、具有清晰的逻辑思维，熟悉数据挖掘常用的工具和算法，有相关经验者优先；6、良好的沟通和表达能力。
岗位描述：1. 负责大数据平台的Spark、Spark Streaming技术研发、性能优化、问题诊断2. 基于Spark构建数据中心，处理离线和实时计算任职要求：1.三年以上大数据平台设计和开发经验，具备优秀的编程能力和良好的开发习惯。2.熟悉Spark、Spark SQL和Spark Streaming内核原理；了解Hadoop生态组件相关技术，例如Hadoop、Hive、Hbase等。3.熟练使用Java语言，熟悉Linux 操作系统，熟练使用Python、Shell脚本语言。4.具有认真的技术态度，良好的团队沟通和协作能力。5.有过海量数据系统、newsql数据库、数据仓库开发经验者优先。
我们研发实力一流：页游《街机三国》月流水过亿，手游《龙之谷》月流水过9亿，多款顶级ip手游在研；腾讯合作伙伴；公司从2018年开始发力微信小游戏，布局多款战略性ACT/ARPG品类H5游戏，并布局海外小游戏市场，已获得腾讯《英雄杀》IP授权开发，《英雄杀》H5游戏突破百万DAU。职位描述：1、负责公司大数据平台建设和维护，基于公司实际业务，对大数据平台整体架构设计及优化；2、深刻理解游戏业务，负责数据产品规划，设计；3、有较好的分析逻辑和建模，基于数据进行业务分析建模及挖掘数据价值；4、负责与各游戏项目的需求沟通；职位要求1、计算机相关专业本科及以上学历，3年以上大数据相关工作经验；2、具有扎实的大数据分布式系统经验，对于大数据基础技术及原理有足够理解；3、大数据开源生态技术： Hadoop、Hive、HBase、Spark、Flink、Kafka、ES，clickhouse，Iceberg，hudi 等）的实际开发及应用经验；4、算法基础扎实，熟悉常见的数据结构，深入理解分布式算法和以上提到的分布式系统；5、数据数据仓库建构，数据模型设计，熟悉传统BI，常用机器学习模型，有游戏项目经验优先；6、有大数据中台建设经验优先；7、有大数据组件二次开发经验优先；8、有腾讯云EMR开发经验优先;
2-8年大数据开发都需要，数据架构也有岗位需求岗位职责：1.通用数据产品研发与技术架构设计，为能源、警务、智慧城市行业提供数据服务和支持，支撑并促进业务的快速健康发展;2.建设数据集成工具和平台，提供数据生产、运维、使用效率；3.离线实时数据仓库运维和管理工具建设4.负责大数据系统及组件的性能、效率、稳定性分析与优化。任职要求：1.本科以上学历，2-8年经验，有大厂经验优先；2.具有扎实的计算机技术功底，扎实的编程基础和数据结构算法基础，极强的编程能力和问题解决能力；3.精通Java/scala语言，熟悉jvm调优及分布式系统开发；4.熟悉Hadoop/Hbase/Hive/Impala等开源大数据技术，精通Spark、Flink、Clickhouse等任意一个大数据组件；5.熟悉Kafka/RocketMQ/Redis等中间件的原理、存储结构；6.熟悉SQL语言编程，深入理解数据库的底层原理；岗位亮点：1.面对海量数据处理的机会，接触数据领域的前沿技术2.数据产品、工具系统具有较高复杂度且需要快速迭代，可以积累丰富的高可用、高并发、高性能和可扩展性经验
"工作职责：1、	大数据平台管理系统后端的设计与开发；2、	智能运维平台的设计与开发。职位要求：1、	本科以上学历，计算机/软件工程专业优先，三年及以上工作经验；2、	有专业的计算机素养，熟悉网络编程、操作系统、基本数据结构和算法；3、	具备良好的模块化设计能力，能够对复杂流程抽象和简化，有一定的产品思维；4、	较强的编程能力，熟练掌握Java或Scala语言者优先；5、	有分布式系统、自动化运维、机器学习算法等相关经验者优先。"
负责splunk，elk项目测试和实施负责与客户沟通项目需求
工作职责：1、负责大数据平台调度任务的性能优化等工作；2、支持大数据平台上层应用的对接，上层数据流转，技术架构优化工作；3、支持部门内需求对接开发工作；任职/岗位要求：1、熟悉分布式技术体系，熟悉Hadoop、MapReduce、Hive、Hbase、ElasticSearch等一种或多种框架，并了解原理架构； 2、熟悉Linux环境，熟练使用Shell编程，至少熟悉Java/Python一种开发语言；3、熟练使用Hive SQL语言，有较好的Hive SQL性能调优经验；4、扎实的独立分析问题、解决问题的能力，并且拥有体系化方法。具备良好的需求理解能力、沟通协调能力和团队合作精神。
1.熟悉掌握SQL或HQL，具备一定的SQL调优能力，并有数据分析或数据挖掘相关经验，对数据工作有着浓厚的兴趣；2.了解数据仓库建模，有任意数据或大数据开发实战经验；3.熟悉Python开发语言以及numpy、pandas、mlib等常用的工具包，能够使用机器学习、深度学习等数据挖掘常用的算法，对数据进行分类、聚类、预测等项目经验着优先注：华为od岗位
1. 扎实的编程能力，熟练掌握SQL/Python编程2. 深入理解数据库（至少一种）：MySQL/Doris/Oracle。3. 熟悉clickhouse、Kylin等OLAP数据分析框架4. 扎实的数据库开发能力，可以根据业务要求建立高效运行的Function，Procedure，View等5. 良好的数据库调优能力，要能写出运行高效的SQL语句。6.具备良好的分享、研究精神，具备文档编写能力。7.良好的团队合作精神，具备高效协同工作能力。8.具有零售行业经验优先
工作职责1、参与大数据应用平台建设开发，打造数据流通一体化，让数据安全、高效流通2、数据平台工具持续集成开发任职资格1、计算机相关专业本科及以上学历，3年以上工作经验；2、2年以上Java研发经历，Java基础扎实、理解I/O、多线程、集合等，良好的编码习惯和数据结构能力，了解jvm原理，熟悉分布式场景，会python加分3、熟练使用常用框架和互联网技术：spring、springboot、mybatis、redis、zookeeper4、熟悉Mysql、Oracle等数据库，至少熟悉使用一种 5、熟悉使用大数据技术栈并有落地经验，如sqoop、hive、hbase、es、flink，6、工作主动积极、强烈的责任感，并乐于接受挑战。学习能力强，沟通、表达能力好，有团队合作精神
任职要求：1.学信网可查本科及以上学历，计算机或相关专业优先，具有1年以上数据开发经验； 2.掌握数据处理开发技术，有oracle、greenplum存储过程开发能力者优先；3.熟练掌握SQL，有SQL调优能力者优先；4.熟悉数仓分层及维度建模原理，具备数据模型设计能力，有数仓实施经验者优先；5.有海运物流、进出口贸易行业、海关报关相关工作经验优先；6.善于了解新业务，能快速熟悉业务流程、业务数据，具备数据需求分析能力；7.具备良好学习及沟通能力，工作仔细认真，有强烈的责任心。备注：此岗位需要现场面试，不能参加或人不在上海的，请勿投递谢谢！           民教网学历以及身份证年龄和实际工作经验不符的请勿投递谢谢！
初级数据开发工程师 要求：    1. 本科以上学历、计算机专业毕业或者应届生    2. 有数据库开发经验，熟练掌握至少一种数据库和etl工具使用，有Kettle、Infarmatic经验者优先考虑；主要做传统的数据库开发    3. 能吃苦耐劳、愿意加班者优先；目前这个岗位需要7*24小时轮班 上12小时，休息24小时。
一.岗位职责1. 参与和完善基于大数据平台的量化投研平台的建设。2. 根据业务需求对于数据进行实时处理和指标运算。3. 调研大数据平台方向的新技术。4. 负责自建数据库的每日数据下载，清洗和检查工作。5. 负责数据调研，采购和部署工作。6. 负责高性能服务器组的运维工作。7. 参与部门数据规划和硬件规划工作。8. 其他数据分析需求的支持。二.教育背景         全日制硕士及以上学历，计算机科学、软件工程、金融工程、数学、物理、通信等相关专业，条件特别优秀者可以放宽到本科学历。三.工作经验         1、有2年以上大数据相关工作经验；        2、熟练掌握相关大数据分析处理机制；四.岗位技能         1、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark）等。        2、熟悉Java/Python语言，能够熟练的进行开发。        3、具有主流数据库（MySql，Oracle，Mongo, Redis）开发和运维经验。        4、具有编写sql脚本的能力。具有互联网或交易厂商大数据相关经验优先考虑。
岗位职责： 1、负责AI大数据研发平台（包括不限于流计算平台、调度平台、元数据平台等）的架构、设计；2、负责离线、实时的数据接入和质量控制的设计；3、收集各业务方的数据需求并协调交付研发平台的功能迭代。岗位要求： 1、计算机及相关专业本科以上学历，5年以上工作经验；2、熟悉Flink、Hive、Spark等开源大数据技术；3、熟练掌握Java 、Scala 等语言，有后端 API 开发经验， 熟练使用Python、多线程、协程，熟悉Linux对应的开发环境；4、有一线互联网/车企/大数据2B公司数据研发平台的研发/产品或架构经验；AI应用与数据标注和数据管理的经验；5、有良好的沟通和团队协作能力。
岗位职责：1、负责大数据平台框架的设计和研发工作；2、负责优化提升大数据平台的高可用性、高性能；3、数据清洗、流批处理、实时计算开发、为线上业务提供数据支撑；4、负责数据架构的规划，关注大数据技术发展趋势、研究开源技术、将新技术应用到大数据平台，推动数据平台发展。 任职要求：1、计算机相关专业本科及以上学历，2年以上相关工作经验；2、熟悉java、scala 至少一门开发语言，熟悉shell、python、ruby等至少 一种脚本语言，熟悉linux操作系统；3、熟悉Hadoop生态圈，了解Hadoop、Spark技术实现原理，具备Hadoop、Hive、Hbase、Storm、Spark等开源项目研发经验；4、具有大规模数据平台架构设计和开发经验，熟悉kylin、flink或对kylin、flink有使用经验者优先；5、熟悉flume 、logstash、fliebeat等至少一种日志采集工具6、熟悉elasticsearch、kafka或对elk架构、kafka有使用经验者优先；7、掌握分布式系统原理，对存储、技术、消息队列、机器管理中的一项或多项有较深入的理解和认识；8、乐于挑战没有明显答案的问题，能快速理解业务场景，从具体问题中抽象出通用的解决方案；9、具备良好的沟通能力、较强的逻辑思维能力、团队协作能力、强烈的责任心，学习能力强，喜欢研究新技术，具备独立解决问题的能力
1.有离线大数据的经验(不含实时,日志这种的) 最好是订单;2.有sparksql离线处理的经验;3.有优化经验;4.有3年以上工作经验，能独立沟通需求；5.有databricks,adf，快销行业经验的优先考虑。
岗位职责：1.负责快递物流业务域的数据仓库的设计和研发工作，推动“数据驱动”模式在业务团队的落地和演进；2.充分理解快递物流各个领域业务，推动相关方制定系统性端到端的数据解决方案并落地；3.保障业务数仓质量，落地行业领先的实时数仓质量保障方案；4.负责数仓实时计算研发工作，推进数据研发规范落地。岗位要求：1.计算机或相关专业，本科或以上学历，3年以上大数据开发相关工作经验；精通数据仓库建模和离线/实时ETL海量数据处理技术，精通SQL查询分析、大数据架构和大数据治理能力;2.熟悉开源大数据生态，精通Hadoop，Flink，Hive，HBase，Kafka等大数据平台和相关技术;3.优秀的业务理解和分析能力，有商业数据分析、数据挖掘、用户画像、风控、机器学习等相关技术和落地经验尤佳；4.有很强的分析复杂问题和解决复杂问题的能力，有责任心和使命感；5.技术视野开阔，学习和抗压能力好，具备良好的沟通和组织协调能力。
1.本科以上学历。2.熟练掌握java/python/c/c++/go其中一种，掌握常见的数据结构，算法，了解软件工程，敏捷开发等知识。3.有云计算，大数据，人工智能，数据挖掘，数据治理，数据湖，领域或运维，运营管理平台开发经验，微服务产品开发经验者优先。PS：本招聘为留学生招聘，欢迎留学生同学来投~地域：西安，东莞，北京，南京，上海，成都 ，长沙，济南
岗位职责：1、参与大数据平台的架构设计和研发；2、构建设计良好的数据流、调度系统、查询引擎、监控系统，保证系统稳定高效运行，以实现数据的最大价值；3、参与数据平台各系统的性能分析与系统优化，不断提高系统运行效率；4、参与面向业务场景的数据模型、数据挖掘和算法的设计与开发。岗位要求：1、2年以上工作经验，熟悉Linux环境下开发，熟悉Python；2、熟悉Hadoop/Spark/Flink/HBase/Flume/Kafka/ElasticSearch/OLAP等大数据相关技术栈，能在项目上熟练部署及应用；3、熟悉数据仓库模型设计与ETL开发经验，掌握维度建模设计方法，具备海量数据处理经验；4、具有良好的沟通能力、判断力、数据敏感度，能及时关注和学习业界优秀技术；5、有druid、doris、web开发经验优先；6、有金融风控行业经验优先。
跨团队招聘，请勿多次投递相同的岗位工作职责:1、负责数据的ETL设计、开发、优化，保证数据准确与稳定2、负责构建业务数据分析体系，帮助确定各项业务数据指标3、负责数据平台相关后端功能系统设计和开发工作要求:1、计算机或相关专业本科以上学历，至少3年以上数据开发实际工作经验2、负责过大型数据平台和数据仓库设计，具有扎实的大数据和数据仓库的理论功底3、熟悉数据分析建模原理和流程，能够围绕业务特征建模解决业务问题4、掌握python/go，掌握python/go WEB开发常规模式，熟悉微服务架构5、熟悉常用机器学习算法，包括但不限于RF、GBDT、XGboost、SVM、ANN等6、拥有优秀的分析及解决问题的能力，良好的沟通能力，思维逻辑清晰，有强烈的责任心，并能自我驱动成长
Tripalink数据工程师职位描述负责设计、搭建并且维护Tripalink公司的数据仓库，搭建并且维护Airflow，Superset负责对接和使用第三方工具进行数据处理负责搭建数据健康系统，保证数据平台平稳高效运转职位要求1年以上数据工程经验熟练掌握Python，或其他一门主流数据编程语言熟练数据仓库底层逻辑，有搭建分区数据仓库的经验;有搭建、使用、维护Airflow的经验理解并重视数据工具的产出效果对于技术保持热情，积极主动，有较强的自驱力，良好的沟通和快速学习能力具备良好的英文Documentation的能力有爬虫经验的优先有熟练使用Databricks的第三方云数据库经验的优先有一定的第三方数据工具使用的经验优先有一定跟数据科学家和BI工作的经验优先Base：北京 / 上海
数据工程师职位描述1、完成数据平台系统的从 0 到 1 的建设；2、负责 ETL 流程设计、开发和优化；3、处理离线、实时计算，为线上业务提供数据支撑。任职要求1、3 年以上数据平台相关研发经验，熟悉数仓架构及原理，具备数仓建模及 ETL 设计开发能力；2、熟悉云服务厂商的数据开发&治理服务产品及解决方案；3、熟悉 Python/Java/Go 中的至少一种编程语言；4、熟悉数据工程生态，比如 Flink/Spark/Kafka/Hadoop/Hbase/ClickHouse/MySQL/MongoDB  等。加分项业务高度敏感，具备体系化解决方案能力
软件架构设计，开发和实施端到端的数据湖仓、商业智能、数据科学、机器学习项目。在Hadoop生态系统上构建大数据管道，包括HDFS、Hive、Spark、Scala、Sqoop、Kafka、Flink和实时流技术以及大数据开源技术栈。熟练使用云原生大数据工具，包括但不限于MaxCompute, Hologres, Dataworks Snowflake, Redshift等开发工具。提供技术以改善数据质量、数据治理和数据安全。综合考虑数据从老系统到新系统的迁移解决方案。按照业务需求书写数据ETL。任职要求：拥有计算机科学、计算机工程或相关领域的学士学位。至少有3年的大数据，数据仓库架构的经验。熟悉Hadoop生态系统，如HDFS、Hive、Spark、Scala、Sqoop、Kafka、Flink、iceberg、airflow。对数据库结构系统和数据挖掘有深刻的认识。具备数据工程、数据管道和数据治理技能。优秀的组织和分析能力。出色的问题解决能力。良好的英文书面和口头沟通能力。
工作职责：1、负责开发大数据工具, 如报表平台/多维度分析工具/ETL平台；2、负责数据仓库的建设, 数据接入/数据建模/数据服务等工作；3、负责大数据平台核心问题的攻关, 解决项目中出现的技术难题。任职要求：1、重点院校本科及以上，计算机、软件工程等相关专业；2、3年左右工作经验，具有良好的学习能力、团队精神以及协调沟通能力；3、掌握大数据生态技术栈, 具备较丰富的Hadoop/Hbase/Hive/Flink等大数据工具的应用和开发经验；4、熟悉Linux系统, 具备Java/Python/Scala一种或几种语言开发能力；5、扎实的SQL功底, 了解不同框架下SQL执行的原理, 熟悉大数据结构化及非结构化分析工具, 有比较丰富的实战经验；6、优秀的业务理解能力和良好的沟通协调能力, 有大数据或者数据仓库项目经验优先；7、喜欢研究开源技术, 对框架源码/底层原理有比较深入的了解。
工作职责： 1、负责大数据平台的性能调优，控制架构质量，解决项目技术难题；对研发项目和任务需求进行评估和方案设计、配合 Leader 完成开发工作。2、实现大数据实时数仓搭建与开发、多业务系统数据实时接入、流式计算、数据挖掘分析及数据可视化的架构设计与能力，支持解决方案实施。3、负责数据模型、数据处理运维、数据安全等架构落地。4、完成技术验证，核心技术攻关，解决开发过程中技术难题。技能要求： 1、具有 3 年及以上大数据架构设计和开发经验；沟通能力强；本科及以上学历。2、熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖据、数据可视化；3、熟悉 Hadoop 相关各种开源项目，掌握 Hive、Spark、Kafka、impala、kudu 等数据处理核心组件；对 HDFS、M/R、Yarn 的原理有深入了解，掌握系统优化方法。4、熟悉流式计算引擎 SparkStreaming/Flink4、熟悉 Java/Python/Scala 等一种或多种语言，熟悉 Linux 平台。5、具有银行、金融领域相关大数据实时数仓系统构建经验者优先。
岗位职责：1. 以科技研发项目为载体，注重面向市场与生产的研发应用、前瞻性技术储备，形成科研成果和公司核心技术；2. 负责大数据研发课题的立项申请、研发实施和结题工作；3. 配合做好大数据开发项目的全过程管理和成果转化、奖项申报；4. 负责与课题相关的技术标准、工法和专利的编制；5. 跟踪、收集国内外行业人大数据发展的动态和科技信息。任职要求：1.硕士研究生及以上学历2.大数据相关专业毕业3.具备大数据相关工作经验优先4.愿意从事相关开发工作
岗位职责：负责公司和驻场项目中的大数据处理流程开发，部署和运维. 和算法工程师合作部署机器学习模型上线，并进行日常运维和问题排查.参与公司数据中台建设，打通业务，知识库，算法模型训练各个模块.职位要求;1. 211 CS专业硕士研究生及以上2. 精通python, pyspark, pandas3. 熟悉至少一种主流数据库(oracle, mysql, postgres)，linux操作系统，restful服务4. 熟悉主流数据结构(数组，链表，HashSet，树，图)5. 了解机器学习算法优先考虑，了解airflow，图数据库(neo4j)优先6. 良好的团队协作精神及沟通能力. 7. 工作认真负责，学习能力强，能够承受工作压力，可以在远程工作环境下保质保量完成项目交互和团队协作
岗位职责：1. 负责公司数据仓库的系统需求分析、核心算法设计，应用接口代码的编写；2. 负责大量用户端、服务端数据体系的建设，通过数据+算法+工程化能力处理和萃取数据，通过数据反哺业务；3. 开发离线、实时数据应用，为海量数据的处理和分析提供高效解决方案。岗位要求：1、熟练掌握Java，python等技术，数据仓库领域至少2年以上经验，具备1年以上的工作经历对实时计算和离线计算熟悉；2、熟练掌握至少3种MySQL、mongoDB、es、redis，kafka，或者其它nosql的使用；3、精通Hadoop/Hive/Hbase/Storm/Spark/Flink等大数据技术的使用，具有大规模数据研发项目经验；4、对算法、数据结构以及后台开发（java/Python等）须非常了解 ,了解Web前端脚本语言者优先
工作职责1. 负责商业大数据产品研发，数仓建设和重构优化工作2. 负责为大客户项目提供技术支撑：技术方案设计，解决平台类、数据类问题，把控代码质量职位要求：1. 4年以上大数据开发经验, 熟悉数据仓库模型设计与ETL开发，具备海量数据处理经验2. 熟悉java语言以及Java生态、熟悉Python或scala3. 熟悉Hadoop、Hive、Hbase、Spark等大数据开源体系4. 熟悉各类大数据平台，具有实际集群搭建和调优经验；5. 有很强的文档撰写能力，有很强规范意识的优先6. 良好的沟通、协调能力、抗压能力，能接受出差
参与供应链预测补货项目的需求分析和功能开发；运用大数据工具分析和处理预测补货数据，负责数据性能分析和优化；任职要求1、本科及以上学历，1年以上大数据数据处理经验；2、精通SQL，了解供应链相关业务系统，具有供应链数据分析经验者优先；3、熟悉JAVA、Python开发语言，具有数据挖掘经验；4、熟练掌握Hive、SparkSQL等主流大数据数据处理技术，能解决应用中的复杂问题，研读过源代码者优先；5、熟悉Kafka等消息中间件技术，了解数据采集系统的设计与实现；6、熟悉Redis，memcached其中一种或以上缓存技术；7、熟悉elaticSearch，了解其体系结构和索引原理；8、有强烈的上进心和求知欲，善于学习和运用新知识，沟通能力强，有强烈的责任心，具有良好的团队合作精神和敬业精神。
职位描述1、负责离线与实时数据仓库的构建；2、负责数据模型的设计，ETL实施，ETL性能优化，ETL数据监控以及相关技术问题的解决；3、负责指标体系建设与维护；4、深入业务，理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；5、参与大数据应用规划，为数据产品、挖掘团队提供应用指导；6、参与数据治理工作，提升数据易用性及数据质量。职位要求1、熟悉数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；2、熟练使用Hadoop及Hive，熟悉SQL、Java、Python等编程语言；3、善于沟通，对业务敏感，能快速理解业务背景，具备优秀的技术与业务结合能力。
岗位职责： 参与建设大数据平台BI系统，维护底层Clickhouse引擎，协助排查和解决业务使用过程中的问题； 岗位要求： 1、两年以上大数据技术相关工作经验，熟练使用hadoop，spark，hbase，hive，flink，presto等相关组件。2、具备一定的JAVA或C++开发能力，基本的数据结构和算法基础。3、熟练掌握SQL，有一定的SQL优化能力。4、有生产系统实际运维clickhouse，doris，starrocks，greenplum等MPP数据库(clickhouse优先)经验。熟悉相关数据库架构，配置，集群搭建及运维。熟悉源码者，有提交patch者优先。5、参与研发过大数据量BI系统，用户标签系统者优先。
高级数据开发工程师1、负责集团金融业务数据和用户行为日志等数据的采集和计算。2、负责数据模型及应用模型设计，带领开发队伍完成交付目标。3、依托数据中台，设计和实现关键数据产品和数据服务。相关要求：1、计算机及相关专业硕士以及以上学历，5年以上工作经验。2、熟悉RDBMS和NoSQL数据库，熟练掌握SQL、PLSQL编程技能，熟悉Python、Java者更佳，有良好的代码习惯。3、熟悉大数据平台hadoop技术栈，使用过Hive/HBase/Spark等大数据平台组件优先。4、至少有流式处理、营销和推荐算法、数据仓库模型、用户画像中两个领域的项目实践。5、对新事物新技术充满好奇，乐于接受挑战，有互联网数据开发背景优先考虑。
岗位描述：1. 负责公司大数据平台的架构设计、研发和调优工作，持续提升平台系统的可用性、可靠性、可维护性和可扩展性；2. 负责企业级数据应用的架构设计和核心模块开发，推动后台基础策略算法和数据挖掘分析能力快速落地并实践；3. 布局大数据团队的技术演进，洞察新技术的发展，组织团队的学习与培训。岗位要求：1. 本科及以上学历，计算机相关专业；2. 3年以上的大数据处理工作经验，对主流大数据技术和框架（如Hadoop、Spark、Flink、Flume等）有深入理解和充分实践；3. 精通分布式存储相关技术，不限于HDFS、Hive、Redis、Mongodb、ElasticSearch、Kafka、Sqoop等；4. 熟悉Linux操作系统，掌握Java、Scala、Python等至少一种开发语言，熟悉分布式应用设计；5. 熟悉常用的分类、回归、聚类等算法及应用场景；6. 对主流的研发流程、质量控制方式、项目管理方式有充分的理解；7. 具备自主的学习能力和追求卓越的态度，具有良好的团队协作精神。
岗位职责：1. 负责大数据应用类系统的设计和开发，以及关键技术的攻克，如推荐、用户画像、数据治理等等；2. 协同产品、算法，设计实现基于业务、产品和技术的数据应用领域解决方案；3. 参与内外部的业务需求分析，推动数据资产和数据可视化建设及优化；4. 参与企业级大数据平台建设及环境整体搭建，实现从数据采集、清洗、加工、汇聚到全链路数据分析应用的全方案落地。任职资格：1. 5年及以上大数据工作经验；2. 在可扩展、高性能，高并发，高稳定性系统设计，开发和调优方面有实际经验；3. JAVA技术知识扎实，熟悉IO，多线程，集合类等基础框架，熟悉缓存，消息，搜索等机制；4. 对Hadoop/Spark/Storm生态有丰富的经验；5. 有良好的系统分析能力、故障诊断能力者优先；6. 有大型分布式系统架构的实际经验；7. 有人工智能相关开发经验优先、熟练使用python语言开发工具的优先、有通信企业工作经验优先；9. 有团队管理经验经验优先。
职责描述：1.负责基于Flink、FlinkSQL的实时计算设计与开发2.负责实时计算服务的性能优化3.负责实时作业的配套文档编写任职要求：1.精通FLink，可对Flink进行开发、调优。2.精通实时流生态组件，如Canal、kafka等3.精通大数据存储，如ClickHouse、InfluxDB等4.熟悉阿里云大数据生态产品，如DataWork、ODPS等5.有实时数仓开发经验的优先;精通goLang语言的优先6.3年及以上Flink实时开发经验
零售大数据业务分析与架构开发
职位描述1.打造业界领先的超大规模批流一体的实时数仓基础设施及架构，并支撑唯品会相关产品线;2.基于Flink SQL打造高效、稳定、易用的实时数据开发平台，降低实时数据开发门槛;3.基于数据湖技术构建批流一体的存储系统，同一种存储同时支持低延迟的实时数仓场景及高性能的离线分析场景;职位要求：1.精通Flink等流处理技术， 有实际项目经验2.熟练使用java开发语言，有大数据量、高并发处理经验3.熟悉Hudi、Iceberg、Delta lake等开源数据湖技术4.了解kudu、Hbase、ClickHouse、Kafka等实时系统原理5.有大型实时数仓架构落地经验者优先6.向开源社区贡献过patch者优先
岗位职责：1.参加大数据流批处理的研发，如实时计算通用组件研发、元数据、血缘分析、指标管理平台、质量管理平台等；2.支持业务数据报告需求；3.大数据资源的调度和优化；4.协助运维做好集群的维护工作；5.积极主动研究大数据时代的各种前沿技术、并能在产品中得以运用实施。任职要求：1.本科及以上学历，5年以上开发经验（3年以上大数据开发），优秀的故障排查和架构设计能力，负责过日均 TB 级数据系统总架构；2.精通 Hadoop/Spark/Flink/Kafka/Airflow 中大部分组件，具备调优能力；3.掌握 Linux 系统下编程经验，熟练掌握一门脚本语言（shell，python 等）；4.精通常用 MPP 数据库（如 HBase，ElasticSearch，ClickHouse）；5.注重代码规范，具有良好的学习能力、文档能力、沟通能力、团队合作意识；6.强烈的责任心与主动性，对所负责工作有owner意识，并能自我驱动成长。
大数据开发工程师大数据开发工程师工作内容：1、负责大数据平台的设计、建模、代码开发和测试；2、规划大数据平台的架构和部署需求，把握系统的高可用、扩展、安全、性能、伸缩性等；3、及时与产品经理/项目经理沟通需求，分析梳理业务场景，协助需求侧解决各种业务实现 问题；4、负责核心技术难题的攻关，攻克团队遇到的技术难题，持续对线上系统进行性能优化及稳定性提升；5、参与对平台的运维和运营的支撑体系的制定和实施，对线上突发问题进行及时响应并解 决；6、负责大数据团队建设及管理，技术文档输出，根据业务发展组织技术预研，并对技术团队布道。岗位要求：1、本科及以上学历，5 年以上相关工作经验；2、热衷于产品研发和技术创新， 具有很强的学习能力并有强烈的责任意识和开放的心态， 工作态度好，积极向上者为先；3、具备大型分布式、高并发、高负载、高可用系统设计、开发及调优经验，有大数据平台 的软件开发、部署经验；4、熟悉 Hadoop 生态圈技术栈，HBase、Hive、MapReduce 等；熟悉 Spark、Storm、Kafka、 Zookeeper、K8S 等开源组件，具备开源项目集成开发经验优先；5、熟悉容器、人工智能、微服务等新技术，有互联网运营平台架构设计或大数据公司同类 平台或产品设计、开发经验者优先。
全职，全国招聘，可以远程在家办公，期望精通spark和scala，可以发简历到***** Marin Software正在寻找经验丰富、富有激情的高级大数据工程师，基于Spark开发成熟的管理数十亿美元的数字广告的企业数据软件产品。 Marin开发SaaS产品，用于衡量、优化和管理跨渠道的数字广告活动。Marin Software是目前管理谷歌广告活动的最大的独立的软件技术公司，每年管理的广告支出为60亿美元，而且管理着40亿关键词。我们也是Facebook上的广告主们优化广告投放的领先的管理工具。Marin已经成为能够提供广告跨渠道管理、生成报告和管理广告预算分配的领先的管理工具。 您将加入我们位于上海的大数据工程团队，并与伦敦和旧金山的其他团队合作。 职责描述 l 负责与OLAP相关的微服务和Spark的工作，从设计、开发到生产的全生命周期l 使用Java/Scala和Apache Spark实现数据开发l 编写高质量的代码，每2到4周发布一次l 对所编写的代码负责，坚持追求简单、高效、可靠和高性能的代码；避免堆积技术债务l 严格执行测试驱动开发l 与全球工程团队合作交付软件l 负责架构和设计，并提出更好的方案l 对初级工程师提供技术指导；积极参与代码设计和代码评审l 主导解决并执行架构和设计中出现的问题，并尽量用更好的方式解决问题 职位要求 l 具有5年以上软件开发经验l 2年以上Spark2.x经验l 有扎实的Java和Scala编程功底l 具备出色的解决问题能力、协作能力和沟通能力l 具有较强的大型系统编程和调试能力l 坚持编写单元测试和可测试的代码l 对Spark有很好的理解l 能用英语进行有效沟通（书面和口头）l 对分布式消息系统架构和Apache Kafka有扎实的理解l 有丰富的Spark优化和调试经验 最好具备以下条件 l 熟练使用Jupyter Notebook进行数据分析l 有谷歌Ads API经验l 熟悉Presto和MySQLl 了解Kafka and Akka
工作职责1、牵头项目的大数据平台建设实施，涉及大数据相关系统平台的设计、开发及快速迭代；2、负责平台数据模型、指标、生命周期的设计和管理；3、开发、实现和运维基于私有云和公有云的大数据基础设施；4、基于对公司项目业务模式的深入理解，发掘数据价值；5、承担所负责系统生产问题定位和问题处置；6、完成上级领导安排的其他工作。任职要求1、本科及以上学历，计算机等相关专业；2、3年及以上软件开发工作经验，1 年及以上大数据系统开发、设计经验；3、精通大数据Hadoop体系的相关技术： Hive、HBase、Storm、Kafka、Kylin等；4、熟练掌握Java、C/C++等程序开发技能，具备行业业务分析、模型设计、数据挖掘等相关工作经验的优先；5、熟悉SAS、R、Python等主流挖掘分析工具，掌握机器学习基本理论以及多种机器学习算法，具备模型调优能力；6、熟悉BI工具，具有大数据平台的开发运维经验7、具备良好的团队合作能力、沟通能力和综合分析能力，学习能力强，承压能力强，工作责任心强，有创新思维，对数据技术和业务发展有高度敏感性。
"岗位职责：1. 负责广告系统数仓、流批任务开发、存储与计算优化、即席查询效率提升等；2. 负责广告系统架构优化评审和分析，设计计算流程、评估计算资源、任务开发和自测；	3. 保障编码、API调用、任务运行符合规范，相关代码注释清晰、明确、无异议；					4. 当所负责的任务出现问题时，第一时间跟进排查并解决问题；					5. 负责大数据系统相关技术处理方案、技术文档的更新与维护。任职要求：1. 熟悉计算机系统原理、常用数据结构和算法、计算机网络、HTTP协议等基础理论；		2. 熟练掌握Java/Scala中的至少一种，熟悉常规JVM参数优化；			3. 掌握Hadoop、Hive、Spark、Flink、Kafka的使用；			4. 掌握常用Spark参数调优、错误定位，能优化复杂Spark任务性能；			5. 深度掌握Impala/Kylin/Presto/Druid中的至少一种分析引擎；6. 有较强的沟通表达能力，善于学习，能迅速理解产品需求；7. 有较强的责任心和事业心，有严密的逻辑思维，有追求卓越的精神，能够自我驱动；8. 有处理PB级以上数据经验者或广告行业数据经验者优先考虑。职位信息"
岗位职责：1、负责大数据实时平台的开发工作2、参与业务数据、生产日志的抽取、转储、计算、检索等相关开发工作3、保证实时接入体系稳定性及扩展性任职要求：1.计算机等相关专业，本科及以上学历，3年以上大数据产品平台或J2EE平台项目研发经验，2.熟练掌握Hadoop、HBase、Hive、Spark、Flink等大数据开源框架，深入理解Map/Reduce、Hive、Hbase、HDFS、ES等相关原理及高级特性，具有丰富的海量数据处理开发经验。3.具有良好的软件工程能力，扎实的java或python技术基础，熟悉常用的微服务开发框架(e.g. Spring Cloud)和web前端开发框架, 并对Web应用有一定的架构设计能力，4.熟悉Linux平台，熟悉k8s技术的优先考虑5.熟悉AWS，阿里云等主流云服务的优先考虑6.在实时计算，离线计算等方面有丰富的项目实战经验7.自驱动能力强，有较强的思考力8.思路清晰，具备良好沟通能力
岗位职责（1）参与大数据需求的开发；（2）根据业务需求进行数据模型的调研、设计、开发及验证工作，并持续进行模型的优化；（3）基础数据ETL处理；岗位要求（1）本科或以上学历，计算机、数据挖掘等相关专业，3年以上大数据开发经验；（2）熟练使用Scala、Java，熟悉shell，python等脚本语言；（3）熟练使用大数据处理技术，Hadoop、Hive，Spark，Kafka等；（4）掌握HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；（5）有电信运营商工作经验者优先
- 对数据处理、数据建模、数据分析等有深刻认识和实战经验，对hadoop生态其他组件有一定了解，比如 HBase， hadoop, Hive, Druid等- 熟悉Hive SQL语言，熟悉shell, python等脚本语言；- 熟悉java或scala；- 熟悉至少一种实时计算引擎 Storm, Spark Streaming, Flink；- 熟悉Linux/Unix系统和丰富的Java开发经验。- 熟悉数据仓库理论，具备复杂业务需求梳理能力。- 熟练SQL开发，精通Mysql等关系型数据库。- 熟悉Linux系统，具备shell、python等脚本开发能力者优先。- 了解微服务开发理念、实现技术，熟悉常见设计模式，熟练掌握SSH开发框架，熟练进行Java、Python代码编写，熟悉多线程编程。- 有hadoop、spark、flink等大数据平台的使用经验优先；
工作内容：1.基于Hadoop/Hbase/Spark/Hive的大数据离线/实时数据平台的开发和维护；2.参与公司大数据平台的数据仓库系统建设；3.参与公司大数据集群的性能优化，以及大数据平台架构的整体设计与改进；4.参与对数据挖掘及业务开发团队提供技术支持，协助方案规划；5.参与大数据平台相关技术攻关和创新技术引用。6.后端开发接口与前端对接任职要求：1.数学相关专业优先考虑，本科及以上学历；2.1年以上Java,Scala编程经验，熟悉流行的大数据编程框架，有大数据处理和应用开发的相关经验；3.精通Hive,hbase,mongoDB,redis等关系型数据库和非关系型数据的使用和优化；4.熟悉Hadoop,Hbase,Spark,Hive等hadoop生态圈的框架的部署,维护和开发5.熟悉Linux系统，精通Shell脚本语言；6.较强的学习能力以及快速解决问题的能力。7.熟悉springboot框架,有参与前端对接的项目经验者优先8.有过大厂经验者优先
岗位职责：a.负责公司级数据管道开发、优化，构建掌门集团中央化数据平台。b.负责不同业务系统数据抽取组件开发，提供易用、低侵入、高吞吐、可重用的抽取组件。c.负责不同业务系统数据元数据管理，制定推动元数据规范落地。d.能分析和解决基础组件问题，解决技术痛点。任职要求：a.本科以上学历，3年以上软件开发经验，扎实的编程基础，熟悉常见数据结构，熟练掌握Java、python、scala中至少一门语言。b.具备从分布的、异构数据源如关系数据、平面数据文件等抽取开发经验。c.熟悉无侵入、低侵入式数据同步技术，且具有实践经验。d.有元数据管理、规范落地经验优先。e.加分项：数据集成组件相关使用经验，对数据交换组件如Datax/Camel/Mule源码有一定的理解。f.良好的沟通能力、团队合作精神；优秀的学习能力；快速解决技术问题的能力；强烈的目标感。
职责描述：1. 负责风险管理相关数据抽取、数据处理和数据展示的架构设计、数据建模和开发。2. 利用流处理引擎计算加工风险监控和策略使用的特征。3. 制定数据治理规则和流程，提升数据的可用性和数据质量，并对数据质量进行长期监控。4. 积极了解业务需求，不断提高数据的查询、分析效率，发挥数据应有价值。 职位要求：1. 熟练应用数据仓库实施方法论、深入了解数据仓库体系，有相关工作经验3年以上。2. 具备较强的动手能力，精通Kafka和Flink。熟练使用SQL/Java/Scala/Python等中的多项，有风控大数据项目经验或者特征加工平台开发经验。3. 对数据敏感，认真细致，善于从数据中发现问题。4. 善于沟通，具备优秀的技术与业务结合能力。5. 能够使用英语工作。
岗位职责：1、负责广告部大规模机器学习离线样本数据流的开发和维护，提高离线特征抽取计算的复用性；2、负责广告部大规模机器学习离线特征的存储组件选型和开发，避免特征数据重复存储，提高存储效率；3、负责广告部大规模机器学习离线数据流平台的开发和维护，提高算法离线特征调研迭代效率；4、构建机器学习数据质量体系，持续提升数据质量和及时发现数据问题；5、跟踪和调研前沿的数据处理和分析、存储技术，不断提升计算和存储效率；任职要求：1、对数据处理相关技术如hadoop、spark、flink等有一定的了解2、对Java、Python有一定的理解；3、对hbase等列式存储系统有实际使用经验；4、有机器学习、大型电商系统、互联网广告、数据挖掘、流计算相关经验者优先。
岗位职责1、主要支持海量数据的分析需求，对多种数据源进行深度诊断性组合分析、挖掘、深度分析和建模；2、熟悉数据统计分析，推动统计分析模型的建立和完善；3、进行大数据仓库建设，分析业务需求，进行数据规则转化，通过数据清洗、转换、集成、统计等技术手段，完成需求的数据交付，利用etl工具建立日常报表调度体系；【岗位要求】1、本科以上学历，统计学、计算机、硕士优先，可接受应届生；2、具备较强的数据敏感性，具备很强的数据洞察能力，能快速从繁杂数据中发现问题，付诸到产品规划和设计；3、善于表达和沟通，能够和用户建立良好关系，能够推动数据和方案实施；4、熟悉linux系统操作，掌握至少一门脚本语言（Shell/Python/Go）；5、基于Hadoop的大数据体系有深入认识，具备相关产品（Hadoop、Hive、HBase、Spark、Storm、Flume、Kafka、ES等）项目应用/研发经验，有CDH/TDH集群搭建和管理经验；6、2年以上数据分析或数据开发经验，精通sql，有hive sql编程、调优经验优先；7、精通Tableau、MicroStrategy、帆软BI等其中至少一种产品设计逻辑及功能实现机理；
岗位职责： 1. 负责大数据服务（离线+实时）的开发； 2. 参与大数据产品的开发； 3. 参与大数据平台、应用系统的业务梳理和架构设计。  任职要求： 1. 2022届获得本科及以上学历，计算机相关专业，成绩优异，学习能力强； 2. 熟悉 Hadoop 生态相关技术，使用过 spark 或 flink，有项目经验者优先； 3. 熟练掌握 java，有项目经验者优先； 4. 熟悉 sql，有项目经验者优先； 5. 有 shell/python 实践经验者优先。
【岗位职责】1.负责理解及协助业务方定义自动驾驶性能及其它相关业务评估核心指标，建立自动驾驶核心数据仓库2.负责定义数据流转的标准、规范，打通数据使用的各个环节及已有的平台，建立自动驾驶场景的数据闭环3.负责理解业务需求，开发实时&离线作业，并进行自动化处理4.负责数据治理，包括元数据管理、数据血缘管理等5.负责优化各类数据查询及存储方式，提升海量自动驾驶数据处理的性能”【任职要求】1.本科及以上学历，2年以上数据开发经验2.熟悉python或者Java其中一门开发语言3.熟悉SQL语言，有spark ETL能力，熟练使用常见的数据接入、数据治理、指标平台等4.熟悉大数据架构，具备离线数据研发能力，熟悉Hive，Kafka，Spark，Airflow，Flink等相关技术并有相关开发经验5.具备实时/离线报表开发能力6.思路清晰，对数据敏感，有良好的沟通表达能力和跨团队协作能力
岗位职责：1.建设数据仓库，负责数据仓库设计、建模、研发等工作，参与业务数据指标体系搭建，根据业务内容提供数据解决方案； 2.参与ETL性能优化，ETL数据监控以及相关技术问题的解决； 3.支持业务团队的数据分析工作，负责面向业务的统计报表，数据提取等工作；4.理解数据仓库架构，在项目实施的过程中，发现并解决各种维度/粒度的数据问题。岗位要求：1.本科院校，计算机、数学或相关专业2.熟悉数据仓库建设方法论，了解基于Hive的SQL开发及SQL性能调优；3.熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等；4.熟悉Linux系统环境，熟悉Shell/Python/Perl等至少一种脚本语言；5.具备良好的学习能力、沟通表达能力及业务理解能力。
岗位职责：1. 参与公司大数据技术团队共同打造新一代智能大数据平台；2. 参与跨产品线（包括大数据分析引擎、云原生资源管理和调度、语义层分析等产品）的架构设计、技术选型、代码评审、质量评审；3. 负责核心技术难题的攻关，攻克团队遇到的技术难题，持续对线上系统进行性能优化及稳定性提升；4. 在实时数仓、SQL优化、云原生架构、分布式存储和索引、增强分析等领域负责关键技术的探索研究，技术落地；5. 依托公司产品，打通用户在数据域（数仓、数据湖）与应用域（用户画像、精准营销系统）之间的隔阂；6. 负责跟进大数据组件的新特性，结合业务需求引入并落地，有效提升平台效益；任职要求:1、五年以上大数据开发经验，有过产品研发工作经验；2. 熟练掌握Java、Scala、Python、Shell等常用编程语言，熟悉常用的JAVA开源框架( 如SpringMVC、MyBatis、SpringBoot、SpringCloud等)，并理解框架的原理和机制；3. 熟悉 Hadoop/Spark/Impala/Flink/Druid/HBase/Redis/ElasticSearch 等两种及以上技术，具有任一框架优化经验者更佳；4. 具备系统开发经验(而不是简单地搭建运维过某开源系统)，对高性能、高吞吐、高可靠的业务场景有丰富的理解和处理经验；5. 善于交流，有良好的团队合作精神和协调沟通能力，积极主动，有强烈的责任心和主人翁意识；6. 负责过大数据业务线或整体产品的架构工作，组织过中等以上规模项目者优先，对开源社区有源码贡献者优先；7. 个人价值观与创业公司价值观兼容。
1、参与各类通用地理位置相关服务的设计/开发；2、参与海量位置相关数据的分析/挖掘，建设位置相关的数据仓库；3、参与在线大流量高并发业务/服务系统设计与开发；4、分析和深入发掘现有系统的不足，定位系统瓶颈，提高系统性能和稳定性；5、根据业务实际需求，为团队引入新技术和新方案；6、以自身良好的项目管理与协调沟通能力，负责跨团队的重点项目的推进工作。职位要求1、本科及以上学历，计算机、通信、地理信息等相关专业；2、有扎实的编程能力，有优秀的设计和代码品位；3、深刻理解计算机原理,有良好的数据结构和算法基础；4、熟悉MySQL 、PostgreSQL、MongoDB、Redis、消息队列等常用组件；5、有以下经验者加分：1）理解空间索引技术并有实际使用经验者，有过空间引擎研发/调优者优先；2）了解常见数据清洗/挖掘算法，有实际运用经验者优先；3）熟悉大数据计算体系，有过业务数仓建设经验者优先；4）熟悉爬虫有数据采集经验者，有地理位置数据经验者优先；5）有地图、POI、LBS等业务背景者优先。
岗位职责：1.大数据算法研究、设计、研发、迭代优化与测试；2.项目与产品核心算法设计与实现，根据不同的业务场景，建立相应的数据挖掘模型，负责为应用层开发各种标签和接口；3.负责大数据服务平台的核心算法层的开发工作，大数据的导入，导出；4.负责大数据平台的管理和优化（Linux、hadoop、Spark、Storm等）。岗位要求：1、5年以上数据仓库、数据开发经验；熟练掌握主流ETL工具(datax等）、实时开发和离线开发2、3年以上CDH平台开发经验，熟悉使用 java hadoop spark flink 等技术栈处理日常开发工作3、熟练掌握主流大数据技术，包括但不限于hadoop、kafka、flink、spark、Hbase，hologres,clickhouse基础原理4、1年以上基于阿里云dataworks的实施经验；5.最好有车联网经验。工作地点：上海 嘉定区于田路7号 大众。
职位描述：1、负责面向发行的BI系统后端研发，功能设计、开发实现、以及运营维护；2、持续改善已有服务，分析系统瓶颈，优化系统薄弱点，提升性能和稳定性；3、为上下游和最终用户提供标准化服务，保证优质体验。职位要求：1、熟悉大数据基础架构、业务数仓架构，能够针对业务需求进行合适的技术选型，并持续迭代优化；2、熟悉大数据生态组件，包括Hadoop、Hive、Spark、Flink、kafka等；3、精通Python/Go/Java/Scala至少其中一门编程语言；4、数据仓库建模及数据ETL开发经验者优先；5、有OLAP开源引擎（clickhouse等）项目经验优先；6、熟悉aws、k8s，有游戏发行、广告平台、商业化经验者更佳7、有热情，爱学习，关注大数据前沿技术发展，逻辑思维能力好，有较强解决问题能力；
岗位职责：1.负责收集、分析业务部门数据类项目需求；2.负责数据类项目（大数据平台、数据仓库、BI类）的开发和管理岗位要求：1、3-5年左右数据开发经验；2、熟练掌握SQL编程语言，熟悉hadoop相关组件，如hive、Spark+；3、熟练掌握HIVE数据库的SQL语言、SQL调优，脚本开发，UDF函数4、具有银行业IT系统数据仓库、数据集市相关领域项目开发实施经验，5、有丰富的数据建模、ETL架构与开发经验，深入了解相关技术者，熟悉银行业务开发者优先考虑；6、具有良好的沟通、团队协作、抗压能力及责任心。
职位描述： 1. 负责大数据基础平台架构建设和研发；2. 负责大数据存储系统和计算引擎相关研究、特性研发和性能调优，偏向于存储引擎； 3. 负责大数据系统整体及组件的性能、效率、稳定性分析与优化。职位要求： 1. 熟悉HDFS/Hive metastore/Presto/Kudu/Kafka等大数据技术和组件，有1-3年大数据组件的使用和二次研发经验； 2. 熟悉Presto/Impala/Clickhouse等OLAP引擎, Spark/Flink计算引擎； 3. 具备扎实的计算机基础，熟悉分布式系统研发； 4. 精通Java研发语言，具有良好的编程研发能力； 5. 对新技术敏感，有较强的学习能力和解决问题的能力，乐于学习分享，有较好的沟通能力和执行力。
1、工作年限方面：本科2年以上，专科3年以上，学历须学信网可查2、开发技能方面：【岗位职责】负责相关项目开发工作【必备技能】1）精通Hadoop技术栈，能独立完成功能模块的设计、开发工作2）熟悉ORACLE、MySQL至少一种数据库，掌握基本的数据库调优技能3）熟悉oracle、hadoop（包括hive），linux shell等方面，有相关经验【工作经验】1、参与过银行业风险条线业务研发工作的优先。2、个人素质方面：做事认真，责任心强，热爱编程工作（不能有被其他公司退用的记录）3、有比较强大学习能力和独立工作能力,善于表达和沟通4、关于人员稳定性：有长期在工行工作的打算。二、福利待遇1、入职即享五险一金；2、节假日享实物福利；3、带薪年假，年度旅游；4、朝九晚六，双休。
工作职责：1、基于Hadoop数据中台，参与数据需求调研、分析、数据模型设计、数据开发等中台建设工作；2、负责数据中台开发、监控及对现有中台优化工作；3、参与数据中台探索应用场景的落地实施工作；4、负责数据中台各大数据组件的性能、效率、稳定性分析与优化工作；任职资格：1、本科及以上学历，3年及以上数据仓库/数据平台/数据中台项目开发工作经验；有大厂经验优先； 2、熟悉数仓领域各种理论知识，如元数据管理，数据质量治理、主流数据建模方法（维度建模、范式建模）等，可以根据实际业务设计数仓模型；3、对Hive有相对深入的理解及实际开发、优化经验，熟悉Linux常用命令，以及Python、Shell等脚本语言； 4、熟练使用Hadoop生态圈技术，如：Hive、Hbase、MapReduce、Kafka、Flume等； 5、熟悉Kafka、Pulsar、RabbitMQ等至少一种消息中间件，熟悉 Storm、Flink、Spark Streaming等至少一种流式数据处理框架； 6、具备一定的Java开发及调试能力，熟悉可视化工具者优先；  7、具有强烈的责任心和充分的主动性，能够积极主动的推进项目的进展； 8、具有较强的抗压能力和学习能力，能够独立、高效地发现和解决或推动解决各种疑难问题； 9、具有良好的沟通能力和团队合作能力。
岗位职责1.负责大数据平台（Hadoop，HBase，Flink等）集群环境的搭建，性能调优和日常维护；2.负责离线数仓、实时数仓、数据服务化的设计、开发、性能优化，为上层分析和挖掘提供可靠、统一的离线+实时数据服务；3.负责大数据平台核心问题的攻关, 解决项目中出现的技术难题。4.负责大数据任务的设计与研发、开发文档的编写5.落地大数据算法和相关应用，优化模型，挖掘数据的价值技术要求1.计算机相关专业，本科及以上3年以上大数据平台开发经验2.熟练运用至少一门编程语言，包括但不限于 Java、Scala、Python、Shell等；3.熟悉常用开源分布式系统，对Hadoop/Hive/Spark/Kafka/Flink/HBase中的一项或多项有深入了解;，能够独立排查及解决分布式系统的问题；4.有ClickHouse/Kylin/Doris/Superset等OLAP和数据可视化相关经验者优先；5.具有物流大数据经验者优先；6.精通数据建模及ETL设计开发，对数据仓库、数据平台、数据分析等有深刻理解，具备丰富的海量数据加工处理和优化经验；7.对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先；8.良好的沟通表达能力和团队合作精神，有一定的组织协调能力，学习能力强有责任心，不断挑战自己；
1、负责负责大数据架构设计、搭建、开发、上线； 2、负责大数据实时检索分析平台的架构和建设； 3、负责指导团队成员开发，对代码质量进行监控、确保开发质量； 4、负责大数据平台新技术的调研及技术选型； 1、熟悉云计算平台(IAASPAASSAAS)、大数据(HADOOPSPARK等)、移动互联网、物联网等技术架构和发展趋势； 2、精通HadoopStormSparkFlink等大数据分布式框架，并有实际经验； 3、熟悉大数据相关技术：Hadoop Hive HBase ZooKeeper Spark MapReduce等； 4、熟悉各种数据结构和算法， 5、5年以上软件开发工作经验，2年以上大数据系统开发，设计，架构经验； 6、具有数据仓库建设或应用相关项目经验优先有实际动手搭建hadoop体系架构经验，有算法经验优先， 对Hadoop体系各个中间间有实践经验，hdfs，mr，spark，hive，hbase，sqoop等
1. 计算机软件及相关专业，有1-2年大数据离线数仓开发经验；2. 具备数据平台相关项目开发设计经验；3. 熟悉数仓建模方法，并有实际应用经验；4. 对Hadoop、Spark、Flink、HBase等有深入的理解，并至少二种以上实际项目应用经验；5. 熟悉Redis、Kafka、Elasticsearch、Flume、ELK等组件。6. 具有海量数据服务（处理）领域的相关工作经验；7. 熟悉linux系统，具有shell、python等脚本语言开发经验；8. 较好的沟通理解能力，工作态度认真，有责任心，良好的团队合作能力；9. 有金融、保险行业相关开发经验的优先录用岗位职责：1. 参与数据平台的架构设计、核心开发及维护；2. 完成相关项目的分析、设计及开发实现，并对现有系统优化；3. 积极探索系统服务（大数据）领域的新技术，并结合公司实际应用到具体项目中
"Sr. Big Data EngineerTeam: GDSLocation: ShanghaiJob Description SummaryAt PayPal Global Data Science(GDS) team, we develop machine learning platform and AI applications to improve PayPal’s global business. Machine learning and AI is one of the core competitive advantage of PayPal, which significantly reduced payment risk loss, brought million dollars’ revenue and expanded to multiple domains rapidly. As an engineer in GDS, you will work closely with analytical team, understand the requirement with cutting-edge algorithm, contribute to the core platform, make the research work to a real product. We are looking for strong technologists who are passionate to solve machine learning problems and able to continuously deliver AI solutions in scalable way.What you will enjoy doing with us:•	Design and build data infrastructures and tools leveraging Big Data industry standards and cutting edge frameworks to enable data scientists to research and deliver analytical solutions via self-service Work side by side with data scientist to address technical issues to enable them to extract meaningful and actionable insights from PayPal data. Lead analytical projects from inception through research, development and all the way to production on PayPal’s data processing infrastructureWhat you need to bring to the role:•	B.Sc. (or above) in computer sciences/ mathematics•	1-10 years working experience, preferably in an Internet company.•	2+ years’experience in JAVA/Scala•	Rich experience on Big Data such as Spark, Hadoop, YARN, Hive will be plus•	Solid foundation in common design patterns, algorithms and data structure.•	Solid knowledge on database(SQL/NOSQL)•	Familiar with Linux, Bash and Network.•	Experience in developing high performance, high scalable distributed systems is a big plus.•	Experience in AI, Machine learning, data analysis and so on is a plus.•	Experience with messaging platform such as Kafka and ActiveMQ is a plus.•	Experience on high concurrent, high scalable microservice is a plus.•	Deep understanding of software engineering best practice, capable of working in a global distributed engineering team.•	Excellent communication skills, Fluent in English, both written and oral.•	Quick learning capability under rapid changing environment.•	Can-do attitude and be willing to challenge the status.•	Strong business sense and analytical ability."
岗位职责：1、负责大数据平台和数据产品的建设，协助产品对外输出；2、使用hive、flink、clickhouse等开源组件，并基于开源组件进行二次开发，满足业务中的定制化需求；3、针对不同业务场景，提供大数据量查询性能优化建议与方案；任职要求：1、5年以上工作经验，熟悉Linux/Unix操作系统，有python、shell等脚本语言编程能力2、熟悉hadoop、hive、spark、flink、kafka、es、redis、zookeeper等大数据相关技术及中间件，了解底层机制与原理，具备开源软件源码分析、二次开发与优化能力，并能结合业务场景进行架构设计；3、熟悉视频业务，有相关工作经验优先；
职位描述       智数云是一个支持敏捷化数据中台建设的平台级产品，帮助企业实现一站式的数据管理、加工、分析和应用，快速实现数据价值。在智数云平台的基础上，需要此岗位开展以下工作：1. 根据客户的大数据应用需求， 构建数据收集、加工和应用流程；2. 测试、管理和维护已有应用流程；3. 培训企业客户自助使用数据中台建设数据应用。岗位要求：1. 计算机或者相关专业；2. 熟悉Python，有一定的编程经验；3.  熟悉SQL语言和关系数据库原理；4. 善于沟通，做事积极主动，责任心强。
"岗位职责：	1. 负责支持前端业务部门的数据处理需求；2. 负责标签体系建设及数据运营；3. 负责外部项目数据开发支持；4. 负责数据产品的数据处理模块设计及开发；5. 按时完成业务部门需求，完成项目及数据产品开发任务；6. 交付结果确保数据质量。岗位要求：1. 本科及以上学历，有1年以上大数据开发、数据仓库开发、数据分析相关经验；	2. 熟练掌握Hive SQL、python、Shell等开发语言，熟悉Hadoop、Hive、Spark等相关大数据工具；3. 熟悉Hive SQL、spark常用性能调优方法，熟悉常用的机器学习（如决策树、逻辑回归、聚类等）算法者优先；4、有海量数据处理的项目经验，有数据仓库或数据产品的架构设计能力；5、具有良好的沟通、团队协作以及项目管理能力，做事积极主动，乐于学习新知识。"
岗位职责：1、参与大数据统一调度平台开发及日常运维。2、参与数据统一交换平台/统一接口服务开发。3、参与数据采集，数据解析及数据推送服务开发。任职要求：1、计算机相关专业本科及硕士以上学历，985/211优先，2年以上相关系统研发经验。2、熟练使用linux，能够使用shell脚本编写代码，熟练使用java，有web项目经验，熟悉JS优先。3、熟练掌握SQL开发语言，了解Scala或Java语言；懂得SQL优化，掌握窗口函数、自定义函数、explode等函数运用；4、熟悉Spark、Hadoop、MapReduce，了解ETL性能优化；熟悉大数据Hadoop生态系统，熟练使用主流大数据平台进行数据的处理，具备其中一种或多种产品(Spark、Hive、Hbase、Kafka、ES、Flink等)使用经验。5、熟悉阿里云Dataworks，maxcompute，QuickBI者优先。6、具备统一调度平台或者数据交换平台自主建设经验，熟悉airflow、Azkaban、海豚调度，XXL调度、datax等开源项目，掌握核心系统设计理念7、熟练使用一种数据库，包括不限于oracle、sql server、mysql、sybase等。8、喜欢开发，热爱技术，有较强的责任心，耐心及大局观，逻辑思维缜密活跃。
1、三年及以上工作经验2、专科及以上学历，计算机相关专业3、熟悉Hahdoop生态圈，包括但不限于Hive、Spark、Hbase、Flink、ClickHouse、Kafka等,有Spark或Flink的开发经验优先。4、精通Oracle
（1）五年以上开发经验，三年以上软件研发经验，至少一年以上大数据相关系统研发经验；（2）有扎实的Java语言基础，有java web经验；（3）熟悉Linux系统，能够熟练用scala/shell/python/ansible脚本处理工具，具备成熟的调优经验；（4）精通SQL，有较好的 SQL 性能调优经验，了解 Hive/MySQL 的基本原理和调优策略；（5）精通Hadoop生态圈技术，有丰富的MapReduce/HBASE开发经验，熟悉HBase、Storm、Spark、Impala、Hive、Sqoop等数据相关技术。
1. 分布式数据应用开发（hadoop/spark/flink/hbase/doris/iceberg）；2. 负责公司内部大数据产品研发和服务接入；3. 处理各类任务异常和故障，确保数据任务的稳定运行；4. 基于实时和离线海量数据分析平台的开发；职位要求：1. 扎实的scala/python基础，精通hadoop生态组件，ETL工具如Sqoop/Kettle/Flume等2. 有一年以上流式计算项目实战经验，掌握spark、flink、phoenix、trino、iceberg应用；3. 有基于PB级数据，数据应用开发经验优先（包括HBase、Redis、Apache Doris）；4. 良好的汉语和英语沟通能力优先。
岗位职责：1、负责基于Spark技术的海量数据的处理、分析、统计、挖掘工作；2、基于Spark框架的数据仓库的设计，开发，维护；3、根据需求使用Spark Streaming和Spark SQL进行数据处理、查询、统计等工作。岗位要求：1、本科及以上学历，软件工程、计算机等相关专业，优秀硕士研究生优先考虑；2、熟悉RDD/DataFrame编程，对Spark体系结构、运行机制有深入研究，熟悉源码；3、熟悉Spark相关技术；4、熟悉linux、shell脚本或python脚本编程；5、熟悉Spark Streaming和Spark SQL，有过程序开发经验；6、具有良好的Trouble Shooting能力；7、能够用python开发数据算法，熟悉python算法库的优先；7、具有海量数据系统开发经验，且在开源社群活跃并有积极贡献者优先考虑。
需要会写spark  跟java   接受银 行 -驻-场任职要求：1、本科及以上学历，学信网可查，计算机、数学等相关专业2、1年及以上大数据项目经历；3、具备较好的业务分析理解能力，具备体系化思维习惯；岗位职责：1、负责项目大数据的开发任务2、按照组长要求分模块进行开发任务的完成3、负责编写软件需求和概设等文档
1.统招全日制本科毕业，3年以上大数据运维工作经验；2.负责公司大数据平台的部署、管理、优化、监控报警,保障平台服务7*24稳定可靠高效运行;3.深入理解公司大数据平台架构,发现并解决性能瓶颈,支撑业务和数据量的快速增长;4.开发大数据自动化运维、监控报警、故障处理相关脚本和工具;5.负责Hadoop/spark/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。
任职资格：1、计算机/数学/统计学等相关专业本科以上学历，硕士学历以上优先，两年以上工作经验，优先毕业生可以放宽。2、熟悉使用springBoot、mybatis等Javaweb框架。3、精通一门或多门开发语言（Java、Python,shell）等。4、项目中使用过3种（含）以上技术：Spark, Hive, mySql,kakfa, sqoop, HBase, flink, Elastic Search等。5、项目中应用过2种（含）以上算法：逻辑回归，随机森林，决策树， 神经网络，Apriori等。6、熟悉使用BI工具如FineBI等。7、善于独立思考，逻辑清晰，热爱挑战，具备快速学习能力。8、有机器学习或数据挖掘实际项目经验者优先。9、具备良好的沟通能力和团队合作精神。
岗位职责： -负责大数据平台的构建;-大数据相关前沿技术、运用调研及落地;-负责数据开发工作，包括数据仓库以及数据应用的技术设计和开发；任职要求： - 良好的SQL 编写及优化能力 - 熟悉至少一种任务调度框架，如airflow , DolphinScheduler- 熟悉Hadoop系大数据组件、工具的原理，能熟练使用Hive、Spark、Flink等大数据开发工具；- 熟悉Linux开发环境，熟悉shell，扎实的数据结构和算法功底；- 3年及以上大数据技术工作经验；- 熟悉Java, Scala开发语言- 熟悉SpringBoot；- 加分项: 熟悉流式计算框架 Storm；学历：统招本科及以上薪资范围（23-35K）年底双薪额外加1-6个月的绩效奖金
1.计算机及相关专业本科以上学历；2.至少3年以上开发经验，其中有1至2年大数据开发经验；3.熟悉大数据相关组件如：Hadoop/Spark/Hive/Kafka/Yarn/Flink等，并对Spark SQL,Hive SQL有一定的优化经验；4.熟悉flink执行原理，具有Flink实时计算项目经验；5.熟悉数据仓库领域知识和技能者，包括但不局限于：数据集市设计、元数据管理、数据质量、主数据管理；6.JAVA基础扎实,理解io、多线程、集合等基础框架,熟悉JVM工作原理7.具备较强的团队沟通和协作能力，较强的自我驱动能力,具备良好的抗压能力，能主动承担并解决问题，能处理紧急情况和复杂问题；
1. 本科或以上学历，计算机、数学或相关专业；1~3年的工作经验；2. 有数据仓库开发、数据建模、ETL开发经验；3. 精通 SQL ，对 Hive 查询优化有丰富的经验；4. 了解 Sqoop，Azkaban，Spark 等大数据生态技术优先；5. 有linux平台经验，熟悉 Shell 命令；6. 有较强的性能优化及问题排查、解决能力；对开源技术非常感兴趣并具有一定的研究能力；7. 有强烈的责任心、良好的沟通协调能力、团队合作精神、优秀的执行能力；8. 良好的语言沟通与表达能力和自我驱动动力，具备较强的逻辑思维能力，能承受工作压力；
1.本科以上学历。2.熟练掌握java/python/c/c++/go其中一种，掌握常见的数据结构，算法，了解软件工程，敏捷开发等知识。3.有云计算，大数据，人工智能，数据挖掘，数据治理，数据湖，领域或运维，运营管理平台开发经验，微服务产品开发经验者优先。PS：本招聘为留学生招聘，欢迎留学生同学来投~地域：西安，东莞，北京，南京，上海，成都 ，长沙，济南
岗位职责1、参与客户端埋点设计，参与开发与测试流程，保障埋点数据质量2、负责数据实时、离线模型建设，优化任务链路，日常ETL运维工作，对故障、异常及时准确地定位、分析，保障数据的准确性和及时性3、负责分析型产品的数据处理，参与产品的架构、数据模型、技术方案设计，提升产品的业务应用价值4、负责部分风控特征指标的计算输出岗位要求：1、2年以上数据仓库相关工作经验，理解ETL过程，有一定的数仓开发经验2、业务敏感度高，能快速理解业务过程与业务数据模型3、熟练掌握SQL/HQL，有较好的Java或者SCALA基础，具有Spark、Flink开发与应用经验，熟悉Hadoop系大数据组件、工具的原理和使用4、责任心强，具备较强的学习、表达、逻辑能力加分项：1、熟悉AWS平台各项服务
跨团队招聘，请勿多次投递相同的岗位工作职责:1、负责数据的ETL设计、开发、优化，保证数据准确与稳定2、负责构建业务数据分析体系，帮助确定各项业务数据指标3、负责数据平台相关后端功能系统设计和开发工作要求:1、计算机或相关专业本科以上学历，至少3年以上数据开发实际工作经验2、负责过大型数据平台和数据仓库设计，具有扎实的大数据和数据仓库的理论功底3、熟悉数据分析建模原理和流程，能够围绕业务特征建模解决业务问题4、掌握python/go，掌握python/go WEB开发常规模式，熟悉微服务架构5、熟悉常用机器学习算法，包括但不限于RF、GBDT、XGboost、SVM、ANN等6、拥有优秀的分析及解决问题的能力，良好的沟通能力，思维逻辑清晰，有强烈的责任心，并能自我驱动成长
该岗位为项目开发外包，不考虑外包项目的请勿投递。任职资格：1、本科以上学历，计算机相关专业，3年以上工作经验2. 熟练掌握Java，具备优秀的代码编写能力，熟悉Java MVC框架3. 熟悉Linux操作系统，并掌握Shell/Python脚本编程语言开发4. 密切关注大数据相关技术的发展趋势，有Hadoop/HBase/Impala/Kafka/Flink/Spark/Kafka等相关技术研究或开发经验5. 编码、设计、算法、调优、故障排查能力强6. 有责任心，乐于挑战，善于沟通，学习能力强7. 有数据平台产品研发经验者优先录用关键领导能力1. 独立进行项目需求的架构和设计2. 良好的团队合作和组织能力3. 优秀的独立思考和解决问题能力4. 善于研究最新的大数据技术，并保持不断学习和实战岗位职责：1.设计和开发企业级大数据管理平台，提升用户使用大数据平台的最佳体验性，也简化大数据平台的监控，管理等方面的工作。2.设计和开发机器学习云平台MLCloud平台产品，提供给数据分析及数据科学团队使用，提高易用性和用户体验。3.设计和开发实时大数据总线，基于现有Kafka的技术栈封装SDK，实现权限ACL控制，最终做到用户自助式服务。
Tripalink数据工程师职位描述负责设计、搭建并且维护Tripalink公司的数据仓库，搭建并且维护Airflow，Superset负责对接和使用第三方工具进行数据处理负责搭建数据健康系统，保证数据平台平稳高效运转职位要求1年以上数据工程经验熟练掌握Python，或其他一门主流数据编程语言熟练数据仓库底层逻辑，有搭建分区数据仓库的经验;有搭建、使用、维护Airflow的经验理解并重视数据工具的产出效果对于技术保持热情，积极主动，有较强的自驱力，良好的沟通和快速学习能力具备良好的英文Documentation的能力有爬虫经验的优先有熟练使用Databricks的第三方云数据库经验的优先有一定的第三方数据工具使用的经验优先有一定跟数据科学家和BI工作的经验优先Base：北京 / 上海
岗位职责：1. 以科技研发项目为载体，注重面向市场与生产的研发应用、前瞻性技术储备，形成科研成果和公司核心技术；2. 负责大数据研发课题的立项申请、研发实施和结题工作；3. 配合做好大数据开发项目的全过程管理和成果转化、奖项申报；4. 负责与课题相关的技术标准、工法和专利的编制；5. 跟踪、收集国内外行业人大数据发展的动态和科技信息。任职要求：1.硕士研究生及以上学历2.大数据相关专业毕业3.具备大数据相关工作经验优先4.愿意从事相关开发工作
数学专业/计算机专业 优先3+年工作经验Hive Spark Flink 熟练 优先数据挖掘经验 优先ETL或者画像 优先
1、负责电池指标离线数据开发；2、与系统业务联动，实现算法层面的表报开发，完成项目链路的实现；3、深入了解业务，按照链路构造开发含有算法逻辑的数据指标，完成数据同步和上线的任务调度；4、参与新项目的对接和技术攻关。任职要求：技能要求：1、熟悉Linux系统, 熟悉Scala、Python、SQL等编程语言,具备较强的编码能力2、熟悉Spark Core常用算子,有用scala编写spark程序经验3、熟悉数据工程生态，比如 Hadoop/HDFS/Hive/Spark/PostgreSQL等4、有扎实的Scala语言基础，具备成熟的调优经验5、3年左右工作经验，具备离线计算经验、具有良好的学习能力、团队精神以及协调沟通能力
岗位职责：负责公司和驻场项目中的大数据处理流程开发，部署和运维. 和算法工程师合作部署机器学习模型上线，并进行日常运维和问题排查.参与公司数据中台建设，打通业务，知识库，算法模型训练各个模块.职位要求;1. 211 CS专业硕士研究生及以上2. 精通python, pyspark, pandas3. 熟悉至少一种主流数据库(oracle, mysql, postgres)，linux操作系统，restful服务4. 熟悉主流数据结构(数组，链表，HashSet，树，图)5. 了解机器学习算法优先考虑，了解airflow，图数据库(neo4j)优先6. 良好的团队协作精神及沟通能力. 7. 工作认真负责，学习能力强，能够承受工作压力，可以在远程工作环境下保质保量完成项目交互和团队协作
数据工程师职位描述1、完成数据平台系统的从 0 到 1 的建设；2、负责 ETL 流程设计、开发和优化；3、处理离线、实时计算，为线上业务提供数据支撑。任职要求1、3 年以上数据平台相关研发经验，熟悉数仓架构及原理，具备数仓建模及 ETL 设计开发能力；2、熟悉云服务厂商的数据开发&治理服务产品及解决方案；3、熟悉 Python/Java/Go 中的至少一种编程语言；4、熟悉数据工程生态，比如 Flink/Spark/Kafka/Hadoop/Hbase/ClickHouse/MySQL/MongoDB  等。加分项业务高度敏感，具备体系化解决方案能力
软件架构设计，开发和实施端到端的数据湖仓、商业智能、数据科学、机器学习项目。在Hadoop生态系统上构建大数据管道，包括HDFS、Hive、Spark、Scala、Sqoop、Kafka、Flink和实时流技术以及大数据开源技术栈。熟练使用云原生大数据工具，包括但不限于MaxCompute, Hologres, Dataworks Snowflake, Redshift等开发工具。提供技术以改善数据质量、数据治理和数据安全。综合考虑数据从老系统到新系统的迁移解决方案。按照业务需求书写数据ETL。任职要求：拥有计算机科学、计算机工程或相关领域的学士学位。至少有3年的大数据，数据仓库架构的经验。熟悉Hadoop生态系统，如HDFS、Hive、Spark、Scala、Sqoop、Kafka、Flink、iceberg、airflow。对数据库结构系统和数据挖掘有深刻的认识。具备数据工程、数据管道和数据治理技能。优秀的组织和分析能力。出色的问题解决能力。良好的英文书面和口头沟通能力。
职位描述：1. 负责公司数据项目的实施交付，为客户提供数据解决方案2. 根据项目需求设计及开发业务指标体系，满足客户数据化运营需求3. 熟练使用flink, doris, clickhouse等开源组件4. 根据业务需求进行数据仓库建模及ETL数据处理职位要求:1. 熟悉hadoop, hive, flink, kafka, es, zoookeeper等大数据相关技术及中间件2. 有埋点数据采集，用户行为数据分析等经验3. 熟悉ETL设计开发流程，至少掌握一种ETL工具datax等4. 熟悉使用python，shell， java， scala中的一种5. 了解hadoop生态体系，具备离线/实时计算经验6. 对列式存储系统有实际使用经验7. 具备数据仓库，数据建模的建设和维护经验
工作职责：1、负责开发大数据工具, 如报表平台/多维度分析工具/ETL平台；2、负责数据仓库的建设, 数据接入/数据建模/数据服务等工作；3、负责大数据平台核心问题的攻关, 解决项目中出现的技术难题。任职要求：1、重点院校本科及以上，计算机、软件工程等相关专业；2、3年左右工作经验，具有良好的学习能力、团队精神以及协调沟通能力；3、掌握大数据生态技术栈, 具备较丰富的Hadoop/Hbase/Hive/Flink等大数据工具的应用和开发经验；4、熟悉Linux系统, 具备Java/Python/Scala一种或几种语言开发能力；5、扎实的SQL功底, 了解不同框架下SQL执行的原理, 熟悉大数据结构化及非结构化分析工具, 有比较丰富的实战经验；6、优秀的业务理解能力和良好的沟通协调能力, 有大数据或者数据仓库项目经验优先；7、喜欢研究开源技术, 对框架源码/底层原理有比较深入的了解。
职责描述1， 基于Hadoop进行MapReduce、Hive和HBase的应用开发；2， 维护和管理大规模Hadoop集群，解决不断增长的海量数据带来的存储和计算挑战；3， 大数据平台数据清洗、转换和建模的开发。技术要求1， 熟悉Hadoop/HBase/Spark/hive生态环境体系的搭建和管理，掌握Hadoop、HBase、MapReduce、HDFS、Hive、Kylin、Zookeeper等开源项目的原理和使用方法，具有实际集群搭建和调优经验；2， 熟悉并有Java开发经验，熟悉springcloud，springboot，ssm框架，有大平台架构开发经验；3， 掌握至少一种NoSQL数据库，具有真正项目使用经验；4， 掌握数据分析的基本流程，擅长数据采集、清洗、分析等环节；5， 熟悉后端服务（Restful Api 服务实现）优先；6， 熟悉使用sqlserver、oracle、mysql一种；7， 良好团队协作和沟通能力；8， 全日制本科及以上学历，学历学位学信网可查，3年及以上工作经验。
工作职责： 1、负责大数据平台的性能调优，控制架构质量，解决项目技术难题；对研发项目和任务需求进行评估和方案设计、配合 Leader 完成开发工作。2、实现大数据实时数仓搭建与开发、多业务系统数据实时接入、流式计算、数据挖掘分析及数据可视化的架构设计与能力，支持解决方案实施。3、负责数据模型、数据处理运维、数据安全等架构落地。4、完成技术验证，核心技术攻关，解决开发过程中技术难题。技能要求： 1、具有 3 年及以上大数据架构设计和开发经验；沟通能力强；本科及以上学历。2、熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖据、数据可视化；3、熟悉 Hadoop 相关各种开源项目，掌握 Hive、Spark、Kafka、impala、kudu 等数据处理核心组件；对 HDFS、M/R、Yarn 的原理有深入了解，掌握系统优化方法。4、熟悉流式计算引擎 SparkStreaming/Flink4、熟悉 Java/Python/Scala 等一种或多种语言，熟悉 Linux 平台。5、具有银行、金融领域相关大数据实时数仓系统构建经验者优先。
岗位职责：1、负责公司数据类产品的研发组织和协调管理；2、负责大数据产品（从数据接入、数据清洗、客户识别、客户合并、标签计算、客群画像管理、BI建模、KPI计算；标签和KPI的共享服务输出）构建、架构设计3、负责组织团队技术创新学习以及日常的团队管理工作；4、配合其他部门相关工作技能要求：1、计算机及电子、数学、物理相关专业学士以上学历；2、有CDP产品研发经验；3、对大数据相关技术和组件熟悉，如Kafka、Hadoop、Spark、Hive、clickhouse、ES等；4、实时、离线数据处理、分析以及架构能力；5、大数据平台调优经验（如内存、磁盘存储）；6、熟悉机器学习算法；7，有丰富软件开发相关经验优先考虑
岗位描述：1、按照教学规范和教学大纲，高质量完成大数据开发课程的授课任务；2、带领学员参加并指导学生完成实训项目；3、完成相关的教学资料(教学PPT、教学用书、教学案例等)的研发工作；4、完成所属教学方向的工作计划和课程，优化改进教学方法，配合完善教学体系的工作；5、完成课程辅导工作，解答学员课程疑问，保证学员的学习质量；任职要求：1、大专及以上学历(本科、硕士学历优先)，年龄不限；2、至少两年以上大数据开发相关经验或者一年以上教育行业经验；3、熟悉flume、kafka那为了保证质量、zookeeper 等多个组件的使用；熟悉Sqoop、Flume 等同步工具；熟悉hadoop 生态系统，应用 yarn、HDFS、hive、hbase 等；4、熟悉MySQL 等数据库的操作；熟悉使用Linux 开发环境，熟悉 linux 基本原理与常用命令；熟悉使用Flink，Spark，hive 进行大数据研化；5、掌握hive sql 的编写及部分调优；掌握Kafka 原理，能够解决生产端、消费端数据一致性问题；6、具备sql、shell 等语言的编程能力；7、了解Superset、sugar、FineBi、FineReport 等可视化工具。薪资待遇：1、14-22k基础薪资，综合薪资18-57k；2、节假日福利，生日福利，团建旅游等。
工作职责1. 负责商业大数据产品研发，数仓建设和重构优化工作2. 负责为大客户项目提供技术支撑：技术方案设计，解决平台类、数据类问题，把控代码质量职位要求：1. 4年以上大数据开发经验, 熟悉数据仓库模型设计与ETL开发，具备海量数据处理经验2. 熟悉java语言以及Java生态、熟悉Python或scala3. 熟悉Hadoop、Hive、Hbase、Spark等大数据开源体系4. 熟悉各类大数据平台，具有实际集群搭建和调优经验；5. 有很强的文档撰写能力，有很强规范意识的优先6. 良好的沟通、协调能力、抗压能力，能接受出差
1.Java背景 做数据开发2.参与过Java/scala的spark/flink 开发3.本科学历，211学历以上优先4.英语读写熟练，不借助翻译，口语简单交流
一、岗位职责：1、负责公司数据仓库、大数据平台，以及各类离线/实时数据应用的研发2、参与大数据平台的技术改进、资源规划、权限控制和运维管理3、参与业务需求的分析，协助业务部门解决各种业务实现问题4、参与大数据项目组相关技术文档的编写二、任职要求：1、本科及以上学历，3年以上大数据开发实际工作经验2、良好的Java编程能力和SQL编写能力3、熟悉Hadoop生态体系，有Hive、HBase、Kafka、Spark、Flink中三种以上组件的实际开发经验4、良好的团队合作精神，诚实、勤奋、严谨的工作态度，优秀的文档编写能力，敢于接受挑战5、有证券或基金行业数据仓库、大数据平台的建设经验、数据治理经验者优先
岗位职责：1.负责车联网数据相关平台的搭建、开发、维护、优化2.负责数据分析、加工、清理、处理程序的开发3.离线&实时数仓的构建4.代码工程调度管理和迭代5.从事海量数据分析、挖掘相关工作任职要求：1.计算机相关专业，本科及以上学历，5年以上Java/Scala开发工作经验，学习能力突出；2.熟悉hadoop生态系统内常见项目的使用（hdfs、hive、hbase、spark、zookeeper,yarn等），具有MapReduce开发经验，有实际大数据项目经验优先3.熟悉流处理开发流程，具有丰富的flink开发经验4.有海量大数据开发经验，有处理时序数据或者车/物联网数据项目经验优先5.有Hadoop、flink，Spark、HBase深入源代码分析经验6.熟练掌握Oracle、MySql等主流关系数据库7.具有良好的沟通能力及团队协作精神，有较强的分析和解决问题的能力；
1、负责数据仓库和大数据处理模块的架构设计、开发和维护；;2、参与数据平台架构设计，完成相关开发任务详细设计、代码优化;3、参与、负责相关模块需求收集、分析、数据清洗，数据表结构、逻辑层详细设计等;4、负责维护数据相关平台及工具; 按照需求提供对外数据输出工作，如报表、对外接口等;5、同产品、分析师等协作建设公共数据服务，实现高质量数据共享，推动部门数据应用能力；岗位要求：1. 计算机相关专业本科及以上学历，5年及以上数据开发经验;2. 熟练掌握SQL,掌握SQL优化技巧,具备复杂SQL的调优能力；3. 熟悉Hadoop/Spark分布式计算框架，熟练使用scala;4.熟练掌握Spark Streaming或Flink；5. 熟练掌握Redis/Tidb/Doris优先;6. 熟练使用Git，Svn，shell等开发工具;7. 较强的分析和解决问题能力，沟通协调能力，具有团队精神和一定的抗压能力;
参与供应链预测补货项目的需求分析和功能开发；运用大数据工具分析和处理预测补货数据，负责数据性能分析和优化；任职要求1、本科及以上学历，1年以上大数据数据处理经验；2、精通SQL，了解供应链相关业务系统，具有供应链数据分析经验者优先；3、熟悉JAVA、Python开发语言，具有数据挖掘经验；4、熟练掌握Hive、SparkSQL等主流大数据数据处理技术，能解决应用中的复杂问题，研读过源代码者优先；5、熟悉Kafka等消息中间件技术，了解数据采集系统的设计与实现；6、熟悉Redis，memcached其中一种或以上缓存技术；7、熟悉elaticSearch，了解其体系结构和索引原理；8、有强烈的上进心和求知欲，善于学习和运用新知识，沟通能力强，有强烈的责任心，具有良好的团队合作精神和敬业精神。
岗位职责：1.参与财务数据体系架构和建设。2.负责基于Hadoop大数据平台的数据开发、建模。3.建立业务模型，对海量数据进行挖掘、优化及统计。任职要求：1. 熟悉Hadoop, Hive, HBase, Spark, Storm, Kafka等大数据相关开源系统, 熟悉ETL过程，掌握Kimball的维度建模设计方法，有两年以上的Hive, Spark的实践经验，有实时开发经验者加分2. 有较强的数据敏感性，有较强的数据分析能力3. 逻辑思维能力强，做事仔细认真，对新技术有较强的求知欲望
岗位职责:1. 负责大数据、BI系统相关模块的实施，项目管理工作，包括但不限于需求管理、项目规划、过程实施、上线验收、交付运营等2. 对接业务方数据需求，遵循数仓分层建设理念，逐步完善公司的数据体系建设3. 为算法和运营团队提供数据支持，辅助分析和决策任职资格:1. 本科及以上学历，计算机、统计学、应用数学等相关专业，熟练掌握Shell/java/python等开发语言2. 4年以上大数据开发经验，熟悉Hadoop、Spark、Hive等框架原理及调优3. SQL能力强，有大数据处理的优化经验4. 熟悉ETL流程，掌握Sqoop/datax等主流数据同步工具5. 了解BI系统，有数据管理、维度建模等相关经验
岗位职责：1. 负责公司大数据平台的设计和开发，负责spark, hadoop, flink等云计算平台的开发和优化；制定数据架构规范，进行核心代码编写，指导团队落地；2. 负责数据基础架构和数据处理体系的升级和优化，技术难题攻关，持续提升核心系统性能，保证系统的安全、稳定、高效运行3. 设计并实现对风控、BI分析、数据产品开发、算法开发的系统性支持4. 研究未来数据模型和计算框架的创新与落地，包括但不限于以下领域：大规模数据实时化、研发模式敏捷化、数据计算框架轻量化、数据模型组织方式业务化等方面参与制定并实践团队的技术发展路线5. 参与培养未来数据人才；有效辅导团队，提升数据研发能力任职要求：1. 有很强的数据设计抽象能力，善于从复杂的数据问题中找到关键路径，能够开发创新而实际的分析方法以解决复杂的商业问题2. 有作为技术负责人系统化解决问题的成功案例；有海量数据建模实践经验优先3. 熟练掌握Hadoop、Spark、Flink 的原理特性以及适用场景，在分布式计算或分布式存储领域有深入研究，有开源二次开发经验者优先4. 性格积极乐观，诚信，能自我驱动，有较强的语言表达能力；具备强烈的进取心、求知欲及团队合作精神；具有良好的沟通、团队协作、计划和创新的能力5. 扎实的计算机专业基础，有5年以上大数据平台开发经验。
工作内容：负责游戏工作室各游戏内千亿级数据的处理、中间层建设和实时计算；负责围绕游戏业务的数据统计、挖掘、展示等工作；大数据离线以及实时特征工程、相关算法实现和算法平台建设；保障工作室已有大数据平台的平稳运行、完善组件功能和稳定性；任职要求：硕士及以上学历，计算机相关专业；熟练sql, python等数据处理脚本，熟悉常用统计方法例如窗口函数、pandas库等；熟悉Hadoop/Storm/Hive/Spark/Flink等分布式开源项目及其工作原理，对分布式有深刻理解，并有实际开发经验；熟悉常用脚本语言Shell,Python等；对大数据实时Drois、ClickHouse有相关工作经验优先；有数仓、数据产品建设经验者优先；善于沟通表达
岗位职责：1.参加大数据流批处理的研发，如实时计算通用组件研发、元数据、血缘分析、指标管理平台、质量管理平台等；2.支持业务数据报告需求；3.大数据资源的调度和优化；4.协助运维做好集群的维护工作；5.积极主动研究大数据时代的各种前沿技术、并能在产品中得以运用实施。任职要求：1.本科及以上学历，5年以上开发经验（3年以上大数据开发），优秀的故障排查和架构设计能力，负责过日均 TB 级数据系统总架构；2.精通 Hadoop/Spark/Flink/Kafka/Airflow 中大部分组件，具备调优能力；3.掌握 Linux 系统下编程经验，熟练掌握一门脚本语言（shell，python 等）；4.精通常用 MPP 数据库（如 HBase，ElasticSearch，ClickHouse）；5.注重代码规范，具有良好的学习能力、文档能力、沟通能力、团队合作意识；6.强烈的责任心与主动性，对所负责工作有owner意识，并能自我驱动成长。
大数据开发工程师大数据开发工程师工作内容：1、负责大数据平台的设计、建模、代码开发和测试；2、规划大数据平台的架构和部署需求，把握系统的高可用、扩展、安全、性能、伸缩性等；3、及时与产品经理/项目经理沟通需求，分析梳理业务场景，协助需求侧解决各种业务实现 问题；4、负责核心技术难题的攻关，攻克团队遇到的技术难题，持续对线上系统进行性能优化及稳定性提升；5、参与对平台的运维和运营的支撑体系的制定和实施，对线上突发问题进行及时响应并解 决；6、负责大数据团队建设及管理，技术文档输出，根据业务发展组织技术预研，并对技术团队布道。岗位要求：1、本科及以上学历，5 年以上相关工作经验；2、热衷于产品研发和技术创新， 具有很强的学习能力并有强烈的责任意识和开放的心态， 工作态度好，积极向上者为先；3、具备大型分布式、高并发、高负载、高可用系统设计、开发及调优经验，有大数据平台 的软件开发、部署经验；4、熟悉 Hadoop 生态圈技术栈，HBase、Hive、MapReduce 等；熟悉 Spark、Storm、Kafka、 Zookeeper、K8S 等开源组件，具备开源项目集成开发经验优先；5、熟悉容器、人工智能、微服务等新技术，有互联网运营平台架构设计或大数据公司同类 平台或产品设计、开发经验者优先。
全职，全国招聘，可以远程在家办公，期望精通spark和scala，可以发简历到***** Marin Software正在寻找经验丰富、富有激情的高级大数据工程师，基于Spark开发成熟的管理数十亿美元的数字广告的企业数据软件产品。 Marin开发SaaS产品，用于衡量、优化和管理跨渠道的数字广告活动。Marin Software是目前管理谷歌广告活动的最大的独立的软件技术公司，每年管理的广告支出为60亿美元，而且管理着40亿关键词。我们也是Facebook上的广告主们优化广告投放的领先的管理工具。Marin已经成为能够提供广告跨渠道管理、生成报告和管理广告预算分配的领先的管理工具。 您将加入我们位于上海的大数据工程团队，并与伦敦和旧金山的其他团队合作。 职责描述 l 负责与OLAP相关的微服务和Spark的工作，从设计、开发到生产的全生命周期l 使用Java/Scala和Apache Spark实现数据开发l 编写高质量的代码，每2到4周发布一次l 对所编写的代码负责，坚持追求简单、高效、可靠和高性能的代码；避免堆积技术债务l 严格执行测试驱动开发l 与全球工程团队合作交付软件l 负责架构和设计，并提出更好的方案l 对初级工程师提供技术指导；积极参与代码设计和代码评审l 主导解决并执行架构和设计中出现的问题，并尽量用更好的方式解决问题 职位要求 l 具有5年以上软件开发经验l 2年以上Spark2.x经验l 有扎实的Java和Scala编程功底l 具备出色的解决问题能力、协作能力和沟通能力l 具有较强的大型系统编程和调试能力l 坚持编写单元测试和可测试的代码l 对Spark有很好的理解l 能用英语进行有效沟通（书面和口头）l 对分布式消息系统架构和Apache Kafka有扎实的理解l 有丰富的Spark优化和调试经验 最好具备以下条件 l 熟练使用Jupyter Notebook进行数据分析l 有谷歌Ads API经验l 熟悉Presto和MySQLl 了解Kafka and Akka
工作职责1、牵头项目的大数据平台建设实施，涉及大数据相关系统平台的设计、开发及快速迭代；2、负责平台数据模型、指标、生命周期的设计和管理；3、开发、实现和运维基于私有云和公有云的大数据基础设施；4、基于对公司项目业务模式的深入理解，发掘数据价值；5、承担所负责系统生产问题定位和问题处置；6、完成上级领导安排的其他工作。任职要求1、本科及以上学历，计算机等相关专业；2、3年及以上软件开发工作经验，1 年及以上大数据系统开发、设计经验；3、精通大数据Hadoop体系的相关技术： Hive、HBase、Storm、Kafka、Kylin等；4、熟练掌握Java、C/C++等程序开发技能，具备行业业务分析、模型设计、数据挖掘等相关工作经验的优先；5、熟悉SAS、R、Python等主流挖掘分析工具，掌握机器学习基本理论以及多种机器学习算法，具备模型调优能力；6、熟悉BI工具，具有大数据平台的开发运维经验7、具备良好的团队合作能力、沟通能力和综合分析能力，学习能力强，承压能力强，工作责任心强，有创新思维，对数据技术和业务发展有高度敏感性。
岗位职责：1. 负责公司数据仓库的系统需求分析、核心算法设计，应用接口代码的编写；2. 负责大量用户端、服务端数据体系的建设，通过数据+算法+工程化能力处理和萃取数据，通过数据反哺业务；3. 开发离线、实时数据应用，为海量数据的处理和分析提供高效解决方案。岗位要求：1、熟练掌握Java，python等技术，数据仓库领域至少2年以上经验，具备1年以上的工作经历对实时计算和离线计算熟悉；2、熟练掌握至少3种MySQL、mongoDB、es、redis，kafka，或者其它nosql的使用；3、精通Hadoop/Hive/Hbase/Storm/Spark/Flink等大数据技术的使用，具有大规模数据研发项目经验；4、对算法、数据结构以及后台开发（java/Python等）须非常了解 ,了解Web前端脚本语言者优先
"岗位职责：1. 负责广告系统数仓、流批任务开发、存储与计算优化、即席查询效率提升等；2. 负责广告系统架构优化评审和分析，设计计算流程、评估计算资源、任务开发和自测；	3. 保障编码、API调用、任务运行符合规范，相关代码注释清晰、明确、无异议；					4. 当所负责的任务出现问题时，第一时间跟进排查并解决问题；					5. 负责大数据系统相关技术处理方案、技术文档的更新与维护。任职要求：1. 熟悉计算机系统原理、常用数据结构和算法、计算机网络、HTTP协议等基础理论；		2. 熟练掌握Java/Scala中的至少一种，熟悉常规JVM参数优化；			3. 掌握Hadoop、Hive、Spark、Flink、Kafka的使用；			4. 掌握常用Spark参数调优、错误定位，能优化复杂Spark任务性能；			5. 深度掌握Impala/Kylin/Presto/Druid中的至少一种分析引擎；6. 有较强的沟通表达能力，善于学习，能迅速理解产品需求；7. 有较强的责任心和事业心，有严密的逻辑思维，有追求卓越的精神，能够自我驱动；8. 有处理PB级以上数据经验者或广告行业数据经验者优先考虑。职位信息"
高级 技术骨干：工作6年及以上，在技术上有深厚的积累，，具有较强的工作责任心，良好的沟通能力。【必备技能】  1）熟练掌握业界流行的前后端技术栈 ，熟悉分布式系统概念，有云原生、k8s等相关经验  2)  熟悉JAVA编程技术；熟悉MyBaits、Springboot、Structs等主流开发框架；熟悉J2EE开发，了解J2EE开发各种常用设计模式，精通J2EE各常用组件；熟悉B/S开发架构；  3)  熟悉MySQL数据库、PG数据库、PL/SQL开发，能够独立编写逻辑性较高的SQL语句，熟练掌握Hadoop、Hive等大数据技术  4)  熟练使用Tomcat、Nginx等主流服务器的配置和部署；  5）熟练掌握html5、css3、javascript、jquery等前端技术栈 ；  6）熟练使用elementUI或其他UI组件，熟悉使用业界流行的angular，vue等前端开发框架及原理 ；【必备工作经验】  1）参与过银行业务研发工作的优先。  2）有银行金融类或合作方系统相关IT系统研发经验者优先考虑。  3）具有较强的工作责任心，良好的沟通和协调能力，严谨、细致、踏实的工作作风和积极主动的工作态度；具有较好的团队协作能力。中级大数据开发：3年以上工作经验，具有较强的工作责任心，良好的沟通能力，有比较强的学习能力和独立工作能力【必备技能】 1）熟悉MySQL数据库、PG数据库、PL/SQL开发，能够独立编写逻辑性较高的SQL语句 ； 2）熟练掌握Hadoop、Hive等大数据技术【必备工作经验】 1）参与过银行业务研发工作的优先。 2）具有3年或以上大数据开发经验。初级大数据开发：1年以上工作经验，具有较强的工作责任心，良好的沟通能力，有比较强的学习能力和独立工作能力【必备技能】 1）熟悉MySQL数据库、PG数据库、PL/SQL开发，能够独立编写逻辑性较高的SQL语句 ； 2）熟练掌握Hadoop、Hive等大数据技术【必备工作经验】 1）参与过银行业务研发工作的优先。
岗位职责：1. 负责复杂业务场景下数据架构体系构建，赋能业务数智化运营，保障数据质量、时效、稳定性；2. 负责基于数据技术平台 数据湖/仓建设，包括数据模型设计、离线/实时计算、性能优化以及相关技术问题的解决；3. 负责数据获取融合、数据中台、数据质量、资产管理等数据治理工作；任职要求：1，全日制本科及以上学历，计算机类相关专业，3年以上大数据相关工作经验；2，精通flink计算框架，能够进行流计算应用开发，对Kafka、Doris、Clickhouse等相关组件有项目实践经验；3， 熟悉数仓原理和实施，有实时数仓、离线数仓设计与开发经验；4，具有零售或制造业相关行业经验注：精通flink，对iceberg/hudi/虚拟湖等技术充满兴趣者可申请
岗位职责：1、负责广告部大规模机器学习离线样本数据流的开发和维护，提高离线特征抽取计算的复用性；2、负责广告部大规模机器学习离线特征的存储组件选型和开发，避免特征数据重复存储，提高存储效率；3、负责广告部大规模机器学习离线数据流平台的开发和维护，提高算法离线特征调研迭代效率；4、构建机器学习数据质量体系，持续提升数据质量和及时发现数据问题；5、跟踪和调研前沿的数据处理和分析、存储技术，不断提升计算和存储效率；任职要求：1、对数据处理相关技术如hadoop、spark、flink等有一定的了解2、对Java、Python有一定的理解；3、对hbase等列式存储系统有实际使用经验；4、有机器学习、大型电商系统、互联网广告、数据挖掘、流计算相关经验者优先。
【岗位职责】1、参与大数据平台项目的实施与运维；2、参与数据仓库平台、Hadoop大数据平台、数据中台、监管报送系统的需求开发工作；3、参与大数据业务集群（Hadoop/HDFS /Hive/ Yarn/ HBASE）等大数据生态圈组件运维管理、故障排查等工作；4、参与建立统一门户、数据标准、标签类目、用户画像、指标管理等项目的开发与运维。【岗位要求】1、本科及以上学历，计算机相关专业；2、具备持续学习的意愿和能力，逻辑思维能力强；3、具有良好的团队协作精神和工作责任心；4、熟悉Oracle、Mysql等一种常用的关系型数据库或了解HDFS、Hive等大数据相关组件者优先。
职位描述1、参与或负责数仓规划、数据研发规范、数据质量及稳定性保障建设；2、参与或负责onedata体系中数据指标的管理（确定业务口径/技术口径）和数据模型的设计（按分层建模的方式把数据更加科学的组织存储）；3、负责业务需求的需求理解、数据探查和分析，进行数据产品的数据研发，发掘数据商业价值，以数据驱动业务不断发展；4、负责基于flink/spark/hive/mapreduce/odps大数据技术的数据仓库架构设计、ETL开发、数据验证、发布部署、运维等，构建易维护、可扩展的数据仓库公共模型，数据集市等，支持BI分析、数据挖掘和上层应用；5、负责数据仓库ETL流程的优化及解决ETL相关技术问题。任职条件1、3年以上互联网/电商行业经验，5年以上数据仓库工作经验，熟悉数据仓库模型设计方法论，有实际的模型设计经验，有互联网公司数仓建设经验；2、具有丰富的基于Hadoop/Flink/Hive/Spark/Odps等分布式系统的大数据开发经验，具备海量数据加工处理（ETL）相关经验，熟悉SQL和Java、Shell；3、了解主流的 OLAP 引擎的优化原理，对Druid/Kylin/ClickHouse等有深入研究及优化经验；4、熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、主数据管理、性能调优等；5、擅长逻辑模型分析、设计，较强的抽象、概括、总结能力，善于发现、思考并能以产品的思路提出解决问题的方案；6、具有较好的沟通理解能力，团队协作和创新能力，性格乐观，态度踏实，积极上进。
职位描述1、负责离线与实时数据仓库的构建；2、负责数据模型的设计，ETL实施，ETL性能优化，ETL数据监控以及相关技术问题的解决；3、负责指标体系建设与维护；4、深入业务，理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；5、参与大数据应用规划，为数据产品、挖掘团队提供应用指导；6、参与数据治理工作，提升数据易用性及数据质量。职位要求1、熟悉数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；2、熟练使用Hadoop及Hive，熟悉SQL、Java、Python等编程语言；3、善于沟通，对业务敏感，能快速理解业务背景，具备优秀的技术与业务结合能力。
高级数据开发工程师1、负责集团金融业务数据和用户行为日志等数据的采集和计算。2、负责数据模型及应用模型设计，带领开发队伍完成交付目标。3、依托数据中台，设计和实现关键数据产品和数据服务。相关要求：1、计算机及相关专业硕士以及以上学历，5年以上工作经验。2、熟悉RDBMS和NoSQL数据库，熟练掌握SQL、PLSQL编程技能，熟悉Python、Java者更佳，有良好的代码习惯。3、熟悉大数据平台hadoop技术栈，使用过Hive/HBase/Spark等大数据平台组件优先。4、至少有流式处理、营销和推荐算法、数据仓库模型、用户画像中两个领域的项目实践。5、对新事物新技术充满好奇，乐于接受挑战，有互联网数据开发背景优先考虑。
岗位描述：1. 负责公司大数据平台的架构设计、研发和调优工作，持续提升平台系统的可用性、可靠性、可维护性和可扩展性；2. 负责企业级数据应用的架构设计和核心模块开发，推动后台基础策略算法和数据挖掘分析能力快速落地并实践；3. 布局大数据团队的技术演进，洞察新技术的发展，组织团队的学习与培训。岗位要求：1. 本科及以上学历，计算机相关专业；2. 3年以上的大数据处理工作经验，对主流大数据技术和框架（如Hadoop、Spark、Flink、Flume等）有深入理解和充分实践；3. 精通分布式存储相关技术，不限于HDFS、Hive、Redis、Mongodb、ElasticSearch、Kafka、Sqoop等；4. 熟悉Linux操作系统，掌握Java、Scala、Python等至少一种开发语言，熟悉分布式应用设计；5. 熟悉常用的分类、回归、聚类等算法及应用场景；6. 对主流的研发流程、质量控制方式、项目管理方式有充分的理解；7. 具备自主的学习能力和追求卓越的态度，具有良好的团队协作精神。
岗位职责：1. 负责大数据应用类系统的设计和开发，以及关键技术的攻克，如推荐、用户画像、数据治理等等；2. 协同产品、算法，设计实现基于业务、产品和技术的数据应用领域解决方案；3. 参与内外部的业务需求分析，推动数据资产和数据可视化建设及优化；4. 参与企业级大数据平台建设及环境整体搭建，实现从数据采集、清洗、加工、汇聚到全链路数据分析应用的全方案落地。任职资格：1. 5年及以上大数据工作经验；2. 在可扩展、高性能，高并发，高稳定性系统设计，开发和调优方面有实际经验；3. JAVA技术知识扎实，熟悉IO，多线程，集合类等基础框架，熟悉缓存，消息，搜索等机制；4. 对Hadoop/Spark/Storm生态有丰富的经验；5. 有良好的系统分析能力、故障诊断能力者优先；6. 有大型分布式系统架构的实际经验；7. 有人工智能相关开发经验优先、熟练使用python语言开发工具的优先、有通信企业工作经验优先；9. 有团队管理经验经验优先。
职责描述：1.负责基于Flink、FlinkSQL的实时计算设计与开发2.负责实时计算服务的性能优化3.负责实时作业的配套文档编写任职要求：1.精通FLink，可对Flink进行开发、调优。2.精通实时流生态组件，如Canal、kafka等3.精通大数据存储，如ClickHouse、InfluxDB等4.熟悉阿里云大数据生态产品，如DataWork、ODPS等5.有实时数仓开发经验的优先;精通goLang语言的优先6.3年及以上Flink实时开发经验
零售大数据业务分析与架构开发
职位描述1.打造业界领先的超大规模批流一体的实时数仓基础设施及架构，并支撑唯品会相关产品线;2.基于Flink SQL打造高效、稳定、易用的实时数据开发平台，降低实时数据开发门槛;3.基于数据湖技术构建批流一体的存储系统，同一种存储同时支持低延迟的实时数仓场景及高性能的离线分析场景;职位要求：1.精通Flink等流处理技术， 有实际项目经验2.熟练使用java开发语言，有大数据量、高并发处理经验3.熟悉Hudi、Iceberg、Delta lake等开源数据湖技术4.了解kudu、Hbase、ClickHouse、Kafka等实时系统原理5.有大型实时数仓架构落地经验者优先6.向开源社区贡献过patch者优先
职责：1. 从事金融交易数据的各类统计分析，快速根据分析需求实现算法2. 开发和维护绩效评估相关的工具、平台和程序3. 开发和维护实时监控、分析、报告系统4. 配合研究部门产生、整理和验证实盘相关数据要求：1.具有国内外顶尖高等院校数理统计、计算机或者相关领域的本科或硕士学历；2.熟练掌握至少一种脚本语言（R或Python），对数据提取、数据操作、统计分析、数据可视化、报告有丰富的经验；3. 熟悉C++，能用于数据分析方面的高性能算法实现，熟悉相关数据结构与基本算法，掌握敏捷的开发流程。4. 能够维护工具体系以及自动化计算流程，熟悉Linux的使用。5.对技术充满兴趣，对编程精益求精，具有自我驱动能力，能针对系统的不足不断提出并落地改进方案。
岗位职责： 1. 负责大数据服务（离线+实时）的开发； 2. 参与大数据产品的开发； 3. 参与大数据平台、应用系统的业务梳理和架构设计。  任职要求： 1. 2022届获得本科及以上学历，计算机相关专业，成绩优异，学习能力强； 2. 熟悉 Hadoop 生态相关技术，使用过 spark 或 flink，有项目经验者优先； 3. 熟练掌握 java，有项目经验者优先； 4. 熟悉 sql，有项目经验者优先； 5. 有 shell/python 实践经验者优先。
岗位职责：1、负责大数据实时平台的开发工作2、参与业务数据、生产日志的抽取、转储、计算、检索等相关开发工作3、保证实时接入体系稳定性及扩展性任职要求：1.计算机等相关专业，本科及以上学历，3年以上大数据产品平台或J2EE平台项目研发经验，2.熟练掌握Hadoop、HBase、Hive、Spark、Flink等大数据开源框架，深入理解Map/Reduce、Hive、Hbase、HDFS、ES等相关原理及高级特性，具有丰富的海量数据处理开发经验。3.具有良好的软件工程能力，扎实的java或python技术基础，熟悉常用的微服务开发框架(e.g. Spring Cloud)和web前端开发框架, 并对Web应用有一定的架构设计能力，4.熟悉Linux平台，熟悉k8s技术的优先考虑5.熟悉AWS，阿里云等主流云服务的优先考虑6.在实时计算，离线计算等方面有丰富的项目实战经验7.自驱动能力强，有较强的思考力8.思路清晰，具备良好沟通能力
职位描述：1、负责面向发行的BI系统后端研发，功能设计、开发实现、以及运营维护；2、持续改善已有服务，分析系统瓶颈，优化系统薄弱点，提升性能和稳定性；3、为上下游和最终用户提供标准化服务，保证优质体验。职位要求：1、熟悉大数据生态组件，包括Hadoop、Hive、Spark、Flink、kafka等；2、精通Python/Go/Java/Scala至少其中一门编程语言；3、数据仓库建模及数据ETL开发经验者优先；4、有OLAP开源引擎（clickhouse等）项目经验优先；5、有热情，爱学习，关注大数据前沿技术发展，逻辑思维能力好，有较强解决问题能力。
岗位职责（1）参与大数据需求的开发；（2）根据业务需求进行数据模型的调研、设计、开发及验证工作，并持续进行模型的优化；（3）基础数据ETL处理；岗位要求（1）本科或以上学历，计算机、数据挖掘等相关专业，3年以上大数据开发经验；（2）熟练使用Scala、Java，熟悉shell，python等脚本语言；（3）熟练使用大数据处理技术，Hadoop、Hive，Spark，Kafka等；（4）掌握HBase、Redis、Elastic Search等开源大数据存储技术，并能结合不同的业务场景深入使用；（5）有电信运营商工作经验者优先
- 对数据处理、数据建模、数据分析等有深刻认识和实战经验，对hadoop生态其他组件有一定了解，比如 HBase， hadoop, Hive, Druid等- 熟悉Hive SQL语言，熟悉shell, python等脚本语言；- 熟悉java或scala；- 熟悉至少一种实时计算引擎 Storm, Spark Streaming, Flink；- 熟悉Linux/Unix系统和丰富的Java开发经验。- 熟悉数据仓库理论，具备复杂业务需求梳理能力。- 熟练SQL开发，精通Mysql等关系型数据库。- 熟悉Linux系统，具备shell、python等脚本开发能力者优先。- 了解微服务开发理念、实现技术，熟悉常见设计模式，熟练掌握SSH开发框架，熟练进行Java、Python代码编写，熟悉多线程编程。- 有hadoop、spark、flink等大数据平台的使用经验优先；
工作内容：1.基于Hadoop/Hbase/Spark/Hive的大数据离线/实时数据平台的开发和维护；2.参与公司大数据平台的数据仓库系统建设；3.参与公司大数据集群的性能优化，以及大数据平台架构的整体设计与改进；4.参与对数据挖掘及业务开发团队提供技术支持，协助方案规划；5.参与大数据平台相关技术攻关和创新技术引用。6.后端开发接口与前端对接任职要求：1.数学相关专业优先考虑，本科及以上学历；2.1年以上Java,Scala编程经验，熟悉流行的大数据编程框架，有大数据处理和应用开发的相关经验；3.精通Hive,hbase,mongoDB,redis等关系型数据库和非关系型数据的使用和优化；4.熟悉Hadoop,Hbase,Spark,Hive等hadoop生态圈的框架的部署,维护和开发5.熟悉Linux系统，精通Shell脚本语言；6.较强的学习能力以及快速解决问题的能力。7.熟悉springboot框架,有参与前端对接的项目经验者优先8.有过大厂经验者优先
岗位职责:1、负责数据平台技术规划，参与数据产品的需求调研；2、负责数据平台实时计算、离线计算架构搭建以及业务开发；3、参与数据产品的技术路线讨论，以及团队内技术创新研究、新技术的引入并评估可行性、技术难题攻关；4、深入研究数据业务以及相关的运维技术，持续优化集群服务架构；任职要求：1、5年以上大数据平台相关工作经验技能：熟悉数据仓库相关理论及研发流程；2、具备实时计算、离线计算实战开发经验，具备一定规模的分布式集群运维经验；3、熟悉Hadoop、Kafka、Spark、Hive、Flink、Doris、Iceberg等相关技术框架和平台；4、熟练掌握程序开发语言，如Python、Java等，熟练掌握SQL语法；5、具有优秀的沟通表达能力，协调应变能力，团队协作能力，较强的工作责任心和团队协作精神，主动思考，自我驱动力强。
岗位职责：a.负责公司级数据管道开发、优化，构建掌门集团中央化数据平台。b.负责不同业务系统数据抽取组件开发，提供易用、低侵入、高吞吐、可重用的抽取组件。c.负责不同业务系统数据元数据管理，制定推动元数据规范落地。d.能分析和解决基础组件问题，解决技术痛点。任职要求：a.本科以上学历，3年以上软件开发经验，扎实的编程基础，熟悉常见数据结构，熟练掌握Java、python、scala中至少一门语言。b.具备从分布的、异构数据源如关系数据、平面数据文件等抽取开发经验。c.熟悉无侵入、低侵入式数据同步技术，且具有实践经验。d.有元数据管理、规范落地经验优先。e.加分项：数据集成组件相关使用经验，对数据交换组件如Datax/Camel/Mule源码有一定的理解。f.良好的沟通能力、团队合作精神；优秀的学习能力；快速解决技术问题的能力；强烈的目标感。
职责描述：1. 负责风险管理相关数据抽取、数据处理和数据展示的架构设计、数据建模和开发。2. 利用流处理引擎计算加工风险监控和策略使用的特征。3. 制定数据治理规则和流程，提升数据的可用性和数据质量，并对数据质量进行长期监控。4. 积极了解业务需求，不断提高数据的查询、分析效率，发挥数据应有价值。 职位要求：1. 熟练应用数据仓库实施方法论、深入了解数据仓库体系，有相关工作经验3年以上。2. 具备较强的动手能力，精通Kafka和Flink。熟练使用SQL/Java/Scala/Python等中的多项，有风控大数据项目经验或者特征加工平台开发经验。3. 对数据敏感，认真细致，善于从数据中发现问题。4. 善于沟通，具备优秀的技术与业务结合能力。5. 能够使用英语工作。
岗位职责：1.建设数据仓库，负责数据仓库设计、建模、研发等工作，参与业务数据指标体系搭建，根据业务内容提供数据解决方案； 2.参与ETL性能优化，ETL数据监控以及相关技术问题的解决； 3.支持业务团队的数据分析工作，负责面向业务的统计报表，数据提取等工作；4.理解数据仓库架构，在项目实施的过程中，发现并解决各种维度/粒度的数据问题。岗位要求：1.本科院校，计算机、数学或相关专业2.熟悉数据仓库建设方法论，了解基于Hive的SQL开发及SQL性能调优；3.熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等；4.熟悉Linux系统环境，熟悉Shell/Python/Perl等至少一种脚本语言；5.具备良好的学习能力、沟通表达能力及业务理解能力。
岗位职责：1. 参与公司大数据技术团队共同打造新一代智能大数据平台；2. 参与跨产品线（包括大数据分析引擎、云原生资源管理和调度、语义层分析等产品）的架构设计、技术选型、代码评审、质量评审；3. 负责核心技术难题的攻关，攻克团队遇到的技术难题，持续对线上系统进行性能优化及稳定性提升；4. 在实时数仓、SQL优化、云原生架构、分布式存储和索引、增强分析等领域负责关键技术的探索研究，技术落地；5. 依托公司产品，打通用户在数据域（数仓、数据湖）与应用域（用户画像、精准营销系统）之间的隔阂；6. 负责跟进大数据组件的新特性，结合业务需求引入并落地，有效提升平台效益；任职要求:1、五年以上大数据开发经验，有过产品研发工作经验；2. 熟练掌握Java、Scala、Python、Shell等常用编程语言，熟悉常用的JAVA开源框架( 如SpringMVC、MyBatis、SpringBoot、SpringCloud等)，并理解框架的原理和机制；3. 熟悉 Hadoop/Spark/Impala/Flink/Druid/HBase/Redis/ElasticSearch 等两种及以上技术，具有任一框架优化经验者更佳；4. 具备系统开发经验(而不是简单地搭建运维过某开源系统)，对高性能、高吞吐、高可靠的业务场景有丰富的理解和处理经验；5. 善于交流，有良好的团队合作精神和协调沟通能力，积极主动，有强烈的责任心和主人翁意识；6. 负责过大数据业务线或整体产品的架构工作，组织过中等以上规模项目者优先，对开源社区有源码贡献者优先；7. 个人价值观与创业公司价值观兼容。
1、参与各类通用地理位置相关服务的设计/开发；2、参与海量位置相关数据的分析/挖掘，建设位置相关的数据仓库；3、参与在线大流量高并发业务/服务系统设计与开发；4、分析和深入发掘现有系统的不足，定位系统瓶颈，提高系统性能和稳定性；5、根据业务实际需求，为团队引入新技术和新方案；6、以自身良好的项目管理与协调沟通能力，负责跨团队的重点项目的推进工作。职位要求1、本科及以上学历，计算机、通信、地理信息等相关专业；2、有扎实的编程能力，有优秀的设计和代码品位；3、深刻理解计算机原理,有良好的数据结构和算法基础；4、熟悉MySQL 、PostgreSQL、MongoDB、Redis、消息队列等常用组件；5、有以下经验者加分：1）理解空间索引技术并有实际使用经验者，有过空间引擎研发/调优者优先；2）了解常见数据清洗/挖掘算法，有实际运用经验者优先；3）熟悉大数据计算体系，有过业务数仓建设经验者优先；4）熟悉爬虫有数据采集经验者，有地理位置数据经验者优先；5）有地图、POI、LBS等业务背景者优先。
岗位职责:1、负责商汤大装置业务的数据产品的设计与研发工作，确保产品研发的进度和质量。2、负责在机器学习训练场景下，提出数据工具与数据服务的系统设计方案，并能够有计划的进行落地。3、负责海量数据的治理和分析工作，评估数据的质量，发掘数据的价值，助力AI模型的迭代优化。4、保持一定的业务和技术前瞻性，持续优化系统的架构和模型设计。任职要求:1、大学本科及以上学历，计算机及相关专业，5年及以上互联网大数据业务研发经验。2、有扎实的计算机科学基础知识，掌握常见的数据结构和算法，具备良好的编程能力和代码风格，熟悉常用业务架构的设计。3、熟练掌握Java 和 Python，熟悉Shell等至少一种脚本语言。4、熟练掌握Hadoop/Iceberg/Spark/Flink/Ray等大数据存储和处理相关的组件的技术原理，并有开发和应用经验。有Iceberg/Trino等技术使用和落地经验优先。5、对数据结构和算法设计有较为深刻的理解，熟悉I/O，多线程等基础知识，有一定的分布式高并发系统设计和实践经验。6、有数据治理/大数据基础架构/湖仓一体建设的实际开发经验，能够根据业务需求构建数据模型和数据流程，并提供高可用的服务。7、优秀的分析问题和解决问题的能力，并具有较强的业务理解能力。8、工作积极主动，具有强烈的责任心，有良好的沟通能力、协调能力、推动能力，技术迁移能力强。9、有独立负责项目或团队管理经验者优先。
岗位职责1、主要支持海量数据的分析需求，对多种数据源进行深度诊断性组合分析、挖掘、深度分析和建模；2、熟悉数据统计分析，推动统计分析模型的建立和完善；3、进行大数据仓库建设，分析业务需求，进行数据规则转化，通过数据清洗、转换、集成、统计等技术手段，完成需求的数据交付，利用etl工具建立日常报表调度体系；【岗位要求】1、本科以上学历，统计学、计算机、硕士优先，可接受应届生；2、具备较强的数据敏感性，具备很强的数据洞察能力，能快速从繁杂数据中发现问题，付诸到产品规划和设计；3、善于表达和沟通，能够和用户建立良好关系，能够推动数据和方案实施；4、熟悉linux系统操作，掌握至少一门脚本语言（Shell/Python/Go）；5、基于Hadoop的大数据体系有深入认识，具备相关产品（Hadoop、Hive、HBase、Spark、Storm、Flume、Kafka、ES等）项目应用/研发经验，有CDH/TDH集群搭建和管理经验；6、2年以上数据分析或数据开发经验，精通sql，有hive sql编程、调优经验优先；7、精通Tableau、MicroStrategy、帆软BI等其中至少一种产品设计逻辑及功能实现机理；
岗位职责：1.负责收集、分析业务部门数据类项目需求；2.负责数据类项目（大数据平台、数据仓库、BI类）的开发和管理岗位要求：1、3-5年左右数据开发经验；2、熟练掌握SQL编程语言，熟悉hadoop相关组件，如hive、Spark+；3、熟练掌握HIVE数据库的SQL语言、SQL调优，脚本开发，UDF函数4、具有银行业IT系统数据仓库、数据集市相关领域项目开发实施经验，5、有丰富的数据建模、ETL架构与开发经验，深入了解相关技术者，熟悉银行业务开发者优先考虑；6、具有良好的沟通、团队协作、抗压能力及责任心。
工作职责:1、 对接车联产品，根据需求完成产品架构、数据链路、数据模型设计，以及数据开发工作；2、 响应数据分析需求，进行车联数据复杂计算，得出分析结论，输出分析报告；3、 参与车联相关产品算法模型设计与开发，优化相关算法；4、 参与车联数据的质量管控和治理。任职资格:1、全日制本科以上学历，计算机或相关专业，6年以上大数据开发工作经验；2、熟练使用Java语言，能独立完成功能开发/其他编程语言为加分项；3、熟悉hadoop生态圈，了解Kafka、Hive等相关组件，了解数据仓库建模及设计思路；4、有Flink使用经验，并且有实际应用Flink的项目经验优先；5、有Spark使用经验，并且有实际应用Spark技术的项目经验优先；6、有物联网数据分析工作经验，了解纯电车辆电子电器架构以及相关信号，有车联网相关经验优先。
【岗位职责】1.负责理解及协助业务方定义自动驾驶性能及其它相关业务评估核心指标，建立自动驾驶核心数据仓库2.负责定义数据流转的标准、规范，打通数据使用的各个环节及已有的平台，建立自动驾驶场景的数据闭环3.负责理解业务需求，开发实时&离线作业，并进行自动化处理4.负责数据治理，包括元数据管理、数据血缘管理等5.负责优化各类数据查询及存储方式，提升海量自动驾驶数据处理的性能”【任职要求】1.本科及以上学历，2年以上数据开发经验2.熟悉python或者Java其中一门开发语言3.熟悉SQL语言，有spark ETL能力，熟练使用常见的数据接入、数据治理、指标平台等4.熟悉大数据架构，具备离线数据研发能力，熟悉Hive，Kafka，Spark，Airflow，Flink等相关技术并有相关开发经验5.具备实时/离线报表开发能力6.思路清晰，对数据敏感，有良好的沟通表达能力和跨团队协作能力
数据开发（中高级）任职要求：（1）统招大专及以上学历；计算机及相关专业（2） 3年及以上大数据开发经验，拥有实际的大数据项目开发经验；（3） 熟悉大数据es、elkcdh开发框架，hadoop，hive，spark，flink，hdfs等大数据主流工具和技术，熟悉Linux操作系统，Shell编程等；（4） 掌握常用的设计模式和架构模式，能够熟练使用建模工具进行系統设计；（5） 能够完成核心产品代码的研发工作，解决项目中关键问题和技术问题；（6） 工作责任心强，具备良好的团队合作精神，良好的沟通及协作能力。熟悉软件开发流程和配置库的使用，拥有良好的代码规范意识和文档编写能力
职责描述：1、基于Hive与Hadoop,进行数据ETL任务开发；2、负责项目中数据清洗、数据处理、数据校验相关开发工作；3、完成研发经理或者上级主管分配的其它工作。任职要求：1、统招大专或以上学历，5年左右工作经验,计算机类专业优先；2、至少三年以上大数据离线相关系统研发经验；3、熟练掌握大数据相关组件（如HDFS、YARN、Flink、Hive、Kafka、dolphinscheduler等）；4、精通HIVE SQL、SPARK SQL；5、精通至少一种主流关系型数据库,Oracle优先；6、会Shell脚本或者Python脚本优先。
工作职责：1、基于Hadoop数据中台，参与数据需求调研、分析、数据模型设计、数据开发等中台建设工作；2、负责数据中台开发、监控及对现有中台优化工作；3、参与数据中台探索应用场景的落地实施工作；4、负责数据中台各大数据组件的性能、效率、稳定性分析与优化工作；任职资格：1、本科及以上学历，3年及以上数据仓库/数据平台/数据中台项目开发工作经验；有大厂经验优先； 2、熟悉数仓领域各种理论知识，如元数据管理，数据质量治理、主流数据建模方法（维度建模、范式建模）等，可以根据实际业务设计数仓模型；3、对Hive有相对深入的理解及实际开发、优化经验，熟悉Linux常用命令，以及Python、Shell等脚本语言； 4、熟练使用Hadoop生态圈技术，如：Hive、Hbase、MapReduce、Kafka、Flume等； 5、熟悉Kafka、Pulsar、RabbitMQ等至少一种消息中间件，熟悉 Storm、Flink、Spark Streaming等至少一种流式数据处理框架； 6、具备一定的Java开发及调试能力，熟悉可视化工具者优先；  7、具有强烈的责任心和充分的主动性，能够积极主动的推进项目的进展； 8、具有较强的抗压能力和学习能力，能够独立、高效地发现和解决或推动解决各种疑难问题； 9、具有良好的沟通能力和团队合作能力。
工作年限1-2年1、全日制本科学历，学信网可查，擅长沟通2、熟悉Hadoop生态相关技术，熟悉MR、Spark、Storm、Hive、presto、kafka等；3、熟悉常用的关系型数据库产品(MySQL、Oracle、Postgre等)4、有数据建模能力和性能调优能力
岗位职责:1、构建数据平台2、支持海量数据的离线和实时分析，对数据敏感，参与大数据系统建设及开发；3、为业务部门、运营部门提供数据处理支持；4、参与相应应用故障排查及优化。任职要求：1、熟悉Java或.NET开发语言2、熟练掌握面向对象思想，数据结构和算法，熟悉常用设计模式，拥有较好程序设计思想3、熟悉Spring,SpringBoot,MyBatis等JAVA技术相关栈的开发或.NET WEB开发相关技术栈开发4、熟练掌握SQL编写、有大数据相关技术栈(HQL,Spark,Flink,ES,Clickhouse)开发经验或大数据平台开经验优先
岗位职责：大数据应用开发，参与产品设计，评估，开发等工作。任职要求：1、本科及以上学历，5年以上工作经验；2、具有5年及以上java 编码经验，熟练使用spring boot （cloud）框架，规范的代码编写习惯；3、有分布式数据库应用开发经验，3年以上gp/hive/MSSqlserver数据仓库作业开发工作，精通SQL应用开发；4、熟练使用一种或多种消息中间件如kafka、rabbitMQ、activeMQ等；5、有spark/flink等运算引擎应用开发经验优先；6、了解并熟悉最新大数据相关技术原理和技术特点；7、热衷于大数据技术方向的应用开发，对数据有较强的敏感度，乐于探索数据价值。8、有医疗行业大数据开发经验者优先。
岗位职责：1. 参与数据平台的数据模型设计、核心开发及维护；2. 完成相关项目的分析、设计及开发实现，并对现有系统优化；3. 积极探索系统服务（大数据）领域的新技术，并结合公司实际应用到具体项目中。任职要求：1. 计算机软件及相关专业，有5年以上大数据离线数仓开发经验；2. 具备数据平台相关项目开发设计经验；3. 熟悉数仓建模方法，并有实际应用经验；4. 对Hadoop、Spark、Flink、HBase等有深入的理解，并至少二种以上实际项目应用经验；5. 熟悉Redis、Kafka、Elasticsearch、Flume、ELK等组件；6. 具有海量数据服务（处理）领域的相关工作经验；7. 熟悉linux系统，具有shell、python等脚本语言开发经验；8. 较好的沟通理解能力，工作态度认真，有责任心，良好的团队合作能力；9. 有金融、保险行业相关开发经验的优先考虑。
1.计算机相关专业本科及以上学历，3年以上数据库经验2、熟悉hadoop、Oracle数据库，熟悉hive sql开发。如果还具备python经验则优先录取:3、熟悉金融行业业务知识，若了解期货证券行业则优先录取;4、擅长逻辑分析，对数据敏感。具备快速学习、分析及解决复杂问题的能力;5、沟通表达能力和组织能力优秀，有较强的团队合作精神;需具备较强的抗压能力，具备同时处理多项任务的能力;
岗位职责1.负责大数据平台（Hadoop，HBase，Flink等）集群环境的搭建，性能调优和日常维护；2.负责离线数仓、实时数仓、数据服务化的设计、开发、性能优化，为上层分析和挖掘提供可靠、统一的离线+实时数据服务；3.负责大数据平台核心问题的攻关, 解决项目中出现的技术难题。4.负责大数据任务的设计与研发、开发文档的编写5.落地大数据算法和相关应用，优化模型，挖掘数据的价值技术要求1.计算机相关专业，本科及以上3年以上大数据平台开发经验2.熟练运用至少一门编程语言，包括但不限于 Java、Scala、Python、Shell等；3.熟悉常用开源分布式系统，对Hadoop/Hive/Spark/Kafka/Flink/HBase中的一项或多项有深入了解;，能够独立排查及解决分布式系统的问题；4.有ClickHouse/Kylin/Doris/Superset等OLAP和数据可视化相关经验者优先；5.具有物流大数据经验者优先；6.精通数据建模及ETL设计开发，对数据仓库、数据平台、数据分析等有深刻理解，具备丰富的海量数据加工处理和优化经验；7.对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先；8.良好的沟通表达能力和团队合作精神，有一定的组织协调能力，学习能力强有责任心，不断挑战自己；
工作职责：1、参与零售全渠道数据中台的建构，负责数据仓库各层模型设计和ETL开发，建设企业级的数据资产及沉淀业务知识库；2、按照大数据平台开发流程和规范，在分布式大数据平台上，完成数据建模落地，包括从ODS、DWD、DWS、DM等数仓各层的建设、数据产品业务指标开发等；3、根据分析师梳理的业务需求，负责日常报表和数据产品的数据层开发、迭代，保证数据及时、准确产出；4、紧跟业务变化，及时充分评估业务变化对线上数据模型和产品的影响；5、参与数据中台的日常运维，对任务异常和数据异常的On Call及时响应、跟进处理，并反馈进度给上下游；6、跟进公司内部业务发展动态，跟进行业发展方向和数据产品最新发展技术，积累新技术和新产品方向。任职要求：1、大学本科学历及以上，1~3年及以上数据仓库开发经验；2、有新零售、电子商务行业相关经验的优先考虑；3、熟悉数据仓库分层架构和各类建模理论，参与过大型数据仓库设计、数据模型设计，有海量数据处理经验的优先考虑；4、熟悉Hive/Hadoop/Spark等分布式计算框架技术，熟练编写Hive Sql并具有一定的性能优化能力；有Java/Python/Shell等编程经验者优先；5、精通SQL，熟悉至少一种主流关系型数据库(Oracle/Mysql等)，熟练掌握MPP数据库(Vertica/Clickhouse/AnalyticDB等)者优先；6、有阿里云平台Dataworks开发经验者优先考虑；7、有进取心，责任心强，有良好的团队合作精神。
1、负责负责大数据架构设计、搭建、开发、上线； 2、负责大数据实时检索分析平台的架构和建设； 3、负责指导团队成员开发，对代码质量进行监控、确保开发质量； 4、负责大数据平台新技术的调研及技术选型； 1、熟悉云计算平台(IAASPAASSAAS)、大数据(HADOOPSPARK等)、移动互联网、物联网等技术架构和发展趋势； 2、精通HadoopStormSparkFlink等大数据分布式框架，并有实际经验； 3、熟悉大数据相关技术：Hadoop Hive HBase ZooKeeper Spark MapReduce等； 4、熟悉各种数据结构和算法， 5、5年以上软件开发工作经验，2年以上大数据系统开发，设计，架构经验； 6、具有数据仓库建设或应用相关项目经验优先有实际动手搭建hadoop体系架构经验，有算法经验优先， 对Hadoop体系各个中间间有实践经验，hdfs，mr，spark，hive，hbase，sqoop等
职位职责：1、负责业务相关数据挖掘核心技术的研发；2、负责多类大数据汇聚分析与开发设计，实现相关业务的实体的关键字抽取、正则化、聚类、Topic等基础特征，为后续处理提供数据；3、负责大数据文本处理性能优化问题；4、参与数据处理底层的工具、平台和部署流程等研发工作。 职位要求：1、3年以上相关工作经验，熟练掌握Java或Scala或python编程语言、熟练使用 Springboot、SpringMVC、Mybatis等框架。2、有扎实的计算机基础，熟悉常用数据结构、算法、设计模式；3、精通 SQL，有较好的 SQL 性能调优经验，熟悉 Hive/MySQL 的基本原理和调优策略；4、熟练使用大数据组件产品，包括但不限于Spark/HBase/Hive等，了解一些基本的机器学习算法;5、动手能力强，喜欢折腾，有解决复杂问题的能力与兴趣。
工作内容：1. 负责高性能、高可用的大数据数据处理与分析paas软件的研发。负责基于Hadoop/Spark平台架构的开发、设计和布局 ；2、 针对海量的用户行为数据进行统计、分析与挖掘，不断提高系统运行效率；3、 负责对数据进行分析，为项目组提供大数据技术指导及分析手段支撑；4、 负责大数据平台的性能监控和持续优化；针对需求提供大数据分析技术解决方案 ；5、 大数据平台的运维工作，持续完善大数据平台，保证稳定性、安全性。任职要求：1. 3年以上工作经验，计算机相关专业本科以上；2. 精通Hadoop大数据平台架构，具有扎实的Scala/Java/Python等开发语言；并可以开发高效可靠的代码；3. 了解分布式系统、大数据平台，有完整的数据工程项目经验，具备一定的框架设计以及抽象能力；4. 熟悉spark、Hive、storm等计算框架者优先，对分布式存储和计算原理有较深的理解；5. 良好的团队精神以及合作意识，热爱技术，高度自驱，追求卓越，对数据敏感；6. 对批量计算、流式计算、时序数据处理、存储引擎、资源调度等一项或多项有深入理解优先说明：自研项目非外包，但此岗位会有出差，介意勿扰
工作职责：参与公司系统日常开发、优化、架构设计参与公司微服务搭建、架构、优化参与重点项目方案设计评审及技术难点攻关任职资格：1.有责任心，良好的团队沟通协作能力2.扎实的Java或Go编程基础，熟练掌握常见的设计模式3.熟练使用Java主流框架例如Spring、SpringBoot、MyBatis等4.熟悉常见的中间件、分布式解决方案及其原理例如：分布式缓存、微服务组件、消息中间件、存储中间件等5.熟悉Hadoop生态、调度系统例如Azkaban、海豚调度6.熟悉大数据数仓架构，熟悉相关组件例如Spark、Flink、Kafka、Hive加分项：1. 了解docker，k8s技术2. 熟悉Python脚本语言
"岗位职责：	1. 负责支持前端业务部门的数据处理需求；2. 负责标签体系建设及数据运营；3. 负责外部项目数据开发支持；4. 负责数据产品的数据处理模块设计及开发；5. 按时完成业务部门需求，完成项目及数据产品开发任务；6. 交付结果确保数据质量。岗位要求：1. 本科及以上学历，有1年以上大数据开发、数据仓库开发、数据分析相关经验；	2. 熟练掌握Hive SQL、python、Shell等开发语言，熟悉Hadoop、Hive、Spark等相关大数据工具；3. 熟悉Hive SQL、spark常用性能调优方法，熟悉常用的机器学习（如决策树、逻辑回归、聚类等）算法者优先；4、有海量数据处理的项目经验，有数据仓库或数据产品的架构设计能力；5、具有良好的沟通、团队协作以及项目管理能力，做事积极主动，乐于学习新知识。"
岗位职责：1. 负责数据体系建设，持续迭代数据仓库，帮助企业沉淀私域流量的数据资产，实践数据智能；2. 负责离线和实时数据仓库数据处理pipeline的设计和开发；3. 负责交互式数据查询以及后台数据服务的设计开发与性能优化；4. 结合业务寻求数据层面的业务价值，深度挖掘大数据应用需求；岗位要求：1. 本科及以上学历，计算机信息类、数学/应用数学类等专业背景，3年以上的数据开发经验；2. 熟悉 Java 和 Scala 语言，精通至少一种分布式计算框架，如 Hadoop 、Spark、Flink 等，并理解其架构和工作原理；3. 熟练掌握常见的分布式存储技术，如 HDFS、HBase、Elasticsearch 等；4. 具有良好的沟通和团队协作能力，对业务有良好的数据化思维能力和敏锐度；5. 熟悉数据仓库各类建模理论，以及数据仓库层级体系，有数仓建设经验者优先。附加信息：工作时间：周末双休上下班时间：09:30-18:30
所属部门：大数据研发中心1）熟悉Linux/Unix平台，熟练使用常用命令；2）精通Java开发，对多线程、消息队列等并有较为深刻的理解和实践；3）熟练使用Tomcat等常见中间件；4）熟练运用Doris，有数据仓库相关经验者优先；5）熟悉kettle、datax、sqoop、flume等数据同步工具的一种或多种；6）良好的沟通能力、团队精神和服务意识；7）善于学习新知识，动手能力强，有进取心。
岗位职责：1. 参与数据仓库和大数据平台的环境搭建、架构设计和程序开发;2. 负责离线和在线数据的采集、清洗和加载;3. 负责分布式批量计算、分布式内存计算、数据仓库类SQL查询统计等离线计算;4. 参与实时数据流的数据处理、查询统计和分析预测等在线计算;任职资格：1. 本科及以上学历，计算机、软件工程或相关专业出身，具有Hadoop、Spark、Flink开发与应用经验，熟悉Flume与Kafka等数据采集和消息通道技术;2. 有较好的Java/Go基础，熟悉Linux环境及脚本开发（Python/Shell等）；3. 理解ETL过程，拥有DW项目开发经验，熟练掌握SQL/HQL；4. 强烈的主动性与工作责任心，对所负责工作有owner意识，并能自我驱动不断成长。
岗位职责：1:数据项目的ETL开发工作2:熟悉hadoop架构 hdfs spark flink3:熟练使用ETL工具，比如datastage/kettle/datax/dolphinscheduler等4:设计ETL整体架构和任务调度平台5:熟悉ETL流程及开发6:参与数据仓库ETL流程优化及解决相关技术问题7:熟练编写plsql8:参与数据仓库建模，不断改进现有数据仓库9:大数据环境的搭建与运维10:熟悉python或java优先11:熟悉MPP（doris clikhouse）优先任职要求：1.全日制本科及以上学历，计算机、软件或者大数据等相关专业。2.1-3年大数据相关工作经验。福利待遇：五险一金  做五休二   早九晚六（弹性工作时间）  下午茶  带薪年假  年度体检  定期团建  享受临港新片区落户和购房政策工作地址：上海临港新片区创晶科技中心（介意地址者勿投）
岗位职责：1、参与数据中台/大数据相关产品的规划和架构设计，带领研发团队进行数据中台/大数据解决方案的实现；2、主导完成数据中台/大数据相关产品部署和使用手册的编写，并在部门内部指导、培训和推广；3、负责大数据解决方案复制和推广，通过项目跟踪，制定可复制解决方案，并进行指导、培训和推广；4、跟踪大数据相关技术的发展趋势，提出大数据相关产品的设计和维护方案(性能、可用性、安全等方面的优化)。任职要求：1、10年工作经验，5年以上大数据项目工作经验，作为骨干人员实施过2个以上数据中台/大数据平台项目；2、熟练使用apache hadoop生态体系相关技术(zookeeper、Hadoop、Hbase、hive、Spark、Flink等组件)；3、熟练使用java、python等编程语言，熟练操作linux系统，具备上述工具在linux下的部署实施经验；4、具有良好文档编写能力，能输出标准、准确的手册供部门实施人员参考；5、有数据中台/大数据中台建设经验、数据治理经验者优先；6、有智慧交通项目经验、熟悉交通业务优先。
岗位职责：1、负责大数据平台和数据产品的建设，协助产品对外输出；2、使用hive、flink、clickhouse等开源组件，并基于开源组件进行二次开发，满足业务中的定制化需求；3、针对不同业务场景，提供大数据量查询性能优化建议与方案；任职要求：1、5年以上工作经验，熟悉Linux/Unix操作系统，有python、shell等脚本语言编程能力2、熟悉hadoop、hive、spark、flink、kafka、es、redis、zookeeper等大数据相关技术及中间件，了解底层机制与原理，具备开源软件源码分析、二次开发与优化能力，并能结合业务场景进行架构设计；3、熟悉视频业务，有相关工作经验优先；
熟悉Oracle、MySQL数据库的开发；熟悉大数据hdfs、hive、kafka、sqoop等技术1、全日制本科以上学历2、精通至少一种主流关系数据库，精通SQL编程；熟悉oracle优先。熟悉Shell,Python等脚本语言；3、.2年以上Hadoop工作经验，熟悉Hdfs/Mapreduce/Hbase/Hive等软件使用；4、具备良好的数据分析能力和学习能力；5、有较强沟通能力，思维严谨；6、有数据仓库、数据挖掘、互联网行业项目经验优先
职位描述       智数云是一个支持敏捷化数据中台建设的平台级产品，帮助企业实现一站式的数据管理、加工、分析和应用，快速实现数据价值。在智数云平台的基础上，需要此岗位开展以下工作：1. 根据客户的大数据应用需求， 构建数据收集、加工和应用流程；2. 测试、管理和维护已有应用流程；3. 培训企业客户自助使用数据中台建设数据应用。岗位要求：1. 计算机或者相关专业；2. 熟悉Python，有一定的编程经验；3.  熟悉SQL语言和关系数据库原理；4. 善于沟通，做事积极主动，责任心强。
任职资格：1、本科及以上学历，计算机相关专业优先；2、具备 3 年以上 Java 编程经验；3、具备 3 年以上大数据相关应用和平台开发经验；4、精通 Doris，Clickhouse 等至少一种 OLAP 组件，熟悉数据湖技术；5、对大数据组件有熟读源码和二次开发能力；6、熟悉大数据生态圈常用技术如 Kafka、ZooKeeper 等；7、熟悉流行的大数据编程框架：MapReduce、Spark、Flink 等；8、熟悉 Linux 系统的各类常用命令。工作职责：1、负责大数据平台下多维分析产品的开发和性能优化，包括OLAP性能调优；2、负责大数据平台实时计算，高并发海量应用开发（如实时风控系统等）；3、负责大数据平台机器学习项目的算法工程化，及机器学习平台的开发；4、负责大数据平台作业调度平台开发；5、完成公司交办的其他工作。
工作内容1、负责公司大数据平台研发工作。2、负责完善现有产品功能的算法及相关分析模型与业务需求的契合度，并能够完美的优化或进行调整；3、配合产品经理，并研发或构建算法实现其落地；4、承担公司机器学习、深度学习、强化学习、预测学习、运筹优化、主决策树等领域的研发、设计、部署等工作；5、承担公司大数据平台程序层的设计开发和算法设计工作；6、负责关注及追踪人工智能方向的前沿算法和相关技术，并将适合我司产品的算法应用到实际的业务需求场景，提升产品能力。任职要求1、计算机、机器学习、数据挖掘、运筹学、自然语言处理、图像识别、统计学或应用数学等相关专业；2、熟悉Java，Perl，Python等一种或一种以上编程语言；3、熟悉Hadoop体系相关技术，如：Spark、Flink、MR、Kafka、Hive、HDFS、Kylin等，并具有实际编码经验；4、熟悉Linux开发环境，熟悉开源工具；5、具有扎实的计算机基础、数据结构和算法基础，在大数据领域有系统化的研究和成功的项目经验。对主流技术如Hadoop 、Spark 、Hive、Flink 、Kafka 等有深入的理解和丰富的使用经验；6、具备业务抽象和信息建模能力，能够将复杂的业务场景分解、抽象成标准化的业务模型；7、对数据分析和算法设计有比较强烈的兴趣，具有统计学、运筹学、数据分析相关知识优先考虑；8、具备自我驱动的快速学习能力，主动追踪人工智能方向的前沿算法和技术发展。
岗位职责：1、参与大数据统一调度平台开发及日常运维。2、参与数据统一交换平台/统一接口服务开发。3、参与数据采集，数据解析及数据推送服务开发。任职要求：1、计算机相关专业本科及硕士以上学历，985/211优先，2年以上相关系统研发经验。2、熟练使用linux，能够使用shell脚本编写代码，熟练使用java，有web项目经验，熟悉JS优先。3、熟练掌握SQL开发语言，了解Scala或Java语言；懂得SQL优化，掌握窗口函数、自定义函数、explode等函数运用；4、熟悉Spark、Hadoop、MapReduce，了解ETL性能优化；熟悉大数据Hadoop生态系统，熟练使用主流大数据平台进行数据的处理，具备其中一种或多种产品(Spark、Hive、Hbase、Kafka、ES、Flink等)使用经验。5、熟悉阿里云Dataworks，maxcompute，QuickBI者优先。6、具备统一调度平台或者数据交换平台自主建设经验，熟悉airflow、Azkaban、海豚调度，XXL调度、datax等开源项目，掌握核心系统设计理念7、熟练使用一种数据库，包括不限于oracle、sql server、mysql、sybase等。8、喜欢开发，热爱技术，有较强的责任心，耐心及大局观，逻辑思维缜密活跃。
"工作职责:	参与BI数据项目的交付 (需求分析/维度建模设计/模型开发/测试)；	参与数据平台（数据湖/数据仓库） 建设工作；	数据平台相关新技术研究探索并落地。任职资格:	至少5年以上开发经验 （如Java，Python，以Java为主），2年以上数据工程相关经验，熟悉维度建模基本理论知识；	扎实的计算机基础知识，熟练掌握Java, 熟练掌握SQL；	熟悉大数据相关技术，包括但不限于Hadoop/Hive/Presto/Spark/Flink/Kafka/Kafka Stream/Airflow；	熟练掌握常用的开发运维工具，比如git/maven/linux常用命令等；加分项:	1、丰富的维度建模设计及开发经验；	2、有过云数仓使用相关经验 （AWS Redshift /Google BigQuery/ Databricks/ Snowflake等 ）；	3、熟悉Kubernetes；	4、熟悉dbt, headless BI, cubejs；	5、熟悉golang，有相关开发经验。"
1. 分布式数据应用开发（hadoop/spark/flink/hbase/doris/iceberg）；2. 负责公司内部大数据产品研发和服务接入；3. 处理各类任务异常和故障，确保数据任务的稳定运行；4. 基于实时和离线海量数据分析平台的开发；职位要求：1. 扎实的scala/python基础，精通hadoop生态组件，ETL工具如Sqoop/Kettle/Flume等2. 有一年以上流式计算项目实战经验，掌握spark、flink、phoenix、trino、iceberg应用；3. 有基于PB级数据，数据应用开发经验优先（包括HBase、Redis、Apache Doris）；4. 良好的汉语和英语沟通能力优先。
岗位职责：1、负责基于Spark技术的海量数据的处理、分析、统计、挖掘工作；2、基于Spark框架的数据仓库的设计，开发，维护；3、根据需求使用Spark Streaming和Spark SQL进行数据处理、查询、统计等工作。岗位要求：1、本科及以上学历，软件工程、计算机等相关专业，优秀硕士研究生优先考虑；2、熟悉RDD/DataFrame编程，对Spark体系结构、运行机制有深入研究，熟悉源码；3、熟悉Spark相关技术；4、熟悉linux、shell脚本或python脚本编程；5、熟悉Spark Streaming和Spark SQL，有过程序开发经验；6、具有良好的Trouble Shooting能力；7、能够用python开发数据算法，熟悉python算法库的优先；7、具有海量数据系统开发经验，且在开源社群活跃并有积极贡献者优先考虑。
职位描述 熟悉微服务架构、Azure 版 Spring 云、Spring Boot 和 Spring Cloud，参与微服务架构设计，了解微服务治理; 熟悉Hadoop生态，有flink、spark、hbase、hive等大数据组件的实际项目经验; 了解无服务器、了解容器以及在生产环境中使用容器的经验者优先; 熟悉 kafka、RabbitMQ 等主流消息中间件; 对技术有热情，具有良好的团队合作和沟通能力。职位要求5年以上大数据，1-2年java，做过微服务。项目经验真实，学历不限做过AWS Support，主要使用，微软云了解就可以，技术过硬。
岗位职责：1、负责资管大数据平台及相关项目的开发和维护工作；2、参与资管大数据平台相关组件的技术研究、开发与维护工作；3、参与基于Hive、MR、Spark、Flink及相关技术对海量数据的处理、分析、统计工作。岗位要求：1、本科以上学历，数据科学、计算机科学、统计学、数学、数据挖掘和分析等相关专业；2、了解Oracle，掌握PL/SQL开发技术；3、学习或使用过Hadoop/HDFS/Hive/Redis/HBase等大数据生态平台及工具；5、掌握数据分析工具Python者优先；6、具备良好的逻辑分析能力、沟通能力；有很强的责任感，有钻研和创新精神，乐于接受工作挑战。7、需要接受实习项目考核1个月后才能发放offer。
需要会写spark  跟java   接受银 行 -驻-场任职要求：1、本科及以上学历，学信网可查，计算机、数学等相关专业2、1年及以上大数据项目经历；3、具备较好的业务分析理解能力，具备体系化思维习惯；岗位职责：1、负责项目大数据的开发任务2、按照组长要求分模块进行开发任务的完成3、负责编写软件需求和概设等文档
1.统招全日制本科毕业，3年以上大数据运维工作经验；2.负责公司大数据平台的部署、管理、优化、监控报警,保障平台服务7*24稳定可靠高效运行;3.深入理解公司大数据平台架构,发现并解决性能瓶颈,支撑业务和数据量的快速增长;4.开发大数据自动化运维、监控报警、故障处理相关脚本和工具;5.负责Hadoop/spark/Kafka等集群服务、业务监控、持续交付、应急响应、容量规划等。
技术部内部职位，非派遣工作地点:浦东张江高科预计到岗时间：22年12月岗位要求：1、负责数据处理开发工作。2、通过对数据仓库模型优化、处理过程优化、大数据平台参数调整，优化计算任务性能，提升资源利用效率;3、负责大数据平台系统开发工作，如任务调度系统、元数据管理、数据监控系统等。4、负责数据服务接口开发工作。职位要求：1、本科及以上，计算机或数据领域相关专业，flink工作经验3年以上2、有flink集群的高可用规划和设计经验3、精通java/scala，具备flink大型实际项目经验、精通flink原理4、熟悉相关流式数据湖平台，熟悉hadoop生态。5、精通SQL编写与调优。6、熟悉shell/python优先。7、有数据接口开发能力优先。大数据开发工程师/中级、高级、资深均可
1、三年及以上工作经验2、专科及以上学历，计算机相关专业3、熟悉Hahdoop生态圈，包括但不限于Hive、Spark、Hbase、Flink、ClickHouse、Kafka等,有Spark或Flink的开发经验优先。4、精通Oracle
（1）五年以上开发经验，三年以上软件研发经验，至少一年以上大数据相关系统研发经验；（2）有扎实的Java语言基础，有java web经验；（3）熟悉Linux系统，能够熟练用scala/shell/python/ansible脚本处理工具，具备成熟的调优经验；（4）精通SQL，有较好的 SQL 性能调优经验，了解 Hive/MySQL 的基本原理和调优策略；（5）精通Hadoop生态圈技术，有丰富的MapReduce/HBASE开发经验，熟悉HBase、Storm、Spark、Impala、Hive、Sqoop等数据相关技术。
岗位职责：1、负责数据平台，元数据管理、分布式任务调度，查询、计算引擎等相关平台的开发； 2、面向大规模数据应用场景，构建高可用、高性能、高并发的数据相关的工具开发； 3、参与需求调研、平台设计和技术选型，降低数据的使用门槛。任职资格：1、计算机或相关专业本科及以上学历，2年以上开发经验； 2、扎实的Java基础，深入理解JVM、线程、并发、网络；3、熟悉SOA架构和微服务架构，有Spring boot/Spring cloud等微服务开发经验；4、熟悉使用主流的缓存、消息、发布订阅等中间件，如 redis、kafka、zk 等； 5、热爱大数据相关技术，有Hadoop、Spark、Flink等大数据组件使用经验优先。
工作职责： 1.基于Hadoop数据平台，参与数据开发及各类数据模型建设工作； 2.负责数仓任务开发并对现有数仓进行优化； 3.负责公司端游和手游等游戏项目的数据中心的建设，和数据报表的开发； 4.参与公司其他大数据类研发项目，结合大数据平台探索应用场景并参与实施。  职位要求 1.本科及以上学历，3年及以上数仓开发工作经验； 2.熟悉数仓领域各种理论知识，如元数据管理，数据质量治理等，可以根据实际业务设计数仓模型； 3.对Hive有相对深入的理解及实际优化经验，熟悉Linux常用命令，以及Python、Shell等脚本语言； 4.熟练使用Hadoop生态圈技术，如：Hive、Hbase、MapReduce、Kafka、Flume等； 5.熟悉Kafka、Pulsar、RabbitMQ等至少一种消息中间件，熟悉 Storm、Flink、Spark Streaming等至少一种流式数据处理框架； 6.具备一定的Java开发及调试能力，熟悉可视化工具者优先；  7.具有强烈的责任心和充分的主动性，能够积极主动的推进项目的进展； 8.具有较强的抗压能力和学习能力，能够独立、高效地发现和解决或推动解决各种疑难问题； 9.具有良好的沟通能力和团队合作能力。
岗位职责：1、负责大数据实战技术课程的授课；2、带领学员参加并指导学生完成实训项目；3、完成课程辅导工作，解答学员课程疑问，保证学员的学习质量；4、完成相关的教学资料(教学PPT、教学用书、教学案例等)的研发工作，跟进技术前沿，更新教学教研体系；5、配合市场需要，完成短期实训和技术讲座的授课任务。任职要求：1、有两年以上大数据开发经验；两年以上Java开发经验优先；2、一年以上教育行业经验有限；有大数据开发培训经验优先；3、熟练掌握Java、Hadoop、Hive、HBase、Zookeeper、Spark、Storm等；4、有知名大企业工作经历优先；5、有大数据典型应用场景实战项目优先；具备较为丰富的数仓及数据平台架构经验，精通离线或实时；有大型金融/互联网系统设计或架构经验优先。
职位描述：1、负责大数据平台的设计、开发、推广和落地，包括但不限于BI系统、广告系统、推荐系统等；2、负责数据治理、数据调度、算力调度、用户画像、智能推荐、机器学习等功能的抽象和技术落地，能够使用合理的技术体系开发大数据平台系统；3、调研大数据相关的技术、产品和解决方案，持续优化大数据平台的架构设计，优化整体服务性能和效率；4、参与大数据研发团队的研发管理工作。职位要求：1、计算机相关专业本科及硕士以上学历，10年以上大数据相关工作经验；2、3年以上研发管理经验，具有良好的学习能力、团队精神以及协调沟通能力；3、掌握大数据生态技术栈, 如Hadoop、Spark、Flink、Hive、HBase、Kafka、Elasticsearch等，并有实际工作经验；4、熟悉Linux系统, 具备Java/Python/Go一种或几种语言开发能力；5、有BI、推荐、搜索、广告相关系统开发经验的优先；6、熟悉阿里云大数据组件，如MaxCompute、Hologres、DataWorks、QuickBI等，并有使用经验的优先；7、熟悉数数科技、神策数据等产品的优先。
工作职责1、统筹和规划数据管理类相关工具和系统。2、负责研究与落地和数据开发相关的工具、平台，提高团队数据开发的效率和能力；3、探索数据、分析业务领域内的痛点，并与业务沟通，提出相应的解决方案。任职资格1、统招全日制本科以上学历, 计算机专业优先，5年以上大数据开发工作经验。2、具有丰富的数据类项目开发交付经验，主导项目整体架构设计和管理过程的工作。3、具备熟练Java开发经验，熟悉微服务框架、中间件、分布式技术等。4、熟悉Flink、Spark、HBase、Clickhouse及其他OLAP产品等基本原理，并有生产化调优等相关实践经验。5、熟悉数据仓库模型设计，并有丰富的sql使用经验，有数据湖经验优先。6、熟悉hadoop/yarn/hive等大数据组件。7、严谨的逻辑思维能力，高水平的沟通能力，有快速学习能力和丰富的问题解决能力，具备高度个人驱动力和执行力，同时具备良好的团队合作精神。8、对ES、图数据库等生产使用经验者优先。
1、扎实的编程、算法基础，精通java，熟练使用spring,Struts,Hibernate SpringMVC等开发框架；2、熟悉hadoop和Flink生态相关组件，有相关项目开发经验，比如hadoop、hbase、spark、spark-stream、presto；3、精通Web前端技术基础，精通各种Web前端技术基础: HTML、CSS、JavaScript。4、热爱数据行业，机器学习、熟悉使用的Dubbo， thrift，spring-cloud等RPC服务框架。
任职资格：1、计算机/数学/统计学等相关专业本科以上学历，硕士学历以上优先，两年以上工作经验，优先毕业生可以放宽。2、熟悉使用springBoot、mybatis等Javaweb框架。3、精通一门或多门开发语言（Java、Python,shell）等。4、项目中使用过3种（含）以上技术：Spark, Hive, mySql,kakfa, sqoop, HBase, flink, Elastic Search等。5、项目中应用过2种（含）以上算法：逻辑回归，随机森林，决策树， 神经网络，Apriori等。6、熟悉使用BI工具如FineBI等。7、善于独立思考，逻辑清晰，热爱挑战，具备快速学习能力。8、有机器学习或数据挖掘实际项目经验者优先。9、具备良好的沟通能力和团队合作精神。
大数据开发1、精通oracle数据库，精通SQL编写技能，存储过程/函数编程，精通SQL优化技术2、有cognos或tableau等报表开发经验者优先3、有过hadoop开发经验者优先4、有过金融行业BI项目经验者优先学历真实，学信网可查
1. 熟悉ETL开发流程，熟练使用大数据组件hive spark等等2. 了解hadoop以及相关组件如 hive spark hbase相关原理及架构3. 有良好的编程基础和规范，熟练使用如python java scala
1、负责数据中台数据应用相关设计、编码开发及生产运维支持；2、负责大数据研发工具研究与选型，3、数据中台当前已有的Hadoop、spark、hive、BDM等大数据框架的运维与问题排查；4、参与数据中台数据集成框架的信创改造工作；1、硕士及以上，35周岁以下，计算机及相关专业，CET4；2、具有较强的问题抽象能力、系统化思维能力、文字表达能力和组织协调能力；3、熟悉greenplum/hadoop/spark/hive/flink等大数据平台架构，有过系统开发、维护经验的优先；4、至少熟练掌握一门开发语言（java/python/go/scala/c++/shell等）；5、3年及以上大数据开发相关工作经验；6、精通高性能SQL开发和SQL性能调优者优先；7、具备良好的自主学习能力、沟通能力和规划能力，积极乐观向上；通过阅读官方文献资料等解决问题的能力。
岗位职责：1、负责系统开发，管控团队开发进度、质量、测试，并撰写相关技术文档；2、按项目管理要求对研发过程进行管理，包括项目计划制定、过程规划、过程跟进、过程协调；3、为技术支持人员提供技术支持，解决技术支持过程中遇到的相关问题；4、完成系统概要设计、详细设计，部分核心功能的编码，并指导开发人员完成代码编写，协调系统测试、版本提交；5、把控项目开发进度，确保产品质量和如期交付。任职要求：1、计算机、软件工程及相关专业，6年及以上软件开发经验，3年以上带队开发工作经验；2、JAVA基础扎实，精通Spring，SpringBoot，SpringCloud等主流开源框架并了解其工作原理和机制，有SpringCloud微服务架构项目设计经验；3、熟悉 MySQL、Oracle 等数据库，熟练地使用 SQL 语句；4、熟悉Hadoop生态圈（HDFS、HIVE）和大数据开发；5、熟悉JS,CSS，能够使用vue,Bootstrap等前台框架；6、熟悉多线程编程、RPC框架、分布式缓存、监控、消息中间件,异步处理等机制；7、熟练掌握分布式通讯框架、消息中间件、分布式缓存（memcache、redis等）、分布式事务处理；8、工作执行力强，有担当，敢于应对变化和创新；9、有Power BI项目开发经验，熟悉DAX/Power Query；10、英语工作环境，要求英语听说读写能力强。
软件开发实习生技能：基础软件工程，会编程加分项：对函数式编程有浓厚的兴趣，主要用elixir,有老师带主动性高，学习能力强计算机专业
数据仓库团队直招岗位职责：1、负责数据相关业务应用场景的分析，利用数据相关技术实现对数据的采集、存储、分析与可视化；2、参与数据平台的相关技术方案设计，负责数据平台核心框架和核心代码开发；3、负责系统的开发、测试、部署和维护。岗位要求：1、熟练掌握SQL语言，熟悉Teradata、Greenplum、Oracle、MySQL中至少一种数据库；2、熟悉大数据开发框架，熟悉Hive、Spark、Flink、Hbase、Impala、Kylin、Kafka中两种以上大数据主流工具和技术，对大数据基础架构和平台有深刻理解；3、熟悉Python、Java、Scala等开发语言中的一种或多种，熟悉Linux操作系统和Shell编程；4、具有2年以上大数据平台、数据仓库相关领域项目开发实施经验，有丰富的数据建模、ETL架构与开发经验，深入了解相关技术者优先考虑；5、熟悉数金融业主题数据模型、中间层模型理论以及多维模型设计，有银行业IT系统开发经验者优先考虑；6、热爱技术，能够主动研究相关新技术，具有较强的学习能力。
【岗位介绍】华为数据存储聚焦数据的“采集、存储、计算、管理、使用”，通过产业生态合作，对数据实现端到端的整合和优化，致力于构筑一个5G-IOT-存储的生态闭环。经历十年发展，已服务全球150+国家，18000+用户，市场占有率已跻身全球第二、中国第一，每年市场空间增长超35%。我们致力于企业存储、海量分布式存储等场景，为大数据分析/HPC/视频图像处理/对象资源池/备份归档/虚拟化/云资源池/AI等应用提供多样性存储服务，实现极致融合、极致性能、极致可靠性、多云流动，构筑存储全球领先竞争力。【岗位职责】1、负责存储大数据存算分离 、数据湖、流式存储 特性的设计、代码开发，测试验证及运维工作，保证系统可靠性，可伸缩性和高性能2、负责交付特性/子系统设计文档和接口，主导特性交付3、参与在实现中验证设计的工作，完成设计问题分析和预防的工作【岗位要求】1、熟练掌握SQL开发及性能调优，熟悉主流数据库Mysql、Oracle、PostgreSql2、熟悉Python、Java、 Scala等至少一种编程语言3、熟悉数据仓库各类建模理论、ETL架构、数据仓库分层分域、多维数据模型设计4、熟悉数据仓库开发流程，包括海量数据的采集、清洗、转换、分析挖掘和数据可视化5、熟悉Hadoop/Hive/Spark/Storm/Flink/Kafka等主流大数据生态技术6、全日制本科及以上【福利待遇】全额五险一金、附加商业保险享受带薪年假、年度体检、班车、节假日礼品等免费夜宵25元标准免费健身房、乒乓球、台球、民主生活会每年至少2次团建旅游、免费电影等【周三&&周五活动日，活动拉满】篮球、足球、羽毛球、网球、三国杀、狼人杀、剧本杀、王者荣耀、和平精英、英雄联盟手游等加入我们，一起点亮数字未来！！
工作内容∶1. 参与数据中心相关数据产品、数据平台的架构设计，及其相关技术研发；2. 负责业务需求的理解与满足，数据价值的探查和挖掘，及相关数据开发；3. 负责企业级数据仓库、数据湖的建设，数据ETL的设计、开发与性能优化。任职要求∶1. 本科及以上学历；2. 3年以上实际大数据开发经验，熟练Java或Scala等编程语言，有良好的编程习惯；3. 熟悉Hadoop/Spark/Flink/Kafka/HBase等大数据组件，并深入理解其原理；4. 熟悉主流开源OLAP引擎ClickHouse/Doris或StarRocks者优先；5. 熟悉主流数据湖解决方案Delta/Hudi或Iceberg者优先；6. 有线上调优、源码阅读经验者优先，社区贡献者更佳。
外企德科OD招聘岗位职责：1.负责大规模系统的核心数据系统设计与开发，实现系统端到端的可追溯性；2.提供面向业务的数据服务，负责系统全生命周期内数据收集、分析、挖掘、治理等业务功能；3.负责搭建项目过程数据分析模型，通过ETL过程实现预警功能；岗位要求：1.计算机、软件、通信等相关专业本科及以上学历；2.熟悉开源大数据技术栈，包括但不限于Hadoop、Hive、Spark、Kafka等；3.有扎实的编程语言基础，包括但不限于Java、Scala、Python、Shell等；4.优选条件(具备一项或多项)：1）熟悉数据仓库建模方法论、常用的数据结构和算法，具有大数据实时跟踪、挖掘分析、软件性能调优，海量数据系统开发相关经验；2）熟悉主流数据库，分布式框架，有设计、实现和运维分布式系统经验；3）对数据敏感，具有较强的逻辑思维能力和分析解决问题能力，对大数据技术栈有热情，能够主动发现并研究新的大数据技术方向；技术点：有1年以上C/C++/JAVA/Python编程经验城市可选：东莞、上海、北京、武汉、西安
1.有ETL、数据库、数据集市，大数据，BI等相关开发经验，精通SQL2.熟悉掌握主流数据库系统中的一种，3.熟悉hadoop  hive  Kafka 等相关技术并有相关实践经验4.熟练使用数据ETL开发工具5.具备良好的领导 沟通 团队协作和创新能力，有强烈的责任心
工作职责：1、参与和完善基于大数据平台的量化投研平台的建设；2、根据业务需求对于数据进行实时处理和指标运算；3、调研大数据平台方向的新技术；4、负责自建数据库的每日数据下载，清洗和检查工作；5、负责数据调研，采购和部署工作；6、负责高性能服务器组的运维工作；7、参与部门数据规划和硬件规划工作；8、其他数据分析需求的支持。任职资格：1、硕士（含）以上学历，特别优秀者可放宽至本科学历；计算机及相关专业；2、三年及以上工作经验，其中至少有二年（含）以上大数据相关工作经验；熟练掌握相关大数据分析处理机制；3、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark）等。熟悉Java/Python语言，能够熟练的进行开发。具有主流数据库（MySql，Oracle，Mongo, Redis）开发和运维经验。具有编写sql脚本的能力；4、具有互联网或交易厂商大数据相关经验优先考虑。
职位描述：1、负责 Hadoop 集群、数据分析平台、计算平台维护和开发；2、负责公司海量用户行为日志数据收集、ETL；3、支持实时数据报表、离线数据报表、交互式数据分析等多种数据应用；4、参与数据分析平台的数据开发和调优。职位要求1、熟悉分布式系统的基础理论知识，2 年以上相关工作经验；2、熟悉 Java/Scala 语言，有扎实的开发功底，有 Python 语言经验优先；3、熟悉 HDFS, Yarn, HBase, Kafka, Zookeeper 等基础组件；4、熟悉 Spark/Flink/Hive/Kylin/Druid/Presto 等开源产品；6、有大数据分析与数据仓库设计及开发经验优先；7、有数据挖掘、机器学习、推荐算法、人工智能、数学建模项目经验者优先；8、良好沟通和团队合作能力，具备很强的问题分析及解决能力。
岗位职责：1、助力合创汽车实现“通过用户数据服务营销转化”的业务目标， 支撑公司数据平台建设及数据治理工作展开2、负责数据采集、清洗、传输、存储、计算、调度等全方位设计与开发3、负责大数据平台数据仓库的架构设计、开发及相关文档的编写4、持续优化ETL流程及性能，推动数据及时有效便捷流动任职要求：1、本科及以上学历，计算机及相关专业。2、3年以上企业ETL及数据仓库开发经验。3、精通SQL，熟悉Hadoop/HIVE生态，了解MapReduce计算框架，HDFS分布式文件系统。4、了解流式计算原理。熟悉Flink, Spark streaming, Storm至少一种计算框架结构。5、熟悉常用数据采集、消息转发、数据存储相关组件及技术。6、爱思考，动手能力强，有团队精神。加分项：1、有Flink项目经验优先2、有实时数仓项目经验优先3、互联网大厂经历优先4、有参与大数据开源项目经历优先
岗位职责:1.负责Spark、存储过程等相关开发；2.参与数据仓库建设和规划、模型设计和优化工作；3.负责各产品模块的ETL设计方案，指标体系建立和落地；4.熟悉大数据开发流程，能够跟进数据项目从需求分析到报表展现的完整流程；5.对数据敏感，在数据算法模型落地有实际应用经验；6.参与大数据应用相关的运维支持等。任职要求:1.3年以上的大数据开发经验，熟悉大数据计算平台常规架构和相关产品组件（Hadoop、Hive、Spark等）基本原理，具备海量数据处理、性能调优经验；2.熟悉MPP，Hive数据仓库生命周期及各类建模理论，有实际数据仓库项目建设经验；3.具备大型数据仓库架构设计、模型设计、ETL设计的相关经验；4.熟悉Linux/Unix环境以及常用命令，有Shell、Python等脚本编程经验；5.有Spark Scala、java编程经验者优先；6.熟悉时序库相关技术和开发者优先；7.有华为、腾讯、CDH、HDP大数据平台经验者优先；8.工作认真负责，有良好的分析、沟通技巧，有强烈的学习/技术研究能力和良好的团队精神。
岗位职责：1、负责基于hive或者spark技术的大数据平台需求分析、设计及开发工作；2、负责基于datax、HQL、传统ETL的大数据平台数据抽取、清洗、转换、加工等入仓的开发；3、负责使用Dolphinscheduler（海豚调度）批量配置跑批调度任务。岗位要求：1、能熟练使用hdfs/kudu、hive、impala、yarn、Tez/spark、hbase、sqoop、flume、datax等大数据基础组件，有CDH/CDP平台使用经验，熟悉基于Cloudera Manager的平台使用管理；2、具有airflow/azkaban/xxl-job/Dolphinscheduler等一种基几种调度工具的开发使用经验，有Dolphinscheduler使用经验优先；3、具备海量数据采集、加工、分析处理等数据平台的开发能力，并有具体的构建海量数据存储、离线/实时数仓等项目实施经验；工作地点：广州天河区5号线动物园站（新达城）工作时间：8:30-11:30  1:30-6:00    双休  福利： 五险一金，餐饮补贴，专项培训，季度奖金，年终奖，绩效奖金，双休法定节假日带薪年假
岗位要求：1、统招本科及以上学历，计算机等相关专业，3年以上数据开发工作经验；2、熟练掌握SQL使用，熟练使用Hive等工具进行数据计算和处理；3、熟悉数据仓库领域知识、管理技能和数据仓库模型设计方法论，包括但不局限于：元数据专业知识管理、数据质量、性能调优等； 4、熟悉Scala/shell/python的使用；5、具备良好的文档能力、沟通能力和团队精神，拥抱开发规范化；6、业务理解能力强，对数据敏感，有房地产/房地产金融行业经验者优先。岗位职责：1、负责基于Hadoop生态的海量数据平台建设和维护；2、参与大数据平台的数据构架设计、完成从业务模型到数据模型的设计和开发；3、基于海量数据的数据仓库，为业务搭建通用的查询和分析解决方案；4、管理并优化存储&计算资源利用效率、监控并维护例行ETL任务；5、梳理整体业务指标，进行可视化报表开发；6、将数据维度的方法和经验进行抽象和沉淀，建设数据应用产品，实现业务支持的规模化和快速横向扩展； 7、忠诚于研究院的事业，完成研究院安排的其他工作。
岗位职责：* 负责核心产品的开发* 使用Java/Scala进行程序开发、数据处理。* 根据产品需求负责产品功能模块功能的设计、开发、部署、调试、故障分析和排除等* 对已上线系统进行定期巡检，持续改进服务端架构和优化，增强系统稳定性* 严格测试，及时维护，保证产品服务器稳定运行* 协同相关人员完成平台的测试工作，并持续对其进行优化。任职要求：* 计算机相关专业，扎实的Java/Scala基础，有自主阅读开发文档的能力* 有CDH、HDP等大数据管理平台使用的相关经验* 对Hadoop、Hive、Spark、Flink等大数据组件熟悉，有单个或多个组件相关的开发经验* 拥有Mysql、MongoDB或相关数据库开发经验* 熟悉Linux，能动手调试和解决Linux中遇到的各种问题，会编写shell脚本优先* 具备良好的git代码管理，代码风格，解决问题的能力以及团协作能力* 有良好的代码开发规范习惯，以及需要对开发思路清晰，能处理一定的项目上问题，并提出开发建议* 满足以上条件，有spring开发经验者优先
岗位职责：1、负责各种网络数据的采集、清洗、整合工作；2、负责大数据的分布式存储和管理工作；3、负责大数据项目的开发、维护工作；4、负责大数据平台各组件的性能优化工作；5、负责部分设计、开发文档的编写工作。任职资格：1、本科计算机相关； 　　 2、3年以上相关工作经验；3、熟悉Hadoop、Spark、Storm、ElasticSearch、Neo4J、Kafka等框架组件，深刻理解分布式数据处理技术原理；4、熟练掌握Java、Python、Scala、C++等语言中的一种；5、熟悉Linux系统，了解Shell脚本语言；6、具有较强的学习能力，有团队观念，能独立解决问题；7、有海量数据存储处理项目经验者优先；8、具有数理统计、机器学习、自然语言处理背景知识及算法者优先。
1.教育部批准的高等学校，计算机、数学、电力电气、工程类、通信、自动化等理工类相关专业本科及以上学历。2.掌握计算机原理、网络技术、数据库等相关知识。3.有扎实的计算机理论基础;熟练Java、Python服务端编程，有良好的编码习惯。4.懂得规划及技术架构。5.具备数据中心设计及开发实施。6.熟悉大数据各开源组件集成开发能力。7.数据存储规划能力。8.深入理解MapReduce，深入理解Lucene/ElasticSearch/Solr等，有Hadoop/Hive/Spark/Storm/Zookeeper 等相关开发经验或从事分布式相关系统的开发工作经验。9.熟练使用Flume/Logstash等大数据组件接入文件数据、消息（Kafka/MQ）数据。10.熟练SQL开发，熟悉常用的关系型数据库、非关系性数据库和数据仓库，具有SQL性能优化经验。11.熟悉至少一种实时计算引擎 Storm,SparkStreaming, Flink, 对hadoop生态其他组件有一定了解。
岗位职责：1，参与公司数据中台的开发，包括模型开发、设计、优化等；2，参与公司业务离线数仓及实时数仓的开发建设；3，负责数据治理及数据质量监控体系建设；4，支持业务团队的数据需求及数据建设工作。任职要求：1，良好的逻辑思维能力及团队沟通能力,具备抽象业务模型及构建数据模型能力；2，有较为丰富的数仓领域知识及实践经验，包括但不限于数据治理、性能调优等；3，熟悉Java 或Scala 或 Python 开发，善于分析系统性能，存储瓶颈，并持续优化；4，熟悉Haoop/Hive/Spark/Flink 等大数据开发技术，有实时数仓建设经验者优先；5，熟悉阿里云相关大数据技术组件如DataWorks、MaxCompute使用者优先；6，具有面向对象的分布式系统设计与开发经验者优先。
岗位职责：1、负责大数据相关开源组件的配置、封装、部署及性能优化，构建海量数据存储和计算平台；2、负责基于Hadoop/Spark生态系统的研发、集群调优和运维；3、研究跟进大数据领域的新技术，能够做技术规划。任职要求：1、计算机或相关专业本科及以上学历，具备5年以上大数据开发工作经验；2、熟练掌握Java开发语言，熟悉Linux环境和命令；3、熟悉Hadoop/Spark生态的大部分大数据技术，具有相关开发、调优和运维经验；4、深刻理解大数据处理(流计算、分布式计算、分布式文件系统、分布式存储等)相关技术和实现方法，对开业项目有源代码贡献者、有架构设计经验者优先；5、有日增量100GB以上，总数据量100TB级别数据规模的大数据平台架构设计和落地经验者优先；6、有MPP、小文件存储、时序数据库、图数据库经验者优先。相关技术要求：1、图数据库：Nebula Graph2、小文件：seaweedFS、minIO、Ceph、GlusterFS、fastDFS……3、OLAP：clickhouse4、组件调优、源码改造
岗位职责：1、负责基于Hadoop的大数据基础平台的建设和开发运维；2、设计开发大数据平台相关的核心系统；3、协同数据分析师开发、优化数据产品和业务；4、跟踪技术社区发展动态，持续优化大数据平台的业务和技术。岗位要求：1、编程基本功扎实，熟悉常用数据结构，熟悉Linux系统和Shell脚本；2、熟练掌握Java服务端开发；了解Python/Scala更佳；3、熟悉Flume/Kafka等数据采集和传输技术；4、熟悉Hadoop/Hive/Spark/HBase等大数据存储和计算系统，了解背后架构和工作原理；5、掌握Flink/Kylin/Presto/ElasticSearch/Redis等等一种或多种系统的优先；6、性格乐观积极，具有主动分析和解决实际问题的能力和态度。提示：公司实行全面禁烟制度。
1.具备数据脱敏、数据隐私计算等数据安全方面的软件开发经验2.掌握计算机原理、网络技术、数据库等相关知识。3.有扎实的计算机理论基础;熟练Java、Python服务端编程，有良好的编码习惯。4.深入理解MapReduce，深入理解Lucene/ElasticSearch/Solr等，有Hadoop/Hive/Spark/Storm/Zookeeper 等相关开发经验或从事分布式相关系统的开发工作经验。5.熟练使用Flume/Logstash等大数据组件接入文件数据、消息（Kafka/MQ）数据。6.熟练SQL开发，熟悉常用的关系型数据库、非关系性数据库和数据仓库，具有SQL性能优化经验。7.熟悉至少一种实时计算引擎 Storm,SparkStreaming, Flink, 对hadoop生态其他组件有一定了解。
工作描述：使用 Pandas，Numpy 对数据进行分析与挖掘根据业务需求编写复杂的 SQL 语句使用 Sklearn 建立机器学习模型负责使用 HiveSQL 编写基于大数据平台的数据分析参与项目讨论，明确项目任务，参与初步数据指标制定和规则选择
岗位职责1、负责平台用户画像的构建及分析，积极推动用户行为数据的完善；2、负责平台日志等数据的清洗和结构化；3、完善各种算法模型的统计分析、指标体系；职位要求1、计算机相关专业，本科及以上学历；2、熟练掌握大数据相关技术；3、熟练掌握java/python等编程语言中至少一种，熟悉Linux；4、良好的逻辑思维能力和数据敏感度，能结合相关领域知识完成特征工程等工作，挖掘有价值的数据，发现有价值的规律；5、良好的业务理解能力、沟通和团队合作能力，做事细心，主动性强；6、有爬虫经验者优先；7、有智能推荐项目经验、丰富的算法独立实现及调优经验者优先。
岗位要求：1.全日制本科以上学历，计算机相关专业，两年以上数据分析经验；2.SQL能力强，掌握并熟练应用Hive、Python等大数据开发工具；3.比较好的业务逻辑和业务数据理解能力，较好的沟通和表达能力。岗位职责：1.基于大数据平台对业务数据类需求进行沟通、开发及优化上线等工作；2.协同业务部门推进公司数据化运营，并承担相应的数据统计、分析和报表开发工作。
岗位职责：1、开发Hadoop大数据计算平台。构建高效稳定的计算平台,为业务提供大数据分析所需的海量计算服务2、开发ETL工具3、参与数据仓库、机器学习平台的建设4、参与图数据库等技术预研任职要求:1、3年及以上工作经验，计算机相关专业本科及以上学历。拥有大数据项目架构/开发/调优经验优先2、熟练设计数据模型、数据仓库等3、熟悉大数据处理框架(Hadoop/Hive/Spark/Presto)相关技术4、了解流式计算引擎，熟悉Kafka/Storm/SparkStreaming/Flink等相关框架5、能熟练使用JAVA及JavaScript进行Web项目的开发,有Spring Boot, mybatis, elementU使用经验者为佳6、具有用户画像、推荐系统等相关经验7、熟悉各类大数据组件的开发，有较好经验者优先
职位描述：1、负责 Hadoop 集群、数据分析平台、计算平台维护和开发；2、负责公司海量用户行为日志数据收集、ETL；3、支持实时数据报表、离线数据报表、交互式数据分析等多种数据应用；4、参与数据分析平台的数据开发和调优。岗位要求：1、熟悉分布式系统的基础理论知识，2 年以上相关工作经验，计算机、统计学、数学等相关专业本科及以上学历；2、熟练掌握Java编程，熟悉Scala语言，有扎实的开发功底，熟悉Shell脚本，有 Python 语言经验优先；3、熟悉 HDFS, Yarn, HBase, Kafka, Zookeeper 等基础组件；4、熟悉 Spark/Flink/Hive/Kylin/Druid/Presto 等开源产品；6、有大数据分析与数据仓库设计及开发经验，用户画像建立及用户生命周期分析经验者优先；7、有数据挖掘、机器学习、推荐算法、人工智能、数学建模项目经验者优先；8、良好沟通和团队合作能力，具备很强的问题分析及解决能力。
岗位要求：1、熟练使用Linux操作系统，能熟练编写脚本2、精通Java/C++/PYTHON/GO其中至少一门语言，有两年以上实际项目开发经验；3、熟悉Hadoop、Spark、Kafka生态等相关技术；4、熟悉Oracle、MySQL或PostgreSQL等关系数据库技术；5、具有一定的技术钻研精神，对大数据领域相关技术有浓厚的兴趣；6、工作主动性强，具有良好的团队意识和沟通能力。工作职责：1、参与公司大数据产品设计和开发；2、大数据软件相关组件配置和搭建,能解决软件遇到的技术和调优问题；3、日常业务数据ETL处理和分析。
上班时间：大小周，不能接受的请勿扰工作职责：1、负责离线计算、实时计算ETL全链路作业&脚本开发；2、参与数仓治理，数据模型建设，提高数仓复用率，降低数据平台使用门槛；3、参与取数平台工具、算法工程化、实时特征工程等技术体系建设和研发；4、负责数据可视化分析平台Finebi设计和开发；任职要求：1、本科及以上学历，计算机相关专业，3年以上大数据平台相关工作经验；2、熟悉Python/SQL/Java ，具备良好的编码习惯和数据基础；3、熟悉华为云或阿里云等商用大数据平台产品使用;4、熟悉Hadoop、Spark、Sqoop、Flink、YARN、delta，kafka，redis，Finebi等大数据平台技术栈；6、熟悉数据仓库产品，对数据处理、维度建模、数据质量，数据分析等有深刻认识和实战经验；
1、负责ETL后端开发、维护以及相关文档的书写；2、负责数据加工、清洗、转换，为下游系统提供数据接口；3、对仓库的数据进行质量检查。1、掌握SQL语言，至少熟练 使用过一种数据库（基础技能）；2、熟悉ETL的概念和流程，至少熟练使用过一种ETL工具；3、至少熟练使用过shell，python等一门脚本语言；4、系统学习过数据库原理，掌握规范化理论原理（重点技能）；5、掌握三范式建模或者维度建模理论一种，具有金融业务相关的数据建模经验（重点技能）；5、对数据标准化有一定的经验；
技能要求： 1、熟悉BI工具（QBI、永洪等），有数据分析经验，对美的家用业务有一定了解。有审美力、UI、美术功底优先。 1、熟悉Hadoop、HBase等分布式计算平台开发，3年以上hadoop使用经验，有大数据应用系统开发经验 2、熟悉Kettle 等ETL 工具的使用和开发；具有一定数据模型和数据架构基础，熟悉hadoop\hive和常用数据库 3、熟悉SQL/HQL，有较好的SQL性能调优经验；熟悉hive sql的开发 4、熟悉ETL设计、调度、监控、算法等，能够熟练的进行事实表、维度表的开发 5、有一定的分布式开发经验，使用HBase进行过2项目开发、或支撑过HBase高并发项目的系统工程师优先
岗位职责：1、参与相关项目的数据开发工作，包括实体和关系的抽取，数据清洗等工作；2、完成相关脚本代码开发、测试、debug等工作岗位要求：1.计算机、数理统计、自然语言处理、机器学习及相关专业本科或本科以上学历，1年以上工作经验；2. 基于Hadoop的大数据体系有深入认识，具备相关产品（Hadoop、Hive、HBase、Spark、Kafka、ES等）使用经验；3.熟悉Linux开发环境、shell以及Python脚本语言4. 熟悉NoSQL数据库，精通图数据库，如Neo4j、Hbase、JanusGraph等；5. 具备良好的客户服务意识，抗压，能接受客户驻场工作。
1、 三年以上大数据开发工作经验，本科及以上学历；2、 熟练掌握Java、Scala中的至少一门语言；3、 熟悉开源开发框架Kafka、Spark、Hadoop、Storm等，熟悉常见的组件优化设计，有实际项目应用经验；4、 熟悉Oracle、Mysql等常用关系数据库，熟练编写SQL语句；熟悉时序库、elasticsearch等；5、 熟悉Linux环境，能够熟悉使用shell脚本；
岗位职责：1.基于大数据平台对业务数据类需求进行沟通、开发及优化上线等工作；2.协同业务部门推进公司数据化运营，并承担相应的数据统计、分析和报表开发工作。技术要求：1.全日制本科以上学历，计算机专业、数学专业或统计学专业均可；2.两年以上数据开发经验；3.掌握并熟练应用Hive、Python等大数据开发工具；4.熟悉sql数据库查询，熟悉Hadoop大数据框架；5.比较好的业务逻辑和业务数据理解能力，较好的沟通和表达能力。岗位福利：周末双休、五险一金、节日礼品/礼品卡、年终奖、带薪年假、体检、下午茶、每月口罩等福利齐全。
斗鱼海外事业部, Base广州。岗位职责：负责大数据平台运维开发、实时数据计算开发、推荐系统开发相关工作。岗位要求：1、本科及以上学历，3年及以上工作经验；2、拥有互联网行业大数据开发、hadoop集群搭建调优日常运维、fink集群维护开发调优相关经验。3、扎实的计算机专业基础，熟练使用Java或者Go；了解数据库和缓存相关知识，有redis、mysql、hbase等使用经验者优先；掌握网络原理，熟悉TCP/HTTP等常用协议；4、熟练使用kafka，有实时流计算开发经验者优先；5、理解服务的高并发、高可用、可扩展、可维护, 有阅读大型开源项目源代码经历甚佳；6、对技术有好奇心，自我驱动，追求卓越；7、具备强烈的责任心，良好的分析、解决问题能力，及良好的沟通协作意识。
1、负责企业财务模型与估值系统后端开发；2、参与智能投研中台建设，承担后端开发工作；任职要求：岗位要求：1、211全日制本硕或以上学历，计算机相关专业。2、逻辑性强，具有良好的数据敏感度，具有3年以上数据开发工作经验。3、熟练掌握Spark、HIVE、SQL、ETL等工具，有Flink开发经验优先。4、有知识图谱、事理图谱相关经验优先。5、具备强烈的责任感及执行力，较强的沟通协调能力和团队合作精神。6、有互联网或金融行业从业经验优先。
岗位职责:1、辅助研发经理完成数据产品设计；2、辅助研发经理完成数据产品的功能研发； 3、辅助研发经理完成集群环境的搭建；岗位要求:1、全日制计算机相关专业，本科及以上学历，至少3年及以上大数据开发相关工作经验；2、精通 Kafka和 Spark架构，有相关的开发经验；3、精通 Spark Streaming、Flink等流处理的原理，有相关的开发经验；4、精通 HDFS/Hbase/Hive/Hadoop等大数据生态技术， 有相关的开发经验；5、精通Java语言，熟练使用Linux操作系统；6、熟悉数据建模及ETL（Kettle）设计开发，对数据仓库、数据平台、数据分析等有深刻理解，具备一定的海量数据加工处理经验；7、对于分布式集群环境、分布式计算搭建有一定的经验；8、具有较强的自我学习能力，良好的沟通表达能力和团队合作精神；9、熟悉主流的Java微服务技术框架及容器技术；10、了解数据仓库分层建模体系；
岗位职责：1、助力小鹏汽车实现“通过数据驱动智能电动汽车变革”企业愿景， 支撑公司数据平台建设及数据治理工作展开2、负责数据采集、清洗、传输、存储、计算、调度等全方位设计与开发3、负责大数据平台数据仓库的架构设计、开发及相关文档的编写4、持续优化ETL流程及性能，推动数据及时有效便捷流动任职要求：1、本科及以上学历，计算机及相关专业。2、3年以上企业ETL及数据仓库开发经验。3、精通SQL，熟悉Hadoop/HIVE生态，了解MapReduce计算框架，HDFS分布式文件系统。4、了解流式计算原理。熟悉Flink, Spark streaming, Storm至少一种计算框架结构。5、熟悉常用数据采集、消息转发、数据存储相关组件及技术。6、爱思考，动手能力强，有团队精神。加分项：1、有Flink项目经验优先2、有实时数仓项目经验优先3、互联网大厂经历优先4、有参与大数据开源项目经历优先
岗位职责:1. 负责大数据平台的整体设计、开发、部署和运维，选择和整合基于AWS云的大数据技术。2. 负责数据仓库和数据湖建设，按需实现主题库、专题库、lakehouse等。3. 开发大数据处理流程,实现ETL、数据清洗、计算和集成。4. 支撑数据分析，通过数据挖掘、预测分析、运营分析等对数据赋能。5. 与App产品、运营、开发团队深度沟通，在数据埋点、业务分析、建模分析等方面提供支持。6. 跟踪大数据技术发展趋势,提出新的技术方案,并试验验证。7. 规划并实施完整的数据管理职能，如数据治理、数据质量、元数据管理、数据整合等。任职要求:1. 计算机、数学、统计学等相关专业，3年以上数据开发相关经验;2. 精通Java/Scala/Python任一语言,熟悉Hadoop、Hive、Spark、Flink等大数据框架。3. 熟练掌握SQL和NoSQL及性能优化,有数据仓库和数据湖整体搭建经验者优先。4. 了解机器学习和深度学习在大数据中的应用,有实际项目经验者优先。5. 良好的项目管理和沟通能力,能够与业务人员高效沟通。6. 对新技术和开源框架有浓厚的兴趣,有不断学习和实践的动力。7. 具备较强的分析和解决问题的能力,对数据驱动和结果导向具有强烈的责任心。加分项:1.有百万用户App用户行为/用户群体系统建设经验优先。2.有推荐系统研发经验优先。
岗位描述:1、负责数据仓库系统中ETL、流程的优化，及时排除ETL流程故障，监控和优化ETL的性能，形成知识库；2、负责协助对数据仓库系统进行规划、建设，并对各类技术方案的可行性、有效性、完整性进行评审；3、参与数据生命周期的相关数据处理工作，包括采集、加工、存储、共享等；4、参与已上线数据应用开发运维，并定期对程序运行情况进行分析调优；任职资格：1、计算机方向相关专业，本科及以上学历，3年以上相关工作经验； 2、熟练使用相关大数据平台工具进行ETL开发；3、精通SQL，熟练使用各种常用关系型数据库和分布式数据库；4、扎实的JAVA基础，熟练使用dataWorks；5、具有数据中台建设经验的优先，有跨境电商行业数据应用经验者优先；
岗位职责：1. 大专及以上学历，计算机、数学及相关专业；2. 4-6年java后端开发经验；3. 熟悉Hive、Spark、Hadoop；4. 熟悉数据仓库理论，数据仓库建模；5. 有Hive、spark调优经验更佳；
岗位职责1、参与研发领域大数据平台和软件产品的设计和开发工作，提升研发作业和指挥效率；2、以用户为中心，理解用户需求，交付高质量的产品；3、技续学习和引入软件开发和大数据开发新技术，对系统技术架构进行改进和优化，提升海量数据的处理性能和用户体验；任职要求1、全日制统招本科及以上学历，计算机相关专业；2、具备大数据相关工作经验，熟练掌握流式计算、kafka、storm、HIVE、spark、hadoop等大数据开发工具；3、有产品设计、开发经验，具备一定的技术敏锐度和洞察能力；4、业务理解力强；有较强的学习能力，能快速接受和掌握新技术。
岗位职责：1、负责大数据平台相关产品的模块设计、开发，文档撰写；2、参与大数据平台上业务应用的功能设计及架构规划；3、负责优化平台软件的模块结构和流程逻辑。任职要求：1、本科及以上学历，计算机、软件工程相关专业；2、3年以上Java开发经验，1年以上大数据开发经验；3、熟悉虚拟机原理，数据结构和算法等基础扎实，熟悉掌握并应用面向对象的编程思想；4、熟悉Hadoop、Spark等相关开源大数据技术，如Hive、Hbase、Strom、Kafka、Flume、Sqoop、Mahout等框架；5、有通过大数据技术实现离线数据分析（关系分析、碰撞分析、标签分析等）、实时数据处理（数据比对订阅）、非结构化文本/图片数据挖掘（人脸识别、车辆识别、文本要素提取等）、大数据存储（机构化与非结构化）或大数据采集（机构化与非结构化）的项目实践经验；6、有较强的执行力、责任心、上进心，有良好的表达和沟通能力。
AI/大数据工程师岗位职责：1、负责公司大数据平台相关的技术开发工作；2、负责大数据存储系统、分布式计算系统、数据集成、挖掘算法等的设计、研发以及维护、优化工作；3、负责公司智能硬件中智能算法的开发工作；4、配合部门领导进行项目需求分析、设计开发工作；5、负责大数据实施过程中相关技术问题解决。6、完成与工作相关的技术文档编写工作。 岗位要求1. 数据科学、统计、计算机等相关专业本科及以上学历；2、掌握概率与数理统计，线性代数，机器学习，深度学习，运筹优化等建模所需的理论基础； 3、3年以上AI/大数据相关工作经验，有智能硬件的研发经验，解决过实际问题；4. 熟悉Linux系统，熟练使用HIVE/SQL/Python，有Hadoop、Spark等平台的大数据处理经验，并熟练掌握常用的数据分析/挖掘方法及相关算法原理；5. 熟练使用tensorflow/Pytorch/paddle等深度学习框架；6. 具备较强的独立处理问题能力和责任心及良好的主动性。
岗位职责：1、负责用户/资产数据的管理，为数据分析、挖掘等提供强有力的支撑；2、理解公司大数据产品的业务意义与功能需求，编写大数据计算程序，完成数据的：采集、抽取、转换、挖掘；3、参与大数据平台的搭建、开发和维护工作。4、参与新技术选型和调研，解决不断增长的数据带来的存储和计算挑战。任职要求：1、本科及以上学历，计算机、统计和应用数学等相关专业；2、大数据处理、数据仓库、数据挖掘方向2年以上相关工作经验；3、熟练掌握SQL数据库语言 Oracle/Mysql/HiveSQL，熟练应用Linux操作系统；4、熟悉Java语言，有Java开发经验，对数据结构和算法设计有一定的理解；5、熟悉Kafka、Flume、Storm等至少一种以上，有Hadoop开发经验，熟悉Spark编程，有实时抽取分析项目经验优先；6、具备良好的团队合作精神和逻辑思维能力，有较好的沟通交流能力，善于主动思考和行动。
【公司介绍】 NCS集团是亚太和中东地区领先的信息技术和通信工程服务提供商，隶属于新加坡电信集团，业务涵盖了亚太和欧洲、美洲等20多个国家。 【岗位要求】1.Request English Fluent2.Strong development skills in Python (or Java/Scala & willing to learn python) 3.Experience working in Spark (preferably pyspark), Hive, Hadoop and other Bigdata technologies4.Experience in CI/CD & Devops automation using Git (Bitbucket), Continuous Integration (Jenkins), Docker, Kubernetes,Airflow etcOnline Test Details:Hackerrank coding test to assess problem solving skills, using data structures/Collections like Array, Strings, Maps/Sets etc (no Graph, Dynamic Programming kind of questions).【薪酬福利】1、全额缴纳五险一金，试用期薪资不打折；2、带薪年假：10天起；3、带薪病假每年享有14天；4、固定13薪、绩效奖金；5、入职体检、年度体检。
岗位职责：1.负责公司自研数据仓库、大数据平台规划与设计，核心功能开发。2.负责教育领域数据资产梳理，数据模型的设计与优化3.与业务部门共同探讨推进数据价值落地4.负责数仓底层相关技术难题的钻研和攻克5.负责内部数据开发标准规范建设岗位要求：1.计算机或相关专业本科及以上学历2.具备5年以上大数据相关工作经验，对于数据管理领域有较为深入的理解3.熟悉Java，SpringBoot 能独立进行系统设计和开发4.精通Hive SQL,有丰富的Hive SQL性能调优经验5.熟悉数据仓库模型设计 ，掌握常用数据建模方法，具备海量数据加工处理相关经验6.具有较强的分析和问题排查能力，积极主动，擅于沟通,热衷于技术，乐于挑战和突破自我
加入理由：1.我们是一个有抱负，有情怀的技术团队。我们崇尚硅谷和谷歌的工程师文化，信奉技术改变世界的力量。我们从来没有作过市场投放，因为我们相信技术、效率带来的价值最终会让市场认可。2.我们一直致力于运用最新的技术，为人们带来更美好的生活。我们主要的技术栈包括：PHP7、MongoDB、ElasticSearch、Symfony、GoLang、VUE、React（Native）、Bootstrap、Ubuntu等。我们还致力研究：大数据处理、人工智能推荐、图像搜索、自动翻译、微服务架构。3.我们的研发中心成员经过严格筛选，只为缔造一个志同道合，合作无间的团队。如果你觉得渴望在团队里面一起做点事情，那加入我们，试着一起创造出伟大的产品。职责范围：1.负责对上游数据进行接入、清洗、加工、转换等数据处理程序开发。2.通过大数据分析平台，实时挖掘相似商品关联度，价格优势等商品潜在价值。3.通过用户行为分析，挖掘用户偏好，推动产品改进和运营活动优化，实现推荐算法。任职要求：1.统招本科及以上学历，计算机或数学相关专业优先。2.具有电商相关平台数据挖掘/推荐算法/数据清洗开发经验；具备行业内的用户理解能力与产品思维。3.熟悉linux环境，Scala/Java开发，有Spark/Flink/Hadoop等大数据通用处理平台的开发经验。4.熟悉 Kafka/RabbitMQ 等消息系统，熟悉ETL开发流程，接触过大数据ETL开发经验者优先。5.具有较强的学习能力，良好的逻辑分析能力与沟通能力。特别提示：到西洋汇招聘官网 job.xiyanghui.com 投递简历，应聘成功率提升90%！！！顺便，关注“西洋汇招聘”公众号，你也需要更全面地了解一下你的未来雇主。
工作职责：1. 与产品经理、后端工程师、数据工程师紧密配合，设计数据处理模型，开发大数据分析加工处理程序，提炼数据价值；2. 优化大数据处理链路，提高数据处理效率，实现数据及时上新；3. 搭建大数据处理平台，促进架构与业务分离，提高开发效率；4. 协助管理和控制数据，构建数据治理监控体系。岗位要求：1. 本科以上学历，计算机相关专业，熟悉操作系统（多线程、多进程）、计算机网络编程、数据结构与算法等基础知识；2. 掌握 Linux 环境下常用语言（C/C++/JAVA/Python）开发经验，熟练使用常用 Linux 命令；3. 了解软件工程、敏捷开发等知识，熟悉常用设计模式，掌握常用系统设计原则、方法和常用的系统设计工具，如UML等；4. 深入理解 lambda 架构/Kappa架构/数据湖架构，参加过大规模软件系统开发并独立完成10K以上模块开发维护；5. 深入理解并掌握至少一种主流大数据开发框架，如Hadoop、Spark、Storm、Flink等；6. 深入理解并掌握至少一种数据库，如HBase、ElasticSearch、Mongodb等。
1.计算机或相关专业统招全日制本科及以上学历，具体2-6年或以上同等工作经验；2.掌握Java或Python技术进行数据分析，SQL脚本编写，熟悉常见大数据开发技术spark，hive，Hadoop，Scala等 ，且有多个项目经验；3.熟悉ETL常见数据清洗，抽取及转化常用工具；4.熟悉Linux或windows 系统；5.SQL语句扎实，外资银行项目需用英文进行面试：自我介绍、项目介绍和技术问答。
职责："一、针对实际数据及业务诉求，收集并整理需求说明书，根据开发规范和数据模型设计实现数据开发任务。二、负责数据应用系统开发，配合外部系统开展数据联调、数据任务部署等工作。三、负责数据仓库系统中ETL流程的优化以及运维过程中ETL相关技术问题的解决。四、负责对大数据新软件系统的可行性进行技术评估工作。"要求："1、学历要求：本科或学士学位，通信、计算机、电子信息工程或相关专业；2、专业知识：（1）熟练操作linux，有Java/Python/shell一种或多种开发能力；（2）熟悉hadoop生态圈架构，如flume、kafka、Hive、Hbase、presto、spark等hadoop组件的使用；（3）熟练掌握SQL的开发和调优；熟悉数据库仓库的搭建和开发；（4）熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、任务调度、分析挖掘和可视化等。3、经验要求：从事过数据处理相关工作，有3至5年大数据开发工作经验者优先；4、能力与个性：具备较强责任心，工作细致严谨；同时具备较强沟通及快速学习能力。"
1、统招本科以上学历，3年相关工作经验；2、熟悉flink/spark/hadoop/hbase/hive等分布式计算技术，熟悉其运行机制和体系结构；3、三年以上大型数据仓库架构和建模经验，熟悉大型互联网企业仓库架构解决方案者优先；
1、全日制本科或者以上学历，计算机软件或者相关专业，5年以上大数据开发经验；2、熟悉hadoop生态（HDFS，Yarn，HBASE，Hive，spark，Flink，Kafka，Flume，sqoop，mapreduce等），有排错，调优经验，研究过相关组件源码；3、熟悉掌握mysql，redis，mongo，ElasticSearch，hbase等数据库；4、Java基础扎实，熟悉j2ee相关技术，熟练掌握Spring Mybatis等；5、能独立解决问题，有良好的职业素养，喜欢探索新技术和理念并应用在工作中；6、熟悉网络编程，熟悉Kubernetes，docker优先；7、有ELK、Spark这两块的项目经验；8、有电力行业软件开发经验者优先；9、有网络安全平台类软件开发经验者优先；10、有带领研发团队经验或担任过技术经理优先。
岗位职责：1.梳理数据采集、处理、存储、展现全流程，规范过程文档；2.进行实时数据程序开发，会使用flink、spark等主流流式处理框架；3.通过java语言和springboot框架进行程序代码开发和上线维护；4.负责大数据产品其他相关平台系统、组件的开发、迭代及业务支撑；任职要求：1.本科及以上学历，计算机或数学相关专业，1年以上大数据平台项目实际开发经验，具备专业的职业素养，热衷技术创新；2.能够根据需求转化为实际的开发方案，熟练使用spingboot进行大数据流式开发；3.具备较强的学习能力，熟悉Doris、HAWQ、CK等MPP或者列式数据库优先；4.了解ElasticSearch、流处理性能优化的优先，有成熟的数据应用开发项目经验优先；5.工作态度积极认真，能承受一定的工作压力。
岗位职责：1、基于Hadoop、Spark大数据技术框架分析、设计和开发应用程序；2、负责业务数据的采集、存储、清洗、分析和发布程序开发；3、在线和离线海量数据分析平台的开发；4、大规模数据分析、数据挖掘和机器学习算法的实现；5、研究大数据前沿技术，用最合适的技术解决业务问题。任职要求：1、本科以上学历，计算机、数学相关专业，具有3年以上工作经验，2年以上基于Hadoop/Spark大数据开发经验；2、理解分布式系统概念、思想，扎实的编程基础，熟悉Hadoop(HDFS/MapReduce/Hive/HBase)、Spark、Kafka、Flume等类框架两种以上，至少有1个以上成熟项目经验；3、熟悉Java、python、scala至少一种开发语言，熟悉SQL开发和调优，熟悉Linux操作系统；4、能独立开展离线数据分析、流数据计算、海量数据实时查询等相关应用的开发工作；5、能独立分析和解决问题，有较强的书面与口头沟通表达能力；6、工作踏实，良好的团队工作和协作能力；7、熟悉Hadoop、Spark、Kafka、Flume的部署，有系统调优经验者优先考虑；8、熟悉SPSS Statistics、SPSS Modeler、R语言等数据分析和数据挖掘工具者优先考虑；9、有排污处理、环境监测行业经验者优先考虑。
岗位职责：1、负责大数据平台相关组件的设计和开发工作；2、负责医疗相关的数据仓库的模型标准制定和数据处理；3、负责大数据平台的日常管理与维护；4、参与大数据平台的设计和开发工作；5、参与研究大数据管理和分析新技术，应用于实际商业场景；任职要求:1、全日制大学本科及以上学历，计算机或相关专业；2、具有3-5年以上大数据平台建设和数据管理的经验；3、扎实的Java编程基础，熟悉常用设计模式、具有良好编程习惯，能使用shell,scala、python,C/C++等开发语言中的一种；4、熟悉Hadoop/Hive/Spark/Kafka/HBase/Kylin/Greenplum/Clickhouse等大数据技术，能独自部署开发5、熟悉Spring, Spring Boot, Spring Cloud, MyBatis等Java开发框架优先；6、熟悉linux常用命令，有实际CDH或HDP或apache版本的hadoop部署及开发经验者优先;7、熟悉面向数据仓库和数据集市的数据建模技术和工具；8、熟悉大数据平台技术的应用和开发，对大数据平台技术有深入的认识和理解；9、熟悉分布式系统概念、架构，有大规模分布式系统设计、实现、部署等经验；10、思维清晰敏捷，逻辑分析能力强，具有良好的语言和书面表达能力和沟通能力。
岗位职责：1、整合公司全域海量数据，建设公司核心数据中台，进行游戏内和平台化数据体系化建设。2、通过数仓模型、实时/离线数据开发、数据服务等方式建设全站的数据能力，以数据＋产品的方式提供丰、稳定的数据服务赋能业务，探索数据本身的增量价值。3、深入理解业务场景，了解业务痛点，为各业务线提供数据驱动解决方案。岗位要求：1、有较为丰富的数据仓库研发经验，熟悉数据仓库、数据体系和数据价值的建设及优化，游戏行业加分；2、熟悉大数据架构，具备实时或离线数据研发能力，熟Hive,Kafka,Flink,Presto,Impala,ClickHouse等相关技术并有相关开发经验；3、具备快速学习能力、跨团队沟通协作能力，有较强的逻辑思维能力和解决问题能力；4、本科及以上学历，5年以上数据研发经验，有数据质量管理，元数据管理等数据治理实施经验者优先，有游戏内数据建模经验优先。
主要职责：1.负责设计、开发数据库系统和数据库应用软件；2.负责数据应用项目的需求分析，分析项目的应用场景3.设计与评审项目开发方案，优化计算任务的性能，4.负责大数据平台的规划升级、平台维护和优化，解决项目开发过程中的重大技术问题5.负责数据采集、数据存储、数据查询、数据计算等基础平台开发;6.参与公司ERP系统数据分析，智能提示，完善项目智能一体化开发；7.和其他部门或团队沟通、资源协调并落实工作。打通原有数据孤岛，建立融合数据体系；要求：1、本科及以上学历，计算机相关专业，熟练掌握Java/Scala/Python的一种或多种语言。2、两年以上大数据平台建设实施经验，有专业的计算机素养，熟悉网络编程、操作系统、基本数据结构和算法；3、具备良好的模块化设计能力，能够对复杂流程抽象和简化，有一定的产品思维；有数据仓库、元数据管理和治理的开发经验优先 ;
工作职责:1. 负责数据仓库及BI项目的系统与业务系统的接口设计和确认工作；2. 协助设计数据仓库的模型结构、ETL流程及mapping逻辑；负责应用分析模块的模型和展现设计3. 实现大数据分析计算需求，支持海量数据挖掘任职资格:1. 精通至少一种主流关系数据库，精通SQL编程；2. 2年以上大数据相关工作经验，熟悉Hive/Spark/Flink/PG以及云数仓Maxcompute中的一种或多种3. 熟悉主流数仓建模理论，2年以上DW/BI项目实施和开发经验；4. 具备良好的数据分析能力和学习能力；5. 有金融数据仓库、数据挖掘、互联网行业项目经验优先。
岗位职责：要求熟悉阿里云oceanbase 数据库1、负责离线/实时大数据存储/计算平台的设计开发和维护工作2、负责设计基于大数据的各种实时、离线计算，ETL流程设计和开发3、运用合适的技术方案支撑公司各种数据处理场景 任职要求：1、1-3年大数据项目经验，精通Java/Python/Scala语言的一种或多种2、精通Hadoop生态圈，具备较丰富的大数据平台构建、维护及调优经验，有超大数据量级下的大数据集市相关经验3、具备丰富的Hive、Spark等大数据处理项目经验，具备一定的数据挖掘经验4、熟练使用MapReduce、HDFS、Hbase、Redis、Kafka5、至少熟练使用storm、spark、flink的一种6、良好的逻辑分析能力、分析问题和解决问题的能力，对数据敏感，良好的沟通能力
岗位职责1.负责公司数据仓库建设，包括数据采集，数据清洗，报表制作，完成数据指标的统计和多维分析。2.数据治理，打点管理和打点规范设计，元数据管理，质量监控。3.解决业务人员在仓库中使用遇到的问题，协助业务发现问题。4.负责公司BI系统模块建设，报表系统和自助分析系统的设计和开发。岗位要求1.计算机相关专业本科及以上学历，有1-3年数据仓库和ETL工作经验。2.熟悉SQL，shell等相关技术，有海量数据处理工作经验优先。3.熟悉hadoop/hive/hbase/kylin/presto/阿里云相关套件等大数据优先。4.熟悉java/go等一种编程语言优先。5.逻辑清晰，对数据敏感，良好沟通能力和协作能力
【职位诱惑】周末双休、五险一金、年假、项目奖金、年终奖【岗位职责】1、通过ETL、Python、SQL脚本等方式实现离线/实时数据采集2、负责实时和离线数据清洗、落地数仓3、基于MaxCompute+Flink+DataWorks开发实时/离线数据服务4、使用Quick BI和DataV等工具开发数据应用报表【任职要求】1、必须有大数据相关经验，熟悉并曾经进行大数据批量清洗2、熟练使用SQL、Python等脚本编程3、熟练使用MaxCompute+Flink+DataWorks大数据平台4、熟练使用Quick BI等报表工具5、沟通能力强，良好的语言表达能力6、必须有大数据实战经验【工作时间】上午：09:30-12:00下午：14:00-18:30
1、 数据模型及报表开发。基于离线数据分析模型设计，业务报表开发，业务洞察数据分析等相关功能的开发    2、根据业务梳理的指标字典，进行指标模型开发，并对外输出数据服务。3、搭建数据仓库，进行数据平台相关功能的持续完善和优化 。4、数据可视化设计开发 工作任务 协助BA进行数据库可视化的设计，不断完善产品、持续改善用户体验    协助对产品进行全面设计，如功能，特性，使用流程，UI/UE，性能要求等    协助进行前端的数据开发。5、领导安排的其他临时性工作 。任职资格 1、全日制本科(含)以上学历，计算机、软件开发等相关专业2、3年以上大数据项目开发工作经验、至少2个以上的数据开发项目经验，有房地产公司BI指标开发经验优先  3、熟悉当前流行的大数据框架、分布式架构、NoSQL数据库技术；:熟悉ETL开发流程，参与数据可视化项目，有地产BI项目从业经验工作经验优先。4、熟悉掌握数据仓库模型设计方法论，有分布式数据存储与计算平台应用开发经验，在大数据资产管理与治理有成功产品化经验。4:熟练掌握Java、.NET、Python语言中的一种。  5、形象良好，沟通能力强，工作积极主动，具有良好的服务意识仅限全日制本科，学历不符合不考虑。
职责描述：1.能够根据项目需求独立完成大数据项目的开发，包括需求分析、模型设计、算法测试和优化；2.在深入理解业务的基础上，能够根据业务需求完成数据分析，数据建模工作；3.参与数仓、数据分析、数据应用等系统的开发；任职要求：1.本科或以上学历，有计算机相关专业，有操作系统、数据库等专业知识基础；2.熟悉Hadoop,Spark,Hive,ES,Hbase,Kafka等大数据技术，并能结合业务场景进行架构设计和模型建设，参与或主导过大数据分析项目，有大型互联网分析项目经验者优先；3.熟悉kettle等工具的使用；4.熟悉Java或一门开发语言，多线程编程、消息系统、数据库、分布式系统、对微服务架构有较深的理解，常规框架能够了解其原理并熟练使用；5.熟悉使用linux操作系统命令，具备shell脚本编程能力；6.具备良好的学习能力，沟通能力，问题分析能力，责任心强。
岗位要求1、负责大数据平台数据架构规划和设计，批量及实时数据处理；2、负责数仓平台建设优化，制定元数据体系，监督和落实元数据标准及规范执行；；3、支持实时数据报表、离线数据报表、交互式数据分析等多种数据应用；4、参与数据分析平台的数据开发和调优。职位要求1、本科学历优先，5年以上大数据相关工作经验；2、熟悉Flink、Spark Streaming 语言，有扎实的开发功底；3、熟悉 HDFS, Yarn, HBase, Kafka, Zookeeper 等基础组件；4、熟悉 Spark/Flink/Hive/Kylin/Druid/Presto 等开源产品；6、有大数据分析与数据仓库设计及开发经验优先；7、有数据挖掘、机器学习、推荐算法、人工智能、数学建模项目经验者优先；8、良好沟通和团队合作能力，具备很强的问题分析及解决能力。不接受线上面试哈，异地勿扰！！！公司福利：以人为本，为爱出发，天纵游戏把员工当成公司最宝贵的财富。天纵为优秀的人才提供具有市场竞争力的薪酬待遇、完善的福利体系、灵活的调薪晋升的制度、丰富多彩的团队活动。心动不如行动，快来加入我们吧！【金币掉落】：项目靠谱，年终奖，优秀的你怎么能错过。【装备配置】：购买五险一金，福利假期（年假、婚假、带薪病假等），积极响应国家政策。【日常补给】：提供午晚餐、零食不断，水果、下午茶（冬日温馨，夏日酷爽），让你在忙碌的工作中也能元气满满！【额外奖励】：全勤奖、节日福利（端午节、中秋节礼品）、生日礼物、年度健康体检，让你感受到溢出的关怀！【打怪升级】：灵活的调薪制度、灵活的双轨制晋升通道，让你一路步步高升。【副本开黑】：团队聚餐、团队旅游、员工活动，让你感受到有爱的团队氛围。【BUff加成】：项目奖金、伯乐奖、绩效奖等等让你有明星般的感受。【其他福利】：双休~弹性工作制，加班打车报销。
1、本科以及以上学历， 3年工作经验以上；2、熟练掌握Oracle/Postgres存储过程开发调试，熟悉L调优，熟悉高斯200数据库优先；3、熟悉Hadoop、zookpeer、kafka、Hbase、spark等大数据工具的使用，并且在实际案例中使用过，有华为云工作经验优先；4、较强的学习，能承担大的工作压力；逻辑分析能力强，善于解决问题；5、有电力行业项目实施背景优先。
"工作内容：1、基于Hive， Spark，Hadoop的计算架构，进行大数据开发工作；	2、在分布式集群上进行Hive和Spark数据开发；	3、能够定位数据计算任务的瓶颈并进行性能优化	基本要求：1. 熟悉Hadoop大数据相关技术体系，包括HDFS、Sqoop、Kafka、Spark、Hive、Oozie、Impala、Kylin，ElasticSearch等；2. 熟悉Python、Scala、Java中至少一种，能熟练编写规范代码；3. 熟悉Spark、SparkSQL、SparkStreaming等框架并能实际使用与调优；4. 个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神；5、有强烈的责任心和团队合作精神、具备良好的沟通能力以及快速学习的能力，有独立项目开发经验；"
1、全日制专科及以上学历，至少 3 年以上相关工作经验； 2、了解 flume、kafka、hive、hadoop、spark 等大数据框架，并具有项目实践经验； 3、了解数据治理体系架构，对数据标准、数据质量、信息模型、元数据管理方法有深入研究； 4、有大型项目数据治理、开发经验优先；
1.优秀的业务逻辑理解能力、思维能力及沟通表达能力，对数据敏感2.熟练掌握SQL，拥有Hive、Python等开发技能的优先（大数据技能非强制）1.基于大数据平台对绩效考核与经营分析项目及运管部业务的相关的数据类需求进行沟通、开发及优化上线等工作；2.协同运管部推进公司数据化运营，并承担相应的数据统计、分析和报表开发工作。关键技能点1.业务逻辑理解能力、思维能力及沟通表达能力2.对数据的敏感程度和SQL的掌握程度，是否细心
一、岗位工作范围和职责：1、负责公司大数据平台相关产品的设计，开发、文档撰写和项目改进 ；2、参与公司大数据平台上业务应用的功能设计及架构规划；3、负责优化平台软件的模块结构和流程逻辑。二、专业知识和技能要求：1、两年及以上Java开发经验；2、熟悉Java语言，熟悉虚拟机原理，数据结构和算法等基础扎实，熟练掌握并应用面向对象的编程思想；3、熟悉Hadoop以及相关开源大数据技术，如Hive、HBase、Storm、 机器学习等框架；4、有较强的责任心、上进心以及良好的表达和沟通能力。三、公司福利：1、全年年收入约14.5个月工资，另外约有1.2万左右的现金福利；2、六险一金，员工年度健康福利体检；其中住房公积金按照月度工资总额的12%购买；3、五天7小时工作制。带薪年假、各类法定节假日、有薪假及出差探亲假等；4、各类过节福利、节日礼品、生日礼品、慰问品等；5、差旅费、差旅津贴、业务招待费、通讯补助、用餐补助、保密补贴等；6、每月不定期暖心下午茶，部门不定期旅游、聚餐；7、公司设有健身房、篮球场、乒乓球室、壁球室等休闲设施，并定期组织各类业余活动。
1、本科及以上学历，3年以上大数据开发经验。 2、掌握ZooKeeper、HBase、Hive、Phoenix、Hadoop、Kafka、Impala、Kudu等原理及开发(至少掌握3种)。 3、熟悉storm、flink、spark-streaming开发，性能调优有经验者优先（至少掌握1种）。4、掌握数据采集组件的使用与开发：sqoop、kettle、flume（至少掌握1种）。5、有CDH大数据集群开发运维者优先考虑。6、熟悉linux等操作系统的日常操作，熟练采用maven，svn；7、熟悉Mysql、oracle等数据库开发，掌握clickhouse、mongodb、elasticsearch数据库优先。
1.计算机、软件工程等相关专业本科及以上学历；2. 能独立承担一个WebGIS项目的设计和开发，熟悉VUE，熟悉threejs的编程，能通过调用JSON接口数据生成3D可视化图形；3. 熟练掌握HTML5、JavaScript、CSS3等技术，熟悉至少一种JavaScript框架，如React、Vue、JQuery、Dojo等，熟练使用至少一种当前流行的前端UI框架，如AntDesign、ElementUI、Bootstrap等；4. 了解GIS理论知识和基本原理，1年以上WebGIS相关开发经验，熟练掌握ArcGIS JS 3.X API开发技术；有ArcGIS JS 4.X版本开发经验,有和三维GIS开发经验者优先；5. 具有较强的学习能力和沟通能力，责任心强，敬业，善于团队协作。良好的编程规范及撰写技术文档能力。
工作职责：（python、java）1、参与分布式爬虫平台架构、开发工作(如任务调度、多样化抓取、负载均衡、海量数据解析与处理、全链路追踪、指标监控及报警等）；2、根据公司各个业务需求，爬取全网海量来源的数据，解决各类反爬问题；3、参与爬虫平台架构演进、稳定性治理及性能调优。职位要求：1、熟悉爬虫工作原理，二年以上爬虫工作经验，技术扎实，有较强的逆向分析能力；2、熟悉常见的反爬方式, 有JS混淆加密、动态库加密、滑块验证、验证码过虑等工作经验优佳；3、自我驱动，执行力强，有攻坚精神，对学习有热情，追求技术进步；4、有app逆向经验者优先；5、熟悉spring boot ,spring cloud等相关技术者优先。公司潜力：1、年轻活力、学习型团队，业内黑马，三年来每年三倍增长！ 2、其他福利：五险一金+带薪年假+餐补+节假日福利+生日会+免费零食+公司团建+部门团建+完善的培训+绿色办公3、工作时间：朝九晚六  双休 4、工作地点：广州市黄埔区彩频路7号广东软件科学园C栋402-1  （交通便利：地铁21号神舟路站B出口500米到达公司）*基层也有机会成为奋斗者，成为事业合伙人
职责：1.负责数据平台能力的建设2.负责企业运营数据的开发工作3.负责企业音视频数据开发、分析工作职位要求：1.本科及以上学历，计算机相关专业2.具备3年以上大数据开发工作经验，能独立进行系统设计和开发3.熟悉hadoop/hive/hbase/sqoop/flume/flink/kafka/olap如doris开源大数据技术4.熟悉数据仓库模型设计，掌握常用数据建模方法，具备海量数据离线计算经验5.具备海量数据实时计算开发经验优先6.具有数据挖掘经验优先7.具有良好的学习能力、问题排查能力、沟通能力
岗位职责:1、参与大规模数据快速查询系统的架构设计和开发；2、大规模数据挖掘和分析算法的实现；3、海量数据分析平台的开发，包括离线计算和实时计算；4、负责客户画像、精准营销等业务模型的数据实现。任职资格:1、本科及以上学历，计算机相关专业，两年以上数据分析类开发经验，熟悉Java,Linux；2、熟悉Hadoop大数据处理系统的开发,搭建及部署者优先；3、熟练地处理数据模型、数据ETL以及存储管理；4、熟悉HDFS/Hive/MapReduce/Kylin/HBase/ES，能独自进行相关工具平台的选型和开发部署；5、熟悉分布式系统概念、架构，有大规模分布式系统设计、实现、部署等经验；6、有过客户画像、精准营销、数据中台等项目实施经验者优先。福利待遇：1、双休、法定节假日及福利，享有婚假、产假、陪产假及带薪年假；2、购买五险一金、定期培训、完善的晋升机制、年终奖及每年享有两次调薪机会；3、各种补贴：餐费补贴、通讯补贴、电脑补贴等；4、年度体检、年度旅游、每周有足球、篮球、羽毛球体育活动，丰富员工的业余生活；5、员工生日会、员工周年礼物，员工结婚、生育礼金，零食任吃、员工活动金。
大数据工程师岗位职责：1.负责星环私有云平台、星环大数据平台运行保障及维护，给应用开发的厂家提供技术支持；2.负责对基于星环私有云平台、星环大数据平台进行巡检、问题排查，协助解决技术问题；3.完成领导安排的其他工作任务；岗位要求（一年及以上工作经验）： 1.了解Hadoop生态环境，有以下一种或多种大数据技术使用经验者，如Flume、Kafka、HDFS、Hive、MR、ElasticSearch、HBase、Spark等；2.熟悉Linux操作系统，了解Linux Shell编程；3.熟悉MySQL或Oracle等一种或多种关系型数据库或mpp数据库，熟悉SQL语句的使用；4.具有良好的沟通能力及工作汇报能力，具有清晰的思维逻辑，具有严谨的工作态度；加分项：1. 熟悉SQL语句的调优，熟悉存储过程和函数开发者优先；2. 有编程经验者（Java或Python）优先；3. 具有Docker、k8s使用经验者优先；4. 熟悉Weblogic、Tomcat等Web中间件者优先；5. 具有JVM调优经验者优先；工作地址：广州石牌桥
岗位职责： 1、负责数据产品的研发，包括但是不限于数据的收集,转化,存储,展示；2、负责维护大数据基础设施，解决大数据的集成，存储，计算，监控等问题；3、负责实时数据仓库的设计和维护,开发可靠、高效准确的数据集市，并提供技术支持职位要求：1、本科及以上学历，应届毕业生；2、熟悉Linux操作系统，熟悉python或shell脚本语言；3、熟悉Java编程基础，熟悉JavaWeb开发，有扎实的编程能力；4、熟悉Hadoop生态，对于生态组件包括但不限于（HDFS、HBase、Hive、Flink、Presto）有深入理解；5、具有良好的理解能力、高度的责任心、优秀的学习能力，能快速理解业务，用数据解读业务
目前广州、东莞、深圳，广西都有需求哈项目介绍：服务对像：政企客户：政府/金融/电力/公检法等行业大数据项目交付和实施和技术支持；项目地址：华南（广东、广西、海南、湖南等）、西南省份项目（四川、重庆、云南、新疆、西藏）等地；项目价值：对海量数据提供大容量的数据存储、查询和分析能力，通过对海量信息数据实时与非实时的分析挖掘，发现全新价值点，如金融：风险控制、精准营销，公检法行业通过大数据研判技术提高破案率。【岗位职责】1、 工作年限至少3年及以上，同时拥有一年以上大数据工作经验&两年以上java开发经验。2、 掌握Linux操作系统日常使用和shell等脚本、可使用脚本处理集群开发、运维相关问题3、 熟悉数据库原理,有ORACLE/MYSQL等数据库开发经验，可编写SQL查询语句，具备SQL调优能力4、 熟悉hadoop生态圈组件,如Hive/HDFS/HBASE/spark/flink等5、 至少熟悉Java/Scala/Python中一门开发语言，熟悉程序报错处理以及应用调试6、 良好的沟通能力，需具备与项目干系人沟通和协助能力。7、 有华为大数据方向HCIP认证优先。【任职要求】1、 客户需求分析和大数据规划方案落地设计 2、 华为大数据产品FusionInsight HD规划设计、部署安装、运维管理，故障处理3、 协助客户或伙伴解决华为FusionInsight HD开发支持和性能调优问题4、 独立完成大数据项目规划和部署、指导客户或伙伴解决华为大数据产品问题，保证项目成功
职位描述： 1. 负责国家级的通用数据平台和分析型产品； 2. 构建设计良好的数据流、数据仓库、调度系统、查询引擎，数据服务、分析系统、流程规范，数据工具产品，降低数据的使用门槛，保证系统稳定高效运行，以实现数据的价值；  3. 负责平台系统的可用性、容量、性能、监控、发布、安全等运维管理工作，确保系统持续稳定、高效运行；任职要求： 1. 了解大数据处理分析相关的工具框架，如Hadoop生态圈的相关组件，了解Hadoop、HDFS、HBase、Hive、YARN、Spark、Storm、MR、Zookeeper、Kafka、Atlas等组件； 2. 了解大数据处理技术的实现方法，有分布式系统疑难问题定位想法和经验； 3. 扎实的java编程基础，熟悉Python、Scala、Go语言之一，对各种开源的框架如Spring、Mybatis、Redis等有深入的了解； 4. 了解常用存储系统（如MySQL/Redis/MongoDB）操作，深入掌握Sql优化；上班时间：早上：09：00~12：00，下午14：00~18：00，五天工作制，周末双休上班地址：广东省广州市黄埔区光谱中路11号云升科学园交通：广州地铁21号线科学城站A1出口，步行约15分钟
工作职责：1. 负责公司大数据基础平台的整体规划和架构设计，参与需求分析、架构设计、技术决策以及详细设计； 2. 熟悉目前主流大数据离线、实时处理框架下的海量数据集成、计算、分析工作；3. 熟悉大数据生态圈组件hdfs、flume、kafka、hive、spark、hbase、ES、flink、BI工具 ，并进行相关的开发维护工作；4. 持续挑战新的技术方向，攻克大数据量，高并发，高稳定性，易用性等各种技术难点。任职资格：1. 3年以上大数据研发和维护工作经验，熟悉Hadoop、Spark、并有丰富的开发运维经验和机器学习经验； 2. 扎实的Java、Scala、Python语言基础，对JVM运行机制有深入了解； 3. 熟悉列式数据库hbase的设计和开发维护； 4. 熟悉大数据相关组件搭建、应用、优化，如：Hdfs、Sqoop、Hive、Spark、flink，flume等； 5. 对常用调度框架有详细的了解，并熟练使用其中一种调度框架平台； 6. 熟练使用ETL工具进行数据抽取，清洗，转换，关联等操作； 7. 熟练使用Linux Unix等操作系统具备编写shell的能力。福利：1、弹性工作时间，9:00-18:00（9:15-18:15），午休1.5小时；2、隔周双休工作制，法定节日按国家规定；3、五险一金；5、午餐补贴；6、享受节日福利、年假、聚餐、下午茶等等。
岗位职责：1、大数据处理系统的规划、设计和技术选型。2、基于各种大数据框架开发应用。3、大数据平台的搭建、日常维护及调优。4、为售前和售后工作提供技术支持。任职要求：1、数学、统计、计算机等相关专业,本科以上学历，3年及以上大数据相关工作经验。2、熟悉各种大数据框，如Hadoop、Hive、HBase、Spark、Storm、Kafka、Zookeeper、Elasticsearch、Solr等的规划、开发、调优、日常维护和安装部署；3、具备良好的数据敏感度和丰富的数据分析经验；4、具备良好的学习能力和独立分析解决问题的能力；5、具备良好的抗压能力、沟通能力、逻辑思维能力，有独立开展分析研究项目经验；6、具备强烈的责任心和质量意识；7、有阅读大数据框架源码经验者优先考虑。
1. 本科及以上学历，计算机或相关专业，有大数据TA经验；2. 具备开发、部署、调优Hadoop生态环境项目经验；3. 熟悉Java或Python开发（至少其一），具备2个以上大型分布式应用系统设计经验，有大数据量，高并发处理经验；4. 熟悉Oracle、MySql等常用关系数据库，以及MongoDB、Redis等NoSQL数据库；5. 熟悉大数据生态技术：有Hadoop、Zookeeper、HBase、Hive、Flume、Kafka、Sqoop、Spark等实际项目经验，6. 熟悉流式处理技术，有Storm，Flink、SparkStreaming至少一种实现项目经验；职位要求：1.熟悉数据结构和算法；2. 有大数据处理实际开发经验（hadoop、spark,、Flink、ElasticSearch、hive、hbase）；3.了解典型数据挖掘工具，熟练应用各种分类聚类算法，熟悉各种相关性算法，回归算法，了解常用的社交分析模型，具有数据挖掘算法开发经验；4.思路清晰、态度认真、责任心强、有较强的时间管理能力；5.具有良好的开发习惯，思维敏捷、具有良好的逻辑分析能力；非常强的自我学习能力，对新技术有热情；
岗位职责:1、负责数据库产品相关功能的设计与开发;2、负责数据库产品bug的定位及解决;3、负责相关项目的方案设计沟通与评审;4、负责项目的支撑及难点攻关。岗位要求：1.计算机或相关专业本科或以上学历,2-3年工作经验2.熟悉SpringBoot、MyBatis、Shiro、SpringCloud等技术框架3.熟悉MySQL、Redis和其他缓存数据库，熟悉SQL优化4.熟练掌握Linux操作系统的基本命令，熟悉Shell脚本、熟悉Tomcat、nginx等应用服务器5.熟练使用Git、SVN等代码管理工具以及项目管理工具Maven6.有软件开发的整体流程，可以从需求分析、架构设计、流程开发、测试管理、生产运维等多方面整体项目管理经验尤佳。7.熟悉HTTP协议，TCP、IP协议，有基础的爬虫知识，有数据挖掘经验优先
岗位描述： 1. 负责汽车大数据系统的设计、开发等工作 2. 为业务提供数据支持 3. 与产品沟通，完成开发任务任职要求： 1. 5年以上技术开发工作经验，有数仓建设或大数据开发工作经验优先 ；2. 熟悉Spark相关技术，如：Spark Streaming和Spark SQL，有MLlib/mahout开发经验者优先；3. 熟悉Scala语言，对Scala原理、底层技术有深入研究者优先；4. 具备海量数据处理、从0到1大数据平台建设，实时数据处理调优经验优先考虑 ；5. 熟悉MySQL、Redis, 熟悉阿里云数仓产品的优先考虑； 6. 良好的沟通和协调能力。
职位描述 1、负责数据中台数据模型设计及开发；  2、负责数据中台各应用类场景核心代码的开发及测试工作；                                                                                                                                                                                                             3、负责数据中台的框架设计和体系结构优化，负责技术方案的讨论、制定和审核，保障项目技术方案的合理性和完整性；                                                                                                                                           4、负责数据仓库平台、Hadoop大数据平台、数据中台的推广，解决集群运营和数据应用支持中的技术难题。                                                                                                                                                                                       任职资格：                                                                                                                                                                                                                                                                           1、本科及以上学历、计算机相关专业毕业；                                                                                                                                                                                                                                               2、具备3年以上数据领域相关工作经验；                                                                                                                                                                                                                                                  3、精通SQL、Perl、Shell、Python、Java、Scala等开发语言（至少二种）；                                                                                                                                                                                                                           4、精通大数据生态相关组件（HDFS、HBase、Hive、Spark、Kafka、Flink、ElasticSearch等），具备Hadoop集群维护运营经验；                                                                                                                                                                            5、对数据敏感，有良好的沟通协调能力、逻辑思维能力和产品执行力；                                                                                                                                                                                                             6、精通数据仓库、数据中台理论；                                                                                                                                                                   7、有较强的工作责任心和团队合作意识，抗压能力强，具有较强分析问题和解决问题的能力，具备良好的协调沟通能力；8、熟悉阿里产品优先
岗位职责：1.负责基于 Hadoop/Spark/Flink 生态的系统研发；2.负责公司大数据的处理、建模、分析、挖掘及存储工作；3.负责公司项目的大数据模块的功能开发，功能优化工作；4.处理海量数据离线计算、在线计算相关的开发工作；5.负责 Hadoop/Spark 集群调优任职资格：1. 25-35岁，统招本科及以上学历，3年以上大数据开发工作经验；2.具备扎实的计算机理论基础，对数据结构及算法有较强的功底；3.熟悉Java，熟悉JVM，具备优秀的系统问题追查和性能调节优化能力，熟悉常见的面向对象设计模式，具备优秀的系统构架设计能力；4.熟悉Kafka、ES、redis、mysqla等开发技术，熟练使用hdfs、hive、spark、Hbase、Flume、Impala、Clockhouse、Doris等大数据组件5.熟练掌握LINUX常规命令与工具；6.具备大规模云集群性能调整优化经验者优先。
岗位职责：1. 负责ToB视频云saas产品数字化、智能化方向的工程优化工作； 2. 负责公司海量用户业务数据的处理，基于大数据技术建立高效、实时的Data Pipeline；3.负责对接业务方进行业务需求整理，调研用户需求、高质量交付；4.负责各数据处理子系统的架构设计和实施；岗位基本需求 1. 计算机、自动化、电子信息或相关专业学士及以上学历； 2. 具备扎实的业务架构设计和代码开发能力； 3. 熟悉工程领域业界成熟技术， 对以下至少一个领域有深入理解：    1）分布式系统；    2)  Java技术栈和技术生态；    3）大规模流式应用；    4)  深入了解HDFS/Presto/Hive/Spark/Hudi 一个或者多个组件；4. 良好的逻辑思维能力，善于发现和推理不同事物之间的关系和影响，在复杂业务场景下能够分解和抽象问题，提供解决方案； 5. 较好的主动性和求知欲，良好的沟通协作能力；
工作职责 1、整体负责CDP（客户数据平台）的架构设计和技术攻关工作； 2、直接参与数据中台核心模块的开发工作； 3、深入理解、挖掘CDP产品相关的业务需求，和产品团队一起构建CDP产品的平台化能力；职位要求1、深刻理解计算机原理，有良好的数据结构和算法基础，扎实的编程能力； 2、熟悉并行计算或者分布式计算原理，熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案； 3、熟悉Kafka/Flink/Doris/Clickhouse 等实时计算引擎的开发和使用； 4、善于沟通，对业务敏感，能快速理解业务背景，具备优秀的技术与业务结合能力； 5、有大规模实时数仓落地经验者优先
工作职责：交通项目数据治理类项目工作1.需求调研及需求整理2.技术方案、项目方案的撰写3.项目管理工作：项目方案制定、计划跟踪4.技术管理工作：有一定技术底蕴，可以进行技术方案的讨论任职条件：1、3年以上方案撰写经验2、3年以上项目调研工作经验3、5年及以上技术工作背景(有交通项目经验、数据治理项目经验优先)4、有项目管理证书者优先5、大专及以上学历技能要求：1、熟练掌握oracle、mysql、sqlserver等关系型数据库操作2、了解数据仓库、数据治理方法和工具3、数量使用文档撰写工具：word/excel/powerpoint、xmind、visio4、了解软件工程各工作环节的任务，职责，提交物5、有大数据治理经验，了解hive，HDFS、hadoop6、了解云平台、虚拟化的通用技术7、对数据治理工具/平台有一定了解8、数量掌握SQL9、有java开发经验或代码开发（后端/服务端）经验者优先
职责要求:1、本科及硕士以上学历（985/211/GIS专业优先考虑）2、2-3年相关工作经验优先考虑3、有GIS背景公司大数据开发经验者优先；4、有大规模离线计算，实时计算，OLAP数据仓库和海量数据存储经验者优先；5、有Spark/Hadoop/Hive/ES大数据开发经验并能结合具体场景深入使用者优先；6、至少熟练掌握如下一种语言：Java/Python/shell/HiveQL，以及在数据处理过程中完成不同平台功能模块的开发、互调；7、有扎实的数据结构和算法功底，学习能力强，对于新技术、数据应用创新有浓烈的兴趣，敢于迎接挑战；8、具备极强的交付意识与学习能力，有较强的产品理解、沟通、团队协作能力，细致耐心、积极主动；9、能接受短期出差优先考虑10、具有软件设计师、DAMA数据治理工程师、数据开发工程师（CCA Spark and Hadoop Developer）、测绘师、PMP，信息系统项目管理证书优先
工作职责:1.负责数仓模型开发，数据集市开发2.负责海量数据的采集、清洗、处理工作，支持数据开发的技术需求3.负责离线/实时的数据存储和加工处理，保证数据质量，负责数据监控体系的建立和维护4.参与大数据平台架构设计和开发工作，平台服务开发5.协助产品经理进行数据需求，数据流程的梳理6.协助处理其他数据相关事务岗位要求：1.5年以上大数据库开发经验。3年以上建模经验，具备医学或财务方面的从业经历或知识背景优先2.精通大数据框架Spark或Flink等，对大数据相关组件性能以及稳定性优化有相关经验3.精通数据仓库有关领域知识，例如元数据管理、ETL工作流、SQL性能调优等4.擅长逻辑模型分析、设计，较强的抽象、概括、总结能力5.出色的沟通能力，自我约束力强，能够完成安排的任务
岗位职责1.负责知识图谱构建平台的建设2. 负责基于知识图谱的服务和应用平台的开发岗位要求：1.熟练掌握知识图谱的构建和应用等技术，2.熟悉NLP、数据挖掘、机器学习等相关技术3.熟悉知识本体和本体建模，熟悉信息抽取和知识管理4.熟悉知识图谱核心算法，如实体以及关系抽取，实体链接；如：schema matching， ontology design5.掌握Entity Linking, Relation Extraction以及图谱相关算法6.熟悉一种以上图数据库，如Neo4j、JanusGraph、Titan, OrientDB等7.熟悉大数据数据处理方法和优化方法;熟练使用Hadoop、Hive、SQL、Spark进行数据处理和分析8.具有图谱构建，图谱上的应用等实际应用经验者优先9.良好的学习能力、沟通能力、团队协作能力、及分析问题解决问题能力，责任心强公司福利： 1、工作时间：9:00-12:00，13:30-18:00（每月第二周周六9：00-12：00，13：30-17：00）2、五险一金：公司按国家和省市有关规定，为员工购买养老、医疗、工伤、失业、生育、重大疾病，商业意外保险，住房公积金； 3、健康体检：公司每年度为正式员工安排一次免费健康体检，让您的身体得到关爱和呵护； 4、话费补贴：公司将为部分员工发放手机卡及每月补贴不等金额的话费； 5、员工互助金：欧科提倡员工互帮互助的精神，特成立互助基金，员工因病住院，将从互助基金拨出款项补贴员工：如探望金300元、疾病抚慰金500元；6、假期安排：公司为您提供国家法律规定的休息日、工伤假、婚假、丧假、产假及5-10天带薪年假，让您快乐工作，快乐度假； 7、员工活动：公司每周为您提供球类活动，并且不定期为您提供旅游、部门聚会、外部联谊、党员周年聚餐、家庭影院等丰富多彩的娱乐活动，让您在业余时间得到放松和快乐；8、周年庆+年终晚会：公司为了感谢大家在一年里的辛勤工作，特精心准备周年庆表彰大会和年终动人晚宴，让您一同享受欧科的收获；9、生日福利：公司在员工生日为其庆生，公司将陪伴您度过每一个生日； 10、节日贺礼：公司给员工发放端午礼品、中秋礼品、年货等；11、培训：公司将为您提供技术、管理、专业知识、心态等各类培训，公司将为您的成长进行长期投资，为您的职业生涯进行持续充电； 12、良好的办公环境：公司提供4000平米的优美办公环境给您，内设阅览室、培训室、茶水厅、休息室，让你在安静舒适的办公区域工作； 13、年终奖：公司将给员工发放年终奖。
职位描述1、基于Spark、Hadoop构建交通大数据数据仓库，负责交通行业业务数据需求分析以及业务评估，负责领域建模和多维度分析，响应业务系统对数据提取的需求；2、对数据进行资产化管理和服务化，数据规范、数据分析指标体系建设及元数据管理；3、负责为业务方提供OLAP多维分析框架、报表、数据建模分析等服务；4、构建精细用户画像、车辆画像、业务建模分析、业务数据挖掘；5、配合算法工程师，负责预测、推荐等算法在大数据平台的实现；岗位要求：1、熟悉JAVA开发，对springboot\spingcloud有一定经验，有Python,Scala经验；2、精通数据库及数据模型设计，熟悉Kettle、StreamSets等ETL开发工具；3、了解行业内的各种数据仓库应用案例和商业智能（BI）实时动态，有OLAP、OLTP经验；4、熟悉MapReduce、HDFS、Hive、Hbase等Hadoop技术栈，至少两年大数据开发经验；能使用大数据技术建立数据仓库；5、熟悉数据库原理，熟悉关系数据库(mysql,oracle等)，了解Nosql更佳；6、了解linux原理，有linux环境开发经验，了解Bash等脚本语言7、熟悉python，有Tensoflow等算法基础优先；
Senior Data EngineerAccountable:１.负责数据云平台Confluent到Confluent Cloud迁移项目中数据Pipeline的迁移工作２.培训和带领初级开发人员作为一个团队支持集团战略项目Data Mesh３.作为Team Leader管理员工和日常的开发任务进度Requirement:1.全日制本科或硕士计算机相关专业 2.10年左右IT工作经验，期中5年以上从事大数据项目的开发经验3.5年以上JAVA开发经验，具有面向对象分析、设计、开发能力，熟悉多线程、分布式、缓存机制，能对JAVA性能调优有丰富的经验。懂Python、scala更佳。4.5年以上kafka开发经验，对kakfa实时了解，了解kafka的工作机制，能使用kafka中间件进行开发，有在云原生架构上设计和实现融合的kafka实时应用程序的经验。5.3年及以上Kubernetes经验，能运用kubernetes发布、管理、预警应用，能自定义资源尤佳。6.对云服务有一定了解，多年在云原生架构上设计和实现融合的kafka实时应用程序的经验，了解Confluent cloud，懂confluent SMT 开发尤佳。7.5年以上Sqlserver、Oracle等关系型数据库经验，熟悉数据库CDC、存储过程、视图等功能，能对sql进行调优。8.有独立解决问题的能力，善于团队合作，在团队环境中善于沟通和协作。9.较强的书面和口头英语沟通能力，懂粤语者优先
岗位职责：1.负责基于spark，flink的离线/实时数据计算2.负责大规模业务,日志等数据的收集、清洗、入库、分析等工作3.负责数据治理,接口开发等工作, 提升数据易用性及数据质量 4.理解并合理抽象业务需求,发挥数据价值,与业务团队紧密合作任职要求：1、本科及以上学历，数学、计算机科学与技术、信息管理与信息系统相关专业优先，具有大数据相关领域5年及以上开发经验;2、熟悉主流大数据技术，包括但不限于Hadoop，hbase，ES,kafka，redis，hive，zk，sqoop，Doris等；3、具有海量数据实际开发经验,能熟练使用Spark、Flink进行离线和实时数据开发及优化；4、熟悉java,scala或者python编程语言;掌握Jvm GC调优;5、熟悉mysql等主流数据库,熟悉sql语言;6、熟悉linux操作系统，熟悉shell开发；7、熟悉高性能,高可用,高拓展者优先,具有车联网以及营销相关大数据开发经验优先；8、善于学习,积极主动,有团队合作精神；职责描述： 1.负责企业级数据仓库设计,规划,建设,实施,管理；2.负责ETL流程设计及开发,包括数据清洗,加载,转换,建模,对ETL的质量及性能负责3.管理数据的生产、数据应用、数据安全及数据质量，负责数据标准管理、元数据管理等4. 负责报表开发，数据提取等
岗位职责：1、根据业务需求，负责大数据相关的研发工作；2、参与大数据分析平台基础架构、产品技术的规划建设，包括数据采集、数据安全、数据治理、数据质量及稳定性保障体系建设；3、完成上级交办的其他任务。任职资格：1、计算机、数学等相关专业本科或以上学历； 2、较强的开发能力，必须熟练使用相关开发语言（JAVA/Scala/Python/Shell等），熟悉大数据生态，能独立完成并指导初级开发人员完成大数据相关的技术实现和调优；3、具备5年或以上软件平台的研发及架构设计经验，具备良好的行业内技术积累，能独立负责技术架构规划与架构演进；4、熟练掌握Hadoop、Hive、Spark、Flink、HBase、kafka、kylin、Yarn等组件或技术，深入了解并有实际的开发经验，能阅读源码跟踪问题；5、熟悉各行业大数据应用场景，有数据仓库、BI、数据挖掘等方面的开发工作经验优先；6、对前沿认知智能技术有一定理解，熟悉知识图谱、知识推理、深度搜索、自然语言处理、深度学习等领域技术；7、对数据敏感，有较强的逻辑思维能力和问题分析能力，对待工作态度认真、好学勤奋、有毅力和耐心，敢于面对挑战主动解决问题。
岗位职责:1、负责电信大数据项目解决方案技术规划、方案设计并参与核心代码编写；2、负责数据接入、数据清洗、底层重构，业务主题建模等工作；3、完成数据指标的统计、多维分析和报表展现;4、与用户沟通需求，并提出解决方案；与公司其他部门或其他项目组保持良好协作，确保项目良好运转。任职要求:1、本科及以上学历，3年以上大数据项目开发经验；2、精通SQL语言、存储过程，熟练使用HiveSQL； 3、精通Python编程;4、熟悉Hadoop、Spark生态相关技术，熟练掌握Hive、Hadoop、Spark、Flink等开发技能；5、有较强的学习能力，良好的工作沟通能力和解决问题的能力。
工作职责:1.参与大数据基础平台的功能实现；2.数据仓库模型开发；3.支撑数据产品和业务；4.协同数据中台相干工作。任职要求：1.熟悉主流数据库mysql/oracle/db2,其中一种或多种数据库;2.熟练使用linux操作系统，熟悉shell编程;3.熟练掌握java/python/bash，要求其中一种主流开发语言;4.熟悉hive/maxcompute;5.工作积极主动，有良好的沟通能力和钻研学习精神;6.有Flink/Storm/SparkStreaming 其中一种流式计算经验优先;7.有金融行业经验，利为开发经验优先。
职责描述：1.负责公司数据仓库的建设2.负责数据仓库模型设计,开发与管理3.进行数据分析平台的构建,对业务部门提供数据支持服务4.编写和维护项目开发文档能力&经验要求:1.至少熟练掌握Java和一门额外的编程语言(Python,Erlang,Scala,Haskell,Lisp,C/C++等)2.熟练掌握Linux操作和运维脚本编写3.良好的算法/数据结构基础4.拥有本科学位5.具备较多JVM平台的性能调优经验6.掌握下列两类开源生态中的任意一类 (1)Hadoop,Hive,Presto,HBase (2)Kafka,Storm,Spark,Flink7.良好的逻辑分析能力,分析问题和解决问题的能力,对数据敏感,良好的沟通能力跟执行力8.不对自己的技术栈设限,愿意从结果出发选择自己需要的工具9.有公开的内容输出,如技术分享,开源代码者优先10.精通SQL,有较好的SQL性能调优经验者优先11.熟悉BI开发流程,参与过大型数据仓库类项目者优先12.精通分布式,缓存,消息,NoSQL等机制,熟悉Redis,Mongodb等NoSQL数据库者优先13.具有业务分析及建模能力,熟悉电商行业相关业务流程者优先14.对常见的数据分析模型有一定的了解,有海量数据分析项目经验,数据挖掘项目经验尤佳
"1、	大学本科以上学历，5年以上大数据开发经验； 2、	有从事分布式数据存储与计算平台应用开发经验，精通yarn调优，有cdh经验者优先，熟悉Hadoop生态相关技术并有相关实践经验优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm；3、	熟悉Spark原理及底层技术，能对Spark性能进行调优及Spark StandAlone模式均有使用及优化经验，能到底层代码进行优化修改4、	熟悉Java 和 Scala，具有相关开发经验3年以上5、	精通flink底层架构，熟悉clickhouse等数据库工具及其使用。熟悉linux系统并能编写shell脚本"
1、负责公司大数据应用产品的平台搭建、架构优化、技术迭代和开发维护，提供稳定的大数据平台服务；构建数据存储、数据挖掘、数据计算及数据服务于一体的大型分布式数据平台；2、负责构建和维护算法平台，对海量数据进行离线计算、实时计算等分析挖掘；协同数据分析师，根据业务场景设计并实现数据模型和服务模型，并跟进和评估模型效果，确保算法和模型的有效落地；3、负责整理和沉淀技术文档，指导下级开发人员。任职要求：1、计算机或相关专业本科及以上学历，3年以上相关工作经验；2、掌握操作系统、网络、数据结构和算法等专业知识；3、精通Java/Scala/Python 其中一门语言，熟悉Linux/Unix开发环境；4、具备一定的大型分布式系统开发经验，精通大数据平台技术架构设计和Hadoop体系相关技术，掌握Hive、HBase、Spark、YARN、MapReduce等大数据开发技术；5、掌握实时数据分析或离线数据挖掘技术框架，如：Spark Streaming，Kafka，Spark SQL等，熟练掌握常见的SQL/NoSQL数据库原理、数据库设计，尤其对数据存储和查询的原理和优化具备较深入的理解；6、具备良好的团队协作能力和分享精神，具有较强的问题分析能力和解决能力。
岗位职责： 1、参与大数据基础架构和技术体系的规划建设，包括数据采集平台、存储平台、实时流处理、机器学习等方面工作；2、对系统框架相关技术和工具进行培训，指导开发人员开发，并解决系统开发、运行中出现的各种技术问题； 3、组织或参与架构评审工作，为项目实施过程中的架构问题提供建议方案，并制定相应规范4、较好的沟通能力和自我学习能力。任职要求： 1、有5年及以上的大数据架构设计和开发经验； 2、丰富的开发实践、热爱技术、精通数据仓库建模及ETL设计开发；有较为系统的海量数据性能处理经验； 3、熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘； 4、对大数据基础架构和平台有深刻理解，掌握Hive、Hbase、Spark、Streaming、Storm、Flink、es等至少四种数据处理核心组件； 5、大数据企业从事大数据架构开发设计者、或有机器学习项目经验者优先考虑；
岗位职责：1、根据业务需求与架构设计，负责数据应用产品业务建模，完成开发、协助测试以完成上线，并撰写相关设计文档；2、参与规划从数据源到数据应用的整体流程，并参与相关产品的决策；3、参与解决核心技术问题，为技术方案进行决策提供支持；5、积极了解业界发展，研究与跟踪大数据新技术发展方向。任职资格：1、精通GoldenGate For BigData相关理论，具备大型数据利用的生产实战经验；2、掌握数据驱动的理论，有设计并生产上线相关数据驱动的产品者优先；3、掌握常用消息中间件的使用，例如kafka/RocketMQ/Apache Pulsar，有解读相关源码者优先；4、掌握hadoop、spark生态体系相关产品的使用，掌握MapReduce编程或Spark编程；5、了解传统数据仓库理论及相关ETL工具，例如kettle/datastage；6、熟悉Oracle、Mongodb、Mysql数据库的使用；7、熟悉Java语言基础，熟悉Java开发工具和调试工具的使用；8、良好的团队协作精神，有能力对团队在软件设计、实现和测试方面进行指导；9、良好的逻辑分析能力和沟通能力，执行力强、对待工作认真严谨、责任心强、具备出色的学习能力和团队合作精神，有一定的推动能力；10、计算机科学、信息技术或相关领域本科以上学历，具有3年以上数据平台项目开发经验，具有大数据平台应用大型项目设计经验优先；11、能承受一定工作压力
岗位职责：1、参与大数据平台架构的搭建；2、负责对现有的数据进行采集和清洗；3、参与主题建模，用户标题体系和指标体系的构建；4、持续开发和优化公司大数据营销系统任职要求：1、统招本科及以上学历，计算机、数学、统计等相关专业；2、有大数据处理实际开发经验，熟悉java、Python、scala、R等一门或多门编程语言；具备扎实的代码编写能力；3、熟悉 hadoop、spark、elasticsearch、hive、hbase、flume、kafka等至少其中4门技能；4、自我驱动能力强、踏实勤勉，对有挑战的问题充满激情；5、标签体系和指标体系开发经验者优先；
资深大数据开发工程师岗位职责：1.负责广告平台系统整体架构设计；2.参与系统的需求挖掘与分析，设计数据库架构；3.负责底层架构设计、各种技术接口开发，系统核心代码实现；4.负责核心技术问题的攻关，系统优化；5.参与制定设计及实现规范，指导和推动设计、实现及部署工作；6.参加技术评审，对技术方案合理性、架构符合性、项目运作规范性等提供参考意见。任职资格：1.本科及以上学历，计算机相关专业,优秀学历放宽； 3年以上项目开发经验，最好具备大型互联网系统开发相关经验；2.精通Java和GO相关的主流框架，具备实时、离线大数据开发经验，如flink、spark、hadoop开发和调优；3.熟悉常见olap、kv数据库的使用，不限于mysql、Memcache、Redis、Tidb、greenplum、hive、doris等，如有高并发、大数据查询调优经验更佳；4.熟练掌握shell、Python、Perl其中至少一种脚本语言；5.能够快速定位和解决系统中的性能方面问题，熟悉常用的数据分析方法；6.工作认真负责，学习能力强，喜欢在技术领域内钻研；7.能承担工作压力，具备良好的沟通能力和团队合作精神。
车辆网大数据架构体系搭建与优化改进，车联网大数据分析应用，数据挖掘，数据仓库建设，高性能实时数据处理，以上方向满足多项酌情加分
岗位职责：1、负责公司大数据集群的构建，任务调度、监控预警，持续完善大数据平台，保证稳定性、安全性；2、负责集群容量规划、扩容、集群性能优化，参与大数据基础环境的架构设计与改进；3、负责实时数据业务的设计和开发；4、深入研究大数据业务相关技术，持续优化集群服务架构。岗位要求：1、计算机相关专业，本科及以上学历，5年以上大数据开发相关经验；2、熟悉 Linux 基础命令操作，能够独立编写Python、Shell脚本；3、熟悉Hadoop生态圈Hadoop、Spark、Kafka、Zookeeper、HBase的安装与调试；4、熟练spark,flink,kafka等相关技术；5、熟悉多线程编程，有分布式开发经验优先；6、工作认真负责，有较强的学习能力，动手能力和分析解决问题的能力；7、能够利用各种开源监控工具、运维工具，HA、负载均衡软件完成工作任务。备注：该岗位需驻点广州/北京两地，介意者慎选！
岗位职责：1、负责公司业务数据产品及数据仓库的应用架构设计与开发工作；2、在项目开发前期撰写并规范数据库设计文档、系统架构设计文档、数据接口文档；3、参与业务部门的需求调研,需求分析,数据指标开发,BI报表开发,数据分析及数据挖掘等开发工作；4、参与制定团队开发规范、编码规范，跟踪开发过程及时纠正；5、上级安排的其他工作。任职要求：1、通信、计算机、软件等相关专业毕业，本科以上学历，熟悉数据结构和算法；2、精通设计模式、SOA、微服务等常用软件架构思想，善于设计可重用组件和可定制化产品；3、具备优秀的编程能力，1年以上JAVA开发工作经验，对JAVA语言有深入的了解，熟悉常见的数据结构和算法；4、熟练掌握hadoop、spark/flink等大数据技术体系；熟悉IO、多线程，熟悉分布式、缓存、消息等机制；5、具备优秀的业务抽象能力、架构分析能力与设计能力，能积极参与前期设计，审核应用开发的设计方案；6、良好的分析问题和解决问题的能力，良好的工作进度管理与把控能力，抗压能力强；7、有基于华为云DGC，阿里云dataworks，AWS EMR等云平台数据仓库建设经验者优先考虑。
岗位职责：1、理解业务，熟悉业务运营模式，根据业务需求及项目要求进行数据开发； 2、开发、建立数字化的监控预警，优化、完善当前数据任务监控预警信息；3、能从业务目标出发，与产品、算法、运营等团队良好协同，形成较好的数据支持解决方案； 任职要求：1、数学、统计、计算机等相关专业本科及以上学历，1年以上相关工作经验（数据开发、数据模型开发、决策支持等） ；2、熟悉Hadoop、HIVE的基本原理并能够熟练编写HIVE SQL；3、精通SQL，能熟练运用ORACLE/MY SQL/HIVE/PostgreSQL等获取分析所需数据；4、具备良好的沟通能力、团队合作精神及抗压能力 ；5、对数据驱动业务有较好的理解，对证券业务有一定的认识。
岗位职责:负责公司大数据平台开发工作；岗位要求:计算机或相关专业本科以上学历；具体技术要求：1、熟悉JAVA语言，具备SpingBoot+Spring+MyBatis框架的开发经验，具备Spark、Flink大数据开发经验；2、熟悉Linux常用相关操作命令；3、具有较强的学习、沟通能力，严谨、细致、踏实的工作作风和积极主动的工作态度，及较好的团队协作能力；4、熟悉Hive、HDFS、Spark、Flink、Kafka等大数据技术体系。5、具备海量数据传输、计算和存储开发经验优先；
1、基于对业务的理解，应用数据分析、数据分析建模、数据挖掘机器学习等技术，为业务决策提供支持；2、用数据及挖掘模型为业务提供更科学、更精细化的规划方案；3、优化和完善日常数据分析体系，包括但不仅限于指标体系、监控报表、业务分析体系等；4、在海量大数据环境中，进行产品的数据分析，数据抽取、统计、建模等开发；5、应用专题模型开发，辅助产品应用进行数据专题模型开发；任职要求：1、3年以上相关工作经验；2、扎实的计算机及数学基础（数据结构、数据挖掘等），良好的逻辑思维能力，擅长数据分析与建模；3、熟练使用HiveSQL,有大数据开发实战经验，掌握python/shell/SQL，熟悉Spark开发环境；4、具备良好的表达能力、文档写作能力和产品原型表现能力或有运营商数据分析挖掘经验者优先；5、责任心强，做事细致，具备较强的沟通协作能力，善于思考总结，具备较好的表达能力；
职位描述：1、做大数据专业课程建设，视频课程的研发和录制；2、讨论教学相关项目的需求，参与案例设计，完成设计文档以及核心模块编写；3、解决案例开发过程中的实际项目和业务问题；4、参与新技术预研并做技术分享；5、负责项目版本更新以及文档维护；6、带领和培养在线班级的学生完成学习任务。任职要求：1、全日制本科以上学历，计算机、数学或统计学相关专业；2、有3年以上大数据开发经验，有带过3人以上团队经验的优先；3、有数据挖掘、数据分析、数据仓库、推荐算法等开发经验者优先；4、有Hadoop/Hive/Impala/Spark/MPI/HBase等相关经验；5、善于沟通，表达能力强，乐于技术分享；6、具有较强分析问题和解决问题能力。
岗位职责：1、负责开发公司自有与外部客户的大数据平台和数据中台项目，主要使用TiDB或Hadoop架构；2、负责大数据集群运维、调优，保障集群高可用、高性能；3、根据产品应用场景设计高效、稳定、可扩展的底层大数据平台架构及编码实现；4、负责新技术调研，并通过技术沙龙方式分享给整个公司技术团队。岗位要求：1、本科以上学历，计算机或相关专业，2年以上Hadoop架构开发经验；2、愿意学习先进技术与新架构，如TiDB，有基于TiDB HTAP的数据平台开发经验优先；3、精通Java或Scala开发，熟悉Linux/Unix环境，熟悉容器；4、基于Hadoop大数据体系有深入认识，具备相关产品（Hadoop、Hive、Hbase、Spark等）项目开发经验，有Hadoop集群搭建和管理经验，读过Hadoop或Hbase源码或二次开发经验的优先；5、态度端正，有较强责任心，具有较强的沟通表达能力、逻辑思维能力和文档编写能力。
1、负责数据仓库ETL（数据抽取、加载、清洗、转换）处理任务的设计和开发工作，支持日常数据批处理、近实时处理的要求，对新的开发需求和异常情况提供技术支持;2、负责数据仓库ETL调度程序的设计和开发工作，支持对任务的监控和配置管理;3、负责数据仓库部分主题的数据建模工作，并完成相关的开发工作;4、支撑BI业务分析的开发和实施工作;5、参与数据管控平台的开发和实施工作;
岗位要求：1. 计算机相关专业，全日制本科及以上学历，四年以上工作经验；2. 2年以上大数据行业经验，熟悉Hadoop、Hive、spark、flink、kafka、ElasticSearch等常用大数据组件，有实际开发、优化、运维经验；3. 熟悉Java/Scala语言，有2年以上后台开发经验；4. 熟悉Oracle、MySQL等关系数据库，精通sql；5. 熟练使用Linux系统，具备Shell脚本开发能力；6. 熟练掌握数据仓库理论，有数据模型设计经验，熟练使用ETL工具进行数据抽取，清洗，转换等；7. BI可视化开发经验；
1）硕士研究生或以上学历，1年以上大数据相关工作经验；2）熟练使用Java、Scala、Python开发语言；3）掌握大数据技术，熟悉HDFS、Hadoop、HBase、Hive、Kafka、Spark的部署、维护及开发；4）熟悉项目开发管理流程，有项目管理及项目过程文档编写的经验；5）掌握AI算法，熟悉AI项目规划、开发及落地过程，具备丰富的项目经验者优先考虑；6）善于数据分析挖掘，熟练部署、使用和开发BI应用系统；熟悉通信技术及数据安全技术；7）了解工业物联网，有相关的从业经验；8）有较强的沟通表达能力，有团队合作精神。
岗位职责：* 负责核心产品的开发* 使用Java/Scala进行程序开发、数据处理。* 根据产品需求负责产品功能模块功能的设计、开发、部署、调试、故障分析和排除等* 对已上线系统进行定期巡检，持续改进服务端架构和优化，增强系统稳定性* 严格测试，及时维护，保证产品服务器稳定运行* 协同相关人员完成平台的测试工作，并持续对其进行优化。任职要求：* 计算机相关专业，扎实的Java/Scala基础，有自主阅读开发文档的能力* 有CDH、HDP等大数据管理平台使用的相关经验* 对Hadoop、Hive、Spark、Flink等大数据组件熟悉，有单个或多个组件相关的开发经验* 拥有Mysql、MongoDB或相关数据库开发经验* 熟悉Linux，能动手调试和解决Linux中遇到的各种问题，会编写shell脚本优先* 具备良好的git代码管理，代码风格，解决问题的能力以及团协作能力* 有良好的代码开发规范习惯，以及需要对开发思路清晰，能处理一定的项目上问题，并提出开发建议* 满足以上条件，有spring开发经验者优先
岗位要求：1.计算机相关专业本科及以上学历、3年以上大数据相关工作经历。2.精通Java开发体系及至少一种微服务框架，具有扎实的编程基础、优秀的编码能力、对代码质量有极致的追求。3.精通Hadoop生态体系，深入理解大数据领域的数据采集、数据存储、计算引擎、质量管理、数据价值服务等。4.熟悉python语言及基于python的web服务器端开发技术，2年以上的开发经验；熟悉Django/FLask至少一种主流Pythonweb服务器端系统框架；用python编程实现系统服务器的业务流程，具有服务器端系统开发调试和性能调优经验；5.熟悉常用的大数据框架及组件，如：Flume、Sqoop、Hdfs、Hive、Hbase、Es、Flink、Spark、Kafka、Rabbitmq等。6.深入理解常用关系型及非关系型数据库的使用、原理，如：Mysql、Mongodb、influxdb等。7.具有良好的系统化思考能力，沟通协作能力，抗压能力。
工作职责：1. 2000+节点大数据平台业务作业的开发，维护，优化和升级2. 负责处理平台Hadoop/Hive/spark/kafka等疑难问题的研究和解决 3. 负责数据平台业务代码的编写4. 根据业务需求开发各类工具工作要求：1. 计算机、数学或者统计学相关专业本科以上学历； 2. 3年以上java开发经验，编程基础扎实，掌握常见的设计模式，掌握基本的数据结构及算法3. 熟悉 MR/Spark/Kafka/ELK/Clickhouse/Pig/Hive/Hbase 等技能栈，一年以上hadoop或大数据生态系统开发经验4. 具备HDP使用，并有相关streaming流式处理经验更佳5.主人翁意识强，积极主动，善于团队协作，主动思考，自我驱动力强；
岗位职责：1.负责大数据与分析需求设计和开发，承担数据抽取、清洗、实时统计及离线数据处理等程序开发；2.承担部分新技术试验和研究，并应用到公司产品；3.独立解决开发中遇到的问题，承担开发与运维的工作；4.负责海量数据应用开发工作，包括数据处理、数据分析统计、挖掘等相关工作；5.利用Hadoop、Spark、Flink等技术进行离线和实时数据开发 ；6.负责大数据平台的规划升级、平台维护和优化 ；7.和其他部门或团队沟通、资源协调并落实工作。岗位要求：1.三年及以上Java开发经验，熟悉Java语言，熟悉虚拟机原理，数据结构和算法等基础扎实，熟练掌握并应用面向对象的编程思想；2.掌握常用大数据组件hadoop、Hive、spark、Flink、hbase、elasticsearch等原理、使用和调优；3.精通常用数据存储技术，如Redis/HBase/mysql/elasticsearch等；4.具备较强技术功底，精通Java开发语言，能根据需求给出技术架构 ；5.有数据仓库、元数据管理和治理的开发经验优先。
1.三年以上开发经验，有报表工作经验，最好大数据统计，思维灵活能处理多表关联问题，了解一定的sql调优；2.熟悉大数据生态组件Hadoop、Hbase、Hive、Spark、Hue、Sqoop等，有源代码优化经验的优先；3.有大数据平台（CDH、Apache Hadoop等）的搭建和维护经验；4.数据Java编程，熟悉Java Api，熟悉多线程编程；5.熟悉数据库（Oracle、Mysql），熟悉SQL优化；6.项目经验丰富，并有过较大、较完整项目的开发经验。
岗位职责:1、负责海量数据平台建设2、负责分布式数据平台框架下数据系统开发与新数据应用开发架构研究岗位要求：1、计算机/软件工程或相关专业出身，工作3年以上2、扎实的代码基础；擅长java。3、熟悉大数据的生态圈和相关组件（hadoop、hive、spark、flink、kafka、hbase、zookeeper等）,能够深了解集群和周边模块4、熟悉Mysql、redis，熟悉网络编程及并发技术，熟悉安全解决方案；5、熟悉Linux环境及脚本开发（Python/Perl/Shell等）6、有互联网公司中大型分布式系统经验优先；
任职要求：1、数学、统计、计算机等相关专业本科及以上学历，3年以上相关工作经验（数据/业务分析、BI、决策支持、数据挖掘）。2、精通Hadoop、Spark、Spark Streaming的基本原理并能够熟练编写spark程序，熟悉Scala或JAVA开发语言。3、精通SQL，能熟练运用ORACLE/MY SQL/HIVE/PostgreSQL等获取分析所需数据。4、具备良好的沟通能力、团队合作精神及抗压能力。5、对数据驱动业务有深入理解，对数据与业务方面有足够的敏感性，有较强的逻辑分析能力和独立思考能力，定义问题和解决问题的能力。岗位职责：1、深入理解业务，熟悉业务运营模式，为业务发展搭建数据分析框架并落地支持业务，基于业务场景规划数据产品并推进落地。2、建立数字化的监控预警机制，对发现及沉淀的重大风险及事件，通过设计并推动风控产品、机制落地来实现管控。3、能从业务目标出发，与产品、算法、运营等团队良好协同，保证用户体验，形成整体的金融风控解决方案。
职责：1.参与大数据平台的ETL流程开发与业务租户保障工作；2.参与数据模型开发，从数据源接入、清洗到数仓设计、数仓建设、标签开发等工作；3.参与数据开发相关的任务调度管理，包括开发/发布/执行/监控调度等；4.参与业务数据字典的制定和管理，数据质量的监控和报告输出。及时处理生产过程中的各种问题；5.参与业务需求的数据分析和提取，与客户沟通需求并完成交付。要求：1.计算机、软件工程等相关专业；2.熟悉Linux运维命令，了解Shell脚本开发，熟悉Python优先；3.熟练掌握SQL语言，有Mysql、Oracle、Hive等其中一个数据库使用经验。4.对大数据平台开发及运维有一定基础和概念，包括不限于Hadoop、Hive、Hbase、Spark、Flume等大数据生态组件的简单使用，熟悉ES优先。5.熟悉数据仓库的基本概念；6.具有较强的学习能力，对大数据开发工作有浓厚兴趣。
1、5年以上大数据开发经验2、有flink /spark /hive /Doris 2年以上实际开发经验3、熟悉Linux开发环境，熟悉 java/scala/python语言4、熟悉大数据组件工作原理5、有大数据应用/大数据平台设计、开发经验6、有数据挖掘经验、机器学习算法数据分析实战经验更好7、逻辑思维清洗，具备较强的责任心和良好的沟通能力
1、本科及以上学历，计算机相关专业；2、精通 Java/Scala/SQL语言，熟悉后台服务开发框架（SpringBoot / SpringCloud等）；3.熟悉Hadoop、Hive、HBase、Storm、Kafka、Spark、ElasticSearch等开源框架,有Flink实时处理经验优先；4.有大数据处理、数据中台、数据仓库经验者或数据挖掘算法优先；5.扎实的编程能力，有优秀的设计和代码品位，有独立的代码实现能力 ；6.具备优秀的团队意识和沟通能力，有较强的学习能力和钻研精神，对平台和系统有自己的思考，有清晰的技术目标和职业目标；
必须会scala，朋友们！岗位职责：1、针对百万级车联网数据用户级别提供海量的数据接入、存储、计算、分析、建模的合理性架构支持.2、负责大数据平台的搭建，完成系统调试、集成与实施.3、负责解决大数据组件技术问题.4、负责优化现有代码，优化数据处理性能，优化生产环境.5、参与大数据项目、架构应用需求、设计、审核和评审，建立大数据平台技术标准规范，编写代码.任职要求：1、熟练使用shell和java/scala编程.2、精通离线和实时数据处理流程，精通大数据技术架构.3、精通spark/hadoop/Hbase/clickhouse的原理和源码，有多年的使用和调优经验.4、熟悉常见数据结构和算法，扎实的计算机理论基础.5、有海量数据实时和离线数据处理5年以上经验，有海量数据实时和离线数据处理的生产环境下的开发运维3年以上经验．6、本科四年以上或研究生三年以上工作经验．7、性格积极乐观，有良好的沟通能力，抗压能力，有强烈的学习/技术研究能力和良好的团队精神.
职责要求：1.负责大数据项目的技术架构设计和产品选型；2.负责搭建大数据平台的本地环境，辅助用户搭建生产环境；3.负责带领团队，完成大数据项目的开发过程；4.负责项目上线及持续运维工作；5.定期进行大数据技术栈的内部培训，充实大数据团队体制和能力；
工作职责1、从事大数据平台建设开发，数据治理，编码的工作。2、负责大数据系统的架构设计和主题及业务需求开发；3、负责TiDB、Hadoop、Spark、Flink、Hive、HBase、Kafka等分布式存储和计算组件业务功能开发和疑难问题定位处理、性能优化、稳定性提升等工作任职资格1、掌握数据仓库基础理论知识，了解数据仓库模型设计和ETL设计技术；2、有丰富的Java/Scala/Python/SQL开发经验，5年或以上大数据开发经验，追求代码洁癖、熟练在Linux上工作，具有系统架构设计及系统调优经验者优先3、熟悉Hadoop和Spark生态系统，熟悉3个以上分布式存储和计算组件原理和应用，如Hive、HBase、Sqoop、Spark、Kafka、Flume等4、熟悉流式/实时计算框架如Spark Streaming、Flink、TiDB的工作原理，具备丰富的实践和调优经验者优先。5、有较强的学习能力和快速定位解决问题能力，对技术有较高的热情，热衷于新技术学习和分享。
1、大专学历及以上，3年及以上的大数据开发经验 ；2、具有Hadoop/Spark开发与应用的实际经验，并应用在生产环境，对spark基本原理有深入了解； 3、了解大数据集群基本知识，熟悉Hive、Kylin、Flink、Doris、Clickhouse、Elasticsearch、Zookeeper的基本原理和操作 。
1、三年或以上java开发工作经验，学习能力强、有上进心、做事积极主动、有较好的沟通表达能力；2、本科或以上学历，熟悉银行（信贷、大数据开发或监管报送类）其中任意一种或多种项目经验优先；3、有良好的编程习惯、熟悉多线程编程，熟悉缓存、并发等处理机制并实践运用;4、熟悉SpringBoot、Dubbo、MyBatis、Sharding-jdbc，熟悉Redis、zookeeper等，并对源码有一定了解；5、熟悉Oracle、MySQL等数据库,会存储过程优先考虑；6、招聘要求内容不是硬性或固定的，欢迎有信心、有追求、上进好学的人才来信详聊；7、我们不仅有节日、生日福利金、13薪和年终奖、全员年终分红、以及优秀项目奖、还有丰富广泛的职业晋升机制，人性化的管理和以能力和实际工作表现为导向的各类激动奖励；8、能力优秀者薪资可谈。
岗位职责:1、基于泛零售行业特点构建企业级数据中台架构,建设TB级共享数据中台;2、负责数据中台相关数据研发及管理工作，参与制定元数据、源数据、数据中间层、数据展示层相关规范并推动实施落地;3、负责数据采集、清洗、转换的方案设计及标准制定;4、负责数据应用产品的开发方案设计，如消费者标签应用、数据分析场景;5、了解行业前沿大数据处理方法。任职资格:1、8年以上数据仓库开发及管理经验，5年以上互联网/电商行业经验；2、精通数据仓库建设方法论，有大型数据仓库建设项目经验（TB级以上）；3、熟悉HADOOP、HIVE、HBASE、SPARK、FLUME等工作原理；4、精通HiveSQL，有较丰富的HiveSQL性能调优经验；5、至少熟练使用Shell、Python、Perl等脚本语言之一；6、工作认真、负责，有良好的团队合作精神，良好的分析及沟通能力；7、有用户画像、ID Mapping项目经验者优先。
岗位职责：1、为数据平台和分析实施数据架构/数据建模。2、负责Analytics、ETL、数据转换等大数据系统的技术设计和开发。3、定义和管理银行逻辑模型和数据平台最佳实践和标准，包括软件开发实践、设计风格和软件部署。4、方便从功能专家和用户社区发现实体、属性、关系和业务规则。5、Metadata 元数据管理。6、与跨职能团队合作，在各种核心业务领域发现并开发可操作、高影响力的数据分析需求和机会陈述。7、评估分析和大数据领域的工具实现和架构，根据业务需求和行业最佳实践审查差距。8、为业务流程设计和受影响领域的重新设计做出贡献。岗位要求：1、至少3-6工作经验，有银行工作经验者优先。2、熟悉关键技术和概念，如SQL、Hadoop、Hive、Spark。3、熟悉Cloudera echo系统。4、具有分析和大数据架构经验的优先。5、熟悉数据仓库关键技术和概念、SQL和大数据。6、熟悉银行和金融服务产品的优先。7、能够编写清晰的程序技术文档，并能够编写开发数据模型规范。8、注重细节，能够遵循明确的故障排除和开发方法。9、熟悉金融服务数据模型中数据架构的专家知识。10、具备Erwin数据建模工具的专业知识。11、擅长数据分析和数据分析。12、高效地安排工作优先级和多任务。13、具备银行业务开发经验者优先；14、具备英语口语交流能力；15、外企管理模式，不加班，双休，弹性上班。
岗位职责：1、负责管理数据厂商进行数据落库，负责实施外购金融资讯数据本地持久化；2、负责金融资讯数据运营，处理数据库日常表变更、负责数据内容跟踪监控；3、负责金融资讯云数据模型开发与运营；4、负责金融数据应用场景的建模及运营；技术技能必备要求1、熟悉PostgreSQL\Oracle\HBase等数据库操作，2年以上PostgreSQL\Oracle\HBase管理和开发经验；2、熟悉数据库原理，熟悉SQL语言，精通存储过程等技术,熟悉UNIX\Linux环境操作；3、对金融数据内容有一定理解，有数据运管经验；4、有数据建模项目经验，了解数据内容价值挖掘，有机器学习相关项目经验优先；5、有万得、贝格、同花顺、财汇等数据服务供应商相关工作经验优先
"[1] 负责平台的整体框架，理解系统的业务需求，制定开发计划，协调开发资源；							[2] 负责跟进和监督项目开发进度，监控项目开发质量；										[3] 负责核心技术问题的攻关、系统优化，协助解决项目开发过程中的技术难题；					[4] 对相关产品系统架构方案进行评审及改进，控制产品系统架构质量；					[5] 积极了解业界发展、相关新技术及趋势，促进技术进步和创新。"
1、参与公司大数据项目应用开发与维护；2、能够协助完成项目需求的整理与设计工作；3、完成公司大数据项目项目搭建整合;
岗位职责：1、数据开发工作，包括运营报表开发，临时性统计需求及数据模型的开发等工作。任职要求：1、具有数据开发经验，对数据处理、数据建模、数据分析等有一定的认识和实战经验；2、计算机或数学专业，对数据敏感、具备良好的逻辑思维能力；3、熟悉SQL，有一定的SQL性能优化经验；4、熟练掌握linux操作系统，掌握基本的shell、python等脚本编程
工作职责：1、负责大数据的数据收集处理、分布式系统框架、大数据基础架构等的设计、架构、和开发工作；2、搭建高可用高扩展高性能的大数据平台、开发和维护大数据相关基础设施；3、负责统计、数据分析等相关各类算法的计算框架及架构的设计和工程实现；4、负责大数据架构及技术的培训和辅导，提升技术团队的大数据相关技能水平；5、大数据平台相关项目的技术售前支持。任职要求：1、统招本科及以上学历，计算机相关专业； 2、有扎实的java基础和算法基础，熟悉Linux； 3、3年及以上大数据相关组件的开发与应用经验，熟悉分布式计算、存储、调度等原理，并有相关的分布式系统的开发经验； 4、熟练掌握主流大数据基础组件的技术原理及技术，如：Hadoop、Storm、Spark、Flink、HBase、Hive、ElasticSearch、Sqoop、Kafka、Flume、Scribe、Azkaban、YARN等，有相关的源码阅读经验，能够基于开源组件进行二次开发； 5、能够独立设计大数据相关的分布式系统的架构、技术选型等架构工作； 6、具有良好的语言表达和文档撰写能力，能够熟练阅读英文文档和学术论文； 7、具备优秀的沟通协调能力和团队合作精神，有高度的责任感，有上进心和主动性，有主人翁意识。
岗位描述1、支持lazada东南亚电商用户增长业务，用数据分析洞察客户产品使用习惯，驱动产品迭代升级。2、建立客户全生命周期管理体系，及时提出营销策略或建议，提升客户转化率与使用率；3、负责多维数据集市的规划与设计、业务数据报表需求分析、设计、落地，为业务及管理层提供决策支持与业务分析；4、负责模型建立与优化，在对业务、场景和用户深刻理解的基础上，能将业务问题抽象为数据问题，并通过建模解决岗位要求1. 对数据敏感，能从数据中发现问题、解决问题，相关工作3年以上经验，有业务增长经验背景优先。2. 能够熟练的使用SQL进行数据获取和分析，并独立地完成分析报告，能理解业界常用的各类数据分析模型及算法，熟悉SAS、R、Python等统计软件者优先；3、思维清晰，逻辑性强，有强烈的好奇心，勇于创新和面对挑战，对工作充满激情，并有良好的沟通能力、自学能力和团队协作精神。
技能集应包括星火，卡夫卡，CDP等知识。大数据框架。经验应该是数据处理和开发相关的。2. 至少4年以上Java，SQL，存储过程和ETL应用程序开发经验。4. 有数据仓库、数据挖掘、数据分析、大数据技术（如Hive/Spark）经验。3. 至少4年以上多个项目管理技能和经验，熟悉SDLC和敏捷（PMP和Scrum大师优先）7.良好的英语水平
岗位职责：1：构建数据仓库，根据业务需求进行数据源结构规划；2：对数据进行抽取（多表关联），补全（分词并提取字段）；3：检查源数据的质量，及时发现错误、不匹配、缺失的数据，并提出合适的解决方案；4：结合业务需求及源数据情况进行数据建模；任职要求：1：熟悉数据仓库架构，掌握维度建模；2：1年以上ETL开发经验，掌握ETL全流程（包括源数据分析、脏数据处理方案沟通确定、ETL转换逻辑确定、ETL开发、ETL调度等）；3：1年以上数据建模经验，设计的模型清晰并能高效满足业务分析场景；4：熟悉SQL语句；5：熟练使用某一种ETL工具；6：责任心强，做事积极主动，细心，团队沟通顺畅。（该职位为公司独立项目，非外包外派职位）
岗位职责：1、负责大数据数据分析和挖掘平台的规划,建立数据中心大数据挖掘、分析和统计的平台；2、高性能数据服务框架设计与开发；3、为公司项目提供数据决策分析。任职要求：1、本科及以上学历，具有5年以上数据平台项目开发经验，3年以上的架构设计经验，具有大数据平台应用大型项目架构设计经验；2、具备大数据和数据仓库项目的总体规划、方案设计、实施等相关经验；3、精通Spark和Hadoop生态，有大数据平台产品架构经验，具备相关系统的调优、运维、开发经验；4、熟悉数据挖掘的相关理论和技术， 精通ETL、数据仓库的设计和开发；5、扎实的Java语言基础，熟悉Java开发工具和调试工具的使用；6、精通Linux运维命令，熟悉Linux的维护和管理，熟悉Shell脚本开发，掌握Python/Scala优先；；7、兼有MySQL，NoSQL、NewSQL开发经验者优先；8、具备大数据项目管理和团队管理经验者优先；9、熟悉BIEE/Tableau/SPSS等BI工具软件优先；10、软件知识体系全面，熟悉与架构设计相关的数据存储/性能调优等相关领域知识；能够解决项目过程中的技术难题。
工作职责：1、根据行业发展趋势和公司战略，牵头制定数字化、智能化规划，并识别相关能力要求，包含IT能力和业务能力，并指导完成项目建设落地；2、负责数字化工作（数据治理及应用方面）规划，包含数据资产建设、数据技术平台、数据分析应用等方面工作规划和实现路径，并指导完成系统研发；3、负责跟进行业前沿技术发展趋势，跟紧大数据技术发展方向和相应技术，负责大数据风控、大数据营销类应用的平台规划。岗位要求：1、全日制本科学历，计算机、数学、统计等专业优先。2、熟悉业务，并善于挖掘数字化及智能化场景，熟悉领域驱动等设计方法，有丰富的架构设计、实施经验；敏锐的技术洞察力和较强的问题分析能力，对技术有热情。3、熟悉大数据风控、营销产品设计、开发的整体实现流程，对业务有很好的理解，具备很强的解决问题的能力。4、熟悉大数据风控、营销应用的数据挖掘流程，曾带领团队负责风险策略分析、机器学习建模者优先。 5、熟悉Spring体系、Mybatis等主流框架，熟悉Hadoop、ZooKeeper等分布式架构和系统；了解云计算、大数据、人工智能等技术方向，并对其应用场景有比较清晰的了解；6、良好的团队精神、沟通能力、逻辑思维能力和学习能力。
岗位职责1、支撑大数据产品与应用系统的需求分析、架构设计、技术规划、技术选型；推动大数据平台对应用系统的有效支撑；2、跟随业界大数据技术发展动态，匹配业务诉求，提前识别关键技术并实现技术准备；3、支撑各地市场与客户探讨项目建设方案，进行需求分析和技术交流，推动公司产品在当地落地实施；4、负责大数据产品与合作厂商的技术交流和对接工作，解决在商用过程中碰到的竞争问题和技术难题；5、负责对研发中心的技术培训以及指导，帮助研发中心进一步提升技术能力；6、负责产品级技术架构设计，以及疑难问题攻关。岗位要求1、全日制本科及以上学历，5年以上技术开发经验，至少3年以上产品架构设计经验；2、熟悉大数据平台体系、政务行业平台等，对相关产品有深入了解和实际使用经验者优先；3、掌握Java服务端编程，熟悉数据库和网络编程，有大数据系统架构设计经验，有核心模块设计经验，对大数据的技术趋势有较深理解者优先；4、深入理解常用数据库原理，熟悉PostgreSQLMySQL、MongoDB、Redis、Kafka原理；熟悉MPP数据库及其原理，对Hadoop，Spark，Flink等大数据计算框架有深刻的理解，具备相关实践经验；5、精通基于Yarn平台的大数据计算框架调优，SQL和性能优化，有海量数据处理经验优先；6、了解数据仓库建设理论与方法、具备丰富的实践经验者优先；7、具备大规模分布式架构设计经验者优先；8、具备良好的文字功底、口头表达能力和人际沟通交流能力。注：国企，广州办公，直签甲方
岗位职责：1、负责公司大数据环境维护，包括但不限于hdfs、yarn、hive、spark、clickhouse、kylin等大数据组件日常维护，如规划、部署、监控及优化等。2、对大数据平台的日常运维管理，集群日常巡检、容量评估、扩容及优化等3、处理大数据平台日常的故障，并对其根因分析及日常风险控制4、熟悉linux系统，熟悉掌握shell、python等，推动大数据运维的自动化工作，提高运维效率5、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长任职要求：1、熟悉hadoop体系架构，熟悉hdfs、yarn、hive、spark工作原理，熟悉源码优先2、3年以上大数据运维工作经验，有大规模管理集群经验优先3、具备良好的沟通、承压能力，善于思考，持续学习。4、具备linux系统操作能力，熟悉k8s docker容器化优先5、具体脚本开发能力，熟悉掌握shell、python。熟悉golang/java优先
1、熟悉大型企业商业智能整体运作模式和系统框架，深刻理解商业智能对业务运营的杠杆作用，能够应用BI工具指导和帮助业务过程的改进。2、5年以上大数据平台(Hadoop、Spark等)使用经验，熟练使用Unix和Linux，深刻理解数据仓库应用设计原理和实践；3、熟悉数据中台产品架构与功能，有数据湖，数据中台建设经验者优先；4、能根据业务需求设计数据仓库模型，有3年以上数据仓库开发实施经验，掌握数据仓库开发，多维分析相关技术和OLAP前端展现工具；5、有相关行业数据分析经验者及汽车行业数据指标体系建立者优先；有数据挖掘应用和开发经验优先；6、强烈责任心，开放的性格，良好的沟通能力；较强的分析问题、解决问题能力，良好的沟通能力、团队精神。7、有一个以上企业级数据仓库项目设计经验，精通数据仓库架构，熟悉数据仓库项目的实施流程；
岗位职责：1、负责大数据平台，数据中台，大数据产品等架构设计工作，保证大数据架构合理演进；2、参与大数据产品需求分析，评审，以及架构、方案设计和技术选型等工作；3、负责大数据核心组件设计与开发，促进业务数字化和智能化发展；4、负责业务需求挖掘、分析和引导，构建有竞争力的数据产品，并赋能业务；5、根据产品需求，带领研发团队完成大数据平台设计，以及项目交付；6、跟踪行业大数据技术发展，结合集团业务需求进行技术分析、评估以及引用；7、负责制定大数据架构和技术路径规划，并指导和推动架构和技术落地；任职资格：1、计算机、数学及相关专业，统招本科及以上学历；2、6年及以上大数据研发工作经验，2年及以上大数据架构师工作经验；3、深刻理解并熟练使用大数据相关组件和平台，包括但不限于Hadoop，Kafka，Flink，Impala，Spark，ClickHouse等大数据组件和平台；4、具有数据采集、数据清洗、数据建模以及数据分析等设计和研发经验；5、熟悉常用关系型数据库，精通SQL，熟练掌握java/python/scala中一种或多种编程语言；6、熟悉并构建过数据仓库，数据中台，报表平台等大数据产品和平台，有智能驾驶舱设计经验者优先考虑；7、熟悉大数据架构和技术发展路径，有机器学习/深度学习算法使用经验者优先考虑；8、具备较强责任心，工作细致严谨，沟通能力、数据分析能力等。
岗位职责：1、负责大数据平台的架构设计、核心代码开发等任务；根据项目要求编写相关技术文档；2、负责大数据平台的架构评审，代码评审，上线评审；参与数据应用需求、设计、审核和评审；3、负责核心模块研发，负责大数据平台的搭建，完成系统调试、集成与实施；4、负责开发大数据开发，如大数据采集产品、调度平台、ETL产品、离线和实时计算平台、多维分析工具、数据模型的研发5、负责建立和维护大数据平台技术标准规范，指导开发人员编写代码；6、跟踪业界前沿技术，应用到实际项目中。负责培训公司大数据开发工程师技能的培训 任职要求： 1、大本科及以上计算机相关专业毕业，5年以上工作经验； 2、精通离线和实时数据处理流程，熟练掌握hive、impala/presto/druid、spark、flink、es、clickhouse等其中或多个组件；3、熟悉大数据技术生态圈，精通大数据技术架构，有大数据平台构建经验；4、熟悉大数据数仓模型、可视化分析，各种BI算法和产品等；5、熟练掌握基本的Linux操作系统和某种脚本语言编程(如Shell等)； 6、有实际大规模数据(TPB级以上)处理经验优先，有互联网工作经验优先；7、负责主导大数据ETL、调度系统的研发工作。 8、工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。
岗位职责：1. 负责公司大数据平台研发和系统设计，负责核心代码编写，进行业务场景和平台实现；2. 负责大数据中台功能研发，包括数据资产/元数据管理/指标体系/数据开发平台/作业调度和监控/大数据门户等平台3. 参与软件工程系统的设计、开发，编写软件说明书 4. 参与到代码评审、知识传递、初级员工培养等工作中，展现领导能力；5. 跟踪行业动态，引入新的技术组件，推广新技术应用岗位要求：1. 6年以上Java应用研发经验，3年以上大数据平台相关应用研发经验；2. 熟练常用开源分布式系统，包括Hadoop/ Hive/ Spark/ Flink/ Clickhouse / Dorisdb / Mongodb / dolphinscheduler /kettle3. 熟悉常用的JAVA开源框架( 如SpringMVC、MyBatis、SpringBoot、SpringCloud等)，并理解框架的原理和机制；有大型项目架构设计开发、优化、治理，有开源社区贡献者优先；4.熟悉java基础技术体系：jvm、多线程、gc,良好的面向对象设计理解，熟悉面向对象设计原则，熟悉常用的设计模式以及应用场景5. 熟悉Mysql、Redis、MongoDB等常用的存储技术，具备优秀的SQL优化能力以及分库分表拆分经验；6. 熟悉消息队列RocketMq,Kafka,rabbitMq中的一种；7. 思维敏捷，逻辑清晰，对系统架构有自己的理解、对技术发展有明确观点，有大型技术项目承担主要职责的经验
工作职责1、 负责公司大数据平台的设计和开发，负责hadoop、flink、spark、yarn等云计算平台的开发和优化；制定数据架构规范，指导团队落地 ；2、 负责数据基础架构和数据处理体系的升级和优化，不断提升系统的稳定性和效率，为公司的业务提供大数据底层平台的支持和保证； 3、 设计并实现对数据产品开发、算法开发的系统性支持； 4、 研究未来数据模型和计算框架的创新与落地，包括但不限于以下领域：大规模数据实时化、研发模式敏捷化、数据计算框架轻量化、数据模型组织方式业务化等方面,参与制定并实践团队的技术发展路线；   5、 参与培养未来数据人才；有效辅导团队，提升数据研发能力。 任职资格： 1、 有很强的数据设计抽象能力，善于从复杂的数据问题中找到关键路径； 2、 有作为技术负责人系统化解决问题的成功案例；有海量数据实践经验优先；   3、 熟悉目前正在发展的大数据分布式平台前沿技术的应用；包括但不仅仅限于：hadoop、flink、spark、等；   4、 性格积极乐观，诚信，能自我驱动，有较强的语言表达能力；具备强烈的进取心、求知欲及团队合作精神；具有良好的沟通、团队协作、计划和创新的能力； 5、 能够开发创新而实际的分析方法以解决复杂的商业问题。
熟悉hadoop  etl  storm  es hbase
工作职责：1、负责大数据领域的产品、项目架构指导及评审；2、负责大数据领域相关公共及底座能力架构设计、技术难题攻关、核心代码编写及开发指导；3、参与大数据领域相关的技术标准规范制定及技术引进；4、上级交办的其他事项。岗位要求：1、计算机相关专业，本科以上学历，8年以上开发经验，2年以上的大数据项目架构经验；2、深入理解大数据产品和数据分析相关技术和实现方法；3、熟练使用hadoop及hadoop生态圈中的常用组件，如Spark、Hive、HBase 等；理解MapReduce、HDFS、spark RDD/DataFrame原理；4、熟悉Flink或者Spark Streaming等实时计算框架；5、至少熟悉Java，Python，Scala一种或者多种语言，熟悉Oracle\MySQL，熟悉Linux及Shell；6、熟悉数据挖掘、可视化分析，各种BI算法和产品等；7、有机器学习或深度学习经验优先；8、熟悉Spring Boot，有Spring Cloud等微服务相关项目开发经验优先；9、具有良好的沟通协调能力和团队合作精神。
架构管理方向1.负责华兴银行数据架构管理与规划，负责大数据基础能力提升、负责商业智能应用规划与建设。2.负责全行数据治理、数据问题整改、优化提升等工作。3.负责数据类相关系统关键框架、核心功能的设计与研发工作。监管应用方向1.负责华兴银行监管数据治理、监管报送质量提升工作。2.负责反洗钱系统、人行大集中、银保监1104、EAST、征信系统等监管报送系统的日常需求开发及报送保障工作。3.负责监管报送类相关系统的关键框架、核心功能的设计与研发工作。
岗位职责:1.负责电商供应链数据仓库及模型建设和设计，并根据需求变化和业务发展，持续优化模型；2.负责电商供应链数据仓库模型代码开发、部署，并对数据质量进行管理和优化；3.提升电商供应链数据质量和运营效率，参与相关事件应急响应；4.参与大数据体系的建立以及配套系统平台的建设与运营。岗位要求：1.计算机或信息技术相关专业，大学本科及以上学历;2.3年以上大数据数仓开发相关工作经验；3.有扎实的数据仓库理论功底和丰富的数据治理实战经验，能够围绕业务和产品特性建模并解决实际问题；4.熟悉大数据系统组件(如Hive、MapReduce、Spark、HBase等)，具备编写、优化复杂SQL的能力；5.了解实时处理技术相关组件（如Kafka、Flink等)；5.负责过大型数据平台或数据仓库设计优先。
岗位职责：1.负责大数据平台整体架构，包括计算引擎、存储引擎、数据开发平台、数据治理等方向的技术体系规划、架构设计及方案落地，为业务产品和算法开发提供高效的数据系统支撑；2.负责大数据相关技术组件的实际规划建设以及性能优化设计;3.负责实时计算引擎搭建、优化、运维，掌握实时数据采集、实时计算，支撑实时数据需求；4.参与公司数据中台建设, 对业务及业务系统进行现状调研，根据需求及行业特点设计大数据解决方案并跟进具体实施项目；5.参与企业级数据中台模型设计、模型开发及优化，构建结构合理完善可扩展的数据中台;任职要求：1.计算机或相关专业本科毕业，5年以上数据仓库相关经验，对数据有较强的敏感性；2.熟悉Oracle等主流关系型数据库，熟练掌握存储过程、函数、触发器等编写；3.深刻理解大数据处理(流计算、分布式计算、分布式文件系统、分布式存储等相关技术和实现方法，有架构和设计实践经验;4.熟悉Hadoop生态，熟悉主流的大数据计算引擎，如hive、spark、presto、Kafka、Flink等，有二次开发经验优先5.掌握主流的数据仓库建模方法论，有数据仓库模型的建设经验；
岗位职责：1.参与银行数据分析、加工等项目的需求分析、技术方案设计和模块开发等工作；2.参与系统性能优化和改进；4.参与制定数据质量评价体系建设；职位要求：1.本科以上学历，3年以上Python开发经验；2.熟练使用Pandas、Numy、pyspark等第三方库做数据处理与数据分析；3.熟悉PostgreSQL、MySQL、Oracle等至少一种主流关系型数据库及Mongodb等NonSQL数据库；4.熟悉Hadoop，Spark，Hive等常用大数据组件。5.有各类统计模型或机器学习模型设计开发的实际工作经验。6.熟悉软件技术文档的编写，具备良好的文档编制习惯和规范的代码书写；7.工作态度积极主动，责任心强，良好的计划、沟通能力及团队合作精神；8.有较强的学习和理解能力，思路清晰，善于思考，能独立分析和解决问题；9.有银行业数据分析、加工项目，尤其是营销数据分析建模经验优先。
关于我们：1.PB级别的区块链大数据项目，100亿级大数据处理能力，领域覆盖元宇宙/NFT/GameFi/DeFi等，面向全球用户；2.已获得国内经纬创投等多家国际知名区块链风投基金千万级融资；3.团队有着超过10年的金融科技、超过5年的区块链技术耕耘。职位描述：1. 负责大数据平台的规划和搭建、为数据分析和展现提供支持；2.负责核心代码编写，指导团队开发及解决出现的系统问题；3. 参与基于大数据平台的创新业务场景进行数据产品的架构设计和交付；4. 负责数据质量、稳定性等数据管理，让数据标准更规范、数据获取更高效；任职要求：1.5年+数据系统建设经验，3年+大数据架构设计经验；2.有大数据量(50g+)计算性能经验，实时数据更新和管理经验。加分项：熟悉数据仓库的设计和开发，对数据架构有项目实践经验；加分项：对SQL的开源查询引擎原理有深入研究；加分项：有敏捷大数据和数据可视化实践经验；加入我们，您将会：1.获得投身最新技术前沿的机会：元宇宙、Web3.0相关技术是下一个十年的最有潜力的技术赛道，且国家大力支持区块链技术的应用和创新；（获得投身最新技术前沿的机会，实现Web 2.0 DEV向Web 3.0 DEV的升级转型）2.获得直接向资深Node.js, Python, Solidity等领域技术专家学习的机会，参与高频次的元宇宙/NFT/GameFi/DeFi项目等课程分享及培训，助你快速成为区块链领域技术、大数据及业务专家；3.加入国际化多元团队，使用国际化的协作及沟通工具，快速提升英语能力。
工作日期：不限工作时间：不限结算方式：日结岗位职责：1、参与海外业务相关大数据的模块开发、报表开发；2、完成大数据相关的设计与开发工作，对数据开发的准确性和进度负责。任职要求：1、本科及以上学历，计算机相关专业；有志于从事大数据开发工作；2、熟练使用SQL，HIVE查询；熟悉python开发，对数据敏感；3、能承受压力，具备良好的沟通协调能力，工作认真负责，富有团队精神，具有良好的自学能力；4、熟悉大数据开发组件或者数据分析工具者优先；5、有Java/go实战开发经验者优先；6、实习期不少于4个月，每周到岗不少于4天.7、不接受远程入职和远程实习。
1：精通Python 开发为主2:精通Java，已开发为主3:精通开源软体二次开发支持各种合作
【工作职责】1. 负责大数据和数据集成产品的解决方案设计及落实，输出产品方案材料等。 2. 负责大数据和数据集成产品在行业客户中的推广，运营和应用，深度挖掘客户需求，有效捕捉合作契合点，为客户提供大数据解决方案，探索行业规模化模式。3. 负责大数据和数据集成产品的整体产品设计，包含但不限于产品功能规划，产品演进路线，架构设计，产品研发等。 4. 负责其他方向新技术的调研及应用，包含但不限于产品技术调研，产品能力应用方向，技术方案资料产出等。 5. 负责进行故障分析、处理、性能调优等，解决相关类型的技术问题。 【岗位要求】1. 本科及以上学历，计算机或信息系统专业领域，5年以上大数据和数据集成相关工作经验。 2. 熟练使用Java，Python等主流开发语言，熟悉主流的代码开发框架。 3. 精通Flink，能够解决底层问题，并能进行客制化的应用场景开发。 4. 熟悉大数据及相关的云服务架构/数据集成服务应用。 5. 熟悉主流流式中间件和消息服务（如Kafka，Rocket MQ，Rabbit MQ等）。 6. 熟悉主流SQL/NoSQL服务（如Oracle，MySQL，SQL Server，DRDS，Redis等）。 7. 熟悉CDC概念，熟练掌握一项以上CDC产品技术（如Flink CDC，Canal，Debezium等）。8. 熟悉数据集成工具，了解数据集成产品技术（如Camal，Talend，DataX等）。 9. 具备丰富的知识技能，对计算机原理、网络协议、软件架构设计和安全等有深入的了解。10、具有较好的英文能力、学习能力、沟通能力、自我驱动、团队协作能力。
工作职责：1、负责亿级实时渠道投放广告系统的开发和维护。2、负责大数据产品的实时计算平台的开发，迭代，及业务支撑；3、参与超大规模实时计算、存储、查询、可视化解决方案的设计、研发。任职资格：1、本科及以上学历，计算机/软件工程相关专业，211/985院校优先；2、有大数据实时处理开发flink经验；熟悉大数据相关技术，有Hadoop/Hive/Strom/等的开发经验3、具备较强的编程能力和实际项目开发经验，熟练使用Java编程语言及主流框架；4、有落地的实时数仓项目经验优先。5、强烈的责任心、团队精神和学习能力，善于沟通合作；善于思考，能独立分析和解决问题；
岗位职责： 1、负责公司CDH集群架构优化及性能提升2、负责公司调度框架，实时架构开发，能够完成公司大数据项目建设和规划3、基于大数据开发组件，可进行组件的二次开发及相关服务开发，进行数据质量，数据监控、数据调度等功能开发，提高服务稳定性和效率4、负责数据库的使用优化工作，解决系统开发、运行中出现的各种问题任职要求：1、大学本科以上学历，5年以上大数据开发经验； 2、有从事分布式数据存储与计算平台应用开发经验，精通CDH底层架构和底层优化，精通Hadoop生态相关技术并有相关实践经验优先，如Hdfs、Mapreduce、Hive、Hbase、Spark、Storm；了解大数据底层架构，可以从源码优化大数据架构。3、精通Spark，flink原理及底层技术，能对Spark性能进行调优及Spark StandAlone模式均有使用及优化经验。精通flink实时开发。4、熟悉Java 和 Scala，具有相关开发经验3年以上5、精通开源dolphscheduler开源架构，能够针对底层架构进行二次开发6、熟悉linux系统并能编写复杂shell脚本
岗位职责：1、负责基于Hadoop/Spark/Flink等生态系统的大数据平台的架构设计、技术选型、搭建、开发、管理、监控和性能调优；2、保证大数据集群高效稳定运行，对数据应用提供数据存储、查询引擎、实时计算、元数据管理的架构设计及落地；3、跨团队/部门协作，系统分析并解决各类大数据平台相关的运行或数据问题；任职资格：1、3年以上的大数据研发经验，本科及以上学历；2、有大型分布式系统设计经验，负责过海量数据平台上高可用、高性能分布式系统的架构设计；3、精通任意一门编程语言，对大数据基础架构和平台底层原理有深度理解和丰富开发经验（Hadoop/Hive/Hbase/Kafka/Spark/Flink等）；4、对复杂系统的性能优化和稳定性提升有一线实战经验，具备相关产品项目应用研发经验；有过采集埋点相关平台建设经验优先，对开源社区有贡献者优先；5、具有一定的项目规划和决策能力，善于捕捉业务需求、架构设计存在的问题，并给出有效的解决措施和方法。
岗位职责：1、研发大数据平台产品，对大数据平台架构设计、底层核心模块、公共模块、网络安全、数据安全、性能优化等方面进行持续研发迭代工作。2、负责开发过程中的关键技术问题的攻关，能够提供完善的技术方案。3、根据公司的业务发展特点，研究相关的大数据技术前沿，解决业务痛点。任职资格：1、全日制大学本科以上学历（研究生优先），国内“双一流”建设高校或世界排名前100名大学，计算机相关专业毕业，相关工作经历匹配的，学校可放宽至一般院校；2、了解大数据相关技术，有一定的Hadoop/Storm/Spark/Hive/Flink/Clickhouse/Dolphinscheduler等组件的开发使用经验；3、熟悉MYSQL/Oracle数据库相关操作，熟悉数据备份、同步、ETL运作机制；4、学习能力强，适应性好，有强烈责任心和安全意识，能主动发现并解决技术难题；5、具备良好的沟通能力以及团队合作精神。
职位描述1、负责项目中的报表开发工作；2、负责项目中的数据处理工作；3、负责项目中产品的安装、部署、数据迁移和系统初始化等实施工作；4、负责试运行和上线阶段，对客户进行业务培训工作；5、完成上级主管安排的其它日常性事务；6、公司提供完善的免费的相关报表开发，数据分析，数据库等等的岗位培训；7、可以适应出差。任职资格1、 了解Excel中数据分析公式运用；2、 有一定的沟通和理解能力，和客户进行沟通，可以把沟通过程，用文字描述形成文档；3、了解SQL语言，主流数据库；4、有自主学习能力；5、有良好的沟通能力及抗压能力；6、试用期满，五险一金，周末双休休，每年一次调薪机会。
一、岗位职责： （自有项目，非外包）1、负责公司数据仓库的建设（基于Spark+Elasticsearch） 2、负责数据仓库模型设计,开发与管理 3、进行数据分析平台的构建,对业务部门提供数据支持服务 4、编写和维护项目开发文档 5、参与大数据平台的数据架构设计，完成从业务模型到数据模型的设计 6、基于海量数据的数据仓库，为业务搭建通用的查询和分析解决方案 7、管理并优化存储&计算资源利用效率、监控并维护例行ETL任务 8、梳理整体业务指标，可视化报表开发 9、完成产品/项目划分的研发任务，按需求规范进行研发 10、参与协助数据团队与公司其他部门的相关工作 二、任职要求： 1、6年以上Java开发经验。4年以上大数据应用系统的开发和设计经验； 2、精通Hadoop、Storm、Spark等，深刻理解原理和适用场景； 3、精通Hive、HBase仓库设计，深刻理解MR运行原理和机制； 4、精通SparkSQL、HIVE HQL； 5、熟悉Linux、Shell、Nginx、ElasticSearch、Redis、Kafka、Mysql 等相关技术。 6、至少熟悉一种或多种主流BI工具。 7、有基于协同过滤推荐系统开发经验优先。三、上班时间和上班地点1、上班时间：朝九晚六，中午休息1.5小时。9:00-9:30为弹性上班时间，早到早走，晚到晚走。周末双休。2、上班地点：天河区天河工业园建工路1号南天大厦3楼301（近地铁5号线科韵路C出口，科韵路公交站）四、薪酬福利1、薪资：15k- 23k *13薪，具体面议，根据工作能力制定；2、六险一金：购买六险一金；3、法定节假日：带薪享受国家法定节假日、年假、婚假、产假、丧假等；4、员工活动：定期举办各种员工活动，如节日活动、生日会、下午茶、团建、旅游、王者荣耀PK赛、麻将争霸赛，增强员工凝聚力，促进工作的顺利开展；5、培训体系：公司设立了三大学习板块，为员工提供针对性的培训，不断提高员工的素质，让优秀的人更优秀；6、晋升机制：公司为每个岗位定制阶梯式晋升机制，通过各方面综合能力的培养与上升，将得到不同空间的晋升，并享受相应的待遇。7、其他福利：调薪机会、股权激励、学习基金、年度体检、健身运动快加入我们吧！绝对让你薪满意足！
说明，本岗位属于校企合作高校教师岗，常驻合作院校，正常签署劳动合同；福利待遇：8小时工作制，周末双休，五险一金，节假日福利，年末体检，三个月全薪寒暑假期，年终奖等。岗位职责：1、负责、参与大数据相关专业培养方案的制定与完善；2、负责、参与大数据相关专业课程建设，包括教学大纲、教材、教学案例、教案、讲稿、多媒体课件等；3、负责大数据相关专业课程的日常授课工作；4、调研大数据人才市场需求发展趋势，研究最新大数据相关技术，更新人才培养方案及课程授课内容；5、能够根据大数据项目开发需求，编写相关售前方案和大数据项目开发。任职要求：1、计算机、数学等大数据相关专业硕士及以上学历；2、熟练掌握Python、Java、Hadoop、Hive、HBase、Zookeeper、Spark、Storm等工具的使用；3、熟练掌握大数据处理技术的典型应用场景；4、具备良好的语言表达能力，有较强的责任心和团队协作意识；5、有工业互联网相关项目开发工作经验者优先；6、有人工智能、数据挖掘、数据分析、数据仓库、推荐算法等开发经验者优先；工作地点：广东白云学院：白云区学院路1号
4年及以下工作经历同学请勿投。请投简历同学先看清楚下面要求再投递，不满足要求请勿投递，谢谢！岗位职责:1. 负责基于Hadoop的大数据基础平台(CDH)的建设和开发运维；2．设计开发大数据平台相关的核心系统；3. 协同数据分析师开发、优化数据产品和业务：跟踪技术社区发展动态，持续优化大数据平台的业务和技术岗位要求：1  熟悉Linux系统和Shell脚本；2．拥有CDH集群搭建和优化实际经验，有进行故障排查的经验；3. 熟悉Fume/Kafka等数据采集和传输技术：4. 熟悉Hadoop/Hive/Spark/HBase等大数据存储和计算系统，了解背后架构和工作原理；5. 掌握Flink/Kylin/Presto/Elasticsearch等等一种或多种系统的优先；6. 性格乐观积极，具有主动分析和解决实际问题的能力和态度；
【岗位职责】1、从事公司大数据应用系统产品的研发，对公司“数据驱动运营”的业务目标进行大数据架构方案实现；2、依据业务需求，负责大数据相关平台的搭建、开发、维护、优化； 3、负责按照要求完成各类设计文档，并参与开发；4、对大数据、AI领域最新技术进行研究分析，并应用到业务中。 【任职要求】1、计算机或相关专业本科及以上学历（特殊人才不限），两年以上大数据相关设计或研发经验；2、熟悉分布式系统的架构，至少1个以上大型成熟项目的经验；3、熟悉Java、HFDS、MapReduce，并有相关的开发及优化经验；4、熟悉MySql、SqlServer等数据库系统，有数据库编程经验、熟悉数据仓库的ETL的开发,有海量数据处理相关经验；5、熟悉Hadoop、HBase、Hive、Spark、Storm等软件；6、有研发过包括利用大数据进行智能推荐、精准营销，大数据风控，大数据决策支持的可优先录用。
计算机及相关专业毕业（学历学信网可查），毕业3年及以上具有相关工作经验。1. 熟悉Hadoop生态，有海量数据处理和并行计算开发经验。2. 了解mySQL/Hive/Spark的使用。3. 熟悉Hadoop/Spark/Hbase/Kafak/ES，并有3年及以上的开发经验。4. 较强开发能力，熟练使用相关开发语言（Java/Python/Shell等）。5. 熟悉Spring、Springboot、flink开发。
岗位职责：1、负责软件系统的后端开发，包括大数据处理，数据分析与挖掘算法研发、机器学习模型搭建与优化、自然语言处理研发；2、根据产品需求，进行系统设计和编码；3、持续对系统架构进行改造和优化。职位要求：1、熟练掌握Python，有 Java或C++编程经验者优先；2、熟练使用基本的数据结构和算法；3、熟悉大数据生态，具有Hadoop、ElasticSearch、Spark、Flink、ClickHouse等使用经验者优先；4、具有机器学习、自然语言处理经验者优先；5、具备良好的沟通能力，敬业、有上进心，有良好的团队合作精神。
工作职责：1、负责公司大数据平台、指标体系建设等应用平台的架构、设计、开发2、支持千亿级数据量上的秒级别的交互分析场景，高效支撑广告/实验平台/用户行为分析等业务场景3、和团队探索前沿技术，落地和推广实时湖上数据分析、流批统一等场景岗位要求：1、计算机或相关专业本科以上学历，5年以上大数据相关工作经验；2、熟悉Java/go/c++语言，精通SQL，熟悉常用的关系型数据库、非关系性数据库和数据仓库，具有SQL性能优化经验；3、熟悉flink、presto、clickhouse、doris等架构与底层实现有深入理解，并有一定的开发、调优、运维经验；4、善于沟通，对业务敏感，能快速理解业务背景，具备优秀的技术与业务结合能力；
岗位职责：1、需求调研（接口，功能）：相应文档的编写，评审，确认；2、需求方案、开发设计方案的制定，编写，评审，工时评定；3、开发问题处理；4、二开功能数据库开发；5、打印模板的新增和调整；6、接口方面的数据库功能开发；任职要求：1、ORACLE 数据库1-2年开发经验。2、年龄在30岁以内；3、有零售行业软件开发经验者优先
(说明:非编制职位)【工作内容】1.负责项目的需求分析、ods数据接入、数据维护、调度作业开发、运维监控。2.负责数据中台存储过程编写，可视化报表实现。协助需求进行数据分析，问题排查3.负责项目的技术类文档编写以及项目的过程文档编写。【技能要求】1. 编程基本功扎实，熟悉常用数据结构和算法，擅长Java编程语言，精通sql及存储过程编写，能编写高质量简洁清晰的代码。2. 熟悉Unix/Linux环境，perl、shell编程，熟悉常用的ETL工具以及调度工具。3. 熟悉主流的关系型数据库（例如Oracle、DB2、SQL Service、Greenplum等），熟悉大数据平台Hive、HBase等数据库。 4. 熟练办公软件，例如Office（Excel、Word、PPt）等。5.熟悉常用的报表工具。如smartbi，网易有数，数智云,永洪报表等5. 有良好的逻辑思维能力，较强的抽象、概括、总结的工作习惯，能自我激励，勤奋好学，善于沟通与团队协作。 7. 有电力行业项目经理优先考虑。 8. 有星环大数据平台开发经验者优先。9.乐观自信，能承担工作压力。
"职位描述：1、	负责电网业务数据分析、数据清洗、统计脚本开发等工作；2、	驻点客户现场开展统计指标准确性校核及分析报告编制工作；3、	配合项目经理完成项目交付工作。岗位要求：1、	具有计算机或相关专业大专或以上学历；2、	熟练使用SQL，有SQLServer、Mysql、Oracle、Hadoop、Postgres、GreenPlum等任意一种或多种数据库工作经验；3、	具有较强的工作计划、实施及执行能力，服从安排，能够适应较大工作压力;4、	具有良好的团队合作精神；工作主动性强，耐心细致，有责任心，学习能力强，善于分析、思考问题;5、	有电力业务背景者优先，如生产、营销、GIS、物资等。6、	有数据分析、数据质量等工作经验者优先；7、	有数据库培训证书、或软考中级及以上证书者优先。"
熟悉数据库，仓，湖，域，及一体化技术。有团队精神和自身实力。熟悉数据治理和生态架构及技术。人品成熟，历炼多。有失败和挫折经历者优先
1、具有扎实的计算机基础知识，在数据结构、算法和代码、软件设计方面具备较强的基础；2、熟悉 Vue，CSS，Javascript等前端技术；3、有微服务设计和开发经验, 掌握Spring Boot、Spring Cloud、Mybatis等流行框架开发微服务，RESTful规范；3、熟悉 Mysql 或 Oracle 数据库，了解 SQL 性能优化；4、具有良好的代码书写规范，会使用主流团队开发工具如svn，git等；5、对新技术感兴趣，学习能力强，有钻研和开拓精神；6、具备良好的团队意识及创新思维、自我激励能力，善于与人合作。7、有吃苦耐劳的精神和较强的逻辑思维能力
熟练使用tableau,Qlikview，Qliksense
岗位职责1.参与公司银行等金融领域知识图谱产品数据相关的数据建模、ETL工作；2.基于公司的产品进行客户化现场实施开发。任职要求1.本科学历，统计学、计算机相关专业等，2.优先熟悉银行业务知识、业务数据存储及分发机制；3.熟悉HDFS、spark、HBase、ElasticSearch等大数据开源技术；4.熟悉linux操作系统，熟悉一种脚本语言shell 、python、JAVA等；5.熟练掌握传统关系型数据库如mysql、oracle，具备存储过程开发和Sql调优经验6.接受内短期出差
岗位职责：1、负责数据仓库的开发建设、部署与调优；2、负责BI报表平台或自助数据分析平台开发，为业务部门自助数据分析提供技术方案及对接；3、高效完成BI数据报表开发及需求交付，对数据质量负责；4、负责离线和实时数据平台的开发和建设，熟练掌握实时数据处理开发经验；5、协助风控算法对实时及离线特征抽取、融合，为数据挖掘及策略平台提供特征服务；任职要求：1、计算机相关专业，本科及以上学历，至少3年以上数据开发经验；2、熟悉数据仓库建模理论，有实际的ETL设计开发以及数据治理经验；3、 熟练掌握python或java语言、对主流的大数据计算框架（不限于Hadoop/Spark/Hive/Flink等）、任务调度系统（DolphinScheduler，Azkaban等）熟练掌握，有海量数据处理经验；4、对数据敏感，有较强的理解能力、沟通能力以及团队协作精神，能承受工作压力；5. 有金融信贷行业数据开发经验优先，有0到1数仓建设经验优先；6. 对阿里云大数据产品体系（如DataWorks）有了解或实际应用经验者优先。
【岗位职责】1、加入行政执法平台的数据研发团队，负责数据平台建设和各类数据应用研发；2、数仓建设：分析业务过程和应用需求，设计数据仓库；实时/离线数据处理和数据服务开发；3、数据应用研发：根据需求研发各类数据应用。【任职要求】 1  本科以上学历，计算机或数学相关专业； 2  有数据仓库和数据类应用开发经验，参与过电子政务研发工作优先； 3  熟悉大数据处理框架：Spark、Flink、Hive、Yarn、HDFS、Hbase，有海量数据（TB级）处理经验的优先  ； 4  精通Java、Scala、Python之一。
岗位职责：1、熟知互联网公司业务数据和业务变化，构建业务数据模型；2、维护业务数据模型，验证数据质量，保障数据完整和可靠；3、进行海量数据研发和分析，支持业务优化、监控和考核；任职资格：1、国内外高校计算机、数学或者计算机类相关专业，本科以上学历；2、2年以上大规模数据开发、数据仓库构建、数据挖掘、数据分析相关工作经验；3、熟悉数据仓库分层架构，数据治理，了解任务执行调度与任务监控、数据质量监控等；4、熟悉HiveSQL、MySQL、Oracle、SQLServer或至少其中之一，熟悉SQL语言；5、有Hive或者阿里云大数据产品（dataworks、maxcompute）使用经验；有主流BI报表开发经验，有帆软开发经验优先；6、熟练应用大数据平台完成项目或任务，具有Python、Shell开发经验优先；7、熟知数理统计、数据分析及挖掘，熟知常用算法，有运用机器学习算法建模的理论基础或实际经验者优先 。
工作职责1、负责核心业务系统维护、数据逻辑开发，问题跟踪与解决2、参与数据提取、清洗、处理和分析工作，使用数据集成、数据分析、机器学习和数据可视化的工具；3、负责业务数据集市的数据架构设计与开发，支持业务系统的数据应用；4、负责数据的自动化分析处理工作，对海量数据进行挖掘，产出数据规律；5、负责数据采集、计算、分析处理等相关开发工作；任职要求1、计算机、数学、统计等相关专业本科及以上学历；2、3年以上数据运维开发从业经验；3、熟悉数据采集、数据清洗、分析和建模工作相关技术细节和流程；4、熟练运用Python/Hive/Oracle/MySQL等工具进行数据开发和分析，能熟练运用SQL、能熟练编写存储过程；5、熟练Python、java、C#中至少一种语言，熟悉面向对象编程技术，良好的学习能力和逻辑思维能力；了解数据迁移及服务器相关知识；6、拥有优秀的数据分析能力和产品思维，对数据敏感，善于从数据中发现问题，工作细致严谨；7、有数据分析、数据开发经验优先，熟悉数据挖掘算法优先；
工作职责：1、 发掘和分析业务需求，撰写技术方案和系统设计；2、 负责数据采集摄取，数据存储，建模、统计及监控等一个或多个环节的开发与维护，负责数据仓库ETL（ 数据抽取、加载、清洗、转换）处理任务的开发与维护；3、 负责管理与优化公司算法系统，不断迭代优化算法效果，提升核心业务指标岗位要求： 1、 具有5年以上大数据平台、数据挖掘相关领域项目开发实施经验，有数据建模、ETL架构与开发经验； 2、 熟悉Java、Scala、Python等编程语言，熟悉Oracle或者MySQL等数据库技术，熟悉Linux操作系统； 3、 熟悉大数据开发框架，熟悉Hive、Spark、Flink、Hbase、Impala、Kylin、Kafka中两种以上大数据主流工具和技术，对大数据基础架构和平台有深刻理解；4、 熟悉消费品行业主题数据模型；5、 对数据敏感，具有良好的逻辑思维能力、业务理解能力、模型分析/解释能力，以及流畅的表达能力，积极主动性强
岗位职责：1、负责信息数据的清洗开发工作；2、负责ETL开发；3、负责数据的校验、同步、分发等工作等；4、完成上级交办的其他事宜。任职资格：1、本科及以上学历，计算机、软件工程、网络安全等计算机相关专业，一年以上数据搭建、架构设计等相关工作经验；2、熟练使用SQL语言，有Python、JAVA、.net开发经验优佳；3、熟悉MongoDB、PostgreSQL、MySQL等关系型数据库和非关系型数据库；4、熟悉Datax、Kettle等常用的ETL工具；5、有Flink、Spark等大数据开发优佳；6、具有较强的代码能力和团队沟通协调能力；7、具有强烈责任心和上进心。
1、基于阿里云dataworks技术打造数据中台平台，以平台支撑大数据分析决策应用的开发2、采集下游业务库数据，在dataworks中 编写HQL语言 进行开发、与调度3、各种业务指标、标签指标的开发4、各类场景BI报表开发5、利用机器学习技术，构建预测、预警模型，深入挖掘数据6、数据中台方案、教育信息管理标准、各类设计文档的编写7、数据中台运行过程中的各模块使用与完善：数据采集、数据治理、数据标签、数据指标、数据集市、数据服务、数据流8、基于cdh平台构建etl+kettle+hadoop+hdfs+hive+spark+任务调度的私有化数据工厂。9、可以自由主导整个数据中台的建设过程，对个人的能力、知识储备提升很有利
岗位职责：1、在技术经理的带领下，根据客户需求开发程序，对技术经理负责，及时汇报任务进度；2、服从技术经理任务安排，负责软件研发任务的详细设计、编码；3、配合技术经理进行项目研发的技术分析工作、参与客户与实施需求调研并进行分析，上报；4、协助现场实施人员，提供技术支持工作；5、熟悉部门软件，进行测试，完成现场软件发布与程序更新工作；6、负责项目过程中相关配套文档编写。任职要求：1、熟悉使用power builder开发工具；有power builder相关从业经验者优先；熟悉sql server 2008以上数据库分析处理；2、一年以上软件程序开发经验，精通面向对象编程，有意向从事PB开发亦可；3、精通大型数据库开发技术，熟悉SQL SERVER数据库系统；4、较强分析、判断和概括能力， 逻辑思维能力，一定的抗压能力；5、专科（含）以上学历，计算机相关专业。6.需要长期出差
1、带领实施团队，负责政务行业的中台数据库开发（MySQL数据库开发、HADOOP开发）。2、本科以上学历，五年以上的数据抽取、清洗、转换、存储、建模、质量稽核、应用等数据全生命周期开发利用的实施经验，需要有带人经验。3、熟悉政务行业数据共享交互、数据库建设与维护工作优先。4、熟练使用主流的ETL工具产品，精通ETL设计和开发，熟悉Kettle、DataX等数据采集工具，熟悉Kafka、ES、Redis等大数据组件的使用优先。5、熟悉MySQL/Hive等数据库，熟悉数据库逻辑设计、物理设计，以及数据库相关的关键模块设计，关键数据库程序实现。
1、计算机、数学本科相关专业毕业，三年以上oracle或高斯开发经验2、逻辑分析能力强，具备大规模数据分析处理能力优先，具备java开发基础优先3、精通存储过程开发，能独立开发复杂逻辑存储过程，精通数据库优化，有高斯存储过程开发经验优先5、熟悉大数据，spark运维实施。熟悉华为云平台优先4、有良好沟通学习能力，强烈的工作责任心和良好的团队协作能力
驻点岗位，弹性上下班，固定双休1、精通BI和数据仓库理论知识。 2、熟悉ORACLE、DB2、TERADATA等任一数据库，能快速进行数据查疑并给出解决方案。 3、精通SAP BO、SmartBI、Tableau等任一报表工具，精通报表优化，能带领团队进行报表开发。 4、3年及以上相关工作经验，本科及以上学历。 5、熟悉DataStage、Informatica等任一ETL工具。 6、精通报表UI设计，可针对需求给出设计方案。"
1.根据项目需求，配合工作人员前往现场进行安装实施。2.负责公司软件产品的安装调试，演示培训，应用指导等实施上线工作。3.具有数据库管理开发经验，精通SQL SERVER熟悉MYSQL具有数据库应用软件分析，设计工具。熟悉VB6.0熟悉C#.能独立开发数据管理系统。
【岗位职责】1.负责公司多款游戏产品的数据分析开发工作；2.配合策划、运营和市场等相关人员，完成数据需求的开发，提供日常数据支持；3.根据业务需要，设计数据日志埋点，并跟进数据质量；实习期薪资：150-200/天【任职要求】1.2023年本科在读或以上学历，计算机、数学、数据、统计等专业优先；2.有一定的编程经验，掌握Python语言，熟悉使用SQL和Excel；3.有责任心，逻辑清晰，好奇心强，有良好的沟通和协作能力，能主动融入团队；4.学习意愿强，不排斥学习新的分析工具；5.平时多接触游戏，有丰富游戏经验的优先。【福利体系】1.工作时间：公司实行弹性工作制，每周工作五天，周末双休；2.丰富活动：每周五篮球、羽毛球活动、月度生日会&生日礼、季度团建、年度旅游。此外还为小伙伴们提供充足的活动经费Team building；3.五险一金：保障员工基本权益，医疗、生育、工伤、失业、养老保险及住房公积金均齐备；4.商业保险：公司为每位入职的员工购买一份意外医疗商业保险；5.带薪假期：享受国家规定的各类法定假期、带薪年假等等；6.暖心福利：交通补贴，零食饮料，年度体检，年底双薪，还有各类节日活动、中秋节、端午节等节日福利；7.职业发展：新人一对一导师制入职培训、系列培训及提供广阔的晋升空间与调薪渠道，完整的激励机制；8.工作氛围：舒适的办公环境，nice的领导，一群热心有爱、志同道合的小伙伴。
【岗位职责】1、参与供应链相关系统平台开发；2、负责公司供应链相关系统日常运维（业务提作管疑、用户需求整理、数据查询支持）。【任职要求】1、本科及以上学历，软件开发、计算机应用、信息管理等相关专业；2、1-2年信息系统开发经验；3、熟练使用SQL语言，编写SQL语句、存储过程、触发器等；4、有参与过WMS、ERP等项目者优先；5、oracle PL/SQL数据库开发经验；6、JAVA开发经验，ERP平台配置开发经验优先考虑；7、有良好的沟通和学习能力，强烈的工作责任心和良好的团队协作能力。
1、带领实施团队，负责政务行业的中台数据库开发（MySQL数据库开发、HADOOP开发）。2、本科以上学历，五年以上的数据抽取、清洗、转换、存储、建模、质量稽核、应用等数据全生命周期开发利用的实施经验，需要有带人经验。3、熟悉政务行业数据共享交互、数据库建设与维护工作优先。4、熟练使用主流的ETL工具产品，精通ETL设计和开发，熟悉Kettle、DataX等数据采集工具，熟悉Kafka、ES、Redis等大数据组件的使用优先。5、熟悉MySQL/Hive等数据库，熟悉数据库逻辑设计、物理设计，以及数据库相关的关键模块设计，关键数据库程序实现。
1、计算机、数学本科相关专业毕业，三年以上oracle或高斯开发经验2、逻辑分析能力强，具备大规模数据分析处理能力优先，具备java开发基础优先3、精通存储过程开发，能独立开发复杂逻辑存储过程，精通数据库优化，有高斯存储过程开发经验优先5、熟悉大数据，spark运维实施。熟悉华为云平台优先4、有良好沟通学习能力，强烈的工作责任心和良好的团队协作能力
主要职责：负责公司的etl ，数据模型/数据的建立和维护以及数据分析职位要求：1. 熟练使用Oracle,mysql等关系型数据库,熟练掌握常用函数、存储过程及自定义函数等，熟悉SQL性能优化；2. 熟悉Linux操作系統和常用操作指令；3. 了解hadoop，Hive ，spark等大数据技术；4. 能使用java，python等編程語言开发。5. 有较强的学习能力和问题分析处理能力，及有良好的沟通能力和团队合作精神。我们为您提供：社会保险及住房公积金、商业医疗保险、年度调薪、年度双薪、10天带薪年休假、其他特色有薪假期、双休
岗位职责：1、为数据平台和分析实施数据架构/数据建模。2、负责Analytics、ETL、数据转换等大数据系统的技术设计和开发。3、定义和管理银行逻辑模型和数据平台最佳实践和标准，包括软件开发实践、设计风格和软件部署。4、方便从功能专家和用户社区发现实体、属性、关系和业务规则。5、Metadata 元数据管理。6、与跨职能团队合作，在各种核心业务领域发现并开发可操作、高影响力的数据分析需求和机会陈述。7、评估分析和大数据领域的工具实现和架构，根据业务需求和行业最佳实践审查差距。8、为业务流程设计和受影响领域的重新设计做出贡献。岗位要求：1、至少3-6工作经验，有银行工作经验者优先。2、熟悉关键技术和概念，如Hadoop、Hive、Spark、Java。3、熟悉Cloudera echo系统。4、具有分析和大数据架构经验的优先。5、熟悉关键技术和概念、SQL和大数据。6、熟悉银行和金融服务产品的优先。7、能够编写清晰的程序技术文档，并能够编写开发数据模型规范。8、注重细节，能够遵循明确的故障排除和开发方法。9、熟悉金融服务数据模型中数据架构的专家知识。10、具备Erwin数据建模工具的专业知识。有证书者优先。11、擅长数据分析和数据分析。12、高效地安排工作优先级和多任务。13、具备银行业务开发经验者优先；14、具备英语口语交流能力；15、外企管理模式，不加班，双休，弹性上班。
1.负责BI项目的实施工作2.熟悉思迈特(Smartbi)工具设计开发3.熟悉sqlserver、mysql、oracle等数据库开发及存储过程编写及调用4.熟悉数仓架构，熟悉使用kettle、informatica等etl工具5.能接受出差
主要职责：1. 帮助公司搭建数据爬取和监控平台2. 整理数据处理流程，完善自动化周期性的数据更新3. 多种数据源的相互自动化校验4. 按照业务部门的需要做数据的二次加工技能要求：1. 熟练掌握常见的爬虫框架和工具，例如scrapy，selenium；熟悉常见的反爬规则以及解决办法2. 了解ELK处理流程，并配置监控看板3. 可以使用常见的web框架做基础接口开发，例如tornado，django，flask等4. 熟悉常见的数据库，例如mysql，mongodb，redis，队列等5. 熟练使用python并有良好的编码习惯，了解git做代码分支管理，会其它语言加分6. 会使用linux环境下的命令行工具，了解容器化部署加分
工作要求：1）.数学、计算机、信息工程等理科类大专以上学历优先考虑2） 精通 达梦/ SQL Server / MY SQL的存储过程编程，熟悉SQL 语法；3） 数量掌握上述数据库的部署及维护；4） 熟练使用各类数据库相关系统；5）具备良好的学习能力、沟通能力、分析及解决问题能力，优秀的团队协作精神。公司福利：1）双休工作制。2）佳节礼品：妇女节、中秋。3）员工聚餐：公司定期安排员工聚餐。4）其他：年终奖励、员工旅游5）提供员工宿舍
"该岗位暂时为全英文面试早九晚六 双休 不加班 一经录用 待遇从优实际有五个岗位：4-9年：数据分析，deep learning, NLP, transformer model3-6年：数据开发，Hadoop, Spark, Kafka, SQL, Flink3-6年：数据开发，Python, SQL, pandas, database2-6年：Machine Learning Engineer，Python, Docker, CI/CD, Machine Learning and/or ML model monitoring experience a plus6-9年：Experience in HDFS, Map Reduce, Hive, Impala, Sqoop, Linux/Unix technologies.  Spark is an added advantage.Job Duties & Responsibilities:•	Support finance regulatory reporting projects & applications as ETL developer | Big Data applications by following Agile Software development life cycle | level 2/3 support of the data warehouse."
（1）负责海量业务数据的实时和批量接入，构建由数据接入到数据服务和应用的可配置化平台；（2）负责以数据为核心，制定数据质量标准，管理数据资产，确保数据安全；（3）负责数据处理流程设计及开发； （4）负责数据对接和开发、模块测试和维护；（5）负责开发文档维护。岗位要求：    （1）全日制本科及以上学历，3年以上软件开发经验；（2）从事数据相关工作领域至少2年以上，熟悉数据处理流程与ETL开发；（3）具有一定的数据模型和数据架构基础，理解云计算和数据服务；（4）具有WebService技术及JavaEE相关领域知识技能经验者优先；  （5）掌握相关数据调度、ETL、元数据管理、数据监控等技术优先；  （6）有丰富的数据处理工作经验，熟悉主流数据库：Oracle、MySQL等；  （7）具有良好的客户服务意识、团队合作精神、沟通能力、学习能力及一定的抗压能力。
【岗位职责】1.负责进行大数据相关的分析、治理以及智能平台产品的开发；2.负责搭建大数据集群以及根据实际需要参与客户现场大数据产品的问题解决；3.完成上级领导交代的其他相关性事务。【任职要求】1.统招本科以上学历，计算机相关专业2.有大数据平台开发实习经验优先，精通Java语言，熟悉Linux系统，理解常用算法和数据结构，具备良好的分析和解决问题能力。
1、SQLServcer数据库，熟练plsql编程,存储过程和函数2、精通数据仓库以及维度建模原理，有建设经验3、负责BI平台数据分析、报表开发工作。
1、负责大数据存储与计算的业务代码实现； 2、协同设计基于大数据的技术解决方案； 3、与其它开发工程师协作完成产品开发。 岗位要求： 1、精通Python语言； 2、精通 hdfs ,Hive Spark、Kafka、ElasticSearch、Redis、Neo4J等大数据组件的开发接口，尤其是Python语言接口； 3、熟练掌握大数据组件开发技巧与性能调优策略； 4、熟悉大数据分析的基本方法； 5、除Python外熟练掌握Java、Scala等其它语言者优先； 6、具备良好的英文技术文档阅读能力； 7、有大数据工程项目经验； 8、1年以上相关工作经验。
岗位职责：1、负责ETL后端开发、维护以及相关文档的书写； 2、负责数据加工、清洗、转换，为下游系统提供数据接口； 3、对仓库的数据进行质量检查。岗位要求：1、本科，计算机相关专业，掌握SQL语言，至少熟练使用过一种数据库； 2、熟悉ETL的概念和流程，至少熟练使用过一种ETL工具； 3、至少熟练使用过shell，python等一门脚本语言； 4、系统学习过数据库原理，掌握规范化理论原理； 5、至少掌握三范式建模或者维度建模理论一种，具有银行金融业务相关的数据建模经验； 6、对数据标准化有一定的经验。
职位要求：1、完成数据库业务系统（包括但不限于：费用中心/用户系统/网关代理/活动运营/客户管理）的设计、研发以及稳定性工作；2、熟练掌握HTML、Javascript、CSS、Java\.Net、Redis、MySQL等语法知识，独立架构web站点，理解web网站开发全栈；3、进行相关产品的文档撰写与方案设计，高效推进产品功能落地；4、研究业界先进技术，保持技术进步；岗位要求：1、全日制211本科及以上学历，计算机相关专业，两年及以上大数据库开发经验；2、有扎实的数据结构与算法基础；熟悉操作系统原理与各类网络协议；3、有良好的文档撰写能力和编码习惯，对代码美感要有不懈的追求；善于发现并解决问题以及总结、沉淀，能够对所负责的项目进行持续的优化。
职责描述： 1.参与海量数据应用开发工作，包括数据加工、数据分析统计、挖掘等相关工作； 保障大数据相关产品的稳定性、扩展性和安全性，提升产品性能； 2.协助新技术研究和落地，应用到公司产品，进一步提高项目品质； 参与大数据平台的规划升级、平台维护和优化； 3.参与来自业务团队数据方面的研发需求； 任职要求： 1.全日制本科及以上学历，计算机相关专业优先，三年以上工作经验； 2.熟练掌握Java（硬性要求）、Scala语言，熟悉面向对象设计原则，具有良好数据结构和算法基础； 3.熟悉Spring生态并有实际项目开发经验，包括SpringBoot，SpringMVC，SpringCloud等框架； 4.了解熟悉Kafka、Flink、ClickHouse、Elasticsearch、MySQL、Redis等常用数据组件的原理，有调优经验； 对数据处理、数据建模、元数据管理、数据分析等有深刻认识和实战经验； 5.有良好的SQL设计编写及优化能力；熟悉Linux系统及其常用命令，熟练掌握Git、IDEA、Maven等常用开发工具； 6.具备良好的团队协作和沟通能力，有较强的工作规划和执行能力，有owner意识，具备独立解决问题的能力。注：薪资结构含固定及绩效部分，最高可综合获得16薪。
工作职责：1.根据业务需求提供报表或看板设计文档；2.确认设计文档方案；3.BI、看板开发；4.数据核对及实施上线；岗位要求：1.熟悉Oracle、Sqlserver、Mysql数据库2.熟悉生产企业业务流程，（2年生产业务工作经验）;3.熟悉生产系统、MES、EPMS、QMS系统等；4.熟悉帆软相关工具开发；5.熟悉VSCode、JAVA等开发语言；
技能要求：a)   熟悉Oracle、SqlServer、Mysql等关系型数据库。b)   参与过离线、实时数据仓库相关开发工作。c)   熟悉Hadoop生态体系，Cloudera或Hortonworks套件。d)   至少掌握Java、Python、C#等其中一门开发语言。工作要求：1) 能配合项目的进度要求，适当加班。2) 根据加班情况，可适当调休，不另行计算加班工资。3) 工作时间正常为周一至周五 9:00 至 18:00。4) 可根据项目进度安排，服从加班要求，加班可调休。5) 请假需补工时，住宿和用餐自行解决。
1.5年以上数据仓库项目交付实施经验；2.熟悉常见的数据建模理论，有丰富的数据模型设计经验，精通维度建模流程及方法论；3.熟悉开源或阿里云大数据产品和技术，对数据采集及集成、数据建模、数据开发、数据资产管理、数据分析服务等大数据领域有丰富的项目实战经验；4.具有良好的项目落地与团队协作能力，能够组织跨团队技术协作，推动项目落地；5.有基于Dataphin进行数据中台架构设计经验或有阿里云数据中台ACP认证者优先；6.有数据中台交付或数据仓库项目经验者优先；7.熟悉Hadoop、Hive、Spark、Flink、Hbase、Clickhouse、Redis、Kylin、Druid、Kudu、Kafka等组件；8.熟悉阿里云大数据产品，包括但不限于MaxCompute、Dataworks、Dataphin、ADB等；9.具备python、java、scala的至少一种编程语言能力。
"岗位职责1. 主要负责ORACLE EBS维护以及二次开发；2. 在相关文档的指导下，独立、熟练的进行EBS二次开发程序代码实现工作；3. 负责信息系统的完善以及新系统功能需求的调研、开发与实施；4. 主动发现信息系统在使用中存在的弊端，结合流程优化、操作便捷性提出优化改进方案；5. 为应用端提供技术支持与指导。任职要求1.	专科及以上学历，计算机相关专业;2.	一年以上ORACLE EBS项目经验，熟悉ORACLE EBS功能模块（GL，AR，AP，OM，PO，INV等），具备独立分析解决问题能力；3.	没有项目经验，但有EBS系统培训经历的，也可以考虑聘为预备开发工程师，经过一段时间熟悉和学习后再独立开发。4. 精通Oracle PL/SQL编程，具备良好的编程习惯和风格;"
【职位描述】1、负责服务器常用开源软件的开发维护工作；2、负责开源软件在POWER服务器上的性能分析和优化；3、提供基于POWER服务器的开软件解决方案；4、协助解决PoC以及客户遇到的问题。【岗位需求】1、计算机、通信、电子、软件相关专业本科及以上学历；2、扎实的编程基础，熟悉GCC工具链，熟悉软件开发和调试工具；3、精通某一类开源应用: 分布式存储(Ceph, HDFS等），数据库(MySQL, Redis等），大数据（Hadoop, Spark)，机器学习(Tensorflow, Pytorch等）；4、熟悉软件性能分析的方法/工具，具备性能优化的技能；5、熟悉POWER架构者优先；6、具备较强的沟通能力，团队合作意识和自我驱动能力。
岗位职责：  1、负责数据可视化项目开发工作；设计数据可视化相关的技术方案；  2、深入理解主要数据可视化展现形式，针对实际场景梳理数据信息，提出专业的数据可视化方案。  3、根据业务需求快速理解实际痛点，利用合适的数据分析及可视化方法展现商业逻辑和成因，高效输出解决方案。  4、提升大数据平台产品化体验，推动数据驱动业务升级。  任职要求：  1、大专及以上学历，3年及以上相关工作经验；  2、学习能力和团队意识强，拥有强大的数据驱动思维及逻辑思维；  3、熟练使用可视化BI工具及前端工具，包括但不限于Tableau，PowerBI，永洪BI，fineBI等；  4、了解脚本语言，包括但不限于Python、R、SQL等；  5、具有地产行业、快消行业、制造行业背景，有可视化大屏或web、APP设计经验的优先考虑；
工作职责:1，负责大数据技术支持，解决大数据技术问题；2，负责大数据平台的搭建以及产品功能开发、测试和维护工作；3，保障大数据相关产品稳定性、扩展性和安全性，提升产品性能；4，关注开源技术动态，结合业务场景，设计最佳解决方案；任职资格:1，本科或以上学历，计算机相关专业，2年以上大数据工作经验2，精通高内聚低耦合的面向对象设计思想，熟悉常用的软件设计原则如单一职责、接口隔离，依赖倒置、liskov替换原则、开闭原则；3，测试设计与实现能力，能根据需求场景熟练设计有效用例，并挑选合适手段验证；4，熟悉Hadoop、Spark、Hive、Impala、Hbase、ElasticSearch/Solr等技术的原理，有良好的系统性能优化及故障排除能力；5，精通Java，熟悉Scala；6，熟悉 Linux，有较强的系统管理、网络管理和故障处理能力，有大规模集群运维经验者优先。7，积极主动、良好的沟通表达，抗压能力强
岗位职责：1、负责各业务与各数据产品的离线/实时数据仓库建设，包括模型设计、开发、优化等；2、负责数据治理及数据质量保障体系建设，保证数据准确、稳定，优化资源使用效率；3、协同数据产品/数据运营制定元数据定义规范，设计元数据管理方案，建设统一的数据体系；4、支持业务团队的数据需求，负责流批一体的数据处理，将业务需求转化为数据需求并落地实现。任职要求：1、本科及以上学历，两年以上数据仓库开发经验，有大数据数仓架构设计经验优先；2、有较为丰富数据仓库领域知识和实践经验，熟悉数据仓库建设方法论, 熟悉大型数据仓库架构和模型设计，包括但不限于：元数据管理、数据治理、性能调优等；3、熟悉Flink| kafka| clickhouse| dolphinscheduler大数据体系建设的技术栈并有相关开发工作经验，精通分布式数仓开发、熟悉CLICKHOUSE数仓ETL开发；4、具备优秀的推动力与抗压性，有良好的学习、沟通能力及团队合作意识；5、从事医疗器械行业工作经验的优先。
岗位职责：1、负责实时报表开发与运维，实现报表每日/月更新，维护和监控报表；2、使用移动 PAAS 系统将数据库数据导出，配合前端人员进行报表展示；3、分析提数需求，实现 SQL 编写；4、负责移动数据支撑，完成临时需求、数据提取等任务；5、协助撰写数据分析或模型分析报告，汇报数据分析结果；6、协助项目经理完成其他任务，确保项目顺利完成。岗位要求：1、1年以上的通信行业数据提取、数据开发、报表开发项目经验；2、掌握SQL、至少熟练掌握和运用一种分析工具（Python、SAS、SPSS、R、等），熟练使用EXCEL及PPT；3、具备业务数据挖掘、数据分析、数据建模相关分析理论知识和工作经验；4、思维敏捷，具备良好的逻辑分析能力和责任感、良好的团队精神与人际沟通能力。
工作职责：1、收集并分析数据需求，以及流向其他系统的数据流；2、熟练使用编程技术，利用数据资源，建立数据分析模型，支持数据进行获取、整合、加工；3、参与公司数据治理、数据安全、数据管控等相关工作； 4、根据业务需求，及时优化和维护数据库性能，并开发相关功能模块；5、完成领导交代的其他工作。任职资格：1、 全日制本科或以上学历，计算机相关专业，熟悉C/C++/RUST其中一种编程语言；2、  3年以上相关工作经验，熟悉数据库应用开发工作，特别是时序数据库；有证券金融历史及时序数据库方面有丰富开发经验的优先，特别是TimescaleDB； 3、 熟悉数据管理的理论，熟悉数据指标建模方法，了解数据清洗转换技术（ETL）； 4、 具备分析、解决问题的能力，善于组织协调，工作认真积极、责任心强、学习沟通能力强，具有良好的团队协作精神。
"Requirement: -	University degree or above in Computer Science or IT related discipline.-	Pass CET4 and has good ability on reading & writting English-	Korean Speaking is necessary-	3+ years experiences in Cobol project development-	Good understanding of SQL tuning-	Be familiar with Oracle and SQL Server-	Team player, and able to work independently and efficiently to meet deadlines.-	Good command of English and Cantonese in written and reading is preferred.    Responsibilities:-	Analyzing user requirements and establishing system objectives.-	Contributing to the analysis of existing system work flows and procedures and devising both information and process oriented flow charts.-	Perform Continuous Analysis and Requirement Handling-	Develop and Test High Quality Products-	Perform Trouble Shooting and Customer Support-	Drive Continuous Improvements of Products and Processes"
1.DB2、Oracle数据库专家服务、故障解决2. 自有数据脱敏，数据库审计产品交付3.数据产品售前工作4.要求熟悉常见操作系统，有一定行业经验，了解大数据平台5.能适应短期出差
要求英语流利2年以上的Kubernetes和相关容器平台生产经验，SparkKafka*创建Docker文件和CICD的经验，拥有：Valid Certified Kubernetes管理认证
1、参与项目需求分析讨论，根据业务需求对项目进行相应分解；2、使用Kettle工具，将源数据抽取到ODS层，并制定抽取频率和抽取方式；3、编写SQL语句，对ODS层的源数据进行清洗、转换及标准化；4、使用ETL工具将标准化数据跨库同步到数据仓库中；5、根据已设计好的数据模型，在DW层创建维度表和事实表，编写存储过程及自定义函数将数据导入维度表事实表中，并根据报表需求生成各类主题统计表，配合报表开发人员完成多维度数据报表展示。任职要求：1.本科及以上学历，计算机相关专业，有1年及以上MySQL、sql server、PostgreSQL管理经验，有知名企业经历的优先； 2.具有丰富的MySQL与sql server数据库日常管理、维护、实施经验。3.熟悉Linux基本管理，熟练使用Shell或Python中的一门脚本语； 4.良好的团队协作能力，积极主动，乐于接受挑战，能承受工作压力和良好的学习能力和对新技术的追求精神。公司福利：1、工作时间：9:00-18:00（大小周）2、福利待遇：五险+商业保险+法定节假日+带薪年假+绩效奖金+饭堂工作餐+节日活动+员工活动办公地址：广州市番禺南村镇南雅电商园18栋二楼（地铁七号线员岗站）
岗位职责：1. 参与数据平台需求梳理、系统设计及运营，支撑业务部门对数据资产的需求、数据探索。2. 制定与落实公司数据平台管理规范，将数据规范贯穿系统建设全生命周期管理并落地实施；3. 加强数据处理的标准化以及管理工作，为业务部门产出高效，安全，可用的数据资源，提升研发过程中的数据使用效率。4. 其他数据技术支持。任职要求：1. 本科及以上学历，计算机相关专业或数学专业且有计算机背景优先，3年以上工作经验；2. 熟悉主流关系型数据库产品，对新兴的NOSQL/NEWSQL也有了解和掌握，有较丰富的数据建模/分类经验；3. 具备良好的数据类IT技能，熟悉SQL/Python/JAVA/R……中至少一种；4. 具有互联网数据产品经验，对数据敏感，有大数据应用、数据平台搭建优先；5. 数据分析能力强，思维逻辑清晰，对事物有较强的领悟能力；6. 拥有较好的沟通技巧及团队合作精神，较强的责任感及进取精神。
1.    计算机软件或相关专业，本科或以上学历；2.    熟练使用Java，对数据结构和算法有较好的掌握；3.    熟练使用Linux、shell脚本的编写；4.    熟悉Hadoop文件系统，精通MR编程，熟悉Hive，HBase，有相关调优经验；5.    熟练使用Oracle、Mysql；6.    具有良好的逻辑思维能力，能够从海量数据中发现有价值的规律；7.    具有高度的工作责任感和团队合作精神，有良好的学习和沟通协调能力，能承受一定的工作压力。
工作职责：1、根据客户业务需求、管理口径，梳理客户系统的数据逻辑，构建报表；2、 根据业务场景，分析跨子系统的业务数据对接关系，评估接口需求的可行性；3、 根据业务场景，分析各种历史数据的质量，制定或实现数据迁移工作；4、定期对客户系统运行环境做检查和分析，识别潜在风险并推动改善。任职资格：1、 本科以上学历，计算机相关专业；2、 2年以上项目实施及售后维护相关经验；3、 熟练掌握SQL语言，能够编写复杂报表；熟练掌握软件产品的数据库结构，能够将数据逻辑与业务逻辑对应；会数据迁移；会服务器相关知识；4、 良好的沟通能力与团队合作能力。
岗位职责：1、参与项目需求分析讨论，根据业务需求对项目进行相应分解；2、使用Kettle工具，将源数据抽取到ODS层，并制定抽取频率和抽取方式；3、熟悉使用PowerBI，PowerBI实现数据可视化经验优先；4、熟悉SQL调优，对ODS层的源数据进行清洗、转换及标准化，编写高效SQL、存储过程；5、使用ETL工具将标准化数据跨库同步到数据仓库中；6、根据已设计好的数据模型，在DW层创建维度表和事实表，编写存储过程及自定义函数将数据导入维度表事实表中，并根据报表需求生成各类主题统计表，配合报表开发人员完成多维度数据报表展示。岗位要求：1、有3年及以上Sql Server、MySQL、PostgreSQL管理经验2、熟悉Linux系统基本操作3、熟悉至少java、javascript一门开发语言4、熟练使用Python或Shell脚本语言优先5、数学、计算机相关专业优先6、熟悉使用PowerBI，PowerBI实现数据可视化经验优先；7、熟悉SQL调优、编写高效SQL、存储过程；8、熟悉至少java、javascript一门开发语言
岗位职责：1）负责数据ETL开发，提取、加工、清洗、处理各类数据；2）负责数据平台的搭建、开发、维护、优化；3）对数据分析团队的业务分析需求给予数据建模支持；能力要求：1）计算机相关专业，本科及以上学历，热爱数据，持续学习；2）熟练掌握MySql，SqlServer，等1-2种主流数据库，有DBA证书或经验优先；3）熟悉Linux/Unix系统环境下的操作；4）有复杂业务数据处理经验优先。5）具有2年或以上数据(仓)库/ETL/性能优化工作经验者优先。6）熟悉各类模型分类与回归算法，熟悉各类变量筛选与降维算法者优先；
岗位职责：1、负责数据处理工作，包括但不限于数据管理、数据处理执行、数据问题诊断，确保数据系统稳定运行；2、协助部署人员更新文件及脚本；3、负责数据库的性能调优及存储过程的开发。4、负责BI日常报表开发，参与需求分析过程，能从系统角度有效分析业务的报表需求；5、参与数据分析呈现设计，进行相关报表数据指标开发；6、基于数据，分析业务状况，提供后续报表的优化改进建议。7、完成上级交办的其他工作。任职资格：1、 本科及以上学历，计算机或数学相关专业；2、 对数据处理生产各环节流程均有了解,熟悉数据仓库,能独立分析设计或调整数据仓库以满足业务需求；3、熟悉或了解元数据管理、数据集成、数据挖掘、指标数据计算等任一数据环节；4、 对数据库(oracle或mysql等)有深入了解，熟悉调优数据库,能对数据库进行性能分析,部署集群；5、具备数据敏感性,有良好的逻辑思维,能协助改进数据生产流程；6、工作认真负责,行动力高,喜欢有难度的工作，能为公司发展提出有益的建议。7、有一定的数据库经验，掌握SQL查询优化方法。
熟悉Python或JAVA熟悉Mysql熟悉Linux有数据处理，数据治理，数据仓库相关经验负责数据采集，数据汇总处理，质量检测，数据分析，数据分发等
远程面试！薪资可谈！英语听说读写！熟悉Unix/Linux;a.有建立大型预置或云系统的经验。b. 2年以上经验;c.了解Spark、Kafka者优先d.有系统管理员(Unix/Linux)工作经验者优先;e.熟悉java脚本或者python加分项：•有Openshift平台经验•有Gitops的经验，例如ArgoCD•有Istio, Kiali, Keycloack的使用经验熟悉RabbitMQ, Apache
职位描述1. 负责健康体检行业数据平台的升级改造与数据整合，构建实时数仓；2. 研发健康行业的实时智能化数据应用平台，通过技术和业务场景的紧密结合，赋能业务，让数据发挥最大业务价值；3. 基于业界标准和最佳实践为医疗、卫生健康客户提供云及大数据中心、中台等解决方案和专业服务；职位要求1. 统计学、应用数学、医学或计算机科学相关专业背景，有医疗、卫健行业经验者优先考虑；2. 3年及以上工作经验，Java基础扎实，熟练掌握Python；3. 熟悉大数据领域的产品的核心功能和技术，包括但不限于：Hadoop/Spark/Hive/HBase/Flink生态相关技术，熟悉MySQL、Oracle、SQL Server等数据库；具有较为丰富的数据仓库及数据平台的架构经验，精通数据业务建模及ETL设计开发，具备实时流计算数据开发经验；具有阿里云数据生态开发经验者可优先考虑；4. 熟悉常用商业BI&数据整合工具，具有ClickHouse/Druid/Kylin/Superset等OLAP和数据可视化相关经验者优先考虑。5. 熟悉常用的数据挖掘、分析的工具和方法，有实际数据挖掘工作经验优先考虑；6. 具有优秀的统计基本知识和直觉，具备跨学科研究经验和较强的学习能力；熟悉医疗、卫健领域上下游业务，对业界的最新的产品、技术发展动态有比较密切的关注，同时对体检行业有较深刻的理解和敏感的触觉，能前瞻性设计行业解决方案；
Job Description如果你想参与阿里大数据的采集、存储、处理，通过分布式大数据平台加工数据，支持业务管理决策，如果你想参与阿里大数据体系的模型设计、开发、维护，通过元数据、质量体系有效的管理和组织EB级的数据，如果你想参与阿里大数据产品的研发，发挥你的商业sense，通过数据分析和算法来洞察数据背后的机会，来探索大数据商业化，如果你想接触世界领先的大数据处理与应用的技术和平台，获得大数据浪潮之巅的各类大牛的指导，那就加入我们吧！Job Requirements如果你所学专业是计算机、数学、统计、数据科学与大数据技术等相关专业；如果你有强的动手能力和学习能力，熟悉一门数据处理语言，如SQL、JAVA、Python、Perl等，熟悉unix或者linux操作；如果你具备扎实的专业基础，良好的沟通能力和团队合作，主动积极，乐于面对挑战；如果你有参与过数据处理、分析、挖掘等相关项目更好；如果你对Hadoop、Hive、Hbase等分布式平台有一定的理解更好；那么成为数据工程师吧，这里就是你的舞台同时，我们还需要你具备：1. 熟悉Hadoop/Hive/Spark,理解云计算，对Hadoop/Hive/Spark源码熟悉者优先2. 熟悉常用的脚本开发语言（Java,Python,Shell)3. 较好的沟通理解能力，性格乐观，态度踏实，积极上进
1、熟悉ipfs源代码和流程，熟悉lotus，有lotus部署和开发经验2、熟悉网络架构和存储方案
熟悉sql，有丰富的finereport报表开发经验，能独立带项目，并进行相关组内技能培训
1.熟练使用hivesql,sparksql2.对数据同步工具sqoop或kettle熟练使用3.熟悉数仓分成设计及原理4.对BI工具能如帆软bi，永洪bi能够熟练使用5.能够编写shell脚本及应用6.熟悉kafka，flink
岗位职责1、根据项目需求对接大数据平台，进行相应的数据接入处理，包含数据的提取、存储以及清洗处理等；2、根据业务需求设计数据库逻辑和物理模型, 开发数据库生产环境所需要的存储过程、函数、脚本等；3、参与数据库生产环境的问题优化和解决。任职要求1、掌握数据库开发技术：包含Oracle、Teradata、DB2、Mysql等，灵活运用SQL实现海量数据ETL加工处理;2、熟悉Linux系统常规shell处理命令，灵活运用shell做的文本处理和系统操作;3、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Hdfs、Mapreduce、Hive、Hbase;4、熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，重点考察Java、Python、Perl;5、熟悉数据仓库领域知识和技能者优先，包括但不局限于：元数据管理、数据开发测试工具与方法、数据质量、主数据管理;6、掌握实时流计算技术，有storm开发经验者优先；7、认真负责，有团队协作精神，能够与团队相处融洽，协同处理好项目工作；
工作职责：1、负责收集评估公司各部门数据分析需求，制定BI产品线路图，确保BI产品能很好地满足用户需求及实现业务价值；2、负责数据报表/分析看板的设计和开发实现，并确保用户体验和交互界面能带来较好的用户满意度；3、负责已有报表体系功能迭代优化，跟进和解决数据问题；4、负责提炼业务分析指标，明确指标定义，计算逻辑和指标加工实现；5、负责功能说明书编写和新功能培训，提供业务支持；6、负责BI报表可视化界面(UI)和用户体验(UED/UX)设计及优化，以提升用户满意度和使用效率。岗位要求：1、计算机，统计学，应用数学相关专业优先，本科及以上学历，工作2年以上；2、具备帆软BI，帆软Report等数据产品实践项目，能独立承担报表设计和开发工作；3、具有分析数据集设计经验，熟悉大数据平台，熟悉SQL及ETL作业调度，了解数据建模和数据分析；4、对数据敏感，工作细心，认真，积极主动，具备良好的沟通及协调能力；5、熟悉快消品及零售行业业务，有相关指标设计经验者优先。
"岗位内容：1.进行财务、供应链一类的数据分析；2.进行数据处理，负责数据标准设计、数据标准开发应用。任职要求：1.专科或以上学历，统计学、应用数学、计算机科学或软件工程等相关专业；2.1-3年数据可视化或BI领域工作经验；3.熟悉使用主流BI工具中的一个，如Tableau、PowerBI、QuickBI、SmartBI、Cognos、MicroStrategy等；4.良好的数据敏感度，并对商业和业务逻辑敏感；5.良好的沟通表达、文档写作能力；此岗位需要中山出差，有出差补贴！【公司福利】			1.五险一金			2.年终奖			3.节假日福利			4.餐补、交通补贴、话费补贴			5.工作时间：双休，8:30-12:00,13:30-17:30"
Job Duties:1. Support in projects management of digitalization, including SAP launch,  report development, Finance process optimization and other Finance digitalization projects.2. Lead/organize finance digitalization projects. Improve finance team working efficiency and optimize process by using digitalization tools (SQL,Phython,PBI and etcs.)3. Act as China Coordinator in Key Group Project FIT4 (SAP S/4 Launch)，and  be responsible for horizontal level (E2E WS Coordinators) project management to ensure project target achievement.  4. Act as SBU Coordinator in FIT4 to organize resource within business unit to participate project and to share progress to the members & local management in regular basic.  5. Act as key member in the system roll out phase when it comes to China ( project management, coacher, super user etc.)6. Other tasks assigned by the supervisor.Competency:1. At least 2 years working experience in Data Analysis/ Finance / Consulting related areas.  2. Proficiency in at least 1 digitalization tools like SQL, Python, PBI and etcs.3. ERP launching experience as key user/sub-project leader role. (SAP is highly preferred).  4. Good sense of business process related, solid skill of project management.5. Proficiency in written and speaking English.
工作地点:广州科学城工作职责:1）基于业务流程的数据库存储过程编程；2）数据库项目安装部署及维护；3）基于数据库的基础维护职位要求:1）.数学、计算机、信息工程等理科类大专以上学历优先考虑2） 精通 达梦/ SQL Server / MY SQL的存储过程编程，熟悉SQL 语法；3） 数量掌握上述数据库的部署及维护；4） 熟练使用各类数据库相关系统；5）具备良好的学习能力、沟通能力、分析及解决问题能力，优秀的团队协作精神。公司福利：1）双休工作制。2）员工聚餐：公司定期安排员工聚餐。3）其他：年终奖励、员工旅游4）提供员工宿舍
岗位职责：1.负责运维自动化系统和工具的设计和开发2.负责运维监控数据的海量处理、特征提取、统计计算、数据分析和数据挖掘，用于智能分析系统性能问题3.在不同的运维场景和业务场景中快速完成具有挑战性的项目任职要求：1.计算机软件或相关专业；2.具有 Java/C++/go任意一种语言开发经验；3.熟悉 Linux 操作系统；4.良好的代码、技术文档编写规范习惯；5.具有很强的钻研精神及自学能力，有较强的独立工作能力和团队协作精神；6.有Flink/Spark Streaming等开源流式计算系统开发经验者优先,熟悉主流hive/impala/kudu/clickhouse等数据分析引擎，有实际使用经验者优先7.熟悉云计算网络/虚拟化/存储技术优先；8.有智能监控、告警自愈、CI/CD,虚拟化平台建设经验者优先。
岗位职责：1）根据开发需求设计数据模型和用SQL编程数据逻辑处理；2）设计并优化数据库物理建设方案；3）制定数据库备份和恢复策略及工作流程与规范；4）在项目实施中，承担数据库的实施工作；5）针对数据库应用系统运行中出现的问题，提出解决方案；6）对空间数据库进行分析、设计并合理开发，实现有效管理；7）监督数据库的备份和恢复策略的执行；8）为应用开发、系统知识等提供技术咨询服务。能力要求：1）数据库技术的基本概念、原理、方法和技术；3）能够使用SQL语言实现数据库操作；3）掌握数据库管理与维护的基本方法；4）掌握数据库性能优化的基本方法；5）了解数据库技术的最新发展；6）掌握计算机体系结构以及各主要部件的性能和基本工作原理；7）掌握操作系统、程序设计语言的基础知识，了解编译程序的基本知识；8）熟悉常用的数据库管理和开发工具，具备用指定的工具管理和开发简单数据库应用系统的能力。9）熟悉Microsoft SQL Server的工作原理，及掌握相关的维护工具；10）熟悉ERP数据模型的优先考虑；工作经验不限，欢迎应届毕业生和实习生也参与投简历挑战自己。上班时间：周一至周五，朝九晚六，每日工作8小时，周末双休。
工作职责1、负责底层数据清洗与数据处理的开发与优化工作，提供准确、稳定、可靠的底层数据，负责相应的数据更新工作；2、参与制定、维护数据内容、字段维度、职能体系等各项数据标准工作；3、负责优化数据处理流程、开发数据分析、自动化脚本，优化质量，提高效率；4、共同参与新数据分析、数据挖掘、算法的研究和方向拓展，体现数据价值；5、基于业务的发展和需求，不断优化迭代数据分析链路和分析方法，构建数据分析全生命周期体系。工作要求1、本科及以上学历，计算机、统计学、数学类相关专业优先；2、一年以上工作经验，有数仓搭建经验者优先；3、熟练运用Python进行大批量数据处理、数据读取及数据分析挖掘等工作，了解多线程多进程的运用；4、熟悉常见数理统计分析方法及机器学习算法，具有数据挖掘、数据分析、数据可视化能力，拥有一定的自然语言处理能力。5、具有较强的学习能力、责任心，工作态度端正，具备良好的团队合作、沟通交流和抗压能力，有上进心。
1.参与区块链技术的研发、设计和开发工作；2.负责底层区块链架构设计及关键部分实现；3.在区块链架构上开发、部署、实施、监控审计节点、智能合约；4.相关智能合约代码测试方案的制定和测试；5.根据项目需求，开发并测试区块链智能合约 SDK （C++/Golang/Node.Js），支持应用层快速开发和链交互调度使用；6.编写相关的技术文档；7.负责研究区块链技术发展动态及前沿发展方向。任职要求:1.本科及以上学历，信息安全、数学、加密或计算机软件专业；2.扎实的计算机理论和网络知识，比如数据结构、算法、数据库理论，计算机网络；3.熟练掌握JAVA区块链系统开发语言，有良好的编程习惯和编码风格，参与区块链开源开发；4.熟练掌握超级账本/区块链的原理、机制、相关加密算法以及主流的共识算法，包括但不限于PoW、PoS、DPoS、PBFT、Paxos、Raft、SM2，SM3，SM4、SHA系列、DES、RSA等；5.熟悉区块链加密算法，共识机制，安全协议，分布式计算、智能合约等底层协议与运行机制者优先；6.熟悉Linux，熟练掌握Docker容器技术和k8s集群的原理，部署和使用优化；　　7.熟悉FISCO BCOS、Hyperledger Fabric、EOS等主流联盟链框架；8.对区块链的开源项目Ethereum、Hyperledger、Bitcoin有研究、开发和实践者优先。福利待遇：周末双休  弹性工作   餐补    五险一金   年终奖金   绩效奖金   专业培训   办公零食    团建活动
岗位职责：1. 遥感/气象算法及项目相关文档的编写；2. 遥感图像处理算法设计与实现；3. 算法程序的维护和测试；任职要求：1.遥感/计算机等相关专业本科及以上学历，2年以上工作经验，对计算机编程有强烈兴趣；2. 熟悉基本的遥感图像处理算法；3. 熟练使用arcgis、envi等遥感处理软件，熟悉IDL编程；4. 熟悉Python、matlab、java其中一种编程语言者优先；5. 熟悉常见卫星资料格式,如HDF/NetCDF/AWX等，具有处理卫星数据的能力；6. 熟悉辐射传输模式,对大气校正有了解;熟悉定标/定位者优先；7. 熟悉Linux系统，了解shell（linux）；8. 良好的沟通、快速学习的能力，较强的自我驱动、分析和解决问题的能力；
岗位职责：1、负责评估公司各业务线数据需求，数据报表/分析看板设计和开发实现；2、负责已有报表体系功能迭代优化，跟进和解决数据问题；3、负责提炼业务分析指标，明确指标定义、计算逻辑和指标加工实现；4、负责功能说明书编写和新功能培训，提供业务支持。岗位要求：1、计算机、统计学、应用数学相关专业，本科及以上学历，工作2年以上；2、具备帆软FineReport、永洪BI等数据产品实践项目经验，能独立承担报表设计和开发工作；3、具有分析数据集设计经验，熟悉星型模型构建，熟悉大数据平台，熟悉SQL、ETL和作业调度；4、工作细心、认真、积极主动，具备良好的沟通和协调能力；5、熟悉零售业务，有零售指标设计经验优先。
工作内容：1、参与项目的实施、协调工作；2、根据项目需要进行需求调研、分析设计、编码实现等；3、编制项目相关文档。工作职责：1、计算机、软件工程等相关专业本科或以上学历；2、掌握js、CSS等前端开发语言，能灵活运用到实际中，主要以数据分析图表开发为主；3、具备较强的文档撰写能力；4、熟悉Oracle数据库，了解python语言、ETL技术优先；5、对数据分析、数据挖掘有兴趣者优先；6、熟悉Linux、Unix操作系统优先。
职位要求：1、统招大专以上学历，理工科专业；2、熟练SQL语句编写，熟练使用Kettle；3、良好的沟通表达和团队合作能力，有责任心、有一定的需求分析能力、文档撰写能力；4、具有良好的学习能力，完成分配的工作任务和学习任务；5、能承受短期高强度的学习考核任务，自学能力强；6、能接受偶尔出差。职位招聘1-5人培养计划项目组长（业务线）及区域项目负责人
岗位职责：  1、ETL数据处理；  2、根据需求为客户定制报表； 3、BI报表制作； 4、医疗项目的需求收集、需求分析、项目执行落地； 岗位要求： 1、本科以上学历，计算机或相关专业，全日制本科以上学历优先，1年以上BI系统相关工作经验； 2、需求分析能力强，思维活跃，逻辑严谨，善于沟通； 3、熟悉医疗行业业务知识，对医院HIS/LIS/PACS/EMR等项目有实际工作经验优先考虑； 4、熟悉FineReport、smartbi、Tableau、powerbi之类的工具使用； 5、喜欢数据分析的工作； 6、熟悉主流数据库技术如：Sqlserver, MySql，Oralce等。
工作职责:1、负责机器学习（尤其是深度学习领域）的研究和算法、模型开发工作，包括但不限于：神经网络模型设计，元学习，自动超参数优化，在线学习和各种优化方法尝试2、监控场景下的图像视频分析算法开发流程，包括场所、装备等目标的检测，特征提取、跟踪、识别等，实现算法的研究3、负责语音/声音降噪相关的算法模块的研发、优化、测试工作任职资格:1、本科及以上学历，计算机、应用数学、统计学、模式识别、人工智能、自动化控制、运筹学、生物学、物理学/量子计算、神经科学等专业本科2年以上相关经验，硕士1年以上相关经验2、熟悉常用机器学习和深度学习图像处理算法，掌握*新SOTA实现，熟练使用Caffe、PyTorch、Tensorflow和MxNet等任一种深度学习开源框架，能独立负责算法的设计、研发、优化等工作3、熟悉Python、C/C++等编程语言，具有出色的代码实现能力4、加分项：①熟悉模型压缩，有深度学习前向推理在各种平台的移植和优化经验（包括移动端平台的ARM/DSP/GPU/NPU，服务器端的CPU/GPU）②熟悉神经网络模型的设计、调参和优化方法③电力平台的算法落地经验（故障，预演等）④发表过相关方向高水平学术论文，参加过相关国际竞赛并取得前列名次⑤CVPR/ICCV/ECCV/NeurIPS/ICLR/TPAMI/IJCV/SIGGRAPH/TOG等国际会议／期刊论文发表经验5、具有优秀的科学技术研究能力、逻辑思维能力和数据敏感度工作地点：佛山，中山，广州
数据/运维工程师岗位职责：1、负责数据接口开发，主要通过SQL开发视图、触发器、存储过程；2、根据业务需求，完成相关数据处理，包括需求沟通、数据分析、数据清洗和集成；3、根据数据集成方案，采用数据交换工具（ODI、KETTLE、DTS）等构建数据交换流程；4、保障部门相关运维工作，如巡检、故障处理、节假日值班轮值。5、其他，完成上级安排的临时任务；6、做好工作周报、月报，年度工作总结。任职要求：1、全日制本科及以上学历；计算机、软件工程、信息管理等相关专业；2、掌握Oracle，SQL Server，MySql，mongodb等相关数据库，至少掌握其中一种；3、掌握ODI，Kettle等ETL相关中间件优先；有教育行业相关经验优先。4、有较强的文档编写能力，优秀的口头表达能力，良好的沟通能力和责任心；5、工作积极主动，执行能力强；有创新精神，头脑活跃、团队合作和服务客户的意识强；6、招聘岗位需驻场，工作地点为客户办公场所，基本是广州市内各大高校。
职位描述：工作职责： 1、协助设计和开发分布式网络爬虫系统；2、协助解决技术疑难问题，包括反爬、压力控制，提升网页抓取的效率和质量；3、研究各种网站、链接的形态，发现它们的特点和规律4、配合产品、设计、运营，确保新产品的顺利进行；5、关注研究新技术的发展和实验。职位要求：1、具备独立开发能力，需后端语言基础.2、本科及以上在读或大专优秀者；3、熟悉Git工作流，Github相关操作流程；4、能快速学习、良好的沟通能力、积极解决代码问题，优化代码性能；5、精通python、计算机网络，熟练使用多线程，熟悉Scrapy等常用爬虫框架；6、熟悉Linux操作、正则表达式，MySQL、MongoDB等常用数据库7、能够解决封账号、封IP、验证码识别、图像识别等问题8、设计模式，数据结构需掌握运用代码实现中。

数字化工程师（工业互联网方向）1、        参与大数据平台设计、建设与实施；2、        参与数据平台对接、现场数据对接、应用数据对接及现场实施；3、        大数据相关数据分析、数据治理、接入方案编写；4、        负责数据接入及数据分析相关的客户交流、人员协调、及相关开发工作；任职条件：1、本科或以上学历，计算机相关专业，有相关的物联网开发经验；2、良好的现场沟通协调能力，完备的代码编写能力3、积极的学习态度和优秀的思考能力、有责任心、吃苦耐劳4、有三年及以上物联网开发经验、并有相应的上线的项目产品5、熟悉java 语言，熟悉IO、Modbus、104、MQTT等实时数据通讯协议（必须满足）6、精通HBase、MySQL、熟悉MongoDB、PISQL、MSSQL数据及相关编程7、有设备管理平台开发经验、以及平台兼容性、扩展性、性能优化设计方案经验者优先
Google Cloud Platform(GCP)Apache Spark-for data transformation within RDP to create refined Data Asset Genome-to generate ETL pipeline which run on Spark Control-M-for scheduling PostgreSQLDenodo-for data virtualisationJava Springboot-to configure/write RADAR APIQlikSense-to build QlikSense on GCP or on-premand develop QlikSense dashboardLead GCP Data EngineerExpert understanding of and at least 5 years delivery experience using GCP; Dataproc, Dataflow, Big Query, Compute, Pub/Sub, Cloud Storage.Expert knowledge of Industry Best Practice for ETL Design, Principles, Concepts.Possess + 5 years experience with at least one of the following languages – Java or ScalaDevOps and Agile engineering practitioner with experience of test driven developmentAbility to work independently on specialized assignments within the context of project deliverablesTake ownership of providing solutions and tools that iteratively increase engineering efficiencies.Design should help embed standard processes, systems and operational models into the BAU approach for end-to-end execution of Data PipelinesExcellent communication skills & team player and collaboratorTeam coaching and mentorship
"工作职责1、 通过海量数据挖掘、机器学习等方法，构建用户画像、个性化推荐、预测、 风险控制等系统；2、 参与数据挖掘项目的设计、实现、算法调研、优化；3、 用户分析、理解及建模，持续提升用户产品体验；4、 调研并促进数据挖掘在公司多个业务领域的应用；5、主导商流（采购执行模型、选品采购模型、销售预测模型、商品推荐千人千面）、供应链金融（企业评级模型、风控控制）人工智能算法的搭建落地。岗位要求1、	本科及本科以上学历，计算机、数学、统计学等相关专业毕业，本科3年以上工作经历，研究生2年以上相关工作经历；2、	熟悉SVM、回归分析、决策树、贝叶斯、XGboost等常用机器学习技术；3、	熟练掌握Java/Python/Scala编程语言中的一种；4、	熟练使用hadoop，hive，spark等工具，有相关数据挖掘、推荐系统算法项目经验； 5、	良好的沟通能力，需求分析能力，独立工作和解决问题的能力，良好团队协作能力。6、	有推荐系统、广告、搜索、用户画像、反作弊、预测算法等领域经验者优先。"
岗位职责：1、研究数据挖掘或统计学习领域的前沿技术，涉及机器学习、深度学习。2、打造AI人脸、物品和NLP等算法引擎，支撑前端AI数字人等AI应用3、基于对用户理解和大量数据特征，针对沃音乐亿级用户进行短视频等行业进行视频实时推荐、广告精准投放、行业深度研究及上线。任职要求：1、机器学习、数据挖掘相关方向本科及以上学历，NLP/推荐系统有经验者优先考虑；2、熟悉C/C++语言、Python、Java任意一种语言，较强的算法和数据结构功底；熟悉大规模数据挖掘、机器学习等相关技术,熟悉Hadoop/Spark/Hive技术优先；3、熟悉深度学习（如DNN、CNN、RNN、LSTM等）以及常见机器学习算法（逻辑回归、SVM、决策树、贝叶斯、GBDT等）的原理与算法，良好的编码习惯和工程优化能力4、良好的逻辑思维能力,优秀的分析和解决问题的能力,对挑战性问题充满激情；5、良好的团队合作精神,较强的沟通能力。
1.根据用户需求，负责产品的可视化开发；参与相关技术选型，推进技术架构演变和升级。2.了解相关系统的数据上下游关系，协助完成数据信息的梳理与数据模型的搭建。3.深入理解主要数据可视化展现形式，协助设计师完成可视化表达的视觉及交互设计。【岗位要求】1.计算机、美术、设计相关专业背景，有3年或以上流媒体开发或IPTV行业经验者优先考虑。2.掌握web相关技术，包括不限于JavaScript、CSS、HTML等。3.熟练掌握 SVG/Canvas/WebGL/three.js 等 Web 前端绘图技术及标准。4.有优秀的沟通能力、团队协作能力。【福利待遇】底薪30000元起，加高额的提成，提成最高可达20000元。【其它说明】1.招聘人数：1人。2.上班地点：广州海珠区丽影广场。3.本岗位签约完成既定工作任务的劳动合同。
职级：13~18级【工作职责】1.负责华为大数据平台设计和核心代码开发，软件架构看护，参与并贡献社区；2.负责流处理/Flink/Hadoop/实时风控/搜索引擎/协同计算/Hetu等产品设计和开发；3.负责大数据组件开源社区动态跟踪、竞争力分析和规划技术演进，看护开源社区发展方向。【业务技能】1.3年以上Java/Scala/Python/C/C++开发经验，熟悉Linux/Unix操作系统，熟练掌握常用设计模式；2.有分布式系统设计开发经验，能独立承担软件模块设计和开发工作；3.熟悉大数据相关组件Hadoop/Flink/HBase/Spark/Sqoop/Oozie/Flume/Kafka/Storm/Hive/Solr/Elasticsearch/Presto内核源码，系统性能调优和分布式架构经验优先；4.熟练掌握Spring MVC、容器等技术，理解SOA、微服务等关键理念与技术，并有实践应用经验。【专业知识要求】1.精通Java/Scala/Python/C/C++中的一种或多种；2.有完整的项目开发经验，具备系统核心模块看护经验；3.熟悉大数据基础知识，具有开源项目开发经验者优先，参与过开源社区贡献者优先。
大数据开发工程师岗位职责：1.数据湖的建设工作；2.参与数据仓库的迁移建设和数据质量监控建设工作；3.负责日常数据需求的开发和维护；4.负责数据建模和数据分析等工作；5.了解和研究前沿新技术。任职要求：1、本科以上学历，2年以上大数据开发经验；2、有Python开发经验；3、Hadoop，Mapreduce，Hive，Hbase，Yarn，Spark，hudi 能熟练开发；4、熟悉ETL工具kettle，Sqoop等，了解airflow5、有金融项目经验优先；6、较强的责任心和沟通能力。
1、大数据相关开发工作3年以上，有过实际大数据项目经验；2、熟悉hadoop、hive、hbase、ES等数据库架构和原理，有过实际开发经验；3、熟悉Flink、spark计算引擎的架构和原理，熟悉Flink SQL等批流处理，有过实际开发经验；4、具备ETL、数据治理、数据仓库等开发经验和能力，参与过大数据平台或中台的开发；5、熟悉JVM架构，具备JVM基础的调优能力，熟悉Spring微服务开发；6、具备良好的Java代码编写规范。
岗位职责:1. 承接业务团队的数据接入需求，对外提供稳定、高效的数据服务2. 负责公司数据接入平台的规划、设计、研发和落地3. 保持技术前瞻性，持续推动数据接入系统架构的合理性，负责团队研发能力的提升任职要求:1、计算机或相关专业，本科及以上学历，3年以上的spark、Flink等相关研发经验；2、精通spark、Flink原理、深入研究底层技术，具有很强的实际问题解决能力；3、精通Java，有Java相关软件开发经验，深入掌握JVM和并发原理;4、熟悉数据仓库、数据集市模型设计方法论，并有实际模型设计及ETL开发经验 ；5、主动性和责任心强，有良好的抗压能力，有强烈的学习/技术研究能力和良好的团队精神
工作职责：1、负责数据仓库开发及维护，包括ETL，数据集市构建，客户标签开发，数据加工和报表开发等；2、处理贷款、理财等业务的数据需求，为产品运营、营销和风控提供数据支持；3、参与常规报表和业务需求开发与维护；4、参与内部数据分析和应用相关的平台、工具开发和维护。工作要求：1、两年以上工作经验，本科以上学历，计算机相关专业优先；2、熟练掌握hive/spark等主流平台；3、熟练掌握Python/Scala，Java，shell中的一种或者多种；4、熟悉spark/flink等流处理技术者优先；5、熟悉银行业务者优先；6、具备开阔的互联网业务思维，对数据敏感，有良好的业务开拓和沟通表达能力。
1、本科及以上学历；2、较扎实的编程能力，熟悉数据结构和算法；3、熟练掌握SQL的使用，熟练使用Java、Python、Scala其中任意一种编程语言；4、熟悉数据仓库，数据分层建模理论，具备数据加工处理ETL的实施经验优先；5、熟悉Hadoop、Hive、Spark、SparkStreaming、Flink、ElasticSearch、Kafka、ClickHouse等大数据相关技术；备注：以上4、5点为加分项，如无相关经验，也欢迎投递简历，我们会给您学习和成长的时间，新入职员工有导师一对一辅导，帮您尽快融入团队。
1、负责数据仓库、数据集市模型设计开发，对数据敏感2、熟悉hadoop生态体系，精通hive，并具备hive调优能力，熟悉其他计算框架(spark、tez等)，熟悉常用olap产品和nosql产品如Doris，ClickHouse，Elasticsearch优先3、深刻理解BI开发相关技术，如数据仓库、建模理论、ETL、数据治理等4、精通python，java，scala其中一种编程语言5、具有良好的沟通能力及团队协作能力6、研究过大数据框架的运行机制、实现原理、源码优先7、对算法有一定了解的优先8、有电商行业经验者优先9、有搜推工作经验者优先10、团队氛围好，非常期待你的加入
岗位职责1、负责大数据平台的架构设计，核心代码开发等任务，根据项目要求编写相关技术文档；2、负责大数据平台的架构评审，代码评审，上线评审；3、负责核心模块的开发，大数据平台的搭建，完成项目调研与落地实现。任职要求1、熟悉spring boot、mybatis、spring cloud、Alibaba等相关组件；2、精通kafka、zookeeper等中间件，具备性能调优的能力；3、熟悉hdfs、mapreduce、yarn等hadoop组件；4、精通sql语言、opentsdb、TDengine、MangoDB、HBase、Hive、ES；5、熟练掌握flume、sqoop、clickhouse、ELK；6、精通spark、flink等实时计算框架；7、熟悉ETL过程，熟练使用至少一种ETL工具（Kettle、Talend、Datastage、Datax)；8、熟悉大数据数仓模型，可视化分析等；9、参与过数据仓库DWS以及数据集市(DM)类项目优先考虑。
岗位职责1、负责数据模型设计、数仓建设，维护和优化工作；2、负责对接部门内外数据采集、数据治理、数据分析需求，参与制定和执行对应大数据开发工作和对应计划文档输出；3、负责平台的整体数据架构设计，对数据有较高敏感性，完成从业务模型到数据模型的设计及开发工作；4、主导并推进项目的实施与落地，持续优化数据仓库及数据集市应用。任职要求1、本科及以上学历，计算机等理工科相关专业，2年以上大数据开发经验优先；2、熟悉数据仓库理论，具备复杂的业务需求梳理拆解、模型设计、全链路优化、项目管理能力；3、有较为丰富的SQL、ETL开发及调优等数据开发经验，至少熟悉Java，Scala，Python一种编程语言；4、熟悉大数据生态架构和基本原理，有相关使用和开发经验，包括但不限于：Flume，Kafka，HDFS，Kudu，Hive，Impala，Spark，Flink等；5、能够独立负责数据平台子模块的设计、开发、及部分管理工作。
工作职责： 1. 参与支付核心业务的数据仓库构建，以及业务数据分析开发工作；2. 建立金融级业务数据的ETL工具组件和配套平台，提供高效的数据资产管理和分析应用能力；3. 参与风控、营销、信用等场景数据分析，为业务提供及时准确高效的数据指标和效果跟踪，提升业务转化和产品体验；4. 与产品和运营团队一起设计和构建准确、完善、深入的指标体系，对数据进行深入分析和洞察，为业务规划和运营提供参考；5. 其他创新性的数据应用场景。 任职要求： 1. 本科及以上学历，2-3年以上数据仓库开发经验；2. 熟练掌握SQL语法，熟悉Hive、Oracle、MySQL常规数据库使用和性能调优技巧；熟悉数据仓库层次模型和数据集市理论，有TB级数据仓库使用经验优先；熟悉调度系统应用者优先；3. 熟悉Spark、Flink等计算框架的使用，对Hadoop生态相关系统有实战应用经验，具有快速构建业务应用的开发能力；4. 较好的业务理解和洞察能力，熟悉支付、信贷、财务等数据分析和模型者优先；5. 熟悉Python和Shell开发，掌握Java、Scala、Golang等开发语言者优先。
工作职责:1、参与金融科技数据产品的研发，工具开发和运营分析，能够针对数据计算过程中遇到的问题和瓶颈进行优化和解决;2、负责维护数据完整性，准确性，一致性和时效性，保证数据开发统计质量，提供数据统计，分析，查询，提取等服务；3、负责计算任务日常运维操作， 能够开发相应运维脚本和使用自动化工具， 对异常任务进行监控告警。职位要求：1、本科及以上学历，计算机相关专业毕业；3年以上相关工作经验；2、熟悉Linux环境下开发，熟悉Python和Java；精通熟悉离线计算和实时计算相关技术；3、熟悉Hadoop/Hive/Spark/Flink/HBase/Flume/Kafka/ElasticSearch/Redis等大数据相关技术栈，能在项目上熟练部署及应用；4、有相关数据治理和调优经验；5、熟悉数据仓库模型设计与ETL开发经验，掌握维度建模设计方法，具备海量数据处理经验；6、责任心强，学习能力优秀，乐于分享，良好的协作意识及团队精神，具有较强的跨团队沟通能力。
1、理工科专业，本科以上学历，要有两年以上大数据实战经验，有一定java代码能力。2、熟悉Spark 、Hadoop、Hbase、Hive、Elastic Search等相关技术;3、熟悉Scala、熟悉Linux开发环境，能进行shell脚本的编写;4、熟悉Oracle、Redis及Kafka等相关技术；加分项：1、深入了解Spark原理，阅读源码者优先2、具有实际大数据项目的成功经验者优先考虑。高级大数据开发岗位：岗位职责：1、最好有数仓架构相关经验。2、参与大数据平台整体架构规划，制定数据架构规范，指导团队落地，为数据仓库、数据应用提供技术支撑。3、参与数仓建设的规划和建设，ODS、DWD、DWS、DM层的数据建模以及方法论的沉淀。4、大数据平台服务架构和开发，包括行为采集、数据接入、任务调度、资源分配、元数据管理、自动优化、监控报警、大数据ETL组件、可视化组件以及数据服务等。5、负责基于Cloudera、Kafka、ES开源系统的大数据集群设计、开发、调优和维护。
【岗位职责】1、负责部署大数据平台，并进行性能调优；2、负责基于Spark Streaming技术完成流数据开发工作，以及基于Spark技术的海量数据的处理、分析、统计、挖掘工作；3、数据仓库系统的ETL设计、数据抽取、数据处理和数据展示等开发工作；4、参与系统需求分析、应用设计与开发以及测试与部署，负责编写模块代码。【任职要求】1、全日制一本及以上学历，985、211、双一流院校优先；2、精通spark开发，熟练掌握CDH，并解决相关问题；3、熟练解决Hadoop相关问题，根据业务需求作出系统调优；4、熟悉开发语言Java，Scala；5、大数据组件 HDFS、Yarn、Hbase、Hive、Spark、MR、Kafka、Redis、Storm、ElasticSearch、zookeeper、Impala、Flume；6、1年以上大数据系统开发经验，熟悉HDFS、Yarn、Hbase、Hive、Spark、MR、Kafka、Redis、Storm、ElasticSearch、zookeeper等，具有丰富的大数据平台工程经验 ；7、扎实的编程基础，精通java开发语言，了解jvm，web开发、缓存、线程池、分布式架构、消息中间件核心技术，熟悉maven、IntelliJ IDEA。【岗位优势】1、项目优势：自研产品，可参与建设新数据中台，成长空间大、机会多，为个人履历增色；2、企业优势：公司近3年保持20%以上的增长，16年来一直专注于自主核心产品研发；3、行业优势：G端业务，互联网+大数据+新媒体模式，赛道优质且稳定; 4、团队优势：自主研发团队，学习型组织，开放型文化，扁平化管理；5、培训及晋升：技术专家作为试用期导师一对一辅导，职业发展路径明确，初级工程师-中级工程师-高级工程师-主任工程师。
1、负责医疗业务数据采集、处理等工作，能用ETL工具进行常用的数据抽取、转换、清洗处理等操作；任职要求：1、有1年以上医院信息化项目实施、运维经验。2、善于数据库表结构分析，视图编写、存储过程编写。3、精通Oracle、Mysql等数据库，精通sql语言、sql程序编写。4、熟练使用ETL工具，熟练数据抽取脚本编写。5、学习能力强，能较快掌握和应用新技术，具备较好的独立解决问题的能力，思维活跃, 具有良好的工作态度和积极的团队合作意识, 能承受较大的工作压力。6、有医疗行业背景的优先
职责描述：1、负责大数据平台开发工作，包括离线数仓与实时数据的采集、清洗和加工。2、负责大数据平台数据仓库的建设，基于业务需求开发数据建模。3、负责大数据平台的日常运维管理，保障数据平台的稳定性。4、解决大数据平台的重大故障及性能问题，提升数据分析效率。任职要求：1、1年以上大数据相关开发经验，具备实时计算或离线数仓经验者优先2、掌握java或python等任一语言，具备扎实的编程技术基础。3、精通Hadoop大数据平台框架，精通HDFS系统原理，熟练掌握Flink、Hive、Hbase、Yarn等组件的应用，熟练掌握常用的ETL工具。4、熟悉Linux操作系统及命令，熟练掌握Shell编程开发。5、精通SQL，有较丰富的SQL开发经验。6、具备良好的沟通能力、较强的主动性及责任心。有海量数据系统开发、大数据性能调优经验者优先。备注：本岗位为荣耀自有员工，非外包。
岗位职责负责工业领域的大数据分析和建模及应用开发：1、负责数据分析、建模、技术实现等；2、对应用中的数据模型进行跟踪、调整和优化；3、开发基于Hadoop/Spark/storm/flink生态的大数据定时/实时应用程序；4、参与业务数据、生产日志的抽取、转储、检索等相关工作；5、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景；任职资格教育：计算机、信息系统、数学、统计学等相关专业全日制本科学历技能：1.了解数据采集、存储、清洗、分析及挖掘等方面的相关技术2.了解大数据平台运行的环境配置及安装部署方式3.了解多项大数据处理/分析相关的工具/框架，如Hadoop、 MapReduce、Hive、Storm、Spark、flink、kafka及HBase等经验：1. 2年或以上大数据开发经验，计算机或相关专业本科以上学历；2. 具备工业领域大数据建模、大数据分析，大数据研发经验者优先
1. 负责公司大数据平台及应用平台的设计、开发、环境搭建、调优及故障诊断； 2. 支撑多样的海量数据分析场景，负责底层大规模数据的存储、索引、分析、推荐和实时查询功能设计和开发； 3. 基于海量特征数据，挖掘用户标签和构建用户画像，建立数据模型，用数据推动业务发展； 4. 熟悉互联网项目开发流程，能够跟进数据项目从需求分析到产品展现的完整流程并且能够保证数据质量； 5. 参与数据指标体系建设，制定相关规范及标准流程的改进，制定合理的工作计划，并在执行过程中管理风险； 岗位要求： 1. 本科及以上学历，计算机相关专业，3年及以上大数据平台研发经验； 2. 精通Hive、HBase仓库设计，深刻理解MR运行原理和机制，能进行任务执行效率的优化； 3. 熟悉掌握Hadoop、Hive、HBase、Impala、Spark、Flink等大数据技术栈； 4. 具备扎实的SQL经验(熟悉Hive sql、Spark sql优先)，至少精通一门开发语言，如Java、Scala等； 5. 有Owner精神，善于沟通，主动性和责任心强，对数据敏感，逻辑性强，有良好的抗压能力，有良好的团队合作精神； 6. 有大数据分析处理、数仓系统建设经验者及海量数据处理经验者优先； 7. 有分析、搜索、推荐或相关大数据算法工作经验，同时做过离线和实时业务经验者优先；
职责要求：1、掌握Scala/JAVA语言,熟悉Linux,熟悉分布式数据库开发（Distributed Database Development）,2、本科及以上学历，3、从事大数据（BigData）,工作1年以上4、熟悉Hadoop,Spark等组件的运行机制与原理
岗位职责：1、根据公司业务特色进行数据中台的需求分析、架构设计和核心功能开发；2、根据公司业务特色进行数仓分层，实时和离线分析架构设计和开发；3、负责分布式任务调度系统、数据治理，监控系统的设计和开发；4、根据公司业务特色，进行数据挖掘，输出潜在用户的画像和对促进业务增长的数据。5、负责智能推荐以及为公司其他系统赋能的架构设计和开发任职要求：1、本科及以上学历，计算机相关专业;7年以上互联网行业大数据相关工作经验；2、掌握大数据实时和离线分析核心原理；熟练掌握Hadoop,HDFS, HIVE, Spark,Storm,Flink，cassandra, hbase、ElasticSearch等常用的大数据系统或分布式式计算框架；3、具有优秀的团队合作和沟通表达能力4、具有抗压和攻关大数据领域的疑难问题的能力。 5、热爱新技术，能根据当前的实际需求采用合适的技术框架。6. 有医疗行业，DICOM领域知识的，优先考虑。
岗位职责:1、 负责商业智能BI分析，数据需求分析，报表开发，数据提取；2、 负责搭建数据集市，建立各类部门的数据主题及分析模型，转化成能够支持决策的价值数据和报表；3、 设计和实现报表和图形展现。任职资格:1、本科以上学历，3年以上集市和报表开发工作经验；2、有独立的BI分析和设计经验，能够独立承担单个或系列商业智能应用产品的分析、设计和开发工作；3、有海量数据处理和优化经验，熟悉oracle/mysql等关系型数据库；4、熟悉hadoop集群，Spark架构，hive等大数据技术优先；5、工作认真负责，有良好的团队合作精神和沟通协调能力，能够承受一定工作压力；6、有电商零售行业经验优先。
1、熟悉 Hadoop、Spark、Flink、HBase、ClickHouse 的原理，不限于一种的OLAP类型的熟练掌握部署，维护,性能优化2、 可以熟练使用 shell 以及 python/golang/java 3、 掌握数据可视化配置4、 熟练Elasticsearch性能优化,以及多库同步DTS5、 参与过数据仓库,数据湖的实践6、熟悉 Linux 系统环境的配置和优化，熟练部署各种应用服务，能够独立处理系统故障者优先7、 具有数据治理、数据中台搭建经验者优先（如元数据管理、数据安全、即席查询等）8、拥有大数据组件深度调优、监控经验者优先；9、实时运算,离线运算经验丰富者优先录用
职责描述：负责腾讯游戏的数据处理、数据统计、数据分析与挖掘等，利用数据辅助产品运营决策；负责腾讯游戏的数据指标体系建设，制定游戏数据统计与分析的标准；负责腾讯游戏的数据应用的、数据开发工作；任职要求：本科及以上学历，3年以上数据处理、分析相关项目经验；参与过完整的数据采集、数据清洗整理、数据可视化、数据分析和建模工作者优先；熟练使用SQL，Hive等技术，了解Hadoop工作原理；有Storm、Flink、Spark等实时计算统计开发经验、API接口开发经验者优先；对数据敏感，有良好的逻辑思维能力，较强的沟通能力和团队合作精神，勇于承担工作压力。
工作职责:1. 参入大数据平台相关产品的设计和研发。2. 具备较强的产品化和平台化能力，对大数据平台建设有一定认识。岗位要求1. 对Java 语言基础有良好的掌握，对面向对象软件开发有较深入的认识。2. 有良好的编程习惯、熟悉代码规范、简洁清晰的代码风格。3. 熟悉Linux操作系统，熟练使用Shell/Python一种脚本语言。4. 熟悉Hadoop生态相关技术，熟悉Hadoop、Hive、Hbase、Spark、Storm、Flink等一种或者多种数据处理技术，熟悉相关源码或者有系统调优经验者优先。5. 熟悉Mysql、Redis等常用数据库。6. 有大数据平台开发经验、分布式数据存储或计算平台应用开发经验者优先。7. 有较强推动能力、沟通能力，能够主动影响推动相关工作进展优先非诚勿扰！
1.本科及以上学历，计算机专业3年以上工作经验，非计算机专业5年以上工作经验，计算机或相关专业者优先；2. 至少精通python/Java/Scala中的一种编程语言3. 精通数据仓库分层和建模，熟悉Hadoop大数据相关组件Flink/kafka/spark/hive/es等，有华为云服务经验者优先4. 有实际的智能推荐相关项目经验，包括不限于：推荐系统、用户画像、计算广告、搜索引擎5. 至少从事大数据及数据挖掘开发3年以上第2个必要条件，3,4满足其中一个即可6、要求毕业证、学位证证件齐全，并提供学信网核查截图，
技能要求：1、熟练掌握SQL语言，有SQL性能调优经验者优先2、熟练掌握Scala/Java编程语言，具备扎实的编程能力3、熟悉常用的Linux命令4、熟悉Hadoop相关技术，了解HDFS、Spark、SparkSQL等组件的原理和使用方法6、有Spark、GreenPlum等数据库开发经验者优先7、有较强的学习能力、沟通能力，良好的团队协作精神，极强的责任心8、本科学历，相关工作经验1年及以上
岗位职责： 1、基于大数据平台的应用系统设计、开发、维护； 2、承担公司大数据相关项目的需求分析、开发、实施、现场支持。 任职要求： 1、计算机或相关专业本科及以上学历； 2、3 年以上相关工作经验，至少熟练掌握Java，Scala，Python中的一种或多种； 3、熟练使用Hadoop、Spark、Storm、SparkStreaming、Hive、HBase 进行应用开发； 4、熟悉搜索引擎，例如Impala，Presto，Elasticsearch等； 5、具备基本的Hadoop运行环境的运维管理经验； 6、有实际的大数据应用工程开发经验；
岗位职责：1.  负责与海外发行商沟通和理解当地游戏运营数据需求, 制定海外数据需求开发规范2. 负责游戏的数据运营指标体系建设,  参与制定海外游戏数据治理与资产建设的标准；3. 负责游戏数据处理、数据统计、数据分析等开发工作，通过数据辅助产品日常运营决策；4. 负责游戏运营活动中实时数据应用的数据开发相关工作, 支持游戏日常运营活动数据服务; 岗位要求1. 研究生2年、本科3年以上数据处理、分析相关项目经验；2. 熟练使用SQL，Hive等技术, 具备storm、flink、spark等实时计算计算开发经验；3. 熟悉linux操作系统开发环境，熟悉java、Python、Golang等一种计算机语言；4. 对数据比较敏感，具备良好的逻辑思维能力，沟通能力和团队协助作精神;5. 具备英语沟通能力加分
岗位职责：   负责公司级平台的数据清洗以及数据分析      岗位要求- 本科及以上学历，扎实的计算机专业基本功，编程基础扎实，对代码质量有追求;- 2年以上scala开发经验，熟练使用scala开发spark任务- 熟悉常见设计模式，熟悉Spring，SpringMVC,Springboot,SpringCloud ,MyBatis等流行开源框架，深入了解其原理和实现机制;- 精通MySQL应用开发，熟悉数据库原理和常用性能优化技术，以及NoSQL、Queue 的原理、使用场景以及限制;- 熟练掌握大数据处理技术栈优先，有丰富的Hadoop/Spark/SparkStreaming/Storm/Flink的实际项目使用经验。- 能够独立或协同，高质量按期完成项目;- 有较强的逻辑思维能力，善于分析、归纳、解决问题，持续学习和总结，自我迭代
岗位职责：1、承担建设基于Hadoop/Spark生态的大数据离线/实时处理平台；2、参与业务数据、生产日志的抽取、转储、检索等相关工作；3、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景；任职要求：1、本科以上学历；2~3年互联网大数据处理经验；有实时处理工作经历并有一定解决方案者优先；2、熟悉大数据开源技术，包含（不限于）Hadoop/Spark/Spark Streaming/Hive/Hbase/Impala/Flume/Kafka/Solr/Es分布式框架/计算/存储/检索等相关技术,并有一定的Hadoop生态系统运维经验；3、掌握Python、Java等开发语言；4、掌握SQL，SparkSQL进行数据开发；较好的SQL性能调优经验；5、优秀的分析、解决问题能力，充分的数据敏感度；有一定的高性能支撑经验和故障排除能力；6、具备强烈的工作责任感，喜欢钻研，态度乐观，团队意识强。
工作职责负责安全相关大数据的接入、处理、分析和挖掘工作负责部门内部和外部离线和实时大数据开发pipeline系统的整合与搭建负责内部大数据平台系统配套运营开发工作要求计算机相关专业毕业，3年以上大数据开发经验；熟练掌握hadoop/spark/hive/flink等常见离线和实时大数据平台架构，有过相关大数据系统开发、维护和整合经验的优先；编程基础扎实、动手实践能力强，至少熟练掌握一门开发语言（python/java/go/scala/c++等），熟悉hive sql使用；熟悉常见的大数据开发工作流，熟练掌握大数据接入、数据清洗、数据挖掘分析&数据可视化工具，有过大数据治理相关工作经验优先；了解常见的机器学习算法基本原理，熟悉安全攻防对抗、广告安全对抗等相关业务场景优先具备良好的自主学习能力、沟通能力和规划能力，积极乐观向上
工作内容：1、负责大数据平台的设计、建模、代码开发和测试；2、规划大数据平台的架构和部署需求，把握系统的高可用、扩展、安全、性能、伸缩性等；3、及时与产品经理/项目经理沟通需求，分析梳理业务场景，协助需求侧解决各种业务实现问题；4、负责核心技术难题的攻关，攻克团队遇到的技术难题，持续对线上系统进行性能优化及稳定性提升；5、参与对平台的运维和运营的支撑体系的制定和实施，对线上突发问题进行及时响应并解决；6、负责大数据团队建设及管理，技术文档输出，根据业务发展组织技术预研，并对技术团队布道。岗位要求：1、本科及以上学历，2年以上相关工作经验；2、热衷于产品研发和技术创新， 具有很强的学习能力并有强烈的责任意识和开放的心态， 工作态度好，积极向上者为先；3、具备大型分布式、高并发、高负载、高可用系统设计、开发及调优经验，有大数据平台 的软件开发、部署经验；4、熟悉 Hadoop 生态圈技术栈，HBase、Hive、MapReduce 等；熟悉 Flink、Spark、Storm、Kafka、 Zookeeper、K8S 等开源组件，具备开源项目集成开发经验优先；5、熟悉容器、人工智能、微服务等新技术，有互联网运营平台架构设计或大数据公司同类 平台或产品设计、开发经验者优先。
岗位职责：1、负责大数据平台架构，进行全局性和前瞻性的架构设计，以及核心技术细节的实现，推动数据采集、数据计算、数据仓库、数据模型、数据治理及相关标准规范的建设和实现；2、负责规划大数据平台能力产品化，为业务提供数据交换，数据服务，数据开发等能力；3、负责数据分析平台规划，推动数据分析、数据挖掘、数据可视化在大数据应用项目中的落地；4、负责大数据平台平台的持续的创新和优化，研究跟进大数据领域新技术；任职要求：1、3年以上大数据架构设计经验，熟悉大数据解决方案，本科及以上学历，计算机专业优先。2、熟练掌握Java、scala、python等主流编程语言、3、 熟悉业界主流大数据处理技术，有丰富的分布式计算平台模型架构(Hadoop, Hive, HBase, Spark /Flink，Sqoop，Flume，Kafka，ZooKeeper，Elasticsearch等)经验，有过从 0 到 1 搭建数据平台的经验；5、具有良好的业务理解、沟通和协作能力，具有较强的学习和总结能力 ；6、 机器学习技术、数据挖掘经验丰富者优先考虑。7、熟悉springboot、Spring Cloud等主流的微服务框架优先考虑；
岗位职责：主导数据采集平台、数据传输平台、存储计算平台、数据分析平台、数据治理等平台的核心研发，故障处理以及平台客户的技术支持。任职要求：1、计算机及相关专业本科及以上学历；8年及以上相关工作经验；2、具有全栈开发能力，对于算法/前端/运维/测试等有深刻理解；3、熟悉网络编程、多线程编程技术；4、精通常见的数据结构和算法，熟悉linux平台； 5、精通以下至少两种脚本语言或编程语言：Perl、Python、Ruby、shell、C++、Java、.net；6、精通Python/Java/Web开发和主流开发框架； 7、精通开源大数据技术栈，精通Hadoop、Spark、Flink、flume、hbase等组件，并具备性能调优经验；8、具有后端系统研发经验及基础架构开发经验；9、熟悉Mysql、时序数据库，具备对事务，分库分表，性能优化等基本技术实施能力；10、具有研发团队管理经验及强烈的技术热情；11、熟悉主流的开源研发工具、研发管理工具及研发管理流程；12、具有优秀的学习能力、抗压能力、逻辑思维能力及沟通能力；13、善于与跨团队协作；积极进取；为人诚实、待人真诚；具备15人以上研发团队的管理经验。
岗位职责：1. 负责 Gitee.com 数据报表系统研发；2. 负责数据采集与预处理、数据存储、数据清洗、数据查询分析和数据可视化；2. 负责制定代码规范、测试规范，保证开发质量控制，撰写技术文档；3. 计划、协调和沟通，驱动开发团队紧密合作，高效项目执行，达成团队目标。职位要求：1.全日制本科及以上学历，计算机软件及相关专业毕业，至少3年以上开发经验，2年数据分析经验。2.会Java/Go/Python，精通SpringBoot、Hibernate、MyBatis、Kafka、Redis、MySQL等通用技术栈。2.熟悉 Druid、ClickHouse、Spark、 Storm、Spark Streaming 等数据分析技术。3.熟悉Linux、Git原型与操作，掌握GitFlow工作流程4.具备一定架构设计能力，提升系统性能、稳定性、可用性和扩展性5.可独立承担某一产品线或项目，负责业务需求分析、系统核心方案设计和代码编写9.有较强的沟通能力，逻辑分析能力，做事积极主动，自我学习能力强。加分项：DevOps 经验的优先
岗位职责：1、与产品经理和业务方一起，完成需求的理解，并根据需求输出系统解决方案，梳理和输出需求涉及的指标体系。2、带领团队，完成基于大数据平台上的应用开发及数据产品交付3、负责解决数据开发的核心技术问题，比如性能、质量控制4、负责数据产品的迭代和交付及财经领域的指标体系输出岗位要求：1、全日制本科及以上，要求计算机及相关专业2、具有3年及以上Java/Spark项目设计、开发经验；3年及以上大数据开发经验；有5人及以上中小型数据开发团队管理经验3、具备扎实的SQL、Java基础，理解SQL优化、IO、多线程等基础框架；同时对数据中台项目有一定的了解和建设经验4、熟悉掌握Spark、Hadoop、Kafka、Flink等开源框架原理，具备一定的Trouble Shooting能力；熟悉掌握 MongoDB、Elasticsearch、Redis 等技术；5、熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制；掌握多线程及高性能的设计与编码及性能调优6、掌握 Linux 操作系统及shell脚本7、对数据中台建设的落地有实践经验的优先，有DAMA数据管理知识理论体系的优先，有华为财经项目经验的优先
腾讯运营超大规模系统，随之而来带来了百万级机器实例，云存储、云数据库等超大规模运营性挑战。在这里，你有机会理解这些挑战，和大牛们一起进行创新性的思考，以产品化、平台化的方式，结合云原生等科技，站在行业视角来解决大规模系统运营挑战。超大规模系统产生了PB级别数据，理解、分析、和解释这些数据是迈向智能化运维的基础。在这里，你将要挑战最新的数据仓库架构，超大规模数据挑战，超大规模模型训练等；为技术产品赋能。- 以高级数据开发工程师的身份参与到整体数据平台建设，主导PB级别数据中台建设；- 与产品、开发、运维、测试相关团队紧密协作；持续理解、改进超大规模运营产品的自动化和智能化挑战；- 以统一基础设施为基础，建设统一数据标签、规范，建立集中式PB级别数据采集、加工、存储、和处理平台；- 建设统一数据分析和训练平台，与业务方共建，以数据赋能业务；- 以生态化的方式参与开源社区建设，影响开源项目发展。工作要求- 统招本科及以上学历，计算机或相关专业，善于与他人合作，学习能力强；- 3 年以上大规模数据中台建设经验，熟悉Apache Hudi/Iceberg/Spark/ClickHouse 者优先；- 有开源经验者优先，有业界知名相关数据类开源项目经验者优先。北京/深圳可选
【岗位职责】1.负责分布式数据平台建设、数据仓库各子系统开发2.负责海量数据处理与开发工作，满足各类数据应用需求3.系统的性能分析与系统优化，不断提高系统运行效率【职位要求】1.本科及以上学历，通信或计算机相关专业；2.熟练java开发，能够独立搭建Hadoop集群；3.能够独立编写Map-Reduce代码；4.熟悉大数据相关组件，如：HDFS、Hive ；5.熟练SQL开发，熟练Mysql、Redis数据库中的一种；6.熟悉Linux系统，具备Shell、Python、Scala等脚本开发能力；
"岗位职责：	1. 负责大型智能视频图像处理平台产品的大数据计算、分析相关的研发工作。参与完整数据链路，包括基于视图的聚类技术开发、视图数据ETL开发等；2. 支撑智能视频图像大数据处理平台相关的项目落地工作，包括大数据应用相关的解决方案设计，解决复杂技术问题；任职要求：1. 熟练使用python/java/scala中的一种或多种开发语言；2. 具备分布式大数据处理系统、数据仓库的开发经验及海量数据处理经验者优先；3. 熟悉大数据平台生态圈，包括但不限于flink/spark/kafka/cassandra/clickhouse/nebulagraph/hadoop等第三方组件，以及k8s/docker等容器技术；4. 具备快速学习能力、较强的沟通表达能力、抽象总结能力、跨团队协调能力。善于分析复杂问题，逻辑清晰；5. 自驱力好，善于发现问题和解决问题。"
岗位职责：1、负责数据类软件项目的需求分析、设计、开发等工作。岗位要求：1、计算机相关专业，大专及以上学历，3年以上相关工作经验；2、有一定的Java开发经验，技能域偏重服务端方向，能独立完成主流数据接口集成开发；3、熟悉Hadoop 生态圈常见开源组件应用以及开发模式，有 Flume、Kafka、Spark、Hive、Flink实战项目处理数据经验；3、熟悉主流数据库的使用及开发，包括MySQL, postgreSQL, Oracle, SQL Server, MongoDB,  Elasticsearch 等；4、熟悉至少一种主流的开源ETL工具，如  Kettle，Apache Airflow，Apache Nifi 等；5、具备优秀的团队意识和沟通能力，有较强的学习能力和钻研精神。公司福利：1、高频率的小组团建，体育锻炼活动。定期组织优秀员工，管理干部海外团建；2、多种类型的技术与管理岗位选择，职业规划辅导，专业性技术与管理培训；3、年假10天起，按工龄增加。五险一金。商业保险。双休。
工作职责1、负责需求技术方案分析、转化为开发任务； 2、对所负责的软件程序进行设计和技术验收、代码复审； 3、组织人员进行软件开发和单元测试，及时解决发现的问题； 4、负责新技术/架构演进、推广； 5、其他安排的工作。任职资格1、本科及以上学历，计算机相关专业； 2、2年以上大数据开发经验，有海量数据开发经验优先； 3、熟练掌握hadoop/spark生态体系，深入理解HDFS和MapReduce原理及优化技巧； 4、具备强悍的编码能力，熟悉Linux环境，工程实现能力强； 5、熟练掌握数据仓库概念，精通Oracle或者Mysql SQL，有使用一种ETL方式经验优先； 6、熟练掌握数据仓库开发从需求沟通、标签定义、mapping规范、编码开发、测试验收、版本移交到生产验证整个流程； 7、对于大数据相关组件：Hadoop、Storm、Spark、Hbase、Hive、ElasticSearch、Kafka、Flume等架构与底层实现有一定的理解，具有相应的研发能力。
【岗位职责】1、 负责数据仓库、大数据方向开发工作；2、 负责数据仓库OLAP体系搭建，建设百TB级高效、灵活的在线分析应用；3、 处理日常数据需求开发，与数据产品、用户一起感知变化，实现高效的数据运营；4 、与小伙伴们一起调研实践数据仓库组件及新技术(如实时数仓、数据治理等)；【任职资格】1、本科以上学历，统计/数学/计算机相关专业；2、2年以上ORACLE/数据仓库/BI/大数据相关工作经验；3、熟悉主流的大数据平台框架及组件（Hadoop、Spark、Hive、Kafka、Flink等）；4、熟悉数据仓库建设方法与主流ETL(KETTLE、Sqoop等)和报表工具(BIEE、SmartBI、帆软)的相关技术；5、对新技术有孜孜不倦的热情，具有良好的学习能力、团队协作能力和沟通能力；能在Linux下完成常用的问题查询任务。【关于研发团队】目前公司研发体系大约有100人左右的团队，团队氛围非常nice，队友们超好相处，技术氛围浓厚，技术大牛多【关于福利】自由的上下班时间；工资全额12%的公积金；跑团、篮球、羽毛球、读书会、桌游、聚餐等日常活动随时安排；团建旅游；年度年费体检……
工作职责：1、针对数据支撑类业务，提供数据分析、数据接口、基础模型、汇总模型、ETL流程等设计和开发；2、参与数据仓库模型建设与管理，参与制定模型开发规范、数据治理规范并推进落地；3、负责数据源调研、入库、离线和实时数据处理的全流程开发工作，并保证数据质量。任职资格：1、统计-应用数学-计算机-软件工程等相关专业本科以上学历，5年以上大数据开发岗位经验；2、熟练掌握Java-Python-SQL等编程语言，熟练掌握维度建模理论，具备业务数据调研分析、仓库模型设计的能力；3、熟悉Hadoop生态系统组件，如Hdfs-Hive-HBase-Spark-Flink-Kafka-ES等，有Flink开发经验者优先；4、具有较强逻辑思维能力、研究能力、沟通能力和团队合作精神。
岗位职责：1、 负责大数据分析平台的搭建、优化和维护；2、负责根据具体的数据需求，进行数据模型的设计。3、根据项目需求，设计验证方案，并进行模型验证。4、负责大数据团队的能力建设任职要求：1、具备大数据平台架构设计能力；2、本科及以上学历，计算机或者数学相关专业，3年以上相关工作经验；3、熟练掌握Hadoop、spark、ELK等大数据存储与分析技术；4、熟练使用建模工具，有相关的数据挖掘、统计分析经验优先；5、良好的Scala编程经验，有python经验优先；6、主动积极，思维清晰，有较强的沟通能力，拥有良好的编程习惯；7、优先考虑熟悉AWS相关大数据相关产品，如EMR,S3,Redshift等
工作职责：1、基于对业务深入全面的了解抽象业务核心逻辑，梳理和设计数据指标体系，建立数据分析模型，输出符合业务需求的数据分析框架和分析报告，辅助业务决策；2、将数据分析思路和框架沉淀为数据产品解决方案，策划数据产品并推动落地，提升各团队的数据化和智能化程度。3、配合项目发展，为产品发展提供相关数据平台，规范数据生产到使用全过程，加速数据生产效率，提升数据服务质量职位要求：1、本科及以上学历，数学、统计、计算机专业优先；2、2年以上金融数据分析和数据体系建设相关工作经验；年龄33岁以下；3、熟悉Python语言，熟悉SQL脚本编写，有海量数据分析处理经验及大数据分析计算平台的开发经验者优先；4、熟悉Hive、MapReduce、Storm、Spark、HBase等Hadoop生态系统，具有实际使用经验，具备一定Sql调优能力；5、熟悉熟悉Java/C++开发语言，熟悉SpartStream、Storm、Flink等流计算开源软件，具有实时计算平台开发经验者优先； ；6、具有强烈的责任心以及团队合作精神，具有较强沟通能力，抗压能力强，积极主动；7、对数据敏感，擅长分析总结，能通过数据分析独立给出优化建议，有证券、基金行业从业经验者优先。
1.对标开源社区的组件性能开发，例如HBase Hadoop spark hive等，2.对标业务的业务开发，例如数据清洗，数据治理，数据中台等。3.服务后端开发，就是针对客户的实际业务场景进行功能开发。
基于Hive， Spark，Hadoop的计算架构，进行大数据开发工作
工作职责:1、负责企业级数据架构设计，MDM、ODS数据仓库等的架构设计；2、参与数据集市、数据服务设计、模型设计与程序开发；3、负责数据应用系统与解决方案的规划设计；4、负责数据治理规划与推动；5、解决项目中的技术难题。任职资格:1.熟练掌握 Java/Scala/Python 中的一项或多项编程语言；2.熟悉 Hadoop 生态体系，包括但不限于：Hadoop、Hive、HBase、Spark、Flink、Kafka 等并有相关项目经验；3.熟悉OLAP引擎ClickHouse，Doris；4.了解分布式系统、大数据平台，有5年以上大数据开发从业经验和完整的数据工程项目经验。5、金融行业从业经验
1. 负责用户画像系统实时方案架构建设，优化系统稳定性、性能、容量、吞吐量2. 负责离线画像系统架构建设，优化离线数据流的稳定性和效率，推进离线数据快速、准确的应用到线上任职要求1. 计算机相关专业，本科及以上学历，有3年以上线上高并发服务开发经验2. 熟悉大规模推荐、广告系统架构、用户画像系统、DMP，做过复杂业务场景的重构或者优化者优先 3. 扎实的数据结构和代码功底，熟悉Java/C++以及Linux开发环境，熟悉SpringBoot，Dubbo等微服务技术，有高并发系统设计及支撑经验者优先，熟悉Flink/Spark、hadoop、Kafka、ES/Clickhouse等大数据组件者优先4. 目标导向，数据驱动，善于结合具体业务场景，抽象解决有挑战性的问题5. 有优秀的逻辑思维能力，对技术有热情，有较强的沟通和推动能力

职位描述岗位职责:1.负责电商供应链数据仓库及模型建设和设计，并根据需求变化和业务发展，持续优化模型；2.负责电商供应链数据仓库模型代码开发、部署，并对数据质量进行管理和优化；3.提升电商供应链数据质量和运营效率，参与相关事件应急响应；4.参与大数据体系的建立以及配套系统平台的建设与运营。岗位要求：1.计算机或信息技术相关专业，大学本科及以上学历;2.3年以上大数据数仓开发相关工作经验；3.有扎实的数据仓库理论功底和丰富的数据治理实战经验，能够围绕业务和产品特性建模并解决实际问题；4.熟悉大数据系统组件(如Hive、MapReduce、Spark、HBase等)，具备编写、优化复杂SQL的能力；5.掌握实时处理技术相关组件(如Kafka、Flink等)，具备编写优化能力；5.负责过大型数据平台或数据仓库设计优先。
【工作地点】深圳、南京、西安【工作职责】1、深度参与到华为大数据Hadoop、Yarn、Spark、Hive、HBase、Kafka、Zookeeper、Flume、AI平台等组件的研发、交付及解决方案支撑；2、探索云服务化实现的前沿技术，并负责华为云大数据服务的架构设计、开发、测试及运维。业务技能要求：1、熟悉大数据相关开源软件，有应用大数据组件的解决问题的实战经验更好，有开源社区代码贡献者优先；2、具备团队意识，与他人合作良好，最好具有团队协作的经验。专业知识要求：1、精通JAVA软件开发，有软件开发项目经验；2、至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Python/Shell等编程语言及脚本语言。
岗位职责:1、负责云客大数据平台的设计与开发，解决海量数据面临的挑战； 2、技术预研、探索并应用大数据、人工智能等前沿技术。任职要求：1、三年以上大数据离线、实时开发经验，本科及以上学历；2、精通开源大数据框架（如Hadoop、Spark，Storm等），熟悉公有云大数据平台（阿里云、AWS等）；3、精通Java/Python等至少一门开发语言，熟练掌握数据库基本原理；4、掌握机器学习算法，有TensorFlow实践经验的优先；5、性格开朗，具有良好的沟通协调能力和团队合作精神，乐于且善于学习新知识新技术。
职责描述：1、承担大数据关联分析产品的软件设计与开发；2、承担大数据与机器学习融合方案的软件设计、模型选型与代码开发；任职要求：1、本科及以上学历，计算机或数学相关专业，深入理解数据结构，有算法项目开发经验优先；2、Java/C++/Golang开发经验，有3年以上独立系统设计和研发经验，熟练使用Linux系统3、熟悉数据库的基本原理，精通SQL的使用4、具备大数据相关知识，熟练使用Hadoop体系的开源组件，特别是Flink、Spark、Hive、Kafka、HDFS等；5、具备大数据软件性能调优能力，具有海量数据系统开发经验者优先，开源社区项目代码贡献者优先。
工作职责：1、对接金融行情数据（包括期货、股票等），参与流批一体数仓的建设、维护和性能提升；2、遵循DRY原则，坚持把代码打磨至简；3、对海量数据进行实时/离线处理，保证大规模的离线、实时任务的稳定运行；4、乐于了解和研究新技术，并把新技术应用于实际开发；5、乐于分享和交流，与团队共同提升技术能力、攻克技术难关。岗位要求：1、大学本科及以上学历，计算机相关专业，1~3年开发相关工作经验；2、精通Java、Kotlin等语言，熟悉Linux常用命令；3、熟练主流开源大数据工具，包括但不限于Hbase、Kafka、Redis等相关经验；4、有大数据处理分析经验，熟悉Flink/Spark等大数据处理引擎的原理和使用；4、熟悉网络协议，能熟练使用fiddler/Charles等工具进行调试；5、有较强的逻辑思维和归纳总结能力，态度认真负责，做事积极主动。
岗位职责：参与在线视频视频BU平台治理工作，利用技术手段挖掘负向场景，包括但不限于：1.梳理业务数据体系，进行数据加工pipeline搭建；2.建设平台治理相关指标体系、数据报表体系，关注数据波动并及时分析；3.通过离线策略识别平台低质、虚假的账号/设备，构建账号/设备风险库；岗位职责：1.1年以上数据分析或数据科学相关工作经验，具备信息安全从业经验尤佳；2.计算机科学、数据科学、统计学、应用数学等领域本科及以上学历；3.敏锐的数据洞察力、严谨的逻辑思维能力和系统的分析总结能力；4.精通SQL/Hive语句，熟悉map-reduce原理，有Hive优化经验者优先；5.有Hadoop、Spark等平台的海量数据处理经验者优先；6.有流量反作弊，黑产对抗经验者优先。
岗位职责：1、基于flink、spark对数据进行实时/离线分析。2、通过数据分析，为线下店赋能。任职要求:1、深入了解 flink、Spark原理，阅读过源码者优先2、熟悉Hadoop、Hive、Hbase、kafka等大数据技术3、精通Python、Java、Scala中至少1-2种开发语言4、具备实际的大数据业务开发经验以及良好的项目沟通和协调能力5、有车联网行业经验者优先。
岗位职责1.负责大数据平台的基础环境搭建、优化和维护2.负责大数据平台的多源数据采集、存储与可视化展示3.负责代码编写、bug维护、设计文档编写岗位要求1.本科及以上学历，2年以上大数据开发经验2.掌握Java/Scala/Python其中至少一种编程语言，3.熟悉Hadoop、Hive、HBase、Spark、Flink、Kafka等4.有电子电商大数据相关工作经验优先
大数据开发工程师   工作职责：熟悉 Hadoop、Spark、Flink、HBase、ClickHouse 的原理，不限于一种的OLAP类型的熟练掌握部署，维护,性能优化- 可以熟练使用 shell 以及 python/golang/java - 掌握数据可视化配置- 熟练Elasticsearch性能优化,以及多库同步DTS- 参与过数据仓库,数据湖的实践- 熟悉 Linux 系统环境的配置和优化，熟练部署各种应用服务，能够独立处理系统故障者优先- 具有数据治理、数据中台搭建经验者优先（如元数据管理、数据安全、即席查询等）- 拥有大数据组件深度调优、监控经验者优先；- 实时运算,离线运算经验丰富者优先录用-计算机专业
岗位职责：1.参与数据应用建设，如管理驾驶舱、数据大屏、风控、推单等2.参与各类专题数据分析工作，如用户转化分析、数据质量分析、异常业务分析等3.与产品、业务、研发、数开、算法团队协同完成数分部分工作4.提升所负责模块的数据驱动业务能力5.参与大数据算法模型的设计、落地及调优技能要求：1.本科或以上学历，数学、计算机等相关专业优先；2.精通sql、python、SAS、Tableau、PowerBI、FinBI等相关分析工具；3.熟悉常用数据分析方法、模型，并运用于日常工作中；4.曾主导过一个或以上数据分析项目，如用户画像、风控、CRM、数字化运营等；5.熟练使用大数据生态组件，如：Spark、Flink、Hive、Kylin等；熟悉olap数据库，如：Doris、ClickHouse6.具备良好的解决问题能力和思维逻辑能力，善于从数据中发现问题、得出结论、指导决策、驱动业务；7.加分项：了解机器学习建模的原理和过程，有算法项目落地经验
高级大数据开发工程师（2023年3月才能入职，介意勿投）岗位职责：　　1、负责核心技术问题攻关，建设高可靠性，扩展性及高性能大数据/数据应用平台;　　2、参与数据中台与数据应用的建设。　　3、制定数据治理领域的管理规范，包括元数据管理、数据标准、数据质量、数据安全等工作，确保数据可信与安全。 　　任职要求：1、计算机相关专业全日制统招本科及以上，5年以上工作经验，4年及以上大数据开发设计经验，熟悉大数据解决方案2、深刻理解大数据处理(流计算、分布式计算、分布式文件系统、分布式存储等相关技术)实现方法，有开发和设计实践经验。3、具有数据湖，湖仓一体，流批一体的数据平台建设经验。4、具有实时数据采集和流计算设计，开发经验。5、具有搭建cdh，或基于原生ambari ，hadoop，spark ，kafka 搭建大数据平台经验。掌握spark，spark streaming,flink ，kafka ，hive，hdfs ，hudi ，altas ，clickhouse ，hbase 等大数据生态组件。6.熟悉掌握3NF数据建模和维度建模，熟悉FS-LDM数据模型，有银行数据仓库建模经验优先。
熟悉注塑成型工艺，精通注塑产品品质各环节管控，有沟通和管理能力。
电气工程师岗位职责：1.参与电气工程招标工作，提供专业的技术支持;2.负责编写电气施工方案，并监督方案的实施情况;3.审核电气专业图纸，并指导施工人员按图纸进行施工;4.负责对电气相关专业工程的设计变更和现场签证进行审核，并按流程办理审批手续;5.检查电气工程项目的施工进度、质量、安全，并及时解决施工过程中出现的技术问题;6.参与编制电气施工所需主要设备、材料采购计划;7.配合监理公司参加重要工序、部位的验收及项目工程竣工初验和竣工验收工作。电气工程师任职条件：1.电气相关专业本科以上学历;2.具备5年以上电气工程施工管理工作经验;3.具备电气工程师中级技术职称;4.掌握专业的电气工程施工工艺以及工作流程;5.熟悉电气工程施工材料市场行情;6.具备良好的协调能力;7.具备分析问题发现问题的能力;8.具备良好的管理能力。
岗位职责：1、完成软件系统代码的实现，编写代码注释和开发文档；2、辅助进行系统的功能定义,程序设计；3、根据设计文档或需求说明完成代码编写，调试，测试和维护；4、分析并解决软件开发过程中的问题；5、协助测试工程师制定测试计划，定位发现的问题；6、配合项目经理完成相关任务目标。任职资格：1、计算机或相关专业专科学历以上；2、2年以上软件开发经验；懂DELPHI语言3、熟悉面向对象思想，精通编程，调试和相关技术；4、熟悉应用服务器的安装、调试、配置及使用；5、具备需求分析和系统设计能力，、以及较强的逻辑分析和独立解决问题能力；6、能熟练阅读中文、英文技术文档；富有团队精神,责任感和沟通能力。
工作职责：1、负责游戏日常业务运维；2、负责业务系统的性能管理、容量管理、监控、变更更新、问题诊断等，确保系统稳定运行；3、对现有系统运维工作提出改进意见和规划设计，并负责落地；4、及时响应并处理线上故障；工作要求：1、3年以上互联网行业经验,其中包括3年以上业务运维经验;2、熟练常用开源软件(apache,nginx,haproxy,zabbix,tomcat,dns,redis,mysql等)及优化配置；3、熟悉ansible或saltstack自动化运维工具；4、熟悉shell或Python等编程脚本，至少精通一门编程语言;5、熟悉Linux系统管理维护，熟悉HTTP协议、TCP/IP网络协议，对系统性能原理有深刻理解；6、具备较强的流程分析和优化能力、项目协调、服务管理能力和良好的沟通技巧；7、高度的责任心、良好的沟通技巧和团队合作精神；
岗位描述及工作内容1、负责电子烟产品方案电路的设计。2、电子物料的辨认，及各阶段物料的跟进及测试。3、产品规格书、说明书、BOM表等技术文件的制定。4、项目开发各阶段评审资料的编写。5、主导并跟踪设计变更及老产品维护。6、专利文件及认证资料的编写。7、完成领导交给的其它临时性工作任务。
技术支持工程师（FAE） 岗位职责1.参与产品开发各个阶段的技术问题.对项目执行进行跟踪、监控、反馈.2.负责产品在客户端功能验证、应用故障排查分析, 协助并参与撰写和检查相关产品的应用参考等技术文档。3.负责客户的技术讲解、技术交流、产品演示、技术支持，包括售前和售后的技术支持；4.负责对业务员进行技术培训，让销售人员掌握必须的产品知识和产品应用广文案资料；5.积级解决客户端可能出现的项目异常情况，必要时规划产品改进建议。6、对市场和客户反馈的异常问题进行分析并处理；7、对客户现场出现的技术问题，及时响应并解决，提高客户满意度。8. 负责公司产品线技术支持工作； 岗位要求1. 电子相关专业本科以上学历有混合信号类&模拟类研发经验1年以上实际经验，或IC电子行业R&D、AE、FAE、测试岗位1-2年以上工作经验2.有现场解决软件问题的能力；3、能用C或汇编编程者优先。4. 具备较强的沟通能力，富于团队合作精神，具有较强的责任心，能独立开展工作，具备开拓精神.5.有智能箱包开发、技术支持经验优先。
【岗位职责】负责量化交易系统和监控及统计分析系统的程序开发。【任职要求】1、全日制本科以上学历，计算机相关专业，有良好的编程思路及习惯；2、理解量化交易系统设计、开发、维护业务和相关算法需求；3、熟悉网络编程、数据库、进程间通讯、高性能计算等；4、熟练掌握C\C++语言，熟悉Linux开发环境下C/C++开发调试和测试技术；5、熟悉常用数据结构和算法、网络传输层或应用层通讯协议；6、具有较强的沟通能力和快速学习能力。
负责MEMS芯片显示驱动系统的设计研发；参与MEMS芯片显示驱动系统规范的制定；参与和外协设计公司的沟通和合作；参与和系统制版公司的对接；参与系统的测试和验收；参与跟显示器件和电路的对接。 任职要求：电子，集成电路自动化控制专业3年以上系统设计的的相关经验，了解驱动电路，掌握和熟悉系统的设计和制作，有显示驱动ASIC和FPGA经验者优先有良好的电子系统基础，团队合作精神，沟通能力，乐于学习, 责任心强985、211院校优先
负责公司技术研发，把握公司发展方向，保持技术先进性，解决技术难题，负责技术开发、维护和优化功能。
移动游戏前端开发
样品工程师1、根据研发提供的资料和物料到库的情况下制作样品；2、协调整合资源并制作成样品；3、完成样品的功能测试，性能测试及可靠性验证；4、测试样品数据提交研发；5、对研发给出的新物料做验证并出具报告；6、新产品导入的主要工作，包括图纸资料、样品问题总结表、BOM清单、工艺流程图，确保新产品顺利量产；7、新产品导入、样品制作整体进度的跟踪、质量的确认、加工到货过程的主导和技术支持；8、完成领导布置的其它工作。
职位要求： （1）大专以上电子专业，3年以上硬件开发经验。 （2）熟悉PADS、PROTEL99SE等设计软件，具有4层板以上的LAYOUT经验。 （3）具备较强的数字电路和模拟电路分析设计能力。 （4）对数码产品EMI,EMC,ESD处理有深刻的认识。 （5）具有良好沟通能力,团队合作精神和创新能力； （6）2年以上蓝牙产品硬件开发经验，有安凯，炬力,CSR等芯片2年以上应用经验者优先。岗位职责：1、在现有原理图进行修改调整，PCB的LAYOUT等工作。2、新产品的样机制作、测试等工作。3、产品BOM编制，说明书编写，试产资料准备，产品性能的提高与持续改进。员工福利：1，可提供住宿（宿舍在公司对面，步行十分钟，精装修）；2，上班时间：大小周、8小时；3，公司活动：不定期组织员工聚餐、户外活动、旅游、看电影、唱K；4、公司环境：公司位于深圳宝安西乡恒丰工业城，精装修两层办公楼，生活娱乐配套齐全，办公环境优良。5、每完成一个项目有项目奖，年终按自己所负责项目的产品有提成。欢迎您的加入。
1、在公司领导的指导下参与市场需求调研、分析，规划产品主体架构和细节，产出明确清晰的产品需求文档， 并推进落地；2、跟客户及时沟通，把握用户需求和行为特点，提升整体产品用户满意度；3、协调技术开发团队，跟踪开发、测试、版本管理、发布、产品上线等流程；4、关注产品上线后的运维情况，对相关数据进行持续监控和分析，并定期对自身产品、整体行业、竞争对手等进行数据分析并评估，优化产品，管理产品的生命周期；  岗位要求：1、统招本科及以上学历；2、3年以上的互联网或软件类产品设计经验，了解相关行业产品发展动态，有自己的方法论；3、了解web应用设计流程，了解用户体验方面的理论；4、有很好的沟通能力；5、有web开发经验者优先；6、有数据发掘经验者优先。
"职位描述：1.	组织制定咨询顾问团队管理制度和流程建设，制定部门工作计划，并监督实施；2.	负责组建项目团队，对项目经理提供方法指导和资源支持；3.	组织策划项目启动和项目结束，并给与重点、特殊控制与支持；4.	审核各项目组的工作推进计划，监督各项目组的项目进程管理；5.	监管各项目组的合同执行情况，对项目回款进行督促与控制；6.	定期访问各项目客户高层领导，协调项目组工作，解决相关问题；7.	指导各项目组对客户需求进行挖掘和开发，审核各项目组对客户潜在需求的开发方案，并组织进行项目建议书编制和项目洽谈；8.	进行新的咨询项目的发掘、筛选、储备、跟进等工作，组织进行咨询项目的前期调研、客户需求沟通，组织或独立进行开发咨询项目建议书编写；9.	组织进行管理咨询项目的知识提炼与总结；10.	组织进行咨询理念、咨询工具的创新与改良；11.	组织进行咨询模块与相关培训课程的设计与开发；12.	审核各项目团队的工作计划和工作管理；13.	组织制定咨询顾问团队管理制度和流程建设，制定部门工作计划，并监督实施；14.	完成上级领导下达的其他相关工作。任职资格：学历：硕士研究生及以上学历专业：经管类、管理类相关专业，MBA、企业管理硕士优先计算机：熟练使用OFFICE word、PowerPoint、Excel及Visio等办公软件工作经验：五年以上管理顾问行业工作经验，三年以上企业管理经验职业能力：1、	具备快速搜索、整理、分析、提炼知识与信息的能力；2、	能够提升咨询师业务能力并带领团队进行项目高质量的交付；3、	对待工作有强烈的责任心，能够承受较高的工作强度和工作压力；4、	熟悉战略管理、组织绩效、人力资源管理等2个以上模块的咨询方法与常用工具；5、	能适应长期出差。"
主美岗位描述：1、配合需求设计全局美术风格，2、负责项目全局风格把控及资源审核，保证产品美术品质；3、为组员提供艺术、技术上的指导和定期交流；4、建立高效的游戏美术开发流程，掌握管理开发进度；5、认真审核部门内部员工的业绩、态度和潜力；6、协调美术与各部门之间的工作。7、参与外包供应商的选择，外包需求整理与验收，把控与提升外包质量。任职要求：1、专科以上，美术相关类专业毕业；2、热爱游戏，关注游戏体验，结合本岗位工作配合产品改进游戏体验；3、具备深厚的美术功底，优秀的美术的鉴赏能力，熟悉游戏美术制作全流程、创新能力强、有大局观；4、五年以上游戏行业美术工作经验，2年以上主导设计岗位，至少参与过2款已上线运营项目开发；（ui和原画岗位者优先）5、了解游戏产业，能够正确理解美术在游戏开发中的地位和作用，对策划及程序的工作方式有一定的了解，能很好地与策划和程序进行项目协同开发；6、做事认真细致，精益求精，具有高度责任感和团队合作精神；7、有较强的综合分析能力，创新能力，准确理解产品需求并高效解决问题；8、有较强的责任心，工作投入度高，有良好的团队意识与项目管理能力；9、较强的学习能力，主动研究或学习新的技术运用到工作中；10、有创业精神，结果导向，能承受一定的工作压力；11、对产品品质与自身提升有要求，有长远且清晰的职业生涯定位与规划；12、有长远的理想主义目标并愿意为之努力者优先。13、简历中需要附带过往项目展现，以及个人作品。
职位概要：负责装修装修。暖通方案设计及材料清单计算任职资格：暖通空调或室内设计或制冷相关专业经验：一两年经验。也可收应届毕业生工作内容： 1、负责协助业务人员跟单，根据业务人员提供的信息和需求现场考察和谈判；2、负责工程的结构装饰、暖通空调、自控的方案设计、工程量计算及相应的施工图设计；3、负责协调电气工程师对工程关于强电、弱电等关于电气方面的设计，并以书面的形式提供电气方面的资料；4、负责配合定购部分设备材料，详见采购流程单规定内容；5、负责施工工地现的现场巡察，并记录现场的情况（如做工如何，有何问题等）；7、负责施工现场技术支持,解决施工现场的技术问题；8、负责组织编写技术标，并负责协助解决标书中的技术难题；9、负责施工前或施工中与甲方或供应商的沟通，并书写《工程联系单》或《工程变更单》；10、负责编写工程竣工检验报告及测点布置图，并在工程完工后编写工程竣工资料及竣工图纸；11、为相关部门提供技术支持与服务；12、按时完成公司安排的其他工作。
【岗位职责】：1、  负责公司产品推荐系统的架构设计和算法研发工作，支持海量数据和请求，实现在相关产品中的精准推荐2、  负责推荐系统的系统升级，研究业界前沿推荐算法，提升产品整体用户体验【任职要求】：1、  计算机科学、机器学习、人工智能等专业本科及以上学历, 扎实的算法和编程能力；2、  具有大型推荐系统相关研发经验，熟悉常用的推荐算法，包括关联规则、协同过滤、Wide & Deep Learning等；3、  熟悉hadoop、hbase、spark、kafka等计算平台和工具4、  有海量数据机器学习、计算广告、搜索引擎相关经验者优先5、  具有深度学习研发经验者优先考虑
岗位要求：精通 Linux 操作系统；精通前端，中间件相关的编程语言，开发工具，测试工具；熟悉虚拟化技术和容器编排的知识；熟悉各平台和工具 (Linux, Python, Node 等) 的包管理工具；有学习热情和团队协作精神。精通 Linux 操作系统；精通前端，中间件相关的编程语言，开发工具，测试工具；熟悉虚拟化技术和容器编排的知识；熟悉各平台和工具 (Linux, Python, Node 等) 的包管理工具；有学习热情和团队协作精神。岗位职责：在腾讯云上部署以及扩展 JupyterHub, JupyterLab。基于 JupyterLab 开发可视化插件。开发和部署云 HPC 计算任务和数据库服务的中间件。研发化学模拟计算任务的管理工具。
工作职责：1、配合团队进行项目的需求分析及方案制定。2、负责Android ROM制定系统软件的开发及系统framework开发及定制。3、负责Android平台的系统分析，架构设计，修改定制系统app（launcher，通讯录，拨号，sos等系统app）。4、负责项目中性能的优化，包含Android与kernel层的优化。5、关键技术和难点技术的识别与攻关，修改app bug���系统bug。6、模块的设计与代码实现。7、相关技术文档的编写。 任职要求：1、计算机科学与技术，软件工程，信息工程及相关专业本科以上学历。2、3年以上手机ROM开发经验，熟悉虚拟机原理，熟悉Android系统性能优化。3、熟悉Android framework架构，熟悉常用系统服务，熟悉Linux内核。4、有ROM跨平台移植和不同厂商机型适配工作经验。5、熟悉Android应用性能，架构优化，掌握相关的技巧和方法，熟悉基于Android SDK的应用程序开发。6、有主导完成优秀应用或相关产品开发经验以及了解相关驱动知识，通信协议者优先。7、良好的英文水平，有较强的代码阅读能力，具有良好的编程习惯和代码风格。8、良好的沟通协调能力，较强的适应能力，优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情。
1、综合分析能力强，逻辑思维能力强，能独立完成各项调研分析报告，如行业、竞争对手、消费者等调研分析报告，从而对产品开发、品牌优化、营销活动等各方面提供决策依据与意见； 2、洞察力强，联想力丰富，善于以消费者的视觉，捕捉产品亮点； 3、有从零开始策划过1-2个品牌的项目案例。
负责幕墙项目现场成本、商务工作1、负责组织、编制项目的施工图预算，收集造价资料，完成工程的造价经济分析。2、负责参与工程现场施工管理、材料和设备招标、工程施工进度。3、参与材料、设备劳务、苗木考察询价，对项目成本、预算定价打基础。4、复核材料差价，收集和掌握技术变更，材料代换记录，会议记要，签证资料，并随时做好造价预算，为领导决策提供科学依据。5。负责幕墙项目现场成本、商务工作6、全面掌握施工合同条款，深入现场了解施工情况，为决算复核工作打好基础。7、工程竣工验收后，及时进行竣工工程的决算工作，并报经理签字。8、竣工结算时及时跟进审计情况，如发现问题及时汇报领导。预算员要做好随时与甲方进行沟通谈判，维护公司利益。任职要求1、大专以上学历，年龄：25-40岁，市政建筑、工程预算、工程造价等相关专业。2、2年以上幕墙项目相关工作经验优先。3、精通CAD软件，能熟练操作广联达预算软件。适应能力强，能适应长期驻场。4、熟练掌握相关工程造价管理和成本控制流程，了解相关工程规定和政策。5、有造价员资格、注册造价师资格、建造师或市政工程预算经验优先，能驻场优先。6、工作严谨，善于沟通，具备良好的团队合作精神和职业操守
一，事业发展部合伙人：负责公司业务拓展、项目执行。          二，方案设计部合伙人：负责公司方案设计部的创意开发，设计管理。                                                                                           三 ，施工图设计部合伙人：负责公司施工图部设计管理，项目落地。
【岗位】操作系统开发工程师/研究员【工作地点】深圳【岗位职责】1）参与Linux系统或下一代OS研发，挖掘关键技术和构建原型系统，推动关键技术落地2）参与基于X86和ARM64等架构的OS核心子系统的特性需求分析、设计、编码和性能调测与优化等研发工作3）负责操作系统生态链构建，如技术开发、开源运作、行业认证等4）开拓国内外顶尖研究所合作项目，捕捉OS领域最新成果【岗位要求】1）计算机相关专业本科及以上学历，3年以上OS领域开发经验2）扎实的Linux系统开发经验和雄厚的专业技术，精通OS关键模块（如内存、调度、文件系统、驱动、安全、性能调优等）3）在OS领域有一定的业界影响力，在相关高水平学术会议发表过学术论文，在开源社区具有较大影响力，或担任过相关领域技术领导者优先4）良好的跨地域、跨文化的交流协作能力，有Linux Kernel社区开发经验者优先【岗位】无人驾驶系统开发工程师【工作地点】深圳 【岗位职责】   1） 参与无人驾驶场景下的操作系统软件需求分析、方案设计   2） 参与无人驾驶汽车操作系统底层基础组件研发及实时性能优化   3） 参与无人驾驶操作系统确定性时延分析、设计、开发和验证   4） 参与无人驾驶操作系统行业安全认证【岗位要求】   1） 深入理解嵌入式操作系统内核架构和实时性能优化，在C/C++, Linux 内核，虚拟化，或其它系统编程技术领域，有扎实的技术积累或相关工作经验       2） 具有人工智能、汽车机载操作系统和丰富实时操作系统内核经验者优先       3） 熟悉ROS或AUTOSAR，具备ROS或AUTOSAR下系统的设计开发经验者优先       4） 具备ISO26262功能安全认证和开发经验者优先
职责描述：1、协助销售部门完成销售指标和利润；2、配合销售提供售前支持、协调资源和跟踪控制项目的进度；3、收集客户意见，处理客户协调工作，进行售前技术分析支持，满足客户多方面的需求；4、与客户进行现场交流，就具体项目交换意见；5、编写、修订和审核技术支持相关文档和作业指导书，为客户提出项目实施改进计划；6、维系客户关系良好发展势头。任职要求：1、大专及以上学历，计算机相关专业优先；2、三年以上网络或信息安全设备实施经验，有相关实施、运维经验优先；3、熟悉华为数通、存储、云计算等产品、熟悉网络架构部署实施；4、具备项目、售前经验，熟悉IT行业项目运作；5、具备良好的文档编写习惯与能力，良好的沟通能力和表达能力，精通word、excel、PPT等办公软件的使用；6、能够积极主动的承担各项工作，具备较强的独立分析问题和解决问题的能力；7、具有较强的客户服务观念、强烈的责任感和很好的团队合作精神，具备很强的自学能力，能够承受工作压力。
敦煌及速卖通开发新品及产品上新底薪+提成薪资面谈 有意向联系
任职资格1、本科及以上学历，电子类专业毕业；                                        2、2~5年以上电源工程师工作经验，1年以上电源产品独立开发能力； 3、精通LED电源或者开关电源正、反激、半、全桥、LCC电路结构与工作原理；4、熟悉LED电源或者电源开发流程，能主导产品的整个开发过程；5、有成本概念，懂安规，有电源EMC整改经验；7、具有快速获取和更新知识的能力，敢于面对新产品、新技术的挑战；                                           8、 具备良好的沟通交流、组织协调及分析能力；9、 做事踏实、谦虚好学，性情坚毅；10、职业操守好、志愿长期在莱福德发展；11、熟练操作PADS 等设计软件；12、年龄24—38岁。主要职责1、参与或独立项目立项工作；参与编制项目计划；2、负责产品设计及调试，负责设计文件、技术规格书、产品的BOM和组装作业标准指导书的拟制及核对确认；3、主导设计的变更、评审及修改工作，及时满足公司生产的需要；4、参与产品各个阶段的评审工作；5、负责设计文件资料的提供工作，为设计文件的准确性和完整性负责；6、负责产品的试产资料提交、试产过程、试产后总结工作；7、对本部门工作目标和工作计划的完成负责；8、为本人（组）负责部分的项目进度、质量和损失负责。
岗位职责：1、参与项目需求分析,进行模块的详细设计；2、根据新产品开发进度和任务分配，开发相应的软件模块；；3、根据公司技术文档规范编写相应的技术文档；4、根据需要不断修改完善软件；5、研究项目技术细节，编写相应的说明。任职要求：1、计算机、通信、电子或者相关专业毕业，本科及以上学历，两年以上工作经验2、精通C++语言，STL编程，熟悉面向对象编程；3、具备良好的编程风格及规范，精通Windows编程、MFC、熟悉网络编程、dll编程；4、了解TCP/IP协议，熟悉socket编程；5、熟悉如何编写安全，高性能、高可靠性的C++程序；6、熟悉常用的数据库SQL Server 或Oracle 操作以及相关的编程；7、具有较强的学习能力，善于沟通、表达，具备独立工作能力；8、有医疗行业经验者优先。
岗位职责：负责嵌入式系统方案的设计，处理器选型，平台搭建，方案设计等工作；1.熟练使用C/C++语言开发以及相关语言编译及开发环境；2.熟悉软件项目的一般开发流程，有良好的编程习惯。3.了解进程、线程间通信原理及编程，了解模、数电基本知识，有一定模、数电硬件相关工作经验者优先；4.具有linux驱动开发经验,应用程序开发经验者优先；二、任职资格:1、大专以上学历,2年以上嵌入式应用软件开发经验,精通c/c++语 言;2、具备嵌入式产品软件系统架构的经验和能力;3、熟悉linux系统下嵌入式应用编程,熟悉嵌入式linux驱动开发 与调试;4、熟悉linux环境下网络编程,熟悉网络协议,熟悉流媒体传输协 议;5、有行车记录仪或者动力dv等方面产品开发经验者优先。6、有钻研精神，有团队观念及自我改善意识，有责任心，易沟通。我们追求把公司营造成家的氛围，每位成员都散发着青春活力，舒适的现代办公环境，清新绿化，氛围和谐，公司位置便利，上班和住宿交通方便，期待你的加入一起开创属于我们的明天！定期组织团建活动，每年组织员工旅游，设有全勤奖+餐补。办公配套：1、高级甲级写字楼，办公环境优美；2、办公设施一应俱全，冰箱、微波炉、中央空调；3、交通配置有公交线路四通八达，临近地铁站。
本厂为充电器厂家，主要生产配机充电器，现招聘充电器工程师一名，要求有同类充电器工程师经验三年左右，符合条件者请与我联系！
1、负责实验室仪器的安装调试及维修2、解决用户在仪器使用中遇到的问题3、负责新的应用方法开发4、配合销售完成仪器的售前技术支持任职要求：1、良好的沟通合作及团队精神，2、责任心强3、物理化学化工相关专业，4、具有良好的化学知识；5、身体健康，适应经常出差
岗位职责：1.熟悉市场上主流的APP应用,并能对其功能做详细讲解；2.热爱移动软件开发专业,善于把控产品细节,逻辑性强,对设计,技术有一定了解；3.为人正派、品德优秀；思维活跃、办事严谨；自律性强、严守工作组织纪律；诚实守信，具有高度的团队合作精神；4.激情、有创业心态和投身新兴资本市场为优质企业提供服务的极大热忱。任职要求：1.28-45岁,计算机信息科学、项目管理、硬件工程等相关专业,本科以上学历；2.具有APP开发5年以上项目工作经验,手机软件行业5年以上研发经验及5年以上项目管理经验；3.具有专业的模型知识及软硬件知识优先考虑；4.良好的沟通表达能力及团队领导力,积极主动,认真负责；5.面试者带上自己参与开发的APP案例。工作内容：1．负责开发APP工作的跟进及控制；2．负责开发APP计划编写及全过程管理跟进；3.全面负责项目交付及质量问题；4.完成好高层领导安排的任务及目标。
岗位职责：1、负责使用PHP开发游戏运营管理后台2、负责与第三方机构的技术对接，公司内部项目组的技术对接3、负责业务需求管理，制定技术规范4、完成上级交予的其他工作需求任职要求：1、精通PHP+MySQL编程，精通PHP的面向对象编程，能够独立进行整个系统的架构设计、模块分解、接口设计、系统集成，独立主导过中等规模PHP Web应用系统的研发2、熟悉JavaScript、JQuery、CSS 等web开发技术3、能够在Linux上进行日常工作，熟悉Shell命令4、对服务器端程序的部署、架构、调优有一定的了解者优先
研发设计充电器和车载充电器电路PCB开发;熟悉认证要求;熟悉开发软件;对应工作经验5年以上;
一、岗位职责：1、 根据公司规划，开发新产品，新功能，根据产品要求制定FPGA程序设计方案；2、 负责产品的FPGA程序设计、仿真、测试和维护工作；3、 编制FPGA设计文档、流程图、通信协议、测试文档及维护指导文档等；4、 配合、协助软件、硬件、测试等岗位及其他部门进行设备整机调试；5、 完成上级交办的其它相关工作。6. 维护公司产品FPGA软件；二、任职条件：1、计算机、通信、电子类专业本科及以上学历；2、有相关工作经验，熟悉模拟数字电路设计原理，熟悉数字信号处理技术，有图像、视频相关开发经验；3、 熟悉FPGA的设计开发流程，熟悉VHDL语言，熟悉相关仪器使用，熟悉相关综合仿真软件；4、 精通verilog或VHDL语言编程和仿真，有独立设计数字电路子系统的经验；5、 精通ALTREA或者LATTICE公司FPGA的板级开发和相关工具链，比如QUARTUS等， 熟练常用IP core。6、熟透悉常见的接口和器件操作，如I2C，SPI，PCIE，DDR3，SDRAM等。7、熟悉Verilog、VHDL语言；8、具有良好的硬件基础，具有良好的英文技术资料阅读能力；9、具有较强的自学能力以及进取精神，良好的沟通技巧和团队协作能力；
1，工作踏实，责任心强，具有良好的团队合作意识和较强的工作主动性。2，具备扎实的软件专业知识，熟练的编程功能，有独立开发分析并解决问题的能力。3，熟悉IOS应用开发，熟悉IOS框架4，有实际的IOS应用项目开发经验(社交APP)5.  有集成音频经验者优先
职位要求：1、大专以上学历，电子类相关专业；2、熟悉PROTEL99se、Altium Designer、PADS等产品设计软件；3、有移动电源、开关电源等新产品开发和测试经验；4、独立设计无线充原理图，PCB layout，开发调试，开发测试；5、有无线充开发经验者优先；6、有QI，EMC认证相关经验的优先；7、产品质量意识和成本意识强，能分析处理产品异常问题；8、吃苦耐劳，责任心强，有优秀的团队意识，服从领导安排。工作职责：1、负责新产品的硬件线路设计及PCB设计；2、负责新产品的电性能调试及软件开发跟踪、调试；3、负责电子物料样品的确认和签样；4、指导新产品样机制作、测试，参与设计开发评审；5、负责新产品电路原理、PCB等图纸及相关技术文件的制作；6、负责公司电子、电气方面技术资料的收集、汇总、归档；7、在部门经理的指导下，负责整机或部件的技术改进；8、协助结构工程师完成整机产品的开发。
岗位职责：1、负责公司大中型室内外精装修项目的设计工作；2、负责现场与施工方在施工工艺与设计等技术沟通；3、现场勘查、分析及测量等工作；4协助设计团队完成招标图，施工图等相关图纸制作；5、协助项目团队完成技术标书制作。任职要求：1、本科学历，室内设计、装饰、环艺、美术等相关专业；2、十年以上装饰行业设计经验，五年以上设计部门全面管理工作经验，3、热爱设计专业，具备手绘功底，能够熟练操作CAD、PHOTOSHOP、SKETCH-UP等设计软件；4、熟悉装饰施工节点，施工工艺，材料及相关国家规范；5、具有良好的沟通能力、工作认真、责任心强、有团队合作精神，吃苦耐劳；6、有大型项目设计工程的工作经验，拥有高级工程师职称，优先考虑；7、全面掌握室内设计相关知识，熟悉装修设计程序和标准规范，具有较强的方案能力，熟悉设计企业业务和流程；   8、富有创意，时尚类触觉敏锐，独立完成过商场、四星级以上酒店、高档办公、公建等装饰项目丰富的设计经验，具独立完成高素质方案设计能力；  9、负责软装设计业务的管理、指导，负责与客户协调沟通；分析目标客户需求，充分理解客户意图，正确把握项目设计创意；设计相关工作规范、流程的制定、监督和执行；  10、领导并组织软装设计等项目的定位、定向、定风格的研究，指导软装设计师策划具体设计与制作，解答设计师在创意方面遇到的问题；  11、全面负责设计项目的质量，对设计的创意、色彩、版式等进行评审；  12、管理、培训软装设计团队，督促团队为客户提供持续优化的长期形象传播顾问服务，负责设计业务的成本控制；  13、负责项目设计方案的制定、审查与修订，领导设计师及制作人员对设计任务的有效完成；  14、负责与客户进设计思想的交流，协助销售部与项目部对设计项目前期与后期的跟踪服务；  15、关注国际与国内设计潮流的动向，及时掌握设计的时尚形态，并融入设计之中；  16、严谨的策划组织能力及人事管理和沟通能力、商务谈判能力；  17、良好的敬业精神和职业道德操守，有很强的感召力和凝聚力，能独立带领团队，责任心、事业心强。
1） 熟悉OpenCV，具有至少2年的开发经验（必要）2） 熟悉C++/linux操作系统，做过相关项目者优先3） 熟悉视觉硬件的选型，对市场上主流的相机、镜头和光源有一定的了解4） 有较好的英语沟通与文档编辑能力,通过CET6者优先考虑5） 本科以上学历，电子、机械、自动化等相关专业，有电子竞赛获奖经历者优先考虑;
1.职位信息制定网络游戏服务器端的开发流程和标准；设计稳定、安全和高承载为目标的服务器整体架构设计和模块划分；负责服务器端总体框架优化和关键架构设计；负责服务端核心功能模块的开发；负责游戏服务端性能优化，技术攻关；负责服务端小组工作计划制定和协调。2.任职资格本科学历及以上，五年以上游戏后端开发经验；拥有至少一款完整的网游服务器架构经验；熟悉C/C++，熟悉常用数据结构和算法，精通TCP/IP协议及socket编程；拥有优秀的学习能力、综合分析能力和执行能力，主动研究和学习新的技术运用到工作中；责任感强，团队沟通协作意识和抗压能力较强。
岗位职责：1.负责新产品工艺制作，跟进生产现场作业工艺指导；2.制作工艺文件、标准工时制定优化产品工艺。任职资格：1.有IE三年工作经验2.对电子类消费产品制造工艺十分了解3.快速制作工艺文件（SIP/SOP）4.熟悉相关辅料应用，及用量评估5.对现有工艺有改善能力，引进新工艺新方法公司旗下网址：http://www.4006.hk/  广州400电话⋐-⋑链接存在风险--⋐-⋑------  深圳400电话http://www.400y.net/  深圳400电话http://www.68cy.com/  深圳网站建设
任职要求：1、本科以上学历，机械设计、机电一体化等相关专业， 8年以上产品设计与开发工作经验；2、具备独立设计能力，熟练运用Pro/e、AutoCAD等设计软件；3、掌握结构设计、材料和五金塑料加工工艺，有塑料模具设计经验优先；4、英语4级以级，具有良好的英文口语及书写能力，有与国外客户打交道经验的优先；5、熟悉产品结构设计、开发整个流程，能自主推进项目。岗位职责：1、负责产品开发的结构设计，评审工作及市场调研；2、产品研发到试产再到量产阶段整个结构方面的资料建立与测试；3、新产品试产和首次量产的跟进；4、研发新产品结构件前期制造工艺的技术跟进。
1、具有独特独到，创意性思维及良好的表达能力！底薪高，提成高！2、能与客户沟通谈单，独立完成设计方案及项目报价3、在空间构思方面具有独特的创意和技术技能，手绘功底好；4、具备良好的职业道德素质、高度的敬业精神，能够配合企业品牌设计团队进行良好的合作。任职资格:1、熟练掌握CAD、Office等设计专业软件。2、能够严格按照设计规范，为客户提供设计方案及相关配套服务。3、能独立完成整套CAD施工图，熟悉装饰整套施工流程及工程预决算。4、有较强的审美判断能力，有较多的现场配合施工经验，有很好的沟通谈判技巧。
1.代表公司管理所承担的工程安装项目。2.负责工程安装项目的进度、质量、安全管理。3.在授权的范围内对外协调、处理施工现场的技术、质量、材料、成本和人员问题。4.负责向有关部门报送资料及预决算问题。
【岗位职责】负责量化交易系统和监控及统计分析系统的程序开发。【任职要求】1、全日制本科以上学历，计算机相关专业，有良好的编程思路及习惯；2、理解量化交易系统设计、开发、维护业务和相关算法需求；3、熟悉网络编程、数据库、进程间通讯、高性能计算等；4、熟练掌握C\C++语言，熟悉Linux开发环境下C/C++开发调试和测试技术；5、熟悉常用数据结构和算法、网络传输层或应用层通讯协议；6、具有较强的沟通能力和快速学习能力。
工作职责：1、负责整机项目中的电源部分和光源驱动部分的系统设计和详细设计；2、负责电源部分与其他子系统之间的规格对接和联合调试；3、负责了解电源行业前沿的技术，优化技术规格和成本，提高性价比；4、负责支持产品量产和试产阶段的电源相关问题分析和解决，并导入设计；5、负责在公司内形成电源设计的相关体系建设，如设计规则，设计检查等内容的建立和维护。 任职要求：1、 熟悉开关电源的拓扑结构，熟悉各类器件的选型要求，熟悉电源行业安规和电磁兼容要求；2、熟悉数字电源（DSP）开发；3、5年以上行业经验，本科以上学历；4、有原厂经验、TV投影行业经验尤佳。
聘岗位要求：1、样品制作、新产品导入跟进 、试产报告问题分析；2、 主导生产现场制程异常处理 ；3、 SOP制作 ，产线工位平衡分析和产品生产标准工时制定；4、工装夹具制作；5、从事过电子烟行业优先考虑。
岗位要求：1. 计算机，软件，电子技术等相关专业本科以上学历，3年以上工作经验；2、编程基本功扎实，熟练掌握C++或python，有学习新语言的兴趣；3、熟悉TCP/UDP网络协议及相关编程、进程间通讯编程；4、全面、扎实的软件知识结构，掌握数据管理、操作系统、计算机系统结构等专业知识；5、精通各类优化算法，例如梯度下降算法；6、不需要懂量子力学。岗位职责：量子计算软件系统开发，测试、部署及维护，具体工作职责可延展解释为：由于超导量子计算机的运行离不开经典计算机和电子学系统的辅助与控制，在超导量子计算系统的实验及运行过程中，软件系统主要负责电子学系统控制，实验数据采集和管理；因此，该岗位要求开发者开发出的软件系统操作简练，同时有较好的可扩展性及较高的鲁棒性
工作职责：1、负责公司手机产品硬件开发、元器件选型、硬件设计、电路板设计开发支持、交付侧重、电源设计、原理图、PCB设计审查、BOM编制等；实现产品化，对产品质量负责。2、负责制定硬件开发的测试方案；负责样机调试、测试、改进，支持系统测试和故障分析并给出改进方案，指导工厂生产测试，及售后问题分析解决。3、负责进行相关模块硬件调试，参与系统联调，小批量试产指导等；负责硬件单元测试，包括信号完整性测试，电源测试，系统功能测试。4、负责完成验证板、产品与相关标准、电磁兼容、从事先进IT/ICT技术研究、原型系统的设计和开发等。5、负责公司研究领域中控制芯片及其他核心芯片的研究和设计工作。6、参与手机产品系统供电解决方案的规划和产品竞争力构建。7、负责项目跟进，与算法、软件开发人员配合共同协作完成样机系统原型硬件部分的搭建，负责生产量产导入和产线问题定位解决。8、负责技术创新与预研，负责其他技术事项和完成相关开发文档的整理和归档工作。任职要求：1、计算机、通信工程、微电子、自动化、信号处理、电子科学与技术相关专业本科及以上学历，具备较强的调研能力，非常熟练的英文专业论文阅读及撰写能力。2、具有5年以上硬件开发工作经验；具备扎实的数字电路、模拟电路、电路分析和信号处理、通信网络等方面的基础理论知识。3、具备高速数字电路设计、混合设计与调测、问题处理、应用开发经验，能进行较复杂电路问题分析定位，能够独立完成硬件方案设计，器件选型，原理图设计，电路调试测试等工作。4、熟练使用相关开发软件；对信号完整性、硬件可靠性有较深入理解。5、具有良好的沟通能力，组织协调能力，较强的逻辑思维能力,有相当的文档编写能力，具有良好的团队合作精神和高度的敬业精神；有乐于钻研的精神和投入工作的激情。6、熟悉掌握C/C+和Verilog，VHDL等硬件语言，有FPGA相关项目经验者优先。7、能独立解决研究项目中出现的技术问题。8、可以接受出差。
岗位职责：1、负责基于2D、3D激光雷达的环境地图构建算法研究及测试。2、负责开发及优化定位地图绘制软件。3、负责在机器人应用环境下开发、测试相应算法并提高算法性能。任职资格：1、扎实的C/C++开发、调试的经验。2、熟悉 Linux 平台下的程序开发。3、扎实的数学基础，至少1年的激光SLAM开发经验。4、熟悉ROS，具有ROS相关开发经验优先基本福利：1、入职即购买六险一金2、双休，朝九晚六 3、免费工作餐4、公司组织每年一次体检5、AI智能行业领航者，良好的发展空间和平台6、宽敞舒适现代智能的办公环境
【岗位职责】：i.负责设计和开发爬虫系统，进行多平台信息的抓取和分析工作ii.参与各种核心抓取策略、算法的设计与开发，提升网页抓取的效率和质量iii.支撑业务项目和产品的数据抓取需求，参与开发和扩展新的数据源iv.负责特殊网页采集任务的分析及采集方案设计【任职要求】：i.计算机相关专业本科以上学历ii.两年以上工作经验iii.熟悉Linux系统使用iv.熟练掌握Java 或Python其中一门语言v.熟悉常用爬虫框架的vi.掌握网页抓取原理及技术，了解基于Cookie的登录原理，熟悉基于正则表达式、XPath、CSS等网页信息抽取技术；vii.熟悉常见网站的反爬虫策略及相应的应对方案【加分项】：i.APP爬虫经验ii.熟悉Seleniumiii.验证码识别经验iv.有海量数据，分布式爬虫设计开发相关经验v.英语良好，可以阅读英文文档优先
岗位职责：1、 新工业园区整体规划，包括整体布局规划，动线规划（物流动线、人员动线、消防动线）等；2、 厂房整体布局规划，包括楼层功能定义、功能模块划分、物流动线、人员动线规划等；3、 厂房内部详细布局规划，包括仓储区域、生产线体、辅助功能区域规划等；4、 厂内物流规划，包括来料入厂、原材料配送上线、成品入仓发运的整体物流解决方案规划；5、辅助设施规划，包括强弱电、工业气体、工业地坪、废弃物处理等设施规划；任职资格：1、大学本科或以上学历，工业工程（IE）专业/物流专业/机械专业；2、能熟练使用CAD；3、5年以上工作经验，擅长精益生产、IE、物流，最好有主导或参与工厂规划的项目经验；4、了解相关法律法规，如建筑设计防火规范；5、反应敏捷、表达能力强，具有较强的沟通能力及交际技巧，具有亲和力；6、有责任心，能承受较大的工作压力，习惯长期出差工作模式；7、有团队协作精神，善于挑战，良好的客户服务意识
跨境电商产品上新需要上新产品不需自己开发，公司已开发好工作仔细认真底薪+提成
职位要求：1、两年以上游戏行业美术工作经验；2、设计类相关专业(艺术设计、动画设计、视觉传达等)，有原画功底；3、具有良好的设计思维，用户交互及用户体验感强，参与过完整的游戏项目开发，了解游戏美术开发流程；4、具备协调能力及工作计划能力， 对工作目标提升游戏画面品质；5、主观能动性好，有良好的抗压能力。岗位职责：1、负责移动端游戏美术的设计和制作(界面设计、图标设计、广告设计等)2、熟练使用设计软件PS、AI、FLASH等；3、参与部门的美术规范和标准的定制；4、简历请附带相关作品或链接。
一、岗位职责：1、负责公司产品的研发、产品优化及相关技术文档的编写；2、负责新产品的嵌入式软件的设计、编程、测试及技术文档的编写；3、负责公司新产品知识产权文档的编写和申报；4、完成上级领导交办的其它工作任务。二、任职条件：1、本科及以上学历，计算机、电子、通信等相关专业应往届毕业生；2、身体健康，品行端正，有较强的学习能力、团队精神和良好的职业道德；3、熟悉单片机系统结构，精通单片机外围芯片接口技术，熟悉I2C、I2S、SPI、UART等常用接口；4、熟练掌握C 、C++，有嵌入式应用经验者优先,有良好的编程风格；5、熟悉数字电路、模拟电路及各种基本电路，能看懂硬件图纸。6、精通STM32 ARM的结构和编程；7、可独立查阅芯片资料和文档。8、有基于ARM的嵌入式系统UCOS和LINUX软件开发经验，掌握文件系统、进程管理、进程通信、多线程等嵌入式LINUX编程技巧；9、熟悉LINUX操作系统下的界面编程，以及简单的接入驱动；10、责任心强、工作认真，具有良好的沟通能力。
岗位职责： 1、负责产品软件技术开发2、负责相关技术文件的制作，包括电路原理图、PCB板图、BOM表、工艺要求文件等；3、协助结构工程师完成整机产品的开发； 4、负责产品生产技术服务和技术改进工作； 任职资格： 1、本科以上学历，电子类相关专业；5年以上电子产品开发设计经验，并有成功的设计产品批量生产过； 2、熟悉MCU软件开发，精通C语言和汇编
一、岗位职责：1. 参与公司后台系统的升级和维护2. 参与公司新系统的研发二、岗位要求：1. 本科以上，1年以上的开发经验，优秀的应届生可适当放宽限制2. 必须具备非常扎实的计算机基础3. 掌握函数式编程和面向对象编程，能够编写模块化、可重用、易维护的代码5. 熟悉数据库SQL，最好了解SQLAlchemy6. 熟悉Linux开发环境，掌握基本的Shell命令7. 具备良好的阅读文档能力，学习能力和表达能力
岗位职责：1、参与产品研发的立项，负责电子方案选型，分析方案可行性；2、制定电子开发计划，管理开发进度，保证项目按时完成；3、负责审核产品开发质量及软硬件设计资料，保证产品的品质要求；4、负责组织电子方面的技术攻关，解决技术难题；5、负责为销售及生产部门提供技术支持；6、负责管理电子开发团队，培养技术人才，提高团队整体能力；7、根据公司市场战略，负责制定电子技术的中长期发展规划及执行路线。任职要求：1、本科及以上学历，电子相关专业；2、精通C语言与汇编语言的软件编程，软件架构及流程清晰，规范性好；3、精通模拟、数字电路应用及元器件的规格参数，能够根据产品功能进行方案选型并设计电路图；4、精通PCB设计与可制造型要求；5、具备较强的英文沟通能力；6、5年以上的消费类电子产品软硬件开发经验；7、5年以上电子开发团队管理经验；8、具备较强的分析和解决问题能力；9、工作认真细致、责任心强。
1、实现区块链系统的底层架构， 能实现公链、侧链、私有链，供应用层调度使用；2、根据需求及应用场景，设计合理的区块链网络的认证与准入机制，开发智能合约；3、根据应用场景，选择合适的加密算法并实现；精通PHP、java等语言至少一种；4、熟悉HTTP、TCP/IP、UDP协议，熟悉主流的加密算法并能实现之；5、熟悉集群技术、系统性能调优；熟悉主流共识算法以及其算法流程。6、熟悉主流区块链平台架构各项技术指标以及优缺点。7、熟悉Ethereum、Hyperledger、Ripple、BitCoin等区块链项目之一的底层技术原理，有相关项目开经验优先；8、有较好团队协作精神和执行力，较强的分析问题和解决问题能力。
一、岗位职责：1. 负责公司产品的维修及样板的焊接调试,故障诊断和排除,填写维修日志;2. 对产品维修记录能进行总结分析,发现问题及时上报解决;3. 能看懂电路原理图 ，协助生产部和研发部解决其他问题4. 协助技术部解决相关技术问题。5. 上级领导安排的其他工作。 二、任职条件：1. 中专以上学历,电子专业优先考虑,优秀者可放宽条件;2. 有维修工作经验1年左右,能熟练使用烙铁 风枪 万用表 示波器等日常维修工具和仪表仪器，能完成BGA植球焊接优先;3. 对电子元件熟悉，能根据元件代码分析查找型号。英语水平良好，能看懂芯片数据表。4. 具有良好的服务意识和团队精神,工作积极主动,认真负责,有上进心;5. 有较强的判断和处理能力,动手能力强,服从上级安排,调动,能适应加班;
工作职责： 1、根据项目任务计划，独立按时完成android客户端软件高质量编码和测试工作；2、规范文档的编写、维护，以及其他与项目相关工作；3、按照开发流程编写相应模块的设计文档；负责根据UI设计图进行Android手机客户端软件的封装；4、按时按需完成客户端软件的维护及更新；5、配合市场等其他部门，提供产品相关技术支持。职位要求：1、大专及以上学历，1年以上App开发经验；需要熟悉熟练使用技术框架；2、具备Rxjava，okhttp，Retrofit，实战经验优先考虑；3、有独立开发经验及成功上线项目者优先；4、精通Android开发平台及框架，熟悉API调用、多线程、HTTP、TCP/IP通讯协议，精通UI布局和控件的使用，了解Android Framework和底层设计原理；5、对Android程序性能优化、内存优化有一定的经验。
华为云EI（Enterprise Intelligence）企业智能服务是AI技术与企业业务场景的深度融合，定位于业务智能的桥梁，方便企业快速应用人工智能，联接智慧，创造未来。基于AI技术，华为致力于打造一个开放的、智能的平台，提供更多面向企业业务场景的新服务。华为云与EI的结合，让华为云更加智能，借助创新技术赋能产业新价值。目前华为云EI服务已经在城市、交通、互联网、医疗、园区、工业等领域有了广泛的商用。岗位职责描述：1、负责华为云EI智能体大数据的开发和维护，确保平台高效、稳定的运行；2、与行业专家一道，深刻洞悉人工智能在城市生活各领域应用和发展趋势，打造华为云智慧城市生态品牌。岗位要求：1、编程能力突出，具有良好的编程风格，熟悉常用设计模式；2、熟悉Java/Scala/python语言，了解Spark/Hadoop分布式框架；3、拥有数据治理、清洗、判重、融合、存储、计算等数据开发经验；4、有大数据平台服务分层框架，数据中台设计开发经验者更佳；
职位描述1. 负责极氪经营业务体系下的数据的数仓模型设计、ETL任务开发，建立规范化、稳定可靠的数据体系； 2. 参与数据质量治理相关工作，提升易用性与数据质量，保证数据安全、稳定、可恢复； 3. 深入业务，理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；任职资格1. 计算机或者相关专业本科以上学历。 2. 三年以上数据仓库建设、ETL相关开发经验，具备扎实的数据仓库与模型设计理论基础&工程能力。 3. 熟悉 Hive、Spark 底层原理，精通SQL 编程、性能调优。 4. 熟悉阿里云大数据产品体系，如Dataworks、Hologres5. 良好的思维逻辑能力、语言表达能力、团队协作能力。
1、参与大数据平台建设，承担大数据平台研发职责。2、构建大数据质量体系，持续提升数据质量；3、在传统大数据开发和数仓建模的基础上，探索创新的方案，构建自动化、智能化的建模引擎4、 促进跨业务线的数据融合，通过技术和业务场景的紧密结合，让数据发挥最大业务价值。岗位要求：1、5年以上大数据处理研发经验；2、扎实的JAVA开发能力，熟悉shell、python或其他脚本语言中的任意一门；3、熟练使用数据库同步、日志采集工具；4、精通hadoop、HDFS、Hbase、Hive等技术；5、精通flink、storm或spark streaming等流式或流批一体处理框架中的一种或多种；6、熟练掌握数据仓库建模和ETL设计方法论；7、有基于数据分析推动业务提升或优化的实际案例；8、有数据挖掘、机器学习经验者优先考虑；
大数据招聘人员要求工作职责:1、针对数据支撑类业务，提供数据分析、数据接口、基础模型、汇总模型、ETL流程等设计和开发；2、参与数据仓库模型建设与管理，参与制定模型开发规范、数据治理规范并推进落地；3、负责数据源调研、入库、离线和实时数据处理的全流程开发工作，并保证数据质量。任职资格:1、熟悉数据仓库理论，指标体系构建，数据质量管理、实时数仓及数据分析相关经验；2、熟练解决Hadoop相关问题，根据业务需求作出系统调优；3、java基础扎实，熟悉springboot框架，熟悉linux系统；4、3年以上大数据系统开发经验、熟悉大数据组件 HDFS、Yarn、Spark、Flink、Kafka、Redis、ElasticSearch、zookeeper等，具有丰富的大数据平台工程经验5、熟练使用数据库，如Oracle，Mysql，Doris，OceanBase；6、具备良好的学习能力、分析解决问题的能力和沟通协调能力，高度责任心和团队合作精神，对业务有自己理解和判断力；
1、参与离线和实时大数据产品研发，优化并解决海量数据的ETL相关技术问题，推动公司大数据平台的演进。2、参与复杂数据链路依赖下的数据资产治理工作，促进数据质量、数据安全管理，满足业务发展对数据的需求。3、参与基于云原生技术的SaaS、PaaS的数据产品探索和研发，助力风险决策领域大数据业务生态建设。资格要求：1、本科以上学历，3年以上工作经验，对技术有强烈热情，对互联网大数据技术发展敏感，关注云原生、人工智能等技术发展趋势，勤于思考，动手能力强。2、熟悉Java/Scala编程，熟练使用IO、多线程、集合等基础框架，熟悉Spring相关框架。3、熟悉Hadoop生态组件，掌握Spark、Flink等分布式计算技术，对框架原理有一定的了解。4、熟练使用HiveSQL，SparkSQL等SQL语法，理解SQL语言编程。5、熟悉Linux操作系统，掌握Shell、Python脚本语言。6、有良好的规划和沟通能力，有强烈的责任感，执行力能力和抗压能力强。7、有大数据业务支撑和完整的大数据平台建设经验优先。
职责： 1. 参与数据仓库的长期架构规划与数据开发，建设大数据平台 2. 负责数据平台相关数据管理工作，元数据管理、研发规范、质量规范、保障规范的制定与推动实施落地 3. 对数据ETL任务进行性能调优及性能瓶颈分析 4. 负责业务功能数据开发，包括（数据统计实现、数据测试，发布上线等）5. 学习新技术，提高整个平台的计算能力和效率 任职要求： 1. 计算机及相关专业毕业，本科及以上学历，数仓领域2年及以上工作经验 2. 熟悉数据建模、ETL设计与应用、报表开发等，并有实际模型设计及ETL开发经验 3. 熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等 4. 熟悉linux系统,熟练掌握python或java语言, sql语法5. 熟悉HADOOP生态相关技术：HDFS, HBASE, HIVE，SPARK, PRESTO等6. 有数据治理经验优先 7. 极强的上进心和求知欲， 良好的沟通能力、组织协调能力、抗压能力 。有电商数仓项目经验者优先有集群管理经验者优先
1、熟悉数据仓库模型设计和精通ETL开发经验 ，掌握3NF、Kimball的维度建模设计方法，具备海量数据加工处理（ETL）相关经验； 2、掌握至少一种数据库开发技术：Oracle、Teradata、DB2、Mysql等，精通并灵活运用SQL实现海量数据ETL加工处理 ；3、拥有数据质量校验与评价，元数据校验与评价，数据接口服务及接口标准定义，主题数据服务，非结构化数据服务，主数据服务等处理经验；4、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等），对内部实现机制深入了解，对其中的部分组件能进行源代码级的研究和优化；5、有5年以上大数据平台实际的相关产品和项目开发经验；或熟悉平台各组件的应用开发接口并有5年以上实际的相关应用软件开发经验； 6、了解各种互联网常用开源软件（如Zookeeper/Redis等），有知名互联网/软件/通信厂商大型项目经验者优先；  7、熟悉Linux系统常规shell处理命令，灵活运用shell做的文本处理和系统操作 ；8、熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，重点考察Python、Perl、java ；9、熟悉数据仓库领域知识和技能者优先，包括但不局限于：数据开发测试工具与方法、数据质量等。
1、ETL数据清洗；2、大数据开发(hive、hbase、hdfs)；3、关系型数据库开发(DB2、MYSQL)；4、shell脚本开发
大数据开发有离线或者实时的ETL开发经验数仓的熟悉数据库基本概念、原理方法和技术
工作内容：1.从事安全大数据分析平台的开发；2.承担与大数据相关业务的代码开发，保证代码质量；3.确保软件版本功能的按时交付。职位要求：1.计算机相关专业，本科及以上学历；2.具有涉及Hadoop、Spark、storm、kafka、hbase等大数据生态圈的实际开发经验，了解其工作原理与应用场景，能完成疑难问题的定位与解决；3.能编写shell、Python脚本或系统运维能力的优先；熟悉git、svn等版本管理工具；4.具备良好的独立思考问题与解决方案的能力，重视团队内部的沟通与协作。
1、 与产品经理、数据分析师、后端工程师紧密配合，设计数据处理模型，开发大数据分析加工处理程序，提炼数据价值；2、优化大数据处理链路，提高数据处理效率，实现数据及时上新；3、搭建大数据处理平台，促进架构与业务分离，提高开发效率；4、协助管理和控制数据，构建数据治理监控体系。岗位要求：1、本科以上学历，计算机相关专业，熟悉操作系统（多线程、多进程）、计算机网络编程、数据结构与算法等基础知识；2、掌握 Linux 环境下常用语言（C/C++/JAVA/Python）开发经验，熟练使用常用 Linux 命令；3、了解软件工程、敏捷开发等知识，熟悉常用设计模式，掌握常用系统设计原则、方法和常用的系统设计工具，如UML等；4、深入理解 lambda 架构/Kappa架构/数据湖架构，参加过大规模软件系统开发并独立完成10K以上模块开发维护；5、深入理解并掌握至少一种主流大数据开发框架，如Hadoop、Spark、Storm、Flink等；6、深入理解并掌握至少一种数据库，如HBase、ElasticSearch、Mongodb等。
1、本科及以上学历，2年以上相关工作经验；2、熟悉Hadoop/Hive/Spark的体系结构、原理和特性，对Hadoop生态系统有一定的了解；3、熟悉Java，有丰富的并发编程经验，可以熟练使用Python/Shell等脚本语言，熟悉Linux操作系统；4、有海量数据分析、处理的相关系统的开发及优化经验；5、有推荐、广告、搜索等相关系统开发经验者优先；6、有良好的数学基础，了解机器学习常用算法，具备自然语言处理、特征分析等方面知识及应用经验者优先；7、责任心强，良好的沟通能力和团队协作精神；
职位描述1、为大规模推荐系统设计和实现合理的离线数据架构；2、设计和实现灵活可扩展、稳定、高性能的存储系统和计算模型；3、生产系统的trouble-shooting，设计和实现必要的机制和工具保障生产系统整体运行的稳定性；4、打造业界领先的存储、计算等分布式系统，为海量数据和大规模业务系统提供可靠的基础设施；职位要求1、熟悉多项大数据领域的开源框架，e.g. Hadoop, Hive,Flink, FlinkSQL,Spark, Kafka, HBase, Redis, RocksDB, ElasticSearch etc.；3、熟悉Java、C++等编程语言;2、强悍的编码和 trouble shooting 能力；3、乐于挑战没有明显答案的问题，对新技术有强烈的学习热情;4、有PB级别数据处理经验加分。
一、工作内容1、深挖行业大数据价值，利用spark、flink框架，结合图分析、文本挖掘、时序挖掘、图像聚类等算法模型，构建多维数据融合的实时产品(人像聚类、知识图谱等)，支撑前沿业务应用。2、利用spark、flink框架，开发各类预警、监控、预测相关实时指标，供业务系统使用。二、能力要求1、熟练掌握基于Spark Streaming 或 Flink的大数据开发技术，有实际项目开发经验。对源码有理解者优先。2、熟练掌握Scala、Java编程语言3、积极主动的奋斗精神，优秀的学习能力，拥抱开源的精神。三、其他优先条件1、具备数据挖掘算法工程化相关经验。2、有实时数仓开发经验者。3、精通业内其他流行的流计算框架。4、Java转大数据方向优先。
工作职责：1.负责数据开发需求分析、数据建模，完成相关设计及编码岗位要求：1、有5年左右大数据开发或传统数据仓库开发经验。2、本科，计算机相关专业3、精通SQL、熟悉Oracle、MySQL、PostgreSQl等关系型数据库4、熟悉HiveSQL/Spark/flink等数据开发技术 5、有一定java/python开发能力，熟悉linux/Shell 6、对Hadoop有一定的理解的优先7、良好的沟通能力和团队合作，主动积极，乐于面对挑战
职位描述：1.参与产品的数据管道和报表开发，于产品经理紧密合作，了解他们的需求，并根据现有架构和最佳实践设计合适的解决方案。2.设计和开发可扩展的数据模型，易于理解，易于使用，具有可重用性，可用于各种分析。3.设计和开发最佳的数据处理流程，可进行快速有效的数据分析。4.确保数据流的良好性能，在出现问题时提供支持并密切监控数据质量。5.参与用户画像，产品画像等数据产品的开发。任职要求：1.计算机或相关专业本科及以上学历。2.精通Java，Scala，Python语言等其中一种或者多种编程语言。3.熟悉Hadoop生态环境，精通以下一种或多种大数据技术，如flink、kafka、hdfs、spark、hive等。4.精通SQL语言，能够复杂大规模sql进行优化。5.有3年以上大数据/商业智能/数据仓库方面开发经验。6.具有较强的数据分析，问题分析，逻辑思维能力，良好的沟通、团队协作能力。
工作职责:1.Hadoop, Hive, HBase, Zookeeper, Spark, Flink等大数据生态圈常用组件的开发及调优;2.熟练掌握大数据处理技术的典型应用场景;3.熟练掌握Java, Python开发经验;岗位要求:1.有2-4年大数据开发的工作经验;2.有大数据培训课程授课经验者优先;3.具备数据挖掘和数据分析相关岗位经验者优先;4.本科学历3年以上工作经验可考虑;华为全球培训中心——有更好的大数据, 需要你做为先行者向世界去传播和解惑;有国际化的视野，需要你面向全球客户担当华为文化代言人;有全新的培训中心，需要你共同打造和践行华为全球培训中心校园文化;来更美的城市，体验更佳的工作环境。二十年沉淀: 杭州华为全球培训中心，萃取和传播华为行业/技术/文化的优秀实践;"高配"环境: 全新启动的一流软硬件设施，涵盖全系列华为设备与研发场景，7大产品线实验室;"自主"选择: 弹性工作，任务目标自主管理，让工作和生活更好平衡;"校园"文化: 图书馆，名师讲座，咖啡厅，灯光球场，兴趣协会等熟悉场景萦绕;
C2M-MSR数据团队服务于集团的"C2M"战略，负责淘宝特价版搜索、推荐、商业化业务数字化运营，通过数据资产+分析决策+数据智能+数据产品驱动业务模式升级，服务下沉人群的消费升级。职责：1. 负责C2M搜索推荐商业化场景底层数据体系的建设，通过数据+算法+工程化，赋能业务，提供全链路、可分析的业务服务能力，支持内部小二以及工厂商家的高效决策分析，驱动搜索、推荐数字化运营和商业赋能。2. 建设数据中台的数据稳定性体系，和技术团队一起抽象场景的数据采集、处理、分析、行动规范，形成围绕竞对的快速支撑体系。岗位要求：1. 丰富的数据仓库及数据平台的架构经验，有搜索推荐业务经验、有较为系统的海量数据性能处理经验更佳。2. 有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验。3. 良好的思维逻辑性、语言表达能力，项目管理的经验，以及逻辑分析能力和数据敏感度。4. 本科以上学历，统计、数学、计算机技术专业优先，2年以上的互联网行业经验。
岗位职责：1. 负责数据中台的设计和落地，降低数据使用成本，让数据赋能业务；2. 发掘数据的商业价值，深入消费者数据体系、商家数据体系、广告等数据业务，探索数据资产变现方法。工作内容：1.研发数据产品，包括但是不限于数据的收集,转化,存储,展示；2.开发可靠,高效准确的数据集市,并提供技术支持；3.维护和升级大数据基础设施；4.进行算法平台的需求分析，方案设计。基本要求：1.熟悉hadoop/hbase/storm/spark等分布式计算技术，熟悉其运行机制和体系结构；2.熟悉Mysql，ES，HBase，Redis等存储引擎的数据存储及使用方法；3.熟悉基本的算法研发，验证，上线流程；4.有一定的数据分析和挖掘能力，能从海量数据提炼核心结果，及时发现和分析其中隐含的变化和问题；5.能够通过数据化运营发现、分析问题和优化流程，推动数据处理流程自动化，提升团队运转效率；6.对数据敏感，有良好的沟通表达能力和跨团队协调能力，乐于寻求挑战和突破自我。成长建议：1. 将个人学习和实践的心得及时整理成文章，发表到博客或者公众号；2. 积极参加线下数据研讨会或者各种沙龙活动，多与社区的小伙伴进行交流；3. 积极参与开源社区，了解大数据领域的新动态。有赞大数据团队技术博客：https://tech.youzan.com/tag/big-data/
岗位职责：1.就各IT相关系统现状，部署，运维和使用等方面，及时组织相关人员进行知识的培训与文档化的作成和更新；并建立相应的制度或方案，以确保相关培训和文档化的目标达成。2.负责IT项目整个实施过程，控管项目目实施范围、进度管理、成本、风险及变更控制。3.指导实施需求调研，实施方案设计，制定实施计划，控制项目实施进度控制和验收。4.充分利用项目组内成员及公司内各部门等项目资源，确保实施工作按既定计划完成，顺利实施。6.负责信息化系统（ERP、OA、视频会议等系统）的软硬件架构设计。7.对现行系统进行整合和改进；保证现行系统正常、稳定、安全运行。8.负责团队的建设、培养、监督和绩效管理，提升技术团队的工作效率；9.负责IT技术团队日常行为准则管理职位要求：1.计算机科学与技术、软件工程等相关专业本科以上学历；2.拥有系统研发设计经验，具备产品系统架构设计及开发的项目经验和技术团队管理经验，IT管理3年以上工作经验；3.对开发技术有深入理解和经验，对技术市场具有敏锐度，能及时掌握市场发展动态，对公司技术发展提供决策性的建议。4.至少掌握JAVA、.NET、Python其中一种开发语言，能够独立进行系统开发5.精通SQL语言的设计编写与优化；6.具备组织和统筹能力，善于沟通，有较强的口头及书面表达能力，有较强的责任心；7.有在企业担任过信息中心或技术中心负责人的工作经历，熟悉汽车行业信息化者优先。
职位描述1. 参与全球化物流中台数据基础平台的建设、演进，量化业务迭代效果，沉淀数据资产；2. 负责实时、离线数据接入，宽表计算，数据仓库、在线数据服务的设计、开发、性能优化，解决计算中性能、功能等多方面的各种挑战；3. 针对具体业务问题，构建数据化解决方案，构建高效、健壮的数据计算系统，通过数据分析与洞察发掘数据价值附能业务。职位要求1. 扎实的Java、SQL编程基础，三年以上开发经验，具备优秀的系统Debug/Profiling能力和经验；2. 熟悉Storm、Flink、HBase、Kafka、RocketMQ、Calcite等开源大数据技术，有大数据工程开发经验，有开源社区开发经验者优先；3. 对业务有良好的数据化思维能力和敏锐度。乐于分享，有公开分享经验者优先。4. 善于思考，能独立分析和解决问题,责任心强，具备良好的团队合作精神和抗压能力，要有创业的激情和坚定的信念。
01.全日制本科及以上学历，2年及以上开发经验     02.熟练掌握SQL/PLSQL；     03.熟练掌握Linux基础命令，具有Shell开发能力；     04.熟练掌握Java的基础编程；     05.熟悉大数据相关组件，如KAFKA、HDFS、YARN、Hive、HBase、ES等；     06.有银行项目经验优先
1、负责华为云EI智能体大数据的开发和维护，确保平台高效、稳定的运行；2、与行业专家一道，深刻洞悉人工智能在城市生活各领域应用和发展趋势，打造华为云智慧城市生态品牌。
"职位描述：1、负责公司的大数据平台的建设，技术架构规划，大数据方案落地；2、参与大数据技术验证、方案选型、架构设计3、大数据平台的调度、可视化数仓、数据资产、数据血缘、元数据管理、数据开发平台、数据分析平台的规划、设计、落地和运营4、与数仓开发人员及应用开发人员协作，将数据分析及开发结果应用到相关业务场景。职位要求：1、	本科及以上学历，计算机及相关专业毕业；2、	有参与过大数据平台的开发，了解DataWorks或类似数据平台系统。3、	熟悉及使用DolphinScheduler、Hadoop生态、Drois等平台；4、	精通 Java 及面向对象设计开发，对部分 Java 技术有深入研究，研究过优秀开源软件的源码并有心得者优先；5、	熟悉常见设计模式；精通 Spring， MyBatis等流行开源框架；6、	3年以上大数据相关工作经验 ，有团队管理经验优先； 7、	学习能力、沟通能力/人际敏感性，有解决复杂问题的能力，有韧劲；"
岗位职责：1.参与SaaS系统内BI系统的搭建和维护。2.分析不同用户统计需求的共性，并将结果集成至系统中。3.建立和维护大数据相关的各种基础系统，包括数据整合清洗、数据应用的设计和开发。4.参与javaWeb项目和大数据业务处理任职要求：1.计算机或数学相关专业，本科及以上学历，两年以上互联网行业大规模数据分析、产品改进迭代相关工作经验。2.精通sql，熟悉Python/Java等语言，能独立完成相关的数据分析工作。3.具备良好的沟通能力、逻辑分析能力、责任心和较强的学习能力，有良好的产品思维，善于协调、推进项目落地。4.了解主流的数据分析框架，熟悉Flink开发框架者优先。5.有javaWeb项目经验和大数据业务处理经验（非仅日志或埋点性日志数据处理经验）6.熟练掌握Java语言。
任职要求：1、计算机相关本科及以上，5年以上大数据开发经验，有扎实的大数据技术基础；2、熟悉Linux操作系统，shell脚本的编写及调优;3、熟悉Hadoop或flink大数据生态技术产品Hadoop、HBase、Hive、Impala、Kafka等；4、熟悉开发语言JAVA、SQL6、熟悉Mysql、Oracle等关系型数据库。7、对于高并发、高稳定可用性、高性能、大数据处理有过实际项目经验8、至少5个数据仓库项目经验，带过技术团队；岗位职责：1、根据需求进行方案可行性分析，设计技术架构及方案2、有良好的编码规范及开发技能，能够独立指导项目组内开发工作3、能够解决项目中的技术难点4、对已完成的程序进行后优化5、对技术有强烈兴趣，有责任心和进取心，以及良好的沟通能力和优秀的团队协作能力
职位描述：1、参与大数据架构设计,搭建和维护2、参与数据仓库的建设3、参与和指导ETL工作4、开发统计分析数据接口 岗位要求：1、熟悉hadoop，hbase，spark，indexr，impala，hive，phoenix 等大数据技术框架以及其生态的二次开发和使用经验。2、熟悉Kettle，tos，SearchAdpter，DataX 等一款或多款数据ETL工具,并且可以根据需要开发数据清洗迁移程序。3、熟悉kafka 、flume 等日志数据收集处理技术。4、熟悉ELK系统。5、良好的沟通和团队协作能力。
岗位职责：1、参与公司数据平台建设（大数据平台的离线，实时数据仓库），主要从事数据平台的基础架构、ETL设计、流程优化，元数据系统设计，整体管理数据的生产、建模、应用及监控体系建设；2、参与数据平台建设，设计并实现，数据产品开发；3、协助开发团队驱动基于数据的产品迭代，为运营决策提供充足的数据平台支持。岗位要求：1、全日制本科及以上学历，计算机等相关专业毕业，1年以上相关工作经验；2、对大数据的技术趋势和SOA模式、微服务模式有较深的理解，有一定的java开发能力；3、 理解Hadoop，及各种大数据计算框架，熟练使用Hadoop、Spark、FLink、HDFS、Hbase、Kafka、ElasticSearch、Kudu、Tidb、Druid有优化经验者优先；4、了解数据仓库、平台、建模建设理论与方法、具备丰富的实践经验。精通SQL，有海量数据处理经验者优先；5、良好的跨组织协调、学习和沟通能力，乐于接受挑战。
要求本科211学历及以上，可以选择base杭州或武汉。岗位职责：1.负责数据仓库平台的建设与维护，数据ETL的设计、开发与性能优化2.建立实时和离线大数据处理流程，负责数据产品平台化和系统化3.负责大数据平台数据挖掘、清洗、建模、分析4.理解业务需求，完成技术选型和技术难点攻关任职要求：1.理解大数据的存储和计算相关技术和原理：Hadoop、Hive，Spark，ElasticSearch,Hbase,Kafka,Flink、ClickHouse等组件，有性能调优经验者优先2.参与过大型数据仓库建设者优先。有实时数据仓库设计、开发经验者优先3.熟练掌握java、scala、Python等至少其中一门语言4.熟悉Linux相关命令，熟悉分布式系统架构设计和运维设计，能独立部署大数据相关集群环境5.熟悉并行计算或者分布式计算原理，熟悉高并发、高稳定性、可线性扩展6.丰富的PaaS项目开发经验，良好的团队协作能力，热爱开发工作
职位描述：1、负责数据仓库的设计与研发。2、负责数据全链路的开发，包括日志埋点、内部与外部数据的采集、数据同步、数据清洗与标准化、数据模型设计、离线数据处理、实时数据处理、数据服务化、数据可视化等。3、负责数据治理工作，包括元数据管理、数据质量检查、数据分级管理等系统的设计、开发及应用，提升数据易用性、可用性及稳定性。4、负责业务交付数据研发。岗位要求：1、计算机及相关专业毕业，本科及以上学历2、熟悉数据仓库相关理论，实际参与过2个以上的数据仓库项目，有数仓模型设计及ETL开发经验；有数据仓库分层架构设定经验者优先；有零售行业数据模型设计经验者优先3、熟悉 Hadoop 生态相关技术，如 Hive、HBase、Spark、Flink、Storm、Elasticsearch、Impala、Druid、Kylin 等，有基于分布式数据存储与计算平台应用开发经验，熟悉阿里云大数据平台（如 MaxCompute、Blink、DataWorks、Dataphin 等）者优先4、熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等5、热爱大数据，性格沉稳，有较好的语言表达能力，能自我驱动，有强烈的求知欲与进取心，有团队合作精神，敢于挑战，能在压力下成长6、有互联网企业工作经验优先，有大型互联网公司数据架构设计经验者优先。
要求： （1）统招全日制学信网可查本科学历，计算机相关专业。熟悉大数据系统、分布式服务系统和数据仓库知识；4年以上毕业后工作经验。（2）深刻理解行业业务知识和核心数据，具有良好的数据思维和数据敏感性；（3）熟悉Oracle/MySQL/maxcompute数据库，精通pl/sql编程,精通存储过程和函数；（4）熟悉数据库ETL开发，熟悉阿里云数据开发组件，熟悉dataworks数据开发过程者优先。职责：对接研发中心，根据数据应用场景和数据需求，负责数据技术方案、数据仓库模型及数据流设计和数据开发实现。早九晚六（午休12.00-14.00），周末双休，法定节假日，入职即缴纳五险一金，加班补贴，年终奖金，带薪年假等。
岗位职责：1、 负责大数据平台架构的开发、设计和布局 ；2、 完成系统框架的设计和核心代码的编写；3、 针对海量的用户行为数据进行统计、分析与挖掘，不断提高系统运行效率；4、 负责对数据进行分析，为项目组提供大数据技术指导及分析手段支撑；5、 负责大数据平台的性能监控和持续优化；针对需求提供大数据分析技术解决方案 ；6、 大数据平台的运维工作，持续完善大数据平台，保证稳定性、安全性。 任职资格：1、 5 年互联网行业开发经验，计算机或相关专业本科及以上学历；2、 精通 Hadoop 大数据平台架构，具有扎实的 Java/Python 等开发语言；并可以开发高效可靠的代码；3、 具有较强的数据分析、数据挖掘的能力；4、 熟悉 spark、Hive、storm 等计算框架者优先，对分布式存储和计算原理有较深的理解；5、 严密的数学思维、突出的分析和归纳能力、优秀的沟通表达能；6、 个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神
工作职责：1、参与海量终端设备指标数据采集和分析以及相关预测算法和模型研究；2、从事大数据分析平台系统的统一规划、设计及落地，为后续技术优化演进提供更加高效的数据系统支持；3、参与整体架构规划、性能优化、稳定性保障建设、数据安全建设、技术难题攻坚。任职资格：1、计算机或者数学相关专业，具有扎实的数据结构和算法功底，具备5年以上大数据分析经验；2、对大数据体系有深入的认识，具备大数据计算和分析相关产品（如大型告警监控等）项目应用研发经验；3、具备海量终端告警监控指标数据计算和分析经验，对常见的指标预测算法模型有深入研究；4、熟悉开源分布式系统，对 Hadoop/Hive/Spark/Flink/HBase/Druid/kafka/elk中的某项或多项有深入了解及实际的开发经验;5、从事过多年的C/C++或者Java开发语言的经验，并且基础知识扎实，理解io、多线程等基础内容及常用的开源框架，可以深入代码一线；6、具备宽广的技术视野和优秀的学习能力，热爱软件技术工作；7、具备优秀的沟通能力和团队合作精神。
岗位职责：1、参与数据中台项目需求调研、数据建模等前期架构设计工作；2、负责数据中台项目数据采集、数据开发等相关开发工作；3、负责数据中台项目接口开发工作；4、负责数据中台项目可视化开发工作； 基本技能要求：1、熟悉Linux操作系统基础命令2、熟悉Java、Pyhton、Scala其中一种编程语言，具备良好的编程能力3、熟悉数据库Mysql、SQLServer、HiveSql中至少一种，熟练掌握常用数据库命令3、熟练使用Dataworks、DataQ、DataV等阿里云大数据产品集4、熟悉Spark、Hive、Hbase、Flume、Mapreduce、Kafka等大数据组件5、较好的沟通能力；6、熟悉安全生产的相关规定并遵守；7、1年以上大数据项目经验
1、2年以上的大数据开发工作经验，计算机或相关专业本科及以上学历；2、熟悉使用HDP/阿里云/华为云一种大数据工具框架,有相关数据平台经验。3、熟悉spark/dataworks,flink/storm/blink 进行离线和实时数据开发，熟悉使用中间件Redis。4、熟练使用JAVA语言，熟悉使用linux命令，有基础的shell脚本开发经验。5、熟练掌握sql,有调优经验，熟悉使用RocketMQ/kafka一种消息队列,熟悉使用hbase/ots等一种数仓。6、做事严谨踏实，责任心强，条理清楚，善于学习总结，有良好的团队合作精神和沟通协调能力。
任职要求1、计算机或相关专业本科以上学历；2、熟练掌握Java语言，熟练掌握脚本语言Shell/Python/Perl之一；3、熟悉SQL，具有丰富的数据开发经验，对数据处理、数据仓库建模、数据分析等有深刻认识和实战经验；4、熟悉常用开源分布式系统，深入研究Hadoop/Hive/Spark/Storm/Flink/HBase一项或多项相关技术；5、有OLAP、海量数据处理、实时计算等相关开发经验者优先；有地理信息索引建设经验优先。6、积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神。
岗位职责：1.负责大数据平台组件、数据中台、大数据应用、流式数据处理等领域的开发工作。2.参与大数据技术验证、方案选型、架构设计。3.负责大数据领域的技术平台的迭代与更新，促进大数据应用能力提升任职要求：1、计算机技术类、信息技术类等相关专业本科及以上学历并取得相应学位；2、熟悉java和shell；掌握MapReduce处理问题思想，熟悉分布式计算模型或有高效索引技术经验者优先。3、熟悉Mysql/PostgresQL等至少一种关系型数据库，掌握SQL开发技术；4、熟悉Hadoop体系结构、对Hadoop生态圈有较全面的了解，熟悉spark/HDFS/HBase/Hive/MapReduce/clickhouse/Impala等相关技术，并有实际的开发经验。
岗位职责：1、 参与大数据各类底层组件，平台和系统的开发及优化；2.、参与大数据相关上层数据产品和应用开发和推广；3.、对公司各类业务开发团队提供技术支持；4.、跟踪业界技术动态，推动公司大数据相关技术的持续进步；5.、不限以上，具体责范围，岗位适配取决于你的能力大小，欢迎来挑战。岗位要求：1、本科及以上学历，3年以上工作经验，2年以上大数据领域工作经验；2、精通java或python至少一门编程语言；2、精通shell脚本编程，至少熟悉Python或perl等一门语言；3、熟悉HTTP协议；4、熟悉HADOOP ／ Hive ／HBase ／ Spark ／Storm ／ Kafka ／ kylin / Druid /postgresql/Mongodb等分布式计算环境进行海量数据分析与计算经验者优先；5、做过数据仓库，对数据治理、数据标准及元数据有很好理念及实施经验的优先；6、良好的沟通能力和团队精神,具备创新意识；7、相关开源领域的活跃贡献者或大型互联网公司相关从业经验者优先。
工作内容：  1 参与公司产品业务开发，撰写相关技术文档；  2 根据产品需求和设计，完成功能实现；  3 参与数据分析算法实现；  4 独立按时高质量完成相应开发任务，并能够及时沟通开发中碰到的障碍。  5 参与项目部分技术选型及难题攻关任职要求：  1 大学本科学历（学信网可查）；；  2 熟悉一种或多种开发语言，包括Python，Java， Scala；  3 熟悉一种或多种数据库技术，包括Oracle、MySQL、DB2，有较好的SQL性能优化功底；  4 熟悉一种或多种大数据技术，包括Hadoop、Spark、Flink、Kafka、Presto、Kylin、ES、Hive等，熟悉源码、有二次开发优先；  5 熟悉常用的数据算法优先，有数据分析、机器学习、数据挖掘经验者优先。  6 对自己做过的项目，用过的技术方案有深入思考，希望在简历中有所体现；  7 工作积极主动和热情，对技术有强烈的热情和好奇心，具备极强的分析解决问题能力及良好的沟通能力；  8 愿意长期从事金融行业，有金融行业经验者优先，有CRM系统经验优先；  9 对于中级、高级、资深工程师要求不同，高级及以上需有团队管理经验。
职位职责： 1.结合业务情况进行大数据平台的开发和设计，数据产品的落地。包括但不限于：数据采集、调度引擎、开发平台、数据治理、数据服务等； 2.参与离线、实时的数据存储和加工处理，保证数据质量，保障集群高效稳定运行，保障数据平台稳定高效； 3.参与数据分析平台的大数据架构、方案和核心代码研发，系统优化； 4.参与大数据组件的选型，新技术的预研，包括但不限于：存储、流/批计算引擎，协助团队解决开发过程中的技术难题； 5.参与数据服务项目开发，为其他部门提供数据支持。  岗位要求： 1.全日制本科及以上学历,三年以上工作经验，计算机、通信、数学等专业优先； 2.精通Java或Scala, 熟悉Python，热爱技术钻研探索，精读hadoop生态内开源组件源码者优先； 3.基于Hadoop的大数据体系有深入认识，具备相关组件（Hadoop、Hive、HBase、Spark、Flink、Flume、Kafka、ES等）项目应用研发经验，参与过spark或Flink实时数据分析项目，有性能优化经验优先； 4.熟练使用Spring Boot、Spring Cloud进行项目开发； 5.有数据平台开发、海量数据处理经验者优先。
任职要求：1、全日制本科及以上，计算机相关专业，大数据开发工作经验3年以上 2、有良好的⼤数据知识体系，对技术、业务流程、产品设计有较好的理解。 3、对⼤数据⽣态中的hadoop/spark/hbase/hive/flink/es等计算/存储引擎，⾄少有1~2种有较深⼊理解和实践经验； 4、有⼤数据离线计算相关的实际优化和改造经验； 5、熟悉常⻅的开源分布式系统，具备系统开发、维护经验以及故障处理能⼒； 6、熟悉java开发语言、spring-boot、mybatis等开发框架，具备独立平台开发能力； 7、有强烈责任心和上进心，能接受加班和出差。岗位职责：1、开发并维护大数据平台，在规定日程内完成指定的相关任务； 2、定义、设计、实现和维护多层级的分布式软件系统，并完善相关文档； 3、确保系统满足功能、性能、可扩展性、可靠性； 4、评估模块的开发工作量，规划实现工作，发布系统变更； 5、理解公司业务及各项目中对于大数据平台的需求，并提出解决方案。
技能要求：数据处理，Spark，Hadoop，Flink，SQL，ElasticSearch职责描述：1. 负责基于Hadoop、spark、flink、ElasticSearch平台的离线/实时数据处理、数据计算、数据开发；2. 负责数据中台建设开发、数据治理、分析、处理、编码、拉通等工作；3. 负责数据中台的高可用性、高可扩展性、高并发的持续优化；4. 负责基于现有数据中台的迭代优化工作；5. 负责搜索引擎ElasticSearch数据加工及分词优化工作。任职要求：1、具备扎实的离散数据、数据结构、线性代数、概率论等基础知识；2、有3年以上的Python、spark、ElasticSearch实际开发经验；3、熟悉Python、scala进行spark代码开发工作；4、精通SQL语句，对数据敏感，有较强的逻辑分析能力，对大数据处理和分析技术有丰富的经验和强烈热情；5、有数据中台实际开发经验、较强的日常故障诊断和性能调优能力；6、对基于Hadoop集群高并发、高可用、高可扩展性体系系统有一定的理解；7、有DataWorks、MaxComputer实战经验者优先；8、有Spark GraphX实战经验者优先；9、有机器学习、数据分析等相关工作经验优先；10、熟悉微服务技术架构、Docker技术的优先；11、熟悉Kafka、Zookeeper、spark、Flink底层源码者优先；12、性格开朗，善于交流，有良好的团队合作精神和协调沟通能力。
职责:1、负责公司核心产品的设计与开发；2、参与核心产品的架构设计，及计算框架的算法实现；3、根据开发进度和任务分配，完成相应模块的系统设计、编码及相关文档的编写，并在开发过程中解决关键问题和技术难题；岗位要求：1、熟悉Java、Scala语言开发，对JVM运行机制有深入了解；2、深入了解spring，mybatis，cache，mq，dubbo等领域的框架的机制与代码；3、熟悉Hadoop/Spark生态系统的使用及开发，至少有一年的Spark(Core/Streaming/SQL/GraphX)开发经验；4、熟悉Spark调优，对SparkOnYARN、SparkStandAlone模式均有部署使用及优化经验；5、具备扎实的计算机系统和算法基础知识，有地理空间相关分析算法研究。6、熟悉企业应用设计模式、面向对象的分析和设计技术，包括设计模式、UML建模等；。7、良好的沟通能力和问题解决能力，有强烈的责任心；8、有团队精神，良好的抗压能力，心态积极，能主动融入团队
职位描述 考拉数据产品技术团队，作为整个考拉的数据中心，我们拥有海量丰富的数据积累和沉淀。对于数据应用，数据管理，实时计算，挖掘算法等电商类数据产品有着丰富的实践经验。我们秉承“一切业务数据化，一切数据业务化”的目标。期望利用数据&技术赋能业务，让业务具备数据化驱动的工具和能力，推动业务发展。    如果，您热爱数据，期望用数据技术建立奇迹，实现梦想。请加入我们，一起创造考拉数据的新未来！1 利用海量业务数据，设计数据模型，搭建数据平台，2 负责解决并实现大数据计算分析需求（离线+实时）。3 负责数据底层引擎OLAP产品的设计开发工作职位要求1 本科及以上学历，3年以上大数据相关工作经验,具有较强的编程能力（Java/Python/SQL）；2 具有数据仓库、海量数据计算，实时流式计算等相关项目经验；3 掌握Hadoop、Hive、Spark，Storm，Flink等大数据相关技术者； 4 优秀的数据分析和解决问题能力，能够把理论成功应用于实践；5 对数据技术有极强的兴趣和热情，有互联网广告项目经验优先。
1. 参与搜索推荐AI大数据平台的开发，解决实时和离线计算流程中性能、功能等多方面的挑战，支持搜索推荐场景下特征处理、样本生产等流程的开发和高效迭代，支持集团算法和业务同学在平台上开发业务需求。2. 与Flink、Hologres等生态深度结合，挖掘计算和存储引擎的潜力，开发相关的组件，推进流批计算的一体化。3. 支持淘宝天猫搜索、拍立淘、AliExpress搜索广告等业务，优化性能和迭代效率。1.  具备扎实的计算机理论基础, 在操作系统、数据结构及算法方面有较强的功底，有很强的学习能力和自驱力。这是我们最为看重的一点。2. 精通Java或者C++，具备优秀的系统Debug/Profiling能力和经验，熟悉常见的面向对象设计模式，具备优秀的系统架构设计能力。3. 熟悉Hadoop/HBase/Flink/Spark等开源大数据技术，有大数据工程开发经验，有开源社区开发经验优先。
职位描述:1、负责蚂蚁金服国际数据体系的建设，通过数据+算法+工程化能力，处理和萃取数据特征以及上层的数据运营、数据决策的体系建设；2、参与大数据基础架构、产品技术的规划建设，包括数据采集平台、数据资产、数据产品、数据质量及稳定性保障体系建设。职位要求:1、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验尤佳；2、较为丰富的数据平台的架构经验，精通数据建模理念和实战能力；有较为系统的海量数据性能处理经验，在数据产品和应用一定的成功经验；3、具备较扎实的理论基础和工程能力，具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；4、良好的思维逻辑性、语言表达能力；有较好英语口语能力尤佳。工作地点:成都，杭州，上海
数据分析师算法数据研发均有需求
大数据开发5年以上经验
【工作职责】1、 研发安全运营平台，包含日志收入、数据处理、自动化响应等；2、 负责安全运营平台需求模块设计、接口设计、代码开发及验证；3、 支撑平台在攻防对抗中的应用和迭代；【任职要求】业务技能要求：1、具备良好的计算机、软件工程领域知识，熟悉软件系统设计、开发、测试等研发领域的流程、工程方法和工具；2、良好的学习能力、团队协作性好，沟通协调能力强；3、有研发工具模块设计、接口设计、开发经验优先。专业知识要求：1、熟悉C/C++、JAVA、Python、PHP中的至少一种，掌握常见的数据结构、算法；2、了解软件工程、敏捷开发等知识，熟悉常用设计模式；3、具备云化、服务化等相关知识并能熟练运用。
任职要求1、熟悉主流大型数据库，熟悉mysql优先；2、熟悉主流的数据仓库、ETL等工具；3、熟悉阿里云/华为云/开源CDH等分布式计算环境进行大数据分析与计算；4、做过数据仓库，对数据治理、数据标准及元数据有很好理念及实施经验的优先；5、良好的沟通能力和团队精神,具备创新意识；优先技能：1、具备电力项目的开发经验优先。2、具备数据中台项目经验优先。
岗位职责:1、负责搭建海量数据处理分布式平台以及数据分析系统； 2、参与数据工具、ETL程序开发工作； 3、参与数据分析平台的数据开发和调优工作。岗位要求：1、1年以上大数据开发工作经验，计算机、或相关专业本科及以上学历优先；2、熟悉Hadoop、Spark等大数据框架，有大型分布式计算开发、部署等相关经验；3、有扎实的Java开发基础，熟悉JAVA平台多种常用框架；4、熟悉Linux操作系统和开发环境；5、熟悉主流的数据存储产品，有开发经验者优先。如：HBase，Hive，Redis，MongoDB，MySQL等；6、具备海量数据处理相关框架及产品的使用经验者优先。如：Storm，Spark，Esper，Hadoop等；
岗位职责： 1.负责数据产品/数据仓库的ETL设计、开发、维护及质量核查； 2.负责数据仓库模型的规划和设计，参与建立并执行统一的数据开发规范； 3.参与或负责数据仓库基础设施和平台的建设，搭建金融行业领域的企业级数据仓库； 4.和需求方进行有效沟通，完成数据需求及数据问题解决等； 5.完成日常数据质量的监控，跟踪处理各类数据质量问题。 任职要求： 1、计算机、数学、统计学相关专业，本科及以上学历，两年以上数据开发相关经验； 2、精通SQL，良好的算法、数据结构基础，至少熟悉JAVA/PYTHON一门编程语言； 3、熟悉数据仓库建模和ETL设计开发，有数据质量与数据治理相关经验； 4、熟悉Hadoop、HIVE、HBase、Kafka、 Flume、Spark、Redis等开源框架； 5、有较为系统的海量数据性能处理经验和数据仓库开发经验； 6、良好的沟通表达能力和团队协作能力，可接受出差工作者优先。
1、参与行云集团跨境数据仓库架构设计与数据开发 ；2、负责数据平台相关数据管理工作，如研发规范、质量规范、保障规范的制定与推动实施落地 ；3、负责来自业务团队数据需求的研发支撑和数据产品落地。职位要求1、熟悉数据仓库模型设计方法论，并有实际模型设计及ETL开发经验；2、掌握大型数据库开发技术，如Oracle、Teradata、DB2、Mysql等等掌握至少其中一种，灵活运用SQL实现海量数据ETL加工处理；3、 熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等；4、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop/MaxCompute生态相关技术并有相关实践经验；5、掌握一门或多门编程语言，如Java、Python、Perl、shell等；6、熟悉常用的实时数据处理技术，如Flink、Storm、Spark Streaming等；7、良好的语言沟通与表达能力和自我驱动动力。8、有电商行业背景、数据应用经验者优先
一、工作内容描述：1、负责大数据平台的开发、维护和性能优化等；2、对原文件解析、清洗，大数据的计算、优化等开发工作；3、基于大数据平台开发专题数据库，包括ETL开发，数据仓库建设等；4、根据业务需求完成数据产品和数据应用开发，发掘数据业务价值，以数据驱动业务发展；5、技术研讨，ETL流程优化，根据业务发展需求引入新技术，提升平台服务效率；6、掌握岗位要求中相关的大部分开发技术，并快速学习掌握技术；7、按照领导要求，完成安排的任务。二、任职要求：1、计算机本科及以上学历，985/211/双一流院校优先；2、熟悉Java开发，对大数据处理、高并发或有网络开发经验尤佳（如：了解大数据技术生态圈相关的技术，Hadoop, Hbase, Hive、Impala, Spark, Yarn等），4年以上开发经验；3、熟悉如MySql、SQL Server等关系型数据库，具有实时数据处理经验以及SQL性能优化经验；4、熟悉Linux操作系统，具备大数据计算服务（maxcompute）平台运维管理经验者优先；5、熟悉知识产权业务，有专利数据类项目向开发者优先。
任职要求：1、熟悉数据仓库ETL的开发和数据建模，1年以上数据仓库实施经验；2、熟练使用MySQL，PostgreSQL主流数据库，熟练编写SQL语句；3、熟悉常用的数据迁移工具Kettle、DataX等；4、熟练Linux及常用命令操作；5、有大数据开发经验者优先；6、熟悉阿里生态圈，具有odps、ads等开发能力者优先。 7、1年以上Java软件项目开发经验；8、工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。
只接受国家统招本科，硕士。基于AWS，ALIYUN技术的大数据开发工程师岗位职责：1、负责数据采集、清洗、加工、整合，并能够独立进行ETL开发和数据分析；2、参与数据仓库ETL流程优化及解决ETL相关技术问题；3、负责相关项目系统架构模型的设计和优化；任职要求：1、本科及以上学历，3年以上ETL工作经验；2、具备简单的ETL 相关的英文读写能力；3、熟悉DW/BI项目系统架构和基础知识，熟悉数据仓库、数据集市的建模理论；4、熟悉Oracle、SQLserver、Mysql、等主流数据库开发，熟练掌握SQL及存储过程；5、熟悉AWS S3 , Glue,  Athena , python 等开发经验优先，熟悉aliyun平台及组件，有dataworks，dataphin平台开发经验优先；6、有ETL项目经验，参与过完整的BI项目并有过完整的BI项目ETL实施经验，精通帆软报表工具或tableau, quickbi报表工具，了解日常作业的部署和调度；7、有较强分析问题的能力、团队协作能力、优秀的沟通能力和高度工作责任心。
【职位描述】：1. 负责微博机器学习大数据平台和计算平台的架构和开发和维护，为业务团队构建稳定易用的平台服务；2. 根据业务需求设计高扩展性、高性能的系统架构和应用架构；3. 为公司核心的机器学习平台提供计算能力支持。【职位要求】：1. 要求本科以上学历；2. 熟练掌握C++/JAVA/Go/Python语言至少其中一种，并具有实际的项目开发经验；3. 熟悉主流的云计算、大数据产品（Hadoop/Hive/Impala/Spark/Flink/HBase/ES/Storm等）和数据分析技术（机器学习)并具有相关项目开发经验优先，有相关运维管理经验优先；4. 具备大数据管理平台建设(如元数据管理，数据治理、数据血缘及数据分析平台服务建设、实时数仓等)经验优先；5. 有平台维护优化以及任务优化经验，有较强的性能优化及问题排查解决能力，对开源技术非常感兴趣并具有一定的研究能力优先；6. 学习能力强，有较强的问题分析和处理能力，具有团队合作精神。
1.负责大数据平台离线，实时等任务的运维工作，涉及到spark，flink等任务的调优，问题排查等工作2.完成大数据平台完成实时，离线等任务的开发工作岗位要求：1.本科及以上学历，3年以上大数据开发工作经验，熟悉java，Scala、Python优先考虑；2.熟悉海量数据的处理，熟悉spark，flink，hadoop等大数据框架的工作原理，有实际的任务调优工作经验者优先考虑3.熟练掌握数仓建模方法论，具备熟练维度建模能力，熟悉OneData优先
1、负责大数据开发及平台稳定性保障工作2、负责处理大数据平台Hadoop/Hive/Spark/Storm等问题及性能优化3、根据业务需求开发相应工具任职资格1、三年以上工作经验，有大型互联网行业从业经验2、有Hadoop/Hive/Spark/Storm/Zookeeper 等相关开发经验或从事分布式相关系统的开发工作3、熟悉Linux/Unix系统和丰富的Java开发经验4、具有强烈的责任心，求知欲望强
1.负责公司大数据产品、项目的后台研发，参与大数据的运维保障工作；2.参与大数据相关的算法和模型分析实现；3.参与大数据的数据治理和数据处理相关java开发工作。4.负责技术预研，产品设计以及文档编写等工作；任职资格：1、本科及以上学历应届毕业生，计算机、软件工程师及其他理工类专业；2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；3、对开源大数据系统有相关经验者优先，包括但不限于Hadoop/Spark/Hive/Flink/Kafka/Kylin/ClickHouse 等；4、对数据敏感，掌握量化分析方法，善于从数据中发现问题者优先；5、具备良好的分析问题和解决问题的能力，有较强的责任心，具有良好的学习、沟通能力，注重团队合作，有创新精神。备注：月薪总额包括基本工资、加班工资、餐补等各类补贴
1、负责大数据开发及平台稳定性保障工作2、负责处理大数据平台Hadoop/Hive/Spark/Storm等问题及性能优化3、根据业务需求开发相应工具任职资格1、三年以上工作经验，有大型互联网行业从业经验2、有Hadoop/Hive/Spark/Storm/Zookeeper 等相关开发经验或从事分布式相关系统的开发工作3、熟悉Linux/Unix系统和丰富的Java开发经验4、具有强烈的责任心，求知欲望强
1、参与和主导大数据平台的开发和设计，数据产品的落地，包括但不限于数据采集、调度引擎、开发平台、数据治理、数据服务等；2、参与平台的技术攻坚，解决平台的疑难杂症，包括但不限于：故障的定位与修复、资源及性能的优化；3、参与平台技术的选型，新技术的预研，主流前沿技术的引入和落地，包括但不限于：存储、（流/批）计算引擎、多维分析及直接支持应用的各类数据产品；4、参与开发流程的优化改造，数据迁移等；5、负责客户需求的梳理，技术方案设计和落地。岗位要求：1、3年以上数据平台开发经验，至少完整负责过下列模块之一：数据集成/调度引擎/开发平台/任务运维/数据服务；2、3年以上的Java开发经验，可熟练开发MapReduce/Spark/Flink之一，熟悉java的IO/并发/容器/内存模型；3、熟悉hadoop生态环境，有HBase/Kafka/Hadoop/Hive/Spark/Flink/ES开发经验；4、熟练操作Shell，可独立使用命令行解决集群问题；5、具备快速学习、团队合作及高效沟通的能力；6、有过PB级数据平台经验者加分；7、熟悉Mongo/Redis/Mysql/Kylin/Druid/Flume/Zookeeper等开源产品者加分；8、熟悉SpringBoot/SpringCloud；9、有电力行业大数据平台建设工作经验加分。
1.负责公司大数据产品、项目的后台研发，参与大数据的运维保障工作；2.参与大数据相关的算法和模型分析实现；3.参与大数据的数据治理和数据处理相关java开发工作。4.负责技术预研，产品设计以及文档编写等工作；任职资格：1、本科及以上学历应届毕业生，计算机、软件工程师及其他理工类专业；2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；3、对开源大数据系统有相关经验者优先，包括但不限于Hadoop/Spark/Hive/Flink/Kafka/Kylin/ClickHouse 等；4、对数据敏感，掌握量化分析方法，善于从数据中发现问题者优先；5、具备良好的分析问题和解决问题的能力，有较强的责任心，具有良好的学习、沟通能力，注重团队合作，有创新精神。备注：月薪总额包括基本工资、加班工资、餐补等各类补贴
1、负责业务的离线和实时数据仓库、数据治理、数据模型等相关设计与开发工作；2、完成日常数据质量的监控、跟踪处理各类数据质量问题，根据需求完成、完善数据质量评估报告；3、配合数据分析师、算法工程师完成项目指标和算法模型工程化，为业务系统体重数据能力支撑。职位要求：1、本科及以上学历，计算机、软件工程、电子信息相关专业背景，3年以上数据开发经验，1年以上实时数据仓库和离线数据仓库的开发经验；2、掌握大数据生态工具，例如：Spark、Flink、Hive、Kafka、Hadoop、HBase、Clickhouse、ES、Flume等的使用，有较为深厚的工具使用和调优经验；3、熟练使用Java、Python、shel等编程语言实现业务逻辑，并能优化相关数据处理流程以及代码；4、数据库基础及hql编程扎实，精通hql代码开发、能够编写和优化高性能hql，能够对海量数据计算进行调优；5、对数据敏感，具备良好的业务理解能力，通过数据体系与业务结合，进行良好的数仓模型设计，保障稳定性和扩展性；6、熟悉微服务开发，熟悉Spring等主流开发框架；7、有良好的逻辑思维性，有良好的抗压能力和自驱能力；8、有良好的问题分析和解决能力，快速理解业务逻辑并转化为技术方案。
岗位职责：1、参与公司项目的需求分析、业务设计、编码实现开发过程； 2、完成单元测试、参与技术讨论、编写技术文档；3、负责子系统模块的设计与实现； 4、负责完成领导安排下来的工作任务。任职条件：1、全日制本科及以上学历，计算机相关专业,有2年以上的大数据技术实践经验；2、精通掌握Java编程，熟悉IO、多线程、集合等基础知识，有性能调优能力；有Python、Scale，Go等编程经验者优先；3、熟练掌握常用设计模式，对面向接口编程、面向服务编程有一定的认识；4、熟悉Hadoop框架体系，掌握kafka等消息中间件知识，有Spark，Kylin，Flink等分布式计算相关开发经验者优先；5、掌握MySQL、Redis、MongoDB等知识，熟悉NoSQL框架，有Hive，Sparksql，Elasticsearch、ClickHouse等数据应用开发经验者优先；6、熟悉Linux下的常用命令，能够熟练使用shell语言进行脚本开发。7、良好的团队协作能力和沟通能力以及极高的项目责任精神，性格成熟沉稳，能够接受工作压力和迎接挑战；加分项：   有数据仓库产品实战经验，对海量数据的存储处理、维度建模、数据分析、数据挖掘等有深刻认识者优先；
1.负责大数据系统的开发工作，包括不限于数据接入，数据清洗，数据挖掘，业务主题建模等。2.对系统存在的问题进行跟踪和定位，并及时解决。3.独立承担技术支持与开发服务工作。4.严格执行工作计划，高效完成任务，保证部门及个人工作目标实现。5.完成部门安排的其他研发相关工作。任职要求：1.计算机相关专业，本科以上学历2.熟悉离线和实时数据处理相关组件和流程，组件包括datax、hive、hdfs、greenplum、mysql、kafka、spark、flink、hbase，流程包括数据采集、数据传输、数据计算和存储等3.能熟练使用hivesql和传统sql解决业务问题4.至少熟悉一门编程语言，如java、python5.具备金融行业数据类项目经验优先考虑
岗位职责：1、负责公司大数据平台整体架构的规划和设计；2、负责大数据平台技术框架的选型和开发；3、负责大数据平台的搭建，完成系统调试、集成与实施；4、负责并参与项目开发过程中的技术攻关及核心代码编写；5、负责大数据应用开发，提供数据应用项目技术支持，参与数据应用类项目任职资格：1、本科及以上学历，计算机相关专业，具有大数据平台搭建、架构和研发经验; 至少参与过一个完整的大数据开发项目；2、熟悉Linux系统，熟悉shell编程，在操作系统、计算机网络和安全方面具备系统知识和相关经验3、熟练掌握Java/Scala，熟悉大数据离线计算生态体系，对Hadoop、HDFS、HBase、MapReduce、Kafka、Yarn、Hive、Spark等开源组件有研究，有海量数据处理经验；4、熟悉日志采集传输、消息队列相关技术，对Kafka、Flume、Fluentd等开源组件有深入研究5、至少熟悉一种编程语言（Python/Java）。6、精通离线和实时数据处理流程，掌握离线数据处理框架，掌握实时数据处理常用技术工具等，熟悉Flink优先；7、有数据仓库开发经验/BI系统开发经验者优先；公司处于团队扩张期，机会多多，普林斯顿AI博士亲自带队研发，领导open, 同事nice, 期待你的加入！
1.具有大学本科及以上学历，计算机及相关专业；2.精通Oracle、Mysql或HIVE、Hbase等数据库，熟练掌握SQL、PL/SQL、PERL、Python等脚本语言开发；3.精通JAVA语言或SCALA语言，精通hadoop大数据基础组件,熟练掌握Spark\Spark-Streaming \ ElasticSearch\ FLINK\ kafka等相关大数据应用设计开发能力。具备大数据源码走读能力，有较为丰富的集群运维经验。4.熟悉银行业务，从事过银行业相关数据开发三年以上；5.曾经主持或者作为系统或者数据架构师参与数据相关中大型项目三个及以上，6.具有5年以上报表系统、数据平台、数据集市建设、数据仓库、大数据相关项目开发经验；7.具有较强的文档编写能力和英语4级或相当水平的外语能力，能阅读英语技术文档；8.具有良好的沟通能力和团队合作精神
职位描述1、充分理解业务的需求，结合数据平台的建设与发展，完成后台数据服务的开发2、结合实际业务场景，完成实时计算流数据及相关服务的开发3、保证团队的数据服务及实时计算构建的稳定性、可靠性、可扩展、可运维并持续迭代的能力；任职要求1、本科及以上学历，计算机相关专业，两年以上服务端研发经验。2、熟练掌握Golang/Java至少一门语言，有过gRPC/SpringMVC/Gin等后台服务框架的实际开发经验3、了解相关大数据组件如：spark，flink, hadoop, druid，redis，kafka，有过大数据实时计算开发经验优先4、关注性能、有分布式系统或高并发开发经验优先;5、具有较好的团队协作精神和沟通能力，能够承担较大工作压力，思维清晰，条理性强，主动性强
工作职责：1、负责大数据平台数据仓库、数据治理、数据模型等相关设计与开发工作；2、负责日常数据报表开发和统计分析工作，理解并抽象业务需求，发挥数据价值；3、负责离线和实时数据服务的设计、开发、性能调优和效果优化；4、完成日常数据质量的监控，跟踪处理各类数据质量问题；5、参与大数据平台的日常运维工作；6、部门领导交代的其他任务。任职要求：1、本科毕业5年及以上，计算机、数学、金融等相关专业；2、5年以上大数据平台开发经验；熟悉大数据hadoop平台及生态，熟练掌握spark、kafka、flume、flink等技术；有一定的数据敏感度，对技术的学习和研究充满热情。3、熟悉hive、hbase、ES、oracle、mysql等数据库其中两种以上，拥有较好的数据仓库设计和建模能力；有数据治理相关经验者尤佳；4、认真负责，具有团队合作精神，良好的沟通、协调及快速高效学习的能力；5、有激情，有担当，执行力强，能承担较大压力；6、有证券、银行、互联网金融等机构相关经验优先。
BASE：深圳/杭州岗位职责：1、深度参与基于大数据平台的资产管理中台架构设计与研发。2、负责中台的金融计算引擎设计、开发、性能优化、自测和文档编写。3、跟进前沿技术发展，参与技术选型。岗位需求：1、全日制本科及以上学历，计算机相关专业； 2、2~5年大数据相关系统研发和性能优化经验，证券/资管行业经验优先考虑；3、对大数据相关组件：Hadoop、Spark、Flink、Hive、Kafka、Flume、DataX等架构与底层实现有深入理解，具备相应的定制和研发能力；4、精通至少一种编程语言（Shell/Scala/Python/Java），熟悉至少一种关系型数据库；5、工作有计划性，责任心和执行能力强，具备高度的责任心、诚信的工作作风、优秀沟通能力及团队精神。6、对技术有热情，有不错的数据思维和敏感度，有一定的数据分析能力优先； 7、具备强烈的工作责任感，喜欢钻研，态度乐观，团队意识强。发展机会：1、学习基金、保险、证券等资管机构的业务需求，推动中国金融行业的业务技术发展，帮助提高个人和家庭的财富管理能力；3、成为资管业务和大数据开发领域的综合性专家，获得稳定和较优的待遇和成长机会。
岗位职责：1、根据业务需要，实现数据采集、清洗入库、数据开发处理等相关工作；2、数据仓库建设，BI应用建设、SQL开发，离线任务和实时任务开发；3、参与规划及建设数据报表系统与基础数据体系，支撑数据需求；4、参与数据平台的部署、日常维护、监控、调优等工作。任职要求：1、熟悉java/scala/python/sql/shell等至少两种编程语言，具备扎实的数据结构和算法基础，对sql优化有一定的了解;2、 有相关的大数据任务调度系统使用、调优经验者优先，如DolphinScheduler、Airflow、Azkaban等；3、 熟悉Hadoop、HDFS、Yarn、Hive、Hbase、Spark、Flink、Datax等大数据技术栈者；4、 对数据治理，即数据质量、元数据管理等有一定的了解5、有过信创项目开发经验优先；6、有过政务类\教育类项目的数据开发经验优先。
岗位职责：1. 负责新闻推荐相关的大数据仓库建设。2. 负责部门实时计算开发、实时仓库建设。3. 负责推荐相关数据业务开发。岗位要求：1. 熟悉java开发语言，一年以上经验。2. 熟悉大数据生态，熟悉hadoop、MR、hive、flink等大数据技术。3. 熟悉数据仓库建设、实时计算相关理论。4. 熟悉mysql、redis、hbase、kafka相关知识。5. 至少一年以上大数据相关工作经验。
1、 计算机、软件工程、电子信息相关专业背景，3年以上工作经验；2、 精通Oracle、MySQL、MSSQL等数据库，掌握SQL语言；3、 精通Hadoop、Hive、ClickHouse、Spart、storm等大数据平台/工具，有相关实践经验；4、 熟悉常见的数据模型，有较好的开发习惯和编程规范；5、 有Java或Python开发经验，会使用常用的开发框架；6、 有报表、BI等相关开发经验优先；7、 具备按时完成项目开发与交付的能力；8、 工作认真负责有责任心，有很强的主动学习能力、理解能力，有大数据项目经验者优先。
岗位职责：1. 负责公司数据层相关的大数据仓库建设。；2. 负责数据采集侧自动化工具开发，部署，维护；3. 负责海量数据性能处理工作，推荐相关数据业务开发；岗位要求：1. 工作强度大，需要加班，熟悉python，java开发语言，一年以上经验。2. 熟悉大数据生态，熟悉hadoop、MR、hive、flink等大数据技术。3. 熟悉数据仓库建设、实时计算相关理论。4. 熟悉mysql、redis、hbase、kafka相关知识。5. 至少一年以上大数据相关工作经验。
岗位职责：（非外包，需学信网可查的全日制）1、负责数据平台的大数据基础架构规划、运维保障、业务监控等，为海量数据和业务系统提供可靠的基础设施；2、参与大数据生态相关技术的前瞻性研究和调研落地，持续扩充大数据能力，优化大数据服务的性能和效率；3、深入了解业务背景，能抽象业务需求，运用大数据技术解决业务场景中的实际问题，能够支撑业务的快速发展。任职要求：1、3年以上的大规模集群(Hadoop/Kafka/ES等)实战运维优化经验，实际解决过分布式系统的线上问题；2、熟悉Linux系统，熟悉Shell脚本，至少掌握Java/Python/C++中一种编程语言，具备源码级问题解决和集群优化改造能力；3、熟悉服务管理、单元部署、自动扩容等运维系统建设，善于捕捉和解决业务需求、架构设计存在的问题，对成本控制、效能提升和故障排查有深刻的理解和实践；4、熟练掌握Hadoop、Kafka、Hive、Impala、Kudu、Sentry/Ranger、HBase、Zookeeper、ELK、Ceph等大数据开发工具中一种或几种；5、对大数据行业富有热情；有较强的责任心，执行能力强；具有优秀沟通能力及团队精神；6、对开源社区有贡献者优先。
岗位职责：1、参与大数据分析平台和数据仓库设计、建模、研发2、对各源数据进行ETL与标准化3、根据业务需求，开发相应数据产品任职要求：1、具备较强的数据分析，问题分析，逻辑思维能力，良好的沟通，团队协作能力。2、计算机或相关专业本科及以上学历；3、熟悉大数据领域相关组件，如Hadoop、Spark、Hive、HBase、Kafka、Flume等其中3个以上4、精通Spark RDD运算模型，熟练开发Spark Job、Spark Streaming应用程序；5、熟悉Mysql，Oracle 等存储引擎的数据存储及使用方法；6、熟悉Linux系统，能够在Linux环境中熟练地部署、配置和开发大型复杂的平台软件，熟练使用shell/python脚本处理问题
1、计算机相关专业2、具有扎实的SQL基础，熟练使用Hive SQL进行开发，有阿里云dataworks开发经验者优先；3、熟悉Linux，至少懂Java和scala一种以上语言编程4、数据大数据编程技术包括：hadoop、hive、spark、flink等5、熟悉数据仓库理论方法及ETL相关技术6、学习能力强，有团队观念，能主动发现问题和较强的沟通能力和理解能力常用负荷。U三相、l三相，P和三相，Q和三相，功率因数COS及三相
岗位职责：1、根据数仓模型架构进行业务理解、业务沟通、核心系统的探查；2、可独立完成实时和离线数据模型设计开发工作；3、可根据设计完成的主题模型，独立进行ETL开发，包括业务数据的清洗、转换、加载；4、独立完成etl代码性能调优、etl调度错误处理，etl依赖管理；5、根据数据质量管控流程，验证数据质量。岗位要求：1、大专及以上学历，计算机、理工等相关专业，1-3年相关工作经验，优秀应届生均可；2、熟练模型架构，熟练数仓的原理及数据库原理，olap的原理；3、熟悉掌握一种以上JAVA、Scala、python等开发语言；4、熟悉掌握flink、spark、HQL、hadoop等大数据生态框架；5、熟悉一种调度系统的原理，如：阿里dataworks、airflow、kettle。
岗位职责：参与数仓平台建设，包括ETL设计，建模，数仓搭建，监控体系搭建参与数据产品，数据分析需求的开发负责数据管控，操作审计等数据安全保障工作负责集群扩容，备份等运维工作任职资格：本科及以上学历，计算机或相关专业本科或以上学历，工作细致、善于思考，有很强的数据分析和问题解决能力2年以上工作经验，精通linux操作系统，对系统性能相关问题有较深刻理解精通shell编程，熟练常用命令精通Hadoop，spark，kafka, hive,flink，ES等相关架构及运维熟悉大数据集群运行基本原理及集群高可用性方案熟悉TCP/IP协议，能够定位linux网络下普通的网络异常强烈的责任心、良好的沟通和协调能力有devops实践经验优先
职责描述：1、负责数据仓库的设计与研发。2、负责数据全链路的开发，包括日志埋点、内部与外部数据的采集、数据同步、数据清洗与标准化、数据模型设计、离线数据处理、实时数据处理、数据服务化、数据可视化等。3、负责数据治理工作，包括元数据管理、数据质量检查、数据分级管理等系统的设计、开发及应用，提升数据易用性、可用性及稳定性。4、负责业务交付数据研发。岗位要求：1、计算机及相关专业毕业，本科及以上学历2、熟悉数据仓库相关理论，实际参与过2个以上的数据仓库项目，有数仓模型设计及ETL开发经验；有数据仓库分层架构设定经验者优先；有零售、医疗行业数据模型设计经验者优先3、熟悉 Hadoop 生态相关技术，如 Hive、HBase、Spark、Flink、Storm、Elasticsearch、Impala、Druid、Kylin 等，有基于分布式数据存储与计算平台应用开发经验，熟悉阿里云大数据平台（如 MaxCompute、Blink、DataWorks、Dataphin 等）者优先4、熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等5、热爱大数据，性格沉稳，有较好的语言表达能力，能自我驱动，有强烈的求知欲与进取心，有团队合作精神，敢于挑战，能在压力下成长6、有医疗行业相关经验优先。
关于我们：- 初创公司，我们致力于打造新一代云原生实时数仓- 数仓内核团队，公司的核心部门- 基于share disk + share nothing架构、读写分离的、支持多workloads的实时数仓我们将为您提供：- 数仓部门技术核心研发岗位，与您匹配的待遇，畅通的技术提升与岗位晋升通道；- 参与从0到1的产品开发过程， 公司业务快速发展和技术转型带来的技术挑战和业绩红利；我们需要您：- 完成数仓与大数据生态的集成，包括flink、spark等- 参与数仓的核心设计与开发工作，包括编写执行器、存储、索引构建等- 参与支撑数仓上层云平台的建设，包括任务调度、编排、治理、数据服务等您必须具备：- 3年（含）以上的大数据开发经验，对海量数据处理和快速计算有浓厚兴趣- 计算机相关专业，基础扎实，能够深入理解代码或者有较强的学习能力与意愿- 良好的英文阅读能力和资料查找能力，能快速地查阅资料、深入分析并解决问题- 精通Java、rust、c，熟练使用Linux操作系统- 熟悉Hadoop生态，可熟练使用Spark进行开发- 良好的团队合作精神，逻辑严谨，责任心强具备以下条件尤佳：- 有较好的数据结构、算法基础，对排序索引、倒排索引、文本检索索引了解优先- 有数据中台、平台开发经验，大数据计算引擎相关的研发经验最好欢迎广大大数据从业人员了解并投递简历，薪资可谈不设限，本岗位非数据ETL和业务开发，如果能力够强，有意愿转到大数据平台开发也可。
职责描述：1.负责业务数据调研、数据ETL；2.负责建立数据模型，根据业务设计数据主题；3.参与团队ETL流程的优化及解决ETL相关技术问题；4.理解数据需求，提供面向业务的OLAP、报表、数据提取等数据服务；5.基于行业数据仓库标准进行数据开发和模型开发支撑业务应用。任职资格：1、掌握数据库应用并熟练掌握SQL开发，并有SQL调优经验；2、熟悉数据仓库模型设计，具备海量数据处理经验，拥有数仓设计或建设的实战经验；3、熟悉数据仓库领域知识和技能者优先，包括但不局限于：数据治理、元数据管理、数据质量监控；4、熟悉Mysql,Clickhouse,Doris,Hive，Hbase， 等离线框架基本原理，能够将技术与业务很好的结合；5、有BI系统项目和JAVA开发经验者优先；6、对大数据技术有很强的兴趣，不断自我学习，对新技术热衷热爱
岗位职责大数据团队致力于构建最强大数据解决方案竞争力，打造极致大数据平台性能，拥抱开源社区，构建合作共赢的大数据生态。岗位要求1、计算机、软件、通信等相关专业本科及以上学历，熟悉C/C++/JAVA/Scala语言编程，有扎实的算法及数据结构基础，有良好的编程习惯，熟悉linux操作系统；2、有软件开发相关实践经验，学习能力强，能够快速阅读和学习开源代码，主动总结分享；满足以下任一条件优先考虑：1、熟悉大数据开发的基本框架，熟悉大数据核心组件Hadoop、Hbase、Spark、Hive、ElasticSearch等组件原理以及相关应用，有组件性能调优经验优先；2、熟悉业界主流流处理平台如Storm/Flink/Spark Streaming之一。
专业要求：1、精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/Shell等编程语言及脚本语言；2、至少熟悉一门大数据计算引擎。如：Spark、Flink、Hive等(有Flink经验优先)，具有实际使用经验；有大数据开发项目的经验，具备一定Sql调优能力；3、熟悉一种或多种数据库mysql、sqlserver、db2、mongoDB、redis等，具有实际开发经验；4、具备出色的学习能力和故障排查能力，良好的技术敏感度和风险识别能力                                                                                                 任职要求：1.  计算机及相关专业本科及以上学历，有互联网医疗行业开发经验更佳；2.善于思考，能独立分析和解决问题,责任心强，具备良好的团队合作精神和抗压能力；3. 良好的编码风格；4.三年以上工作经验福利待遇：双休，五险一金，国家法定节假日，年终奖金，餐补，生日福利等我们为员工提供有竞争力的薪金和福利待遇，欢迎加入我们的团队！
岗位描述：专业：计算机或相关专业；年限：一年以上Java大数据开发经验；1、有较强的责任心并具有一定的抗压能力，具备良好的团队合作精神，较强的沟通协调能力；2、善于学习，对业务有浓厚的兴趣，能够快速理解业务，能够独立与业务人员进行有效沟通；3、熟悉Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境，具有扎实的j2se基础，注重代码规范、代码执行效率，善用设计模式；4、熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，熟练掌握主流Spark框架，熟悉主流NoSQL数据库；5、熟悉Hadoop、流式计算、任务协同管理、YARN资源管理、多线程并发及通讯编程；6、熟悉数据仓库原理，熟悉SQL语言。7、熟悉机器学习常用相关开源框架，如Mahout、MLlib、Trident等优先；
岗位职责：1、承担建设基于Hadoop/Spark/Flink生态的大数据离线/实时计算处理工作；2、参与业务数据、生产日志的抽取、转储、检索等相关工作；3、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景；任职要求：1、3~5年互联网大数据处理经验；有高频大数据实时计算处理工作经历并有一定解决方案者优先；2、熟悉大数据开源技术，包含（不限于）Hadoop/Spark/Spark Streaming/Flink/Hive/Hbase/Impala /Flume/Kafka/Solr/Es分布式框架/计算/存储/检索等相关技术,并有一定的Hadoop生态系统运维经验；3、掌握Java开发语言，熟悉Springmvc、Spring、Mybatis、Spring Cloud等主流开源框架；4、掌握SQL，SparkSQL进行数据开发；较好的SQL性能调优经验；5、优秀的分析、解决问题能力，充分的数据敏感度；有一定的高性能支撑经验和故障排除能力；6、具备强烈的工作责任感，喜欢钻研，态度乐观，团队意识强。
负责实时大数据研发.有flink、kafka等大数据工具研发经验
工作职责:1、理解客户业务需求，将需求转化成对数据加工生产的要求2、深入理解政务行业数据，理解和提炼标准，结合数据的技术特点设计数据模型和加工生产逻辑3、对数据处理过程中的问题进行准确的分析和定位4、根据实际数据项目需求，设计整体实施方案，指导数据项目建设，负责数据调研、数据归集、数据建模、数据标准、数据产品使用、数据质量、数据共享服务相关工作5、完成数据项目的实施交付，能够及时发现项目交付工作中问题、风险，并能有效寻找解决途径；任职资格:1、1年以上同岗位经验，理解数据治理的方法，具备数据仓库建设经验，包括数据归集、数据清洗、质量监控和评估、数据建模等实施经验2、具有政务行业数据标准梳理的能力，对政务行业领域数据模型和标准有深入了解3、熟悉政务行业典型数仓的建设过程4、对数据的可视化展现有深入认识和理解5、掌握各类数据库的使用场景，包括常见的关系型数据库、NoSQL数据库、MPP数据库等6、有阿里大数据平台DataWorks数据开发的经验7、熟悉政务相关领域的业界产品和方案8、具有很强的沟通能力和技术文档撰写能力9、精通Hive/SparkSQL，理解底层原理，熟悉常用优化技巧，至少能使用一种Python、Scala、Java、Shell等脚本语言；
岗位职责1. 研究大数据领域相关业务、产品、技术情况；2. 负责企业项目的运维平台大数据设计开发，带领团队实现大数据相关业务；3. 设计大数据运维产品，包括产出需求，原型与相关的配套文档；4. 与各产品研发团队合作，推动产品的发布；5. 与项目团队合作，推动产品的交付； 任职要求1. 4-10年工作经验，精通Kafka、Flink、ElasticSearch等大数据相关技术；2. 具有较好的沟通能力，组织、协调、团队管理及解决问题的能力；3. 熟悉软件产品生命周期及生产过程，有与研发团队配合的经验；4. 具有较好的方案能力，能设计与编写产品原型、需求与方案配套文档；5. 具有强烈的学习、成长意愿；有责任心，能承受较大的工作压力；有团队协作精神，善于挑战；6. 加分项：拥有运维平台、数仓建模、数据治理
岗位职责1、负责对运营提出的数据需求，进行数据抓取、清洗和处理；2、负责大数据应用相关产品需求分析、架构设计以及开发实现；3、设计和开发大数据应用相关统计分析系统和挖掘系统。任职要求1、大学本科及以上学历，计算机相关专业；2、熟悉至少一种主流开发平台和语言（C#或Java）；3、具备良好的沟通力、表达力、团队协作力以及责任心。
一、岗位职责1）负责银行各类数据业务开发工作。二、任职要求1）大学本科及以上学历，计算机相关专业；2）熟悉Gauss/IBM DB2/Oracle/Teradata/离线平台等相关数据库和平台，熟悉数据仓库技术，能熟练使用一种及以上关系型数据库；3）3年以上数据仓库应用系统分析、设计和开发经验，具备项目管理或开发团队管理经验者优先；4）具备良好的沟通力、表达力、团队协作力以及责任心；5）熟悉Gauss数据库开发经验者优先；6）熟悉银行数据报送工作者优先。
职位描述1.负责数据基础架构和数据处理体系的建设与优化。2.负责大数据平台的架构设计，参与数据应用需求、设计、审核和评审。3.负责大数据 ETL 的研发工作。4.负责建立和维护大数据平台技术标准规范，指导开发人员编写代码。职位要求1.本科及以上学历，有3年以上的工作经验，大数据相关产品设计及开发至少经验1年以上；2.熟悉大数据开发框架及业界主流技术框架，如Hadoop、Spark、Hbase、Storm、Flink、SparkStreaming等；3.熟悉Clickhouse/Greenplum/Presto/Druid等OLAP计算引擎的一种或多种。4.熟悉JAVA、Scala中的至少一种，掌握常见的数据结构、算法；5.对数据质量管理、数据应用等有独到见解的优先。
职责1、负责电商领域和供应链领域的数据仓库建设和维护；2、负责构建电商平台全链路数据指标体系；要求1、本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业，3年及以上大数据平台开发工作经验；2、熟练使用java、scala、python等开发语言中的一种； 2、熟悉数据仓库模型设计，掌握常用数据建模方法，具备海量数据加工处理（ETL）相关经验；3、有hadoop和hive、spark、flink实际开发经验；4、了解大数据组件的使用限制和应用场景，如hdfs、hbase、hive、kafka、ES、MongoDB等。4、能够独自完成数据调研和探索，以数据驱动业务，发现潜在问题；
职位描述：一、岗位职责： 0、本岗位为首次招聘，希望有勇气和经验伙伴加入，所使用大数据平台为阿里公有云平台；1、参与数据中心规划，分析业务问题，数据模型设计； 2、负责物联网核心数据处理程序开发、部署调优、验收，及技术方案编写； 二、任职要求： 1、熟悉Linux/Unix系统和丰富的Java开发经验；熟练使用Spring boot，具备从事分布式相关系统的开发 2、精通大数据仓储技术栈有(Spark、Hive、HBase、redis、kafka、Hadoop等)相关开发经验 3、精通SQL，熟悉常用主流数据库，包括MySQL、PostgreSQL、Redis、MongoDB，并精通其中任意一种，具有SQL性能优化经验 4、掌握主流ETL开发工具（Sqoop、Kettle） 5、熟悉至少一种实时计算引擎 Storm, Spark Streaming, Flink6、对大数据治理、数据分析、BI，数据安全等大数据相关领域了解其一或部分
岗位职能：1、负责公司数据平台项目的ETL设计、实现以及优化。2、负责ETL流程优化，关键问题解决；3、研究医院信息化数据，负责数据建模、数据存储设计；4、使用ETL技术对医院信息系统数据进行提取、清洗、转换和整合；5、负责基于Hadoop/Spark生态的大数据离线/实时处理平台开发;6、负责基于阿里云的maxcompute的大数据离线处理平台开发;7、负责数据源调研、入库、开发的全流程工作，并保证数据质量；岗位要求：1、有2年以上医疗行业数据建模经验；了解数据建模方法论，并且在项目中实践甚至优化扩展；有大型项目建模经验优先；对数据模型有独到理解；2、熟悉大数据平台，了解Hadoop、Hive、Hbase，有大型数据中心运维经验或实施经验者优先；3、2年以上医院业务信息化实施开发经历优先 ；有His、Emr开发经验优先；4、有数据仓库ETL经验，对调度、元数据、数据质量等有一定理解；5、有良好的逻辑思维能力，主动思考，善于学习，与团队沟通无障碍；6、熟悉java,python,shell,scala等任一种开发语言;7、拥有良好的沟通、表达能力，工作认真负责，学习能力强，执行力强，乐于接受挑战并具备较好的承压能力；
岗位职责：1、深入理解医疗行业业务，负责大数据相关的指标、报表、接口等需求的收集、理解、跟进、以及落地工作；2、承担数据抽取、清洗、转化等ETL全流程工作；3、根据业务设计合理的数据模型、并落地、推广、监督，建设高质高效的数据中台；4、根据业务制定合理的医疗大数据使用标准、管理方式以及安全保障机制；5、结合业务研究大数据存储计算技术，优化数据仓库技术栈，提高离线数据服务质量和效率；6、总结并提炼日常工作流程，参与设计自动化工具和产品，提高大数据开发效率。任职资格：1、3年及以上数据仓库建模经验，精通大数据建模方法论，对数据模型有深入的理解，并且在项目中实践和扩展；2、精通Hadoop，Hive，Spark，DataX，Kafka等大数据技术；3、精通SQL，对SQL优化有一定经验，熟练使用PostgreSQL等关系型数据库；4、熟练掌握数据仓库ETL工作技能，对计算任务调度、元数据管理、数据质量管控、数据安全保障等工作有深入的理解；5、对业务知识感兴趣，有良好的逻辑思维能力以及沟通能力，善于思考，勤于学习、主动沟通；7、有互联网海量数据ETL经验、熟悉常用分析方法和挖掘算法者优先；8、有建设实时计算平台、实时数据仓库服务经验者优先；9、有医疗行业从业经验者优先。公司在信息港园区，办公环境优良，地铁规划就在楼下，交通便利。周边房价适中。节假日福利多多，有一群可爱活泼的小伙伴等着你哦~~
1.熟悉大数据中台数据治理业务2.熟悉数据集成ETL相关开发，及开源框架使用3.熟悉大数据各组件开发及问题定位4.能基于Springcloud微服务架构进行开发者优先5.大数据相关专业优先
岗位职责: 1、负责实时数据产品化的开发和架构工作。通过不断完善数据产品来降低数据的使用成本，提升数据的可维护性。2、深入业务，通过数据化产品看清业务现状、推动数据决策闭环。3、对数据工程方向的稳定性负责。任职资格: 1、计算机或数学相关专业，本科以上学历；2、熟练掌握 Java 语言，精通 Spring 生态技术栈，有微服务开发经验，熟练掌握脚本语言 Shell/Python 之一；3、熟悉 SQL，具有丰富的数据开发经验，对数据处理、数据仓库建模、数据分析等有深刻认识和实战经验；4、熟悉常用开源分布式系统，深入研究 Hadoop/Hive/Spark/Flink/HBase 一项或多项相关技术；5、有OLAP、海量数据处理、实时计算等相关开发经验者优先；有地理信息索引建设经验优先。6、积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神。7、良好的横向沟通能力和学习能力，对业务有好奇心。
1、负责大数据基础平台、海量数据存储/处理分布式平台、数据分析系统架构设计和研发，实时计算平台基础架构设计、部署、监控、优化升级；2、协助或进行策略和算法工作，保障数据挖掘建模和工程化；3、深入研究大数据相关技术和产品，跟进业界先进技术，负责技术难点的攻关；技能要求：1、三年以上大数据系统架构经验；2、精通Hadoop/HBase/Spark/Storm/Redis技术及其生态圈； 3、能够搭建主流大数据平台如CDH，以及大数据平台的优化策略；4、具备Python/Java/Scala等开发经验，熟悉数据挖掘和分析的策略与算法； 5、具有大数据领域相关研究背景，对并行计算、实时流计算、数据挖掘与分析等技术有较深的理解 6、熟悉分布式计算的各种范式，分布式算法实现，有较好的分布式架构设计能力。掌握MapReduce处理问题思想，熟悉实时分布式计算模型或有高效索引技术经验者优先；
1.负责现有行业大数据、数据加工、数据清洗、处理程序的开发; 2.从事海量数据分析、挖掘相关工作; 3.负责大数据相关平台的搭建、开发、维护、优化; 4.对各业务部门的数据分析、数据采集等需求给予实现与支持; 5.对公司业务功能目标进行大数据架构方案实现。 1、计算机、数学、统计相关专业，本科及以上学历，3年以上数据相关工作经验； 2、有中大型数据仓库架构设计、模型设计、数据治理的实际经验，掌握Hadoop/Hive/Hbase/Storm/Spark/Flink/Kafka 等技术的原理和使用；3、熟练使用各种关系型数据库，能够进行集群配置、主从复制、数据迁移、安全、调优、监控等工作;4、熟练中大型日志系统的架构和实施，能够基于日志进行告警，以及基于日志对用户进行行为分析；5、掌握分布式系统架构理论，有高并发系统实际操作经验，能够独立排查及解决分布式系统的问题；6、具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力。
职位描述岗位职责1.    整体负责批流一体数据仓库体系建设，推动企业级数据模型建设及数据治理体系的落地2.    推动公司数据研发流程的改进，提升数据研发质量与效能3.    与数据分析师合作推动数据为产品运营赋能4.    负责数据仓库的团队建设与管理工作，培养与组建技术梯队任职要求：1、计算机相关专业本科及以上学历，6年以上数据仓库相关工作经验，3年以上互联网团队管理经验；2、精通数据仓库相关理论，有企业级的数据仓库建设经验，有数据治理相关成功经验。3、对批流一体、数据湖等业内前沿方向有深刻理解，有实际团队落地经验者优先；4、熟悉Hadoop 生态相关技术，如Hive、Hbase、Spark、Flink、Storm、ES、Impala、Druid、Kylin等，有业务实际落地案例。5、良好的业务理解能力，能从业务视角看问题，从技术角度解决业务问题。7、有较强的责任心、执行力、自驱力，结果导向。
岗位职责：1. 负责大数据开发平台建设，构建数据开发、管理和服务的统一平台2. 负责海量数据的数据仓库建设和数据分析，支持业务场景和应用解决方案开发岗位要求：1. 计算机或相关专业本科及以上学历，对数据处理、数据建模、数据分析等有深刻认识和实战经验；2. 熟悉Hadoop/Spark/Hive/HBase等大数据工具，主导过大型数据平台建设者优先；3. 精通SQL，熟悉常用的关系型数据库、非关系性数据库和数据仓库，具有SQL性能优化经验；4. 了解微服务开发理念、实现技术，熟悉常见设计模式，熟练掌握SSH开发框架，熟练进行Java、Python代码编写，熟悉多线程编程；5. 思维敏捷，对新技术敏感，有较强的钻研学习能力；6. 具备良好的团队协同、沟通交流及抗压能力，善于独立分析和解决问题。
"岗位职责：	1. 参与公司大数据产品规划,大数据处理分析平台的设计;2. 负责数据分析、加工、清理、处理程序的开发;3. 负责数据相关平台的搭建、维护和优化;4. 负责基于Hadoop/Flink/Hive/Kafka等分布式计算平台实现离线分析、实时分析的计算框架的开发；职位要求：1. 掌握Java、Scala语言;熟悉Spring相关框架；2. 熟练使用Hadoop、Spark、Flink等分布式计算技术，熟悉基本原理3、熟悉Mysql，ES，HBase，Redis等存储引擎的数据存储及使用方法4. 有数据挖掘、数据分析、机器学习研发实践经验者优先;5.有Flink框架开发经验者优先"
1.熟悉0racle、Mysq1数据库和开发;2.熟悉大数据基本开发原理，掌握hive、hbase等常用大数据技术，熟悉 h2o，tensorflow能学习框架者优先;3.精通python，java等至少一种编码语言，熟悉1inux平台，使用过人工智能模型框架，在智能学习算法上有所了解;4.精通至少一种常用大数据平台或者核心功能组件，如spark，storm. tesorflow等1.熟悉0racle、Mysq1数据库和开发;2.熟悉大数据基本开发原理，掌握hive、hbase等常用大数据技术，熟悉 h2o，tensorflow能学习框架者优先;3.精通python，java等至少一种编码语言，熟悉1inux平台，使用过人工智能模型框架，在智能学习算法上有所了解;4.精通至少一种常用大数据平台或者核心功能组件，如spark，storm. tesorflow等咱们公司根据面试结果定级定薪噢，所写范围仅作为参考噢，能者多得，有意向的咱们唠唠～~~
技能要求:1 熟练使用 MapReduce、Hive、Hbase、HDFS 等主流 Hadoop 框架技术2 熟悉 Spark 原理和执行流程，熟练使用 Spark Sql、Spark Core、Spark Streaming3.熟悉Flink原理和执行流程，熟练使用Flink4 熟练使用Kafka、yarn、zookeeper 等常用组件5至少掌握一种编程语言：Java、Python、Scala 等6 有独立搭建Hadoop、Spark 体系架构的能力7 有意愿挑战 TB、PB级以上数据量数仓设计职业要求:1 两年及以上数据开发工作经验，本科及以上学历，具有独立解决问题能力2 具有良好的沟通能力，和良好的团队合作精神3 工作积极主动，自我驱动，自主学习业务知识和技术知识，并勇于在业务上进行创新4 有车联网大数据相关工作经验者优
职位详情1.负责数据接入，数据存储与计算，多维分析引擎的底层研发，构建面向业务的经营分析系统的高性能，考可靠性，保稳定性数据产品2负责大规模离线实时任务的调度管理和优化，以及运维监控，保证每天上万任务的稳定高效运行。3.挑战几十P规模，几千节点的大数据集群建设，构建稳定，安全，低成本全球化的数据服务技术体系。4.要求熟悉JAVA高并发，对大数据服务组件hadoo p，flink，spark内核有一定了解5.有推荐，搜索或用户画像经验也可6.希望具备协作精神且能承受一定压力的牛人加入。我们提供世界级的舞台，大家一起携手创造未来
职位描述1. 负责飞猪大数据相关应用和数据产品的系统架构设计研发，通过数据+算法+工程能力，不断完善公司的数字化运营能力；2. 维持系统架构设计的一致性，参与关键组件和代码的CodeReview，承担设计质量的责任；3. 保持一定的前瞻性， 推动技术和业务的融合，推动团队的架构设计能力提升；职位要求1. 计算机等相关专业，本科及以上学历，3年以上互联网产品或大型业务应用系统的开发设计经验2. 扎实的JAVA基础，技术思路清晰，结构化思维清晰，善于解决复杂问题3. 对大数据相关技术栈（Flink/Spark/HIVE/ES/CLICKHOUSE等）有丰富的使用经验4. 在企业内部有大数据领域平台开发、数据产品开发经验者优先
基本要求：2年+开发经验，★统招全日制本科及以上学历（成教民教不考虑），计算机、软件相关专业。一、职位描述：1.负责源数据平台的分析优化，包括但不限于业务分析、数据建模、数据开发、数据质量等；2.参与能源数据平台的数据研发，与技术团队一起打造数据产品；3.研究业界数据建设模式，跟进大数据领域新技术，建设PB级数据应用；二、职位要求：1）熟悉数据仓库模型设计与数据开发经验，如数据集市设计、数据质量管控等，具备海量数据加工处理相关经验2）熟练运用大数据计算平台来处理数据，包括但不限于ODPS、Flink、Hadoop、Spark等，掌握一门或多门编程语言，如Java、Python等；3）良好的数据敏感度，能从海量数据提炼核心结果，需要具备数据统计的基础知识，能够在数据探索上有自己的洞见分析能力，（加分项）掌握常用的数据分析方法和函数库，如分类、偏差分析；4）（加分项）对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先。
岗位职责：1. 参与公司数据仓库建设；⁣2. 负责数据仓库的需求和优化，保障数据仓库满足业务需求；⁣3. 参与公司数据应用产品开发，通过数据为业务赋能。⁣任职要求：⁣1. 2023年及之后毕业的在校学生，本科及以上学历，计算机或者软件工程相关专业，扎实的计算机以及网络基础；⁣2. 计算机基础扎实，熟练掌握常用算法、数据结构、数据库原理等；⁣3. 了解大数据生态圈的常用技术，如hadoop/hive/hbase的优先；⁣4. 有一定的钻研精神，关注技术趋势，乐于尝试新的技术；⁣5. 思路清晰，有一定的抗压能力，善于沟通和团队协作，责任心强；6、毕业前至少提供3个月实习时间。
岗位职责：负责公司和驻场项目中的大数据处理流程开发，部署和运维. 和算法工程师合作部署机器学习模型上线，并进行日常运维和问题排查.参与公司数据中台建设，打通业务，知识库，算法模型训练各个模块.职位要求;1. 211 CS专业硕士研究生及以上2. 精通python, pyspark, pandas3. 熟悉至少一种主流数据库(oracle, mysql, postgres)，linux操作系统，restful服务4. 熟悉主流数据结构(数组，链表，HashSet，树，图)5. 了解机器学习算法优先考虑，了解airflow，图数据库(neo4j)优先6. 良好的团队协作精神及沟通能力. 7. 工作认真负责，学习能力强，能够承受工作压力，可以在远程工作环境下保质保量完成项目交互和团队协作
负责数据仓库和大数据处理模块的架构设计和开发
岗位职责:1、理解产品需求，梳理产品需求和数据之间联系；2、参与数据仓库总体架构设计；3、参与数据仓库数据标准、元数据管理的规划设计；4、参与数据逻辑模型与物理模型设计；5、优化数据查询算法及数据库性能调优。 任职要求：1、本科以上学历，计算机相关专业；2、2年以上相关大数据开发工作经验优先考虑，可接受优秀应届毕业生；3、具有Java编程能力，熟悉SQL开发，MySQL、PostgreSQL、Oracle等关系型数据库中的一种；4、有接触过阿里云产品，熟悉阿里云dataworks、dataq组件的优先考虑；5、逻辑思维能力强，对数据敏感，有较强的学习能力和创新思维；6、能接受经常出差的优先考虑。
职位描述1. 参与全球化物流中台数据基础平台的建设、演进，量化业务迭代效果，沉淀数据资产；2. 负责实时、离线数据接入，宽表计算，数据仓库、在线数据服务的设计、开发、性能优化，解决计算中性能、功能等多方面的各种挑战；3. 针对具体业务问题，构建数据化解决方案，构建高效、健壮的数据计算系统，通过数据分析与洞察发掘数据价值附能业务。职位描述1. 扎实的Java、SQL编程基础，三年以上开发经验，具备优秀的系统Debug/Profiling能力和经验；2. 熟悉Storm、Flink、HBase、Kafka、RocketMQ、Calcite等开源大数据技术，有大数据工程开发经验，有开源社区开发经验者优先；3. 对业务有良好的数据化思维能力和敏锐度。乐于分享，有公开分享经验者优先。4. 善于思考，能独立分析和解决问题,责任心强，具备良好的团队合作精神和抗压能力，要有创业的激情和坚定的信念。
负责华为云计算大数据云服务开发 承担建设基于Spark Flink Trino生态的大数据离线/实时处理云服务大数据云服务开发工程师岗位职责:1、参与华为云大数据服务、产品的能力建设;承担相关服务、产品的技术架构设计和研发工作，打造面向未来、业界一流的大数据技术;2、参与华为云大数据服务体验提升工作，通过业界对比分析.倾听客户反馈，问题分析等手段打造技术领先、体验优秀的大数据云服务;3、参与华为云大数据重大巿场项目技术比拼、问题攻关，支撑大数据市场项目成功;专业知识1、具备良好的计算机、软件工程等专业领域基础知识:2、具备云计算、高性能计算相关领域开发维护相关经验:3、工作思路清晰，较好的沟通能力和技术学习能力，拥有良好的编码习惯，有很强的自学能力和自我提高的愿望;业务技能:1、至少精通C、C++、JAVA、PYTHON中的一种;2、有完整的项目开发经验，具备系统核心模块看护经验者优先;3、有大数据相关经验，熟悉HADOOP/SPARK/HIVE/OOZIE/FLUME/FLINK等开源大数据技术优先;4、有云服务化开发经验，DEVOPS实践经验，开源社区项目代码贡献者优先;
我们希望1.你追求极致，创造力和改变2.是一个开放，务实和理性的年轻人3.热爱web3，拥有极客精神，最好熟悉加密行业
岗位描述：专业：计算机或相关专业；年限：一年以上Java大数据开发经验；1、有较强的责任心并具有一定的抗压能力，具备良好的团队合作精神，较强的沟通协调能力；2、善于学习，对业务有浓厚的兴趣，能够快速理解业务，能够独立与业务人员进行有效沟通；3、熟悉Linux/Unix开发环境，熟悉Java者优先；4、熟悉常用开源分布式系统HDFS，Hadoop/Hive/Spark/Yarn，熟练掌握主流Spark框架，熟悉主流NoSQL数据库；5、熟悉Hadoop、流式计算、任务协同管理、YARN资源管理等；6、熟悉数据仓库原理，熟悉SQL语言。
岗位描述：1、负责大数据技术平台的系统架构、技术架构设计、算法平台和交通平台的设计及核心模块研发； 2、负责在分布式离线/在线/实时计算平台上的算法平台的设计和研发； 3、负责前沿大数据分布式存储、内存云计算、机器学习平台、深度学习平台的新技术和算法的研究和可行性验证。岗任职要求：1、本科及以上学历，计算机、数学、统计类相关专业，3年以上相关工作经验；2、熟悉面向对象设计和分析，精通Java容器技术，了解Web前端技术； 3、深刻理解分布式存储和计算的核心原理和相关算法，有相关开源贡献者优先； 4、深入理解RDBMS/NoSQL的优势和劣势,并具备相关业务研发经验； 5、熟悉主流大数据计算平台的原理，熟悉MR/RDD/Graph等计算模型，具有Hadoop、Spark、Storm等分布式数据存储与计算平台的应用经验，有平台优化经验者优先； 6、具有推荐系统架构设计经验者优先； 7、能够积极主动创新，勇于面对挑战和承担压力，具有很强的责任心； 8、优秀的团队合作精神，诚实，勤奋，严谨，有担当。
岗位职责：1、 负责大数据平台的搭建、开发、维护、优化；2、 负责业务数据接入、数据治理、ETL和存储；3、 支持业务部门和AI工程师的数据加工需求。任职要求：1、 硕士/学士学位；2、 熟练掌握Python、Scala、Java等编程语言，Shell、Perl等脚本语言；3、 熟悉Hadoop/Spark生态系统组件的使用，熟悉Hadoop/Spark编程；4、 熟练使用至少一种关系数据库（Oracle/MySQL/PostgreSQL等），一种非关系数据库（MongoDB/Elasticsearch/Redis等），精通SQL；5、 熟悉数据治理、数据仓库开发、ETL开发；6、 有良好的逻辑思维能力和商业判断能力，沟通能力强，善于团队协作，能积极排除困难推动工作的开展。加分项 ：1、 良好的英语口头和书面沟通能力；2、 有云计算平台（AliCloud / AWS)开发经验的优先；3、 在医疗/医保/医药或相关领域拥有工作经验。
• 岗位描述：1、 负责电商业务的离线or实时数据仓库的构建；2、负责数据模型的设计，ETL实施，ETL性能优化，ETL数据监控以及相关技术问题的解决；3、负责指标体系建设与维护；4、深入业务，理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；5、参与大数据应用规划，为数据产品、挖掘团队提供应用指导；6、参与数据治理工作，提升数据易用性及数据质量。• 岗位要求：1、熟悉数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；2、熟练使用Hadoop及Hive，熟悉SQL、Java、Python等编程语言；3、善于沟通，对业务敏感，能快速理解业务背景，具备优秀的技术与业务结合能力。
岗位描述：专业：计算机或相关专业；年限：一年以上Java大数据开发经验；1、有较强的责任心并具有一定的抗压能力，具备良好的团队合作精神，较强的沟通协调能力；2、善于学习，对业务有浓厚的兴趣，能够快速理解业务，能够独立与业务人员进行有效沟通；3、熟悉Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境，具有扎实的j2se基础，注重代码规范、代码执行效率，善用设计模式；4、熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，熟练掌握主流Spark框架，熟悉主流NoSQL数据库；5、熟悉Hadoop、流式计算、任务协同管理、YARN资源管理、多线程并发及通讯编程；6、熟悉数据仓库原理，熟悉SQL语言。7、熟悉机器学习常用相关开源框架，如Mahout、MLlib、Trident等优先；
岗位要求：1、全日制本科及以上学历，重点大学计算机相关专业，有良好的业务理解能力，和架构设计能力；2、熟悉数据仓库开发流程，具备独立的业务建模能力；3、熟练掌握 Hive SQL，理解 Hive/MySQL/Oracle 原理和调优方法，有独立处理大规模数据/日志的经历；4、有3年以上数据仓库(DW) / 商业智能(BI) / ETL开发相关工作经验；5、良好的沟通能力，有团队协作精神，工作积极主动，认真负责。岗位职责：1、理解业务，设计数据标准、数据模型；2、建设数据仓库，搭建高可用的数据基础；3、负责数据仓库的架构与模型设计以及相应的ETL开发；4、负责业务需求的架构设计和实现。5、负责数据问题的定位及解决
# 目标与职责- 负责 JuiceFS 与 Hadoop 生态的集成和产品化；- 建设存储计算分离的大数据平台方案；- 参与客户项目的技术支持工作。## 需要参与以下工作：- 提升/简化/精进 JuiceFS 与各种大数据计算框架和数据仓库的集成度，包括且不限于 Spark、Hive、HBase、Presto；- 大数据平台计算与存储性能的深度优化；- 支持客户业务的性能问题诊断与优化，性能与兼容性测试，包括测试框架的设计与研发。## 可以在工作中收获：- 对大数据平台建设的深度理解和掌握；- 对主流大数据计算框架的深入掌握，以及二次开发、调优的能力。# 任职要求- 熟练 Java 编程，有 3 年以上大数据平台实施、维护经验；- 熟练掌握至少一种大数据计算、调度框架；- 善于自己定位问题，通过网络查找解决方案并解决问题；- 熟练英文阅读，能使用英语搜索、学习、解决工作中的问题；- 喜欢学习新东西；- 有很好的沟通、倾听和理解能力；- 加分项：熟悉任意一个大数据开源项目的源代码。
岗位描述：1、负责大数据技术平台的系统架构、技术架构设计、算法平台和交通平台的设计及核心模块研发； 2、负责在分布式离线/在线/实时计算平台上的算法平台的设计和研发； 3、负责前沿大数据分布式存储、内存云计算、机器学习平台、深度学习平台的新技术和算法的研究和可行性验证。岗任职要求：1、本科及以上学历，计算机、数学、统计类相关专业，3年以上相关工作经验；2、熟悉面向对象设计和分析，精通Java容器技术，了解Web前端技术； 3、深刻理解分布式存储和计算的核心原理和相关算法，有相关开源贡献者优先； 4、深入理解RDBMS/NoSQL的优势和劣势,并具备相关业务研发经验； 5、熟悉主流大数据计算平台的原理，熟悉MR/RDD/Graph等计算模型，具有Hadoop、Spark、Storm等分布式数据存储与计算平台的应用经验，有平台优化经验者优先； 6、具有推荐系统架构设计经验者优先； 7、能够积极主动创新，勇于面对挑战和承担压力，具有很强的责任心； 8、优秀的团队合作精神，诚实，勤奋，严谨，有担当。
岗位职责：1、 负责大数据平台的搭建、开发、维护、优化；2、 负责业务数据接入、数据治理、ETL和存储；3、 支持业务部门和AI工程师的数据加工需求。任职要求：1、 硕士/学士学位；2、 熟练掌握Python、Scala、Java等编程语言，Shell、Perl等脚本语言；3、 熟悉Hadoop/Spark生态系统组件的使用，熟悉Hadoop/Spark编程；4、 熟练使用至少一种关系数据库（Oracle/MySQL/PostgreSQL等），一种非关系数据库（MongoDB/Elasticsearch/Redis等），精通SQL；5、 熟悉数据治理、数据仓库开发、ETL开发；6、 有良好的逻辑思维能力和商业判断能力，沟通能力强，善于团队协作，能积极排除困难推动工作的开展。加分项 ：1、 良好的英语口头和书面沟通能力；2、 有云计算平台（AliCloud / AWS)开发经验的优先；3、 在医疗/医保/医药或相关领域拥有工作经验。
岗位职责: 1、负责客户业务数据分析需求，理解业务逻辑，并根据业务需求设计相应主题的数据模型；2、参与BI报表开发；岗位要求：1、对数据处理、数据分析和关联等有较深的认识； 2、熟练掌握SQL查询技术、性能优化; 3、熟悉mysql、sqlserver、oracle等主流数据库系统，有使用Hadoop、hive、 Spark、clickhouse、Antdb等经验者优先；5、具有BI数据分析工具经验者优先；6、有一定的java开发经验者优先；
【工作职责】1、负责公司大数据平台产品的技术工作，包括需求分析、架构设计、研发、以及性能分析工作；2、负责整体提升Hadoop集群的高可用性、高性能、高扩展特性，已有的大数据平台架构的维护工作；负责海量数据的导入优化工作以及整理和完善各类技术文档；【任职要求】1、计算机相关专业毕业，具备2年以上开发工作经验；2、从事过关系型数据库开发，熟悉SQL语言；3、熟悉函数式编程规范，精通Java（JDK 1.8以上）或Scala语言；4、熟悉Hadoop、Spark、Solr等大数据平台体系结构和工作原理，具备MapReduce、RDD等编程模型的开发经验；5、了解基本的统计分析方法和机器学习理论。
岗位职责：1、负责SPARK/FLINK/KAFKA/Hbase/TIDB/StarRock/ 等组件维护,解决日常工作中海量数据面临的挑战；2、负责Sqoop/seatunnel/flume/ftp/synce/otter 大数据采集功能建设,日常维护；3、与产品/开发/业务团队紧密配合,深入理解并高效支撑业务需求,包括离线/实时数据处理,数仓,BI,数据挖掘,数据应用等；4、对数据平台整体稳定性和数据质量负责，协助排查线上数据问题。5、对前言技术进行调研，预见性对现有系统进行完善；6、支撑人工智能工程化建设，对Python,操作系统内核,docker 环境融合有一定的解决思路；知识要求：1、熟悉CDH/APACHE/Fusioninsight大数据平台,精通一种 CDH/APACHE/Fusioninsight 平台操作及原理。2、对操作系统内核有充分了解。熟知RPC、IPC、内存、缓存、透明大页,存储性能...3、精通JAVA/C/Python 其中一种；4、较强的ownership,能对自己做的事情负责；5、PB 级大数据平台维护经验；6、有体系化数据管理/数据安全/自动化运维体系建设经验优先。优先项1、5年以上大数据平台或者相关经验2、熟悉Hadoop,Spark,Flink,Storm,Kafka,Hive,Hbase,Mysql等大数据生态产品。有源码级别trouble shooting,或者实时相关经验优先3、开源领域有贡献,或者有成熟大数据平台运维开发经验优先。4、对于网络/主机/通信有一定了解，了解数据中心建设流程，有数据中心建设方案以及实施方案(集群迁移,数据迁移,软硬件架构)经验优先。5、能根据业务规划，部门建设，形成大数据解决方案者优先。
岗位职责：1、负责华为云AI数据服务产品特性的系统设计、代码开发，测试验证及维护工作；2、负责交付特性/系统设计文档和接口，参与核心代码等开发；3、控制服务的架构质量，协助解决服务开发过程中的技术困难；岗位要求：1、精通C、C++、Java、Python中的一种；2、有完整的项目开发经验，具备系统核心模块看护经验；3、有大数据相关经验优先，熟悉Hadoop/Spark/Sqoop/Oozie/Flume/Kafka等开源大数据技术；4、有云服务化开发经验，DevOps实践经验，开源社区项目代码贡献者
1. 熟悉私有云大数据，实时计算平台的搭建2. 熟悉Storm，Spark等平台的开发3. 有在大数据平台上进行深度学习项目经验的优先4. 热爱技术工作，善于沟通5. 2年以上工作经验
大数据开发 岗位职责：1. 负责公司数据平台研发；2. 分布式数据仓库建设，数据ETL；3. 实时数据分析任务和平台开发；4. 维护公司大数据平台以及大数据平台稳定性优化。岗位要求：1. 本科及以上学历，3年以上大数据开发经验；2. 精通hadoop生态圈产品组件，包括但不限于HDFS，Spark，Impala，Hive，Kafka，Hbase理解其内部运行原理；3. 精通Flink流计算组件；4. 熟悉Clickhouse，Neo4j，ElasticSearch，Redis等大数据相关组件；5. 对大数据平台组件有一定的优化经验；6. 有主人翁意识，并且有较强的沟通能力和理解能力。
岗位职能：1、负责大数据平台的性能调优与基础开发，运维；2、参与基础架构的设计与模型设计；3、参与数据采集，分析，治理端到端建模；4、团队内开展技术分享；任职资格：1、具备4年以上开发经验，大数据2年以上工作经验 2、熟悉Linux开发环境，熟练掌握至少一种编程语言（Java / Python /SQL/Shell） 3、熟悉数据仓库建模理论，了解数据仓库数据分层架构、多维数据模型设计，掌握数据挖掘数理知识；4、有大数据量场景下调优经验，熟悉大数据场景下的各个组件调优方案；5、熟悉大数据平台的技术，能在Hadoop/Spark等框架下进行数据提取和分析 、熟练使用大数据组件hbase，hive，spark，flink等;6、掌握大数据挖掘主流技术和数据挖掘方法；7、 掌握爬虫技术，ETL技术，常用数据挖掘算法，模型评估。Spark Mllib，具备扎实的数理统计知识和计算机知识。
工作职责：1）、数据ETL工作；2）、参与数据产品设计工作：数据分析挖掘：与业务专家配合，承担数据仓库构建、模型构建、数据标签、知识库、画像分析等相关数据产品等设计工作；3）、数据挖掘分析工作；4）、数据产品研发工作。任职要求：1）、具有深厚的统计学、数据挖掘等相关知识，熟悉数据仓库和数据挖掘的相关技术，精通建模方法并有过独立的建模实践；2）、熟悉软件产品研发流程：精通SAS，R，SPSS等统计分析软件，具有海量数据挖掘、分析相关项目实施经验，参加过完整的数据挖掘项目并有成功案例；3）、精通Kettle、pentaho等工具的使用或开发；4）、熟悉Python、TIDB、关系型数据库、大数据Hadoop生态编程及数据库操作者优先录用。
（1）负责GIS图层数据开发，二三维空间大数据分析，以及分析组件功能开发；（2）负责创建二三维数据服务与上层业务系统对接与应用工作；（3）负责对业务发展目标进行拆解，搭建业务监控指标体系，快速觉察并分析指标波动；（4）数据赋能业务，挖掘空间数据价值，提供增长建议与决策支持。
岗位职责：1、参与数据中台的建设。2、参与数据仓库平台的建设与维护，数据ETL的设计、开发与性能优化。3、参与部分数据服务接口的开发。岗位要求：1、熟悉Linux操作系统基础命令。2、具有扎实的Java基础、熟练使用springboot+mybatis框架​3、熟悉Flink、Kafka、Doris等大数据组件4、了解数据仓库、数据中台等产品、有相关相关经验者优先​4、第一学历为本科及以上学历
1.数据开发岗位。要求熟悉数仓建模的分层建设理论，对数仓建设有深刻的认识。数仓开发经验要求，硕士2年以上，优秀的候选人本科3年以上。有一定的JAVA工程能力。有算法基础尤佳，属于加分项，非必要条件。2.掌握hive. spark基本原理，熟练使用SQL进行数据处理加工。有实时计算项目经验尤佳。3.业务驱动力强，需要较强的沟通能力、执行力，善于利用碎片化信息，跨团队沟通能力较强。4.学历要求：硕士及以上。5.岗位信息：阿里大脑业务线，base杭州。
1.负责大数据解决方案技术规划、方案设计并参与部分核心编码编写；2.负责大数据解决方案的技术项目，主导技术发展方向的预研；3.参与大数据后端开发4.参与客户需求调研抽象客户需求、理解行业痛点、技术特趋并保证最终落地。任职要求：1、3年以上相关工作经验；2、熟悉Hadoop生态圈技术栈，HBase、Hive、Sqoop等，熟悉Spark、Storm、Kafka、Zookeeper等开源产品者优先；3、精通flume、kafka、redis、spark、presto、elasticsearch等实时系统处理中间件一种或者几种，有至少一个以上相关项目开发经验；4、具备大型分布式、高并发、高负载、高可用系统设计、开发及调优经验，有大数据平台的软件开发和部署经验者优先；5、软件基础理论知识扎实，具有良好的数据结构、算法功底，良好的编程开发能力，精通Rust及其他开发语言。(211/985硕士优先)代码能力差的勿扰！
工作职责：1、参与业务调研、数据需求调研；2、负责业务数据的开发工作，负责业务数据的采集，清洗及转换；3、负责数据仓库的分层设计，模型建设和优化；4、深入理解业务，与业务分析师一起规划数据产品解决方案；5、带领和指导其他开发同事共同推进项目的开展；任职要求：1、全日制本科及以上学历，计算机及相关专业；2、熟悉数据仓库架构设计及数据建模理论，具备至少2个项目的数仓建设经验；3、熟悉Hadoop体系，精通Hive SQL, 具备较好的SQL性能调优经验；4、熟悉SAP BW相应技能（包括数据源、模型及例程开发、权限配置等）者优先考虑；5、熟悉SAP系统部分模块业务功能和数据流的优先考虑；6、优秀的团队协作、解决问题的能力；
工作职责:1. 负责当贝业务数据资产的设计与研发，包括架构和内容设计，项目计划，开发测试部署等。构建行业标杆级的操作系统领域核心数据资产池；2. 打造先进的大数据平台，包括实时数据流、数据仓库、调度系统、查询引擎，用户行为分析，abtest 实验系统等，降低数据的使用门槛，实现数据的最大价值；3. 建设适合业务的大数据存储、计算等分布式系统，为海量数据和大规模业务系统提供可靠的基础设施。任职资格:1. 本科以上学历，3年以上工作经验2. 有3年以上的大数据仓库构建和数据分析经验3. 有很强的架构设计能力, 编码能力扎实，熟悉Java，SQL及常用工具4. 熟悉主流分布式计算引擎，中间件，NoSQL数据库，如hadoop，hive，flink，kafka，hbase，redis等，并熟悉运行原理5. 有Github等开源社区贡献者优先6. 具备大规模分布式服务设计能力和经验优先
资深大数据开发工程师
职位描述1.负责公司海量用户行为、音乐内容日志数据收集、ETL，结合音乐内容领域业务特点，进行指标/标签体系的搭建；2.基于公司平台工具进行实时方案探索落地；3.负责面向业务的olap，报表开发，数据提取等工作；支持实时数据报表、离线数据报表、交互式数据分析等多种数据应用；4.负责面向数据产品的数据ADS层设计与开发；5.参与数据规范制定、文档编写，保证数据质量；6.具有数据科学相关知识，能够在业务需求中进行算法应用。职位要求1.本科及以上学历，软件工程/计算机/通信/数学等相关专业；2.3年以上大数据开发经验，熟悉业务抽象、数据模型设计理论和实践方法；3.熟悉Hive SQL语言，熟悉shell, python等至少一种脚本语言；4.有hadoop、spark、flink等至少一种大数据平台的使用经验；5.有用户行为、内容资产的数据研发工作经验优先；6.具有强烈的责任心和充分的主动性，能够积极主动的推进项目的进展；7.具有较强的抗压能力和学习能力，能够独立、高效地发现和解决或推动解决各种疑难问题；8.具有良好的沟通能力和团队合作能力。
【岗位职责】1. 参与公司产业大数据湖仓一体化分析平台研发建设工作;2. 负责数据相关平台的搭建、维护和优化;3. 负责基于Hadoop/Spark/Hive/kafka/flink等分布式计算平台实现离线分析、实时分析开发；4. 跟进大数据前沿技术的发展，适时引入合适的技术支撑业务场景【岗位要求】1. 至少精通Java、Scala、Python的一种，熟悉常用设计模式、具有重构能力;有湖仓一体化建设经验优先。2. 熟悉Hadoop、Hbase、Kafka、Hive、Spark、 Elasticsearch。熟悉CK、Doris等OLAP引擎。熟悉Presto等查询引擎。精通底层框架和实现原理优先；3. 3年以上工作经验，需要有至少2以上年离线/实时数据 平台开发经验优先；4.熟悉血缘分析，数据安全，数据质量优先5.良好的逻辑思维能力、沟通能力、问题解决能力。
1. 我们是谁？Chainbase是一个领先的Web3区块链交互层基础设施。任何人都可以发现、建立和连接开放的API来快速访问和使用区块链网络和多链数据。我们的愿景是成为一家超级酷的公司，解决实际问题，成为客户最信赖的合作伙伴。团队内部成员都是希望在Web3世界实现个人价值的伙伴，在这里能遇到一言不合就实现metamask验证的门禁系统的全栈工程师，有过往黑客大会的常客，也有多次见证公司在美上市经验的资深工程师。作为数据开发工程，我们有机会实现web3下一代的去中心化交互网络2. 我们期望的伙伴？- 志同道合，有决心在Web3实现个人价值的伙伴- OwnerShip，不设边界，聚焦努力把我们产品变得更好3. 岗位职责- 负责HOLAP数据仓库的方案选型，落地实施，且为其稳定性负责；- 负责区块链数据的结构化，ELT，数据建模等数据开发工作；- 负责与产品研发共同开发下一代的去中心化交互网络；4. 要求- 3 年以上大数据业务相关经验；- 具备丰富的大数据平台架构设计、研发和优化经验；- 熟悉 MPP 架构设计，深入了解多种 OLAP / OLTP / HTAP 引擎；- 熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案；- 熟悉理解 Crypto 、Web3 以及区块链技术优先；
负责内推-全流程跟进-实时查看最新面试情况职位描述1、负责电商业务数据体系的研发设计和建设，通过数据产品和数据服务等方式，赋能商家、运营的业务增长；2、负责电商业务的数据建设、数据服务化的设计、开发、性能优化，为上层分析和挖掘提供可靠、统一的离线+实时数据服务；3、负责电商数据分析平台建设，面向商家、运营、分析师等提供体验良好的万亿规模的交互式/可视化分析产品；4、负责离线/实时的ETL工作，为业务提供定制化的数据支持，并优化计算任务性能；5、负责沉淀电商数据化运营平台，并基于对业务和数据的理解，主动挖掘数据运营的机会，设计、开发并运营有价值的数据产品。职位要求1、计算机相关专业，本科及以上学历，1-8年大数据开发相关工作经验，有电商数据产品的研发经验者优先（如生意参谋、数据银行等）；2、精通Java/Python/Scala/Golang等至少一门语言，熟悉Hadoop/Spark/Hive/HBase/Flink等大数据研发工具；3、精通数据建模及ETL设计开发，对数据仓库、数据平台、数据分析等有深刻理解，具备丰富的海量数据加工处理和优化经验；4、有ClickHouse/Druid/Kylin/Superset等OLAP和数据可视化相关经验者优先；5、对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先；6、优秀的自我驱动力和责任心，良好的沟通表达能力和团队合作精神，学习能力强有责任心，不断挑战自己。
岗位职责：1.负责研发大数据平台和数据治理工具；2.负责进行大数据产品的离线与实时计算；3.负责数据平台的大数据基础架构规划、运维保障、数据监控等，为海量数据和业务系统提供可靠的基础设施；4.参与大数据生态相关技术的前瞻性研究和调研落地，持续扩充大数据能力，优化大数据服务的性能和效率 。岗位要求：1.熟练进行Java的代码编写，良好的代码编写素养，良好的数据结构算法技能；2.熟悉Java/Python/Shell等语言，具备良好的编程能力，具备源码级问题解决和集群优化改造能力；3.有数据平台开发经验，包括但不限于离线开发平台、数据质量中心、元数据管理、数据权限管理、数据资产管理，实时流平台等；4.熟悉开源大数据组件如Hadoop，Spark，Flink，Hive，Kafka,  Elasticsearch, Clickhouse, Dolphinscheduler等，有实际的报表平台、多维度分析工具、ETL平台、调度平台中至少一种工具的实际建设经验；5.具有很强的团队意识、沟通能力和独立解决问题的能力，学习能力和主动性强，具有钻研精神，充满激情，乐于接受挑战。
工作职责：1、负责数据模型的设计，ETL开发，ETL性能优化，ETL数据监控以及相关技术问题的解决；2、负责指标体系建设与维护；3、深入业务，理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；4、参与大数据应用规划，为数据产品、挖掘团队提供应用指导；5、参与数据治理工作，提升数据易用性及数据质量。任职要求：1、熟悉数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；2、熟练使用Hadoop及Hive，熟悉SQL、Java、Python等编程语言；3、熟悉parquet文件的原理及其解析，有实际相关开发经验优先；4、善于沟通，对业务敏感，能快速理解业务背景，具备优秀的技术与业务结合能力；5、此岗位为兼职，要求工作时间内能够有效沟通，可以利用下班时间或周末时间进行开发，可以作为您的一个副业，自由职业者尤佳。
本岗位需要良好的英文阅读能力，能快速浏览国外算法文献；数学专业、统计专业优先录用.对非对完全信息动态博弈有研究，擅长动态采集样本情况下离线数据画像的分析、标签工作1、负责服务器/云平台端数据库仓库和数据湖的设计，搭建和维护;2、用户画像、研究数据，进行数据建模，负责数据工作流的设计和编排，能优化数据存储和ETL过程;3、理解业务需求，负责数据采集、清洗、存储程序以及实时数据计算的开发以及相应优化工作;4、开发高效的数据读写接口;5、编写相关技术文档。6、擅长分布式系统0到1的搭建，熟练掌握Hadoop生态，zookeeper/hive/Kafka/h base/Cassandra等开源技术[任职要求]1、计算机相关专业硕士以上学历，数据开发工作经验3年以上，英文读写流利;2、熟练掌握SQL和No SQL数据库原理，有相关的开发和应用经验;3、有Hadoop和AWS大数据开发经验;4、熟练掌握Python,会C++ 更好;5、吃苦耐劳，执行能力强.敢于挑战，能承受一定的工作压力。具备较强的问题分析，逻辑思维能力。团队协作能力，有良好的沟通能力和责任感;6、逻辑思维能力强，对数据敏感，有较强的学习能力和创新能力。
职位描述： 1、参与数据服务平台的设计及开发工作； 2、负责数据服务平台数据检索，索引、关系建模及计算、任务调度相关开发工作； 3、跟进大数据前沿技术的发展，适时引入合适的技术支撑业务场景。职位要求： 1、本科及以上学历，计算机相关专业，2年以上大数据开发经验； 2、熟悉Hadoop/Hive/Spark的体系结构、原理和特性，对Hadoop生态系统有一定的了解； 3、熟悉Java，掌握Python/Shell等脚本语言，熟悉Linux操作系统； 4、有数据分析处理优化经验，推荐、广告、搜索等相关系统开发经验者优先； 5、有良好的数学基础，了解机器学习常用算法，具备自然语言处理、特征分析等方面知识及应用经验者优先； 6、责任心强，良好的沟通能力和团队协作精神。
岗位职责：1. 负责数据中台的设计和落地，降低数据使用成本，让数据赋能业务；2. 发掘数据的商业价值，深入消费者数据体系、商家数据体系、广告等数据业务，探索数据资产变现方法。工作内容：1.研发数据产品，包括但是不限于数据的收集,转化,存储,展示；2.开发可靠,高效准确的数据集市,并提供技术支持；3.维护和升级大数据基础设施；4.进行算法平台的需求分析，方案设计。基本要求：1.熟悉hadoop/hbase/storm/spark等分布式计算技术，熟悉其运行机制和体系结构；2.熟悉Mysql，ES，HBase，Redis等存储引擎的数据存储及使用方法；3.熟悉基本的算法研发，验证，上线流程；4.有一定的数据分析和挖掘能力，能从海量数据提炼核心结果，及时发现和分析其中隐含的变化和问题；5.能够通过数据化运营发现、分析问题和优化流程，推动数据处理流程自动化，提升团队运转效率；6.对数据敏感，有良好的沟通表达能力和跨团队协调能力，乐于寻求挑战和突破自我。
岗位描述：1、负责大数据平台的设计和开发，构建自主可控的 云原生 大数据平台，提供一站式的大规模计算和分析能力；2、负责大数据平台产品开发，包括ETL、OLAP、HeadLess BI指标平台、数据治理平台、AI数据平台等大数据产品；3、打造业界领先的大数据平台，为零售、商超、金融、制造、政府等行业提供海量数据治理、分析、应用能力，期待您的加入！岗位要求：1、本科及以上学历，熟练使用JAVA，Python，Scala，JS等一种或多种开发语言；2、有大数据平台开发经验，包括但不限于存储平台、计算平台、数据治理平台等；3、熟悉Flink、Spark或Hadoop EcoSystem等大数据领域的开源项目，有数据湖、实时计算、数据集成或开源贡献者优先；4、有实时计算内核开发（flink,spark streaming）经验，或者对hudi，iceberg有深入了解者优先；5、熟悉Modern Data Stack；
岗位职责：1、负责大数据平台的各类数据的采集、接入、存储和计算工作。2、参与大数据平台各类基础组件的的架构设计和系统建设。3、负责各类实时和离线大数据应用的开发工作，包括且不限于：指标，标签，在线分析,用户画像，数据可视化，数据挖掘，数据服务等。4、负责Hadoop，Hive，Spark等存储和计算集群的管理，优化工作，5、跟踪大数据生态的最新动态，推进平台的持续演进和组件优化。岗位要求：1、熟悉分布式系统的基础理论知识，了解大数据处理的常用算法。2、熟悉Java,Scala和Python等常用的大数据开发语言，有扎实的开发功底。3、熟悉Hadoop,Hive,Spark,Hbase,Flink,Kafka等大数据组件及技术。4、精通SQL优化和大数据计算平台性能优化。5、有数据仓库ETL经验，对于作业调度、数据治理，数据质量管理有较为深入的理解。6、有埋点数据的采集，处理，建模和可视化经验优先。7、具有良好的沟通能力，具有较强的分析和解决复杂问题的能力。
（1）统招本科及以上学历，计算机、数学、统计学、电子信息、自动化、地理科学、测绘遥感等相关专业；（2）精通Java、Python或者Scala等语言;（3）熟悉大数据相关平台组件（Hadoop/CDH/Ambari/Hive/HBase/Kudu/HDFS等）的工作原理，负责搭建、实施、及项目开发；（4）掌握SQL、HiveQL，Spark SQL以及Flink、Spark等计算引擎;（5）了解Hadoop运行原理，能分析调查Hadoop的系统性能瓶颈；（6）了解ETL、OLAP、实时数仓等数据管理产品与原理，了解kubernetes 容器化技术；（7）在知名互联网公司有过大数据平台开发经验优先。
岗位职责：1. 负责互联网出行业务各数据产品的ETL设计方案，代码开发工作。2. 参与实时计算项目的架构设计，技术选型，实时仓库构建等。3. 参与公司大数据平台的运维保障，系统和组件，包括维护、调优、容量规划等。岗位要求：1.5年以上大数据开发经验，至少3年以上互联网背景；2. 熟悉数据仓库模型设计与ETL开发经验，掌握维度建模设计方法，具备海量数据处理经验；3. 熟练运用各类SQL，对sql优化经验丰富，有Hadoop、Hive，Spark 等开源组件使用经验；4. 熟悉流式计算框架(Flink/Storm/SparkStreaming)优先考虑；5. 熟悉大数据生态组件，如Hadoop、HBase、Hive、Spark、Kafka、Flink, 熟悉CDH/HDP等大数据管理工具, 有搭建运维能力优先；6. 具备良好的数据敏感能力、较强的逻辑分析能力，良好的团队协作精神。
【岗位职责】1、参与数据平台团队而0-1的建设；2、数仓、数据工作流、数据模型的设计、开发、维护；3、跨团队提供高效可靠的数据分析系统与最佳实践。【任职要求】1、全日制统招本科及以上学历，计算机相关专业；2、2+年数据仓储、数据工作流(Data pipeline)、ETL方面的研发架构经验；3、良好的编程风格，扎实的编程和数据结构算法基础，深入理解面向对象编程思想，具有较强的模块设计能力；4、熟悉分布式计算原理，熟悉高并发、高稳定性、海量数据的系统技术方案；5、精通分布式数据处理技术栈Hive, Presto, Hbase, Kafka, Spark, Flink；6、精通Python、Java、Scala(至少其一) 开发语言；7、精通SQL，熟练使用分析、视图工具对海量数据进行分析；8、具有较好的分析复杂问题和解决复杂问题的能力，有强烈的责任心和使命感，良好的沟通表达能力和团队协作能力；8、有Google/AWS云、Bigquery、Google Data Studio经验、有大规模实时数仓落地经验者优先。
职位描述1、负责日常数据分析，数据仓库建设以及建立数据生态。2、设计并实现业务系统分析设计，能够独立完成建模及数据分析工作。3、跨部门协作，协同分析并解决数据问题，深入数据挖掘和数据分析。4、负责数据基础工具及数据仓库建设，核心业务指标可视化及监控，提升数据与业务交互效率。任职要求1、计算机或相关专业本科以上学历；2、熟练掌握Java语言，MapReduce编程，熟练掌握脚本语言Shell/Python/Perl之一；3、熟悉SQL，具有丰富的数据开发经验，对数据处理、数据仓库建模、数据分析等有深刻认识和实战经验；4、熟悉常用开源分布式系统，深入研究Hadoop/Hive/Spark/Storm/Flink/HBase一项或多项相关技术；5、有OLAP、海量数据处理、实时计算等相关开发经验者优先；6、积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神。7、有国际化业务开发经验、英语口语好优先。
工作职责:1.理解业务需求，负责数据采集、清洗、存储程序以及实时数据计算的开发以及相应优化工作；2.参与需求分析、并完成需求设计相应文档的编写；3.参与核心代码实现、系统性能优化；4.支持业务部门的数据需求,参与BI应用开发，报表制作。任职资格:1.计算机相关专业本科以上学历，数据开发工作经验一年以上，有保险行业数据开发工作经验优先考虑；2.熟练掌握Java/Python/Scala等至少一门编程语言；有大型项目开发经验优先；3.掌握数据库知识，较强的SQL/ETL开发能力；4.有大数据分布式计算平台开发经验,熟悉Hadoop,Hive，Storm，Spark，Flink，Kafka等大数据框架原理及应用，有阿里大数据生态Maxcompute、dataworks项目经验的优先考虑；5.具备较强的数据分析，问题分析，逻辑思维能力，团队协作能力，有良好的沟通能力和责任感，能够承担工作压力，独立分析和解决问题者优先；6.对技术有激情，有较强的独立、主动的学习能力。
1、本科学历、2年以上银行审计或风险模型开发经验2、3-5年大数据开发经验，熟悉常用大数据组件原理、掌握hadoop、hive、hbase等组件使用方法3、精通SQL、HIVE SQL存储过程开发、调优4、熟悉Linux下的常用命令，能够使用shell语言进行脚本开发5、熟悉数据云平台，有云平台运维经验，具有数据云数仓项目经验优先
1、负责公司数据平台LDP产品的规划设计、研发、交付和相关文档的维护工作2、能够深入理解业务需求，提供具体问题的解决方案，并以产品服务化的方式交付3、为公司平台团队提供后台技术支持，保证数据平台的高质量运行岗位要求：1、计算机相关专业，本科及以上学历，2年以上数据平台开发经验，如：数据库服务平台、数据集成平台（ETL）、大数据服务平台等2、必须：精通 Shell、Python 、JAVA或 Go 至少两种编程语言，具有扎实的编程基础，精通SQL3、熟悉 ETL 模型设计与实现，熟悉 ETL 流程优化，熟练使用至少一种开源或者商业 ETL 工具4、熟悉分布式计算系统的工作机制，具有分布式数据库、分布式存储等架构设计经验者优先5、必须：具有较强的学习、沟通、团队合作能力，具有强烈的责任心和良好的抗压能力6、熟练容器相关开发经验如Docker、K8s；具备一定的DevOPS能力(优先)
岗位职责1、基于综合能源服务业务需求和应用场景，设计和实现相关大数据相关产品的研发；2、负责采集数据抽取和处理的相关设计，开发，优化数据接入、数据存储、数据计算服务框架；3、负责优化分布式框架，解决大并发下的各种问题；4、为公司所有业务线提供数据支持和服务；5、负责前沿技术预研，指导和带教整个大数据开发团队。技术要求1、计算机相关专业，全日制本科及以上学历； 2、3-5年左右大数据应用开发经验，熟悉软件开发的主要流程，熟悉分布式，J2EE，Hadoop，数据挖掘，云计算，机器学习等技术路线；3、 扎实的Java基础，具备良好的面向对象编程经验；精通Java核心编程技术，深入理解NIO、多线程、数据结构、面向对象编程技术，精通设计模式；2.大数据应用平台的算法设计与实现，主流编程工具及相关软件平台的使用， 熟悉Kafka、ZooKeeper、Hadoop、Spark、Storm、Flink、Hive、HBase、Presto、Flume、Sqoop等技术中的一种或数种；3.负责海量数据的自动化分析、处理和挖掘工作；4.完成大数据技术应用创新研发的各类技术文档5、具有高效执行能力、强烈的责任心、沟通能力及团队精神。薪酬面议
【工作职责】1、负责华为大数据平台设计和核心代码开发，软件架构看护；2、负责Hadoop/流处理/批处理/实时风控/搜索引擎/HetuEngine/Hudi/CarbonData/ClickHouse等产品设计和开发；3、负责大数据组件开源社区动态跟踪、竞争力分析和规划技术演进。【任职要求】1.掌握Java/Scala/Python/C/C++语言，熟悉Linux/Unix操作系统，熟练掌握常用设计模式；2、有分布式系统设计开发经验，能独立承担软件模块设计和开发工作；3、熟悉大数据相关组件Hadoop/Flink/HBase/Spark/Sqoop/Oozie/Flume/Kafka/Storm/Hive/Elasticsearch/Presto/CarbonData/Hudi/ClickHouse内核源码，系统性能调优和分布式架构经验优先；4、有云服务化开发经验，DevOps实践经验，开源社区项目代码贡献者优先；
1、负责数据应用平台建设；2、参与公司业务需求分析、架构设计、技术研究和实现。 3、主动挖掘数据应用新场景并推进创新落地。任职资格1、本科及以上学历，3年以上大数据开发经验；2、熟悉Kafka、Flink、Hadoop、Hive、Hbase、ClickHouse等大数据开源框架的使用；3、熟悉Java编程，了解ANSI SQL标准； 4、理解大数据处理（分布式计算，分布式存储，流计算等）相关技术和实现方法； 5、主动性强，合作意识强，学习意愿强。
阿里巴巴云计算是国内领先云计算厂商，市场份额国内市场第一。在阿里云中，大数据的处理需求是用户的刚需，阿里云上的企业级客户已是云计算的应用主体，随着产业互联网的升级，云上企业级客户迫切需要将这些技术能力和他们面临的业务问题结合到一起，在这里你可以参与到阿里云和阿里经济体的大数据基础设施和新一代大数据分析基础设施的建设中，和团队一起打造高性能的计算存储服务，期待与你一起合作，拓展基于云计算的应用边界！职位描述1. 计算机或相关专业本科及以上学历2. 精通C++/Java程序开发(至少一种)，熟悉Linux/Unix开发环境3. 面向对象的程序设计，出色的设计和架构技巧4. 有大规模分布式程序开发的项目经验更佳5. 具备较强的学习能力；具有良好的沟通、团队协作和推动能力，工作积极主动、责任心强。
岗位描述- 负责依图智能安防产品相关的需求分析和研发工作- 负责按照软件开发流程，根据产品和项目计划，按时完成所负责模块的设计文档编写、架构设计、编码、测试的全流程工作- 负责支持并解决实际项目在使用大数据产品时遇到的系统问题- 负责持续优化系统架构，提高系统在多种部署环境下的容灾容错能力，保证系统的可运维、高可用性、高可靠性- 参与关键技术点攻坚工作，持续提升系统在工程规模/性能上的提升，团队内的技术推广- 负责组件的技术预研工作，了解开源的进展，以及在产品中可能的应用场景- 辅导新人养成良好的软件工程知识和编码规范意识任职要求三年以上大数据领域开发经验, 优秀者不限.精通 java, 熟悉JVM、IO、多线程、集合等基本原理, 熟悉并使用过SpringBoot框架熟练掌握flink或spark之一, elasticsearch, hive, hbase, hdfs 等多种大数据工具和技术原理熟悉linux常用命令, 能熟练使用如 python, bash 等至少一门脚本语言熟悉 数据处理建模, 数据治理, dmp工程构建过程加分项:熟悉规则决策引擎熟悉图数据库以及图计算, 图算法等.熟悉常用机器学习算法并有实际案例.具备独立沟通需求、设计、架构、开发、测试、运维的能力
岗位职责：1、参与公司数据仓库建设（大数据平台的离线，实时数据仓库），主要从事数据仓库的基础架构、ETL设计、流程优化，元数据系统设计，整体管理数据的生产、建模、应用及监控体系建设；2、参与数据平台建设，设计并实现，数据产品开发；3、协助开发团队驱动基于数据的产品迭代，为运营决策平台提供充足的数据平台支持；人员要求：1、本科2年以上相关工作经验，计算机、数学相关专业优先；2、有2年以上大数据系统架构与设计、重大模块设计经验，对大数据的技术趋势和SOA模式、微服务模式有较深的理解；3、 深入理解Hadoop ，及各种大数据计算框架，熟练使用Hadoop、Spark、FLink、HDFS、Hbase、Kafka、ElasticSearch、Kudu、Tidb、Druid有优化经验者优先；4、JAVA基础扎实，熟悉常用的设计模式，对JVM原理有一定的了解5、了解数据仓库建设理论与方法、具备丰富的实践经验。精通SQL，有海量数据处理经验者优先；6、良好的跨组织协调、学习和沟通能力，乐于接受挑战。
岗位职责：1.负责大数据平台管理工具及相关大数据组件的二次开发、管理及维护工作； 2.负责处理Hadoop稳定性等问题，保障集群高效、稳定、经济运行 ；3.与开源社区保持交流，发现对业务场景有帮助的特性并引入生产环境，或将经内部验证的特性贡献到社区。任职要求：1.对技术有追求，能够刨根问底的搞定技术问题；2.熟悉hdfs/yarn大数据系统原理及源码； 3.具备大规模hadoop集群的故障诊断与性能优化能力； 4.具备大规模跨集群、跨机房迁移经验者优先；
地点：上海，杭州，成都，深圳职位描述：1、负责蚂蚁金服国际数据体系的建设，通过数据+算法+工程化能力，处理和萃取数据特征以及上层的数据运营、数据决策的体系建设；2、参与大数据基础架构、产品技术的规划建设，包括数据采集平台、数据资产、数据产品、数据质量及稳定性保障体系建设。职位要求：1、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关开发经验，有Spark/Flink的开发经验尤佳；2、较为丰富的数据平台的架构经验，精通数据建模理念和实战能力；有较为系统的海量数据性能处理经验，在数据产品和应用一定的成功经验；3、具备较扎实的理论基础和工程能力，具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳；4、良好的思维逻辑性、语言表达能力；有较好英语口语能力尤佳。
1、负责公司大数据体系建设，构建数据中台，赋能业务；2、负责数据仓库、实时计算、质量体系、智能归因等系统设计与研发。职位要求：1、全日制本科及以上学历，计算机、通信等相关专业，2年以上相关工作经验；2、有扎实的编程能力，有优秀的设计和代码品位，有独立的代码实现能力 ；3、熟悉数据采集、清洗入库、统计计算、Web展示核心要点，可实现指标计算需求；4、熟悉Hadoop/YARN、Hive、Spark、Storm、Kafka 等，有Flink实时处理经验优先；5、优秀的理解沟通能力，能快速理解业务背景，责任心强，具有良好的团队沟通与协作能力；6、有大数据处理、数据平台、数据仓库经验者或数据挖掘算法优先。
1.扎实的Java、SQL编程基础，1年以上开发经验；2.熟悉Flink、HBase、Kafka、Spark、Hive等开源大数据技术，有大数据工程开发经验，有开源社区开发经验者优先3.参与大数据平台业务规划设计、建模及运维工作；4.完成基于相关技术平台计算服务开发、实施工作5.4年及以上，软件工程、计算机、自动化等专业
参与公司数据处理逻辑、数据模型的设计、优化和开发；3年以上的TB级别数据平台开发经验，至少2种分布式计算引擎的实现原理； 名校毕业或高学历者优先、有开源社区贡献如 apache Committer 优先、有海量数据处理经验优先。
岗位职责：1、建设中台基础数仓，为数据应用和分析提供完善的数据基础。2、负责业务数据平台的搭建、开发和维护，挖掘现有数据价值，驱动业务发展。3、独立完成对业务数据的提取、分析、报表、挖掘等系统设计和开发工作。负责工作：1、参与需求讨论，对业务有思考理解，基于开发视角提出想法建议。​2、熟悉数仓业务，参与数仓平台的建设，配合和协助数据分析/数据挖掘形成底层/中间层的业务逻辑切片​3、从架构和技术层面参与建设数据仓库，包括元数据管理、数据质量、数据管理、性能优化和调优​4、负责业务功能数据开发，包括（数据统计实现、数据测试，发布上线等）​5、配合bug或故障处理，能寻找问题本质​6、需求的计划输出和跟进，概要设计的输出
岗位要求1.计算机相关本科及以上，5年以上大数据工作经验和java工作经验，有扎实的大数据技术基础。2.了解大数据环境搭建，开发，维护，优化。3.熟悉linux操作系统，shell脚本的编写及调优。4.熟悉hadoop或flink大数据生态技术产品hadoop，hbase，hive，impala，kafka等。5.熟悉开发语言java，sql。6.熟悉mysql，oracle，elasticsearch。岗位职责1.根据需求进行可行性分析，技术方案选型。2.有良好的编码规范及开发技能，能够独立完成需求功能的开发。3.能够解决项目中的技术难点，预研新技术。4.对技术有强烈的兴趣，有责任心和进取心，以及良好的沟通能力和优秀的团队协作能力。
岗位职责：1、负责数据仓库架构设计、建模和ETL开发，数据仓库对应的项目中的报表开发工作。2、数据平台相关研发工作，如研发规范、质量规范等并推动实施落地。3、参与数据治理⼯作，提升数据易⽤性及数据质量；4、理解并合理抽象业务需求，发挥数据价值，与业务、BI团队紧密合作。任职资格岗位需求：1、1年及以上⼤数据⽅向建模⼯作经验；2、熟悉常⽤的数据仓库、数据集市建模⽅法，并能根据具体业务场景做出改进；3、具有很强的数据建模、分析和逻辑推理能⼒；4、具有较强的信息收集、整理能⼒和数据处理能⼒，以及较强的分析能⼒；5、熟练使⽤Linux系统、shell编程、数据库编程；6、具有统计、数据挖掘、机器学习专业⽅向优先；7、有⼤数据⼯具建设思想，且能够使用java或python落地实现相关BI系统⼯具经验者优先；8、熟悉flink、clickhouse、Hadoop等⼤数据任⼀技术者优先；9、有责任⼼和团队精神，踏实肯⼲。
新零售供应链全链路是新零售业务的主战场,作为新零售时代下的智慧供应链,整合了上下游资源,协同起来提供端到端的供应链服务。天猫超市,天猫国际,零售通,天猫电器城,盒马等业务的基座.全链路稽核团队:供应链业务的风险控制,资损诊断师,既有丰富的大数据技术学习和应用场景,也有全面了解供应链整体的业务实践.职位描述1、熟悉大数据技术栈,hbase,hive,kafka,spark,blink,olap数据库等技术有相关经验.2、扎实的Java编程基础，熟悉各种设计模式；熟练掌握Spring/Struts/Ibatis或其他主流JAVA框架；3、熟悉MySQL/PostgreSQL数据库中的一种或多种，有数据库调优经验；4、 熟悉整个软件过程，能够沟通需求、控制项目进度，有良好的文档能力；5、有高并发在线系统设计、分布式事务处理、领域模型经验更优；6、对挖掘计算机极限的技术有无限渴望；7、能够积极创新，乐于面对挑战，负责敬业；8、优秀的团队合作精神；
● 岗位职责：1. 基于阿里云大数据开发平台进行离线和实时ETL开发2. 根据业务需求构建数据报表体系和数据指标体系3. 制定数据口径和数据规则，沉淀数据字典4. 流程化工具化数据清洗和数据处理流程5. 沉淀数据分析和数据挖掘思路，提炼数据产品需求，协同和推动数据产品落地6. 与业务团队协作进行数据规则和模型建设，推动业务团队的数据化运营● 岗位要求：1. 本科及以上学历，计算机、软件工程、信息技术、数学等相关专业2. 3年以上大型数据库处理和数据管理工作经验3. 有互联网行业数据处理和数仓建设经验4. 精通SQL，熟悉JAVA、Python更佳5. 熟悉Hadoop等分布式计算系统，精通Hive SQL6. 了解Flink、Spark等实时计算框架7. 熟悉阿里云ADB for MySQL和ADB for Postgre SQL优先8. 熟悉阿里云DataWorks大数据套件优先9. 熟悉阿里云MaxCompute和RealtimeCompute优先10. 有toB业务数据开发经验优先
1.具有丰富的数据建模实践经验及分布式平台数据处理相关工作经验2.具备较扎实的理论基础和工程能力，具备一定的JAVA、Python语言的开发能力，具备机器学习算法能力尤佳3.技术或业务理解上有亮点，自我学习，对新技术热衷热爱4.良好的思维逻辑性、语言表达能力；有较好英语口语能力尤佳。5.强烈的驱动能力,有带团队经验最好
岗位职责：1.负责项目技术管理与团队管理工作；2.负责数据采集、数据处理、ETL流程、ETL调度、大数据集群的设计与开发，文档撰写；3.负责大数据平台建设，数据流调优，保障系统高效稳定；4.负责数据分析、挖掘、行为预测等数据开发工作，参与海量数据的数据挖掘与价值探索；5.负责数据标准与数据质量的制定与管理；6.负责定义数据仓库/数据中台设计与开发工作，从计算性能、存储性能、ETL任务与流程等层面进行优化；7.负责交付现场的疑难问题解决；8.负责开发计划的排定。岗位要求：1.计算机、软件工程、信息技术、统计学、应用数学等相关专业，本科及以上学历（必须）；2.具有5年以上研发实施经验，参与过项目管理，熟悉项目管理流程；3.具备大数据架构能力与技术解决方案设计能力；4.具有2年以上系统架构和开发经验，至少精通Java；5.熟悉LINUX系统，熟悉Shell编程，在操作系统、计算机网络和安全方面具备系统化的知识体系；6.熟悉SQL，熟悉ORACLE、SQLServer、GP、MySQL、PG等数据库，能够编写高效SQL、存储过程，熟悉简单数据库调优（必须）；7.熟悉以下任意一种ETL开发工具：KETTLE（优先）、DataStage（优先）、Informatica尤佳；8.熟悉大数据技术（Hadoop、Flink、Hive、HBase、Yarn、Spark、ES等），有CDH/HDP等大数据集群的使用、运维和调优经验；9.熟悉项目研发管理技能；10.优秀的表达沟通能力、业务理解能力与写作能力。
1.负责数仓模型设计，ETL开发，海量数据下性能调优，以及复杂业务场景下的需求交付2.深入业务，理解并抽象业务需求，沉淀高质量体系化的数据资产，对多模据处理、建模、数据分析等有深刻认识和实战经验，熟悉 kimball维度建模4.熟悉大数据常用的技术栈hadoop spark hive flink5.精通sql，具体python和shell开发6.有责任心、具备强烈的进取心和团队合作精神
职位描述1、基于阿里集团大数据技术体系，负责大数据基础架构和技术体系的规划建设，包括数据采集平台、数据资产管理与治理平台、数据质量及稳定性保障体系、数据处理智能化和自动化体系的建设；2、跟踪和调研大数据处理和分析的新技术，推动大数据平台技术持续演进；3、构建大数据质量体系，持续提升数据质量；4、促进跨业务线的数据融合，通过技术和业务场景的紧密结合，让数据发挥最大业务价值。职位要求1、5年以上大数据处理研发经验；2、扎实的JAVA开发能力，熟悉shell、python或其他脚本语言中的任意一门；3、熟练使用数据库同步、日志采集工具；4、精通hadoop、HDFS、Hbase、Hive等技术；5、精通flink、storm或spark streaming等流式或流批一体处理框架中的一种或多种；6、熟练掌握数据仓库建模和ETL设计方法论；7、有基于数据分析推动业务提升或优化的实际案例；8、有数据挖掘、机器学习经验者优先考虑；9、有大型电商系统大数据分析经验者优先考虑。
岗位职责: 1. 参与⼤数据离线计算平台的发展规划、设计及落地实现，围绕稳定性、易⽤性、性能 2. 负责⼤数据离线核⼼组件（hadoop/spark/hive）的问题定位、技术治理、性能优化 3. 负责建设⼤数据的衍⽣产品（如任务诊断、任务⾃动优化、任务异常定位等），致⼒于提⾼平 台效率 4. 根据业务发展，积极参与平台建设，不仅限于产品建设、业务流程改造、技术调研落地等岗位要求: 1. 3年以上java开发经验，熟悉java知识体系（5年以上⼯作经验） 2. 对⼤数据⽣态中的hadoop/spark/hbase/hive/ﬂink/es等计算/存储引擎，⾄少有1~2种有较深⼊ 理解 3. 有⼤数据离线计算相关的实际优化和改造经验，不限于具体技术、模块 4. 熟悉常⻅的开源分布式系统，具备系统开发、维护经验以及故障处理能⼒ 5. 有hadoop/spark/hive/ﬂink等组件的源码级优化实践 6. 有良好的⼤数据知识体系，对技术、业务流程、产品建设的有较好的理解
职位诱惑：周末双休 绩效奖金 核心产品开发 行业前景好 上升机会多岗位职责：1.参与数据中台团队系统需求分析和设计开发工作；2.利用大数据相关技术实现对数据的分析、挖掘、加工、处理、及数据可视化等相关工作。3.参与推动团队内技术经验分享，前沿技术研究，技术演进。职位要求：1.本科及以上学历，3年及以上Java开发经验，扎实的java基础知识；2.3年以上大数据开发、数据分析相关工作经验，熟悉Flink,、Spark、ES、Kafka、Doris/StarRocks、ClickHose等相关大数据技术；3.了解数据仓库建模理论，对数据仓库、数据平台、数据分析、数据治理等有理解，具备的数据加工处理和优化经验；4.熟悉Hadoop、HDFS、Hive、HBase等常用组件的一种或几种，了解其中的架构与技术原理； 5.熟悉Linux操作系统，计算机网络，大数据应用性能调优经验者优先；6.个性乐观开朗，沟通能力强，具备良好的团队协作精神，能利用自身技术能力提升团队整体研发效率。7.有0-1搭建离线/实时数仓经验，熟悉flink，有flink二次开发经验者优先；8.熟悉Java基础，spring框架，k8s者优先；
计算机或相关专业本科以上学历；有3-5年大数据平台开发方面相关工作经验；熟悉数据仓库和数据建模的相关技术细节，有编程经验，熟悉JAVA或者SCALE语言；熟悉SQL/Hadoop/Hive/Hbase/Spark/KFK/flink等大数据工具具有海量数据处理经验，或有互联网行业数据挖掘工作经验者优先；有电商,个性化推荐经历者优先考虑;
一、职责范围：1、负责规划设计大数据基础平台及研究相关技术；2、负责海量数据采集、处理及存储、应用方案的技术选型及架构实现；3、负责海量数据分析/查询、分布式存储、流式/实时计算等应用层架构搭建及核心代码实现；4、负责大数据技术应用的技术难点攻关、技术发展研究。二、任职要求：1、本科及以上计算机相关专业毕业；具有8年以上大数据平台工作经验；2、熟悉大数据技术生态圈，精通大数据技术架构，有大数据平台构建经验；3、丰富的DBA/DW/BI/大数据解决方案和架构设计经验；4、深入理解数据仓库体系架构，熟悉Hadoop/Spark/Storm等开源大数据平台；5、掌握YARN及MapReduce算法与原理，具备大规模并发设计与开发能力；6、具有良好的服务意识、沟通能力、团队协作和敬业精神，抗压能力强；7、掌握Java、Python、Scala等开发语言中的一种，掌握该语言的主流开发框架。
职位描述：1.负责理解云上客户场景需求，理解业务，深度梳理客户大数据需求、设计应用阿里云大数据产品，为客户提供大数据能力技术落地；2.参与基于阿里云计算平台和大数据项目之上，将需求转化为产品架构设计，将实现过程沉淀为产品方案，并应用到业务中的数据研发工作；3.具备将业务问题转化成大数据技术落地问题，帮助客户解决大数据实际问题，拿到结果；4.学习能力强，有激情，能同期支持多个项目研发工作；5.具有娴熟的沟通技巧，执行力强，具有优秀的团队合作精神、敬业精神；职位要求：1、计算机、数学或统计学相关专业本科以上学历；3-5年及以上数据开发应用经验；熟练掌握主流大数据产品解决方案(CDH/Hadoop/国内云厂商-阿里云/华为云/腾讯云/UCloud/青云等)；2、有过3年以上大数据研发或产品相关经验。熟悉大数据架构及原理，具备对大数据整体架构设计、应用数据开发和处理性能调优等相关经验；熟悉Hadoop/Spark/Flink技术之一，精通SQL/Hive，有较好的数据建模与数仓设计经验；3、熟悉Java or Python等常用的编程语言(至少一种)，有实际数据项目开发经验4、擅长通过深入浅出的方式将技术与商业价值融会贯通传递给客户和前方售前/销售，同时能够根据业务需求对现有产品进行轻量技术改进；6、具备优秀的逻辑思维能力。具有业务理解能力，能够快速理解业务需求，切入场景， 同时能够根据业务状态生成具体工作需求；7、是参与开源项目Commiter，有大数据产品落地交付经验者优先。有云计算/金融大数据行业经验者优先工作地 上海/杭州
岗位描述1、负责公司物联网平台架构设计、开发及管理2、负责对数据进行深度挖掘，用数据推进业务3、负责对平台算法进行改进   岗位要求：1、计算机或者数学及相关专业本科以上学历，有5年以上的大数据开发和大数据业务设计经验。2、精通Java语言，有成熟微服务架构应用。3、精通Spring boot、Mybatis、dubbo等框架，开发过大型web系统者优先。4、精通Hadoop、Spark、Hive、Sqoop、Hbase、elasticsearch等技术，深入理解Mapreduce的运算原理。5、熟悉常用的机器学习算法，如分类算法、聚类算法。6、有深度参与过数据产品业务设计者优先，例如，设计机器学习平台、数据治理相关的产品。7、对技术有自己独到的认识和见解，有较好的技术前瞻性。8、具备较强的学习能力。
职位描述1.负责政务领域数据仓库ETL和数据指标体系全链路构建；2.与相关团队协作进行数据建模工作，推动业务部门的数据化运营;岗位职责：1.负责企业级数据建模以及etl开发，针对业务和实际数据情况，能独立完成项目的系统分析和数据对接采集工作，保证数据质量；2.熟悉数据仓库模型设计，掌握常用数据建模方法，具备海量数据加工处理（ETL）相关经验，有dataworks平台经验优先；3.熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等；4.负责完成业务数据指标、报表、接口等需求的分析及开发，能够与业务需求部门进行有效沟通，进行需求设计；5.能够利用python进行数据处理;6.能自我驱动，有责任心和进取心，有团队合作精神，敢于挑战。
工作内容：1. 负责大数据相关平台技术基础设施规划与建设；2. 负责数据仓库、BI、计算平台建设，实施各类数据分析、机器学习应用场景；3. 关注大数据行业技术发展，制定大数据策略，提前识别关键技术并实现技术准备；4. 与业务部门密切配合，寻求数据层面的业务价值；5. 负责数据标准制定及数据质量管控任职要求：1. 本科5年以上相关工作经验，有3年以上大数据系统架构与设计经验，对大数据的技术发展趋势有较深的理解；2. 具有丰富的海量数据处理经验，熟练运用Storm、Hadoop、Spark、HDFS、Hbase、Kafka、ElasticSearch、Solr等核心技术组件；3. 可独立进行大中型数据平台架构设计和搭建、模型设计、ETL设计等；4、对深度学习及神经网络等前沿AI技术的有深入探究及理解，熟悉TensorFlow、Caffe等；5. 具备极强的数据sense，能从数据中发现价值；6. 良好的跨组织协调、学习和沟通能力，乐于接受挑战；具备优秀的项目管理与团队建设能力者优先；
0. 负责工程项目管理领域产品的数据架构规划、设计、评估和检验，支撑产品在数据技术选型、数据架构规划、数据服务设计等方面的业内前瞻性和领先型；1. 负责实时、离线数据分析处理、日志数据采集及通用平台的建设，以及创新性技术方案的开发与验证2. 负责大数据平台资源规划、权限控制、运维架构设计，为各产品业务提供稳定、高效、安全的运行环境；3. 负责基于海量数据采集、存储、治理及服务方案的技术选型及架构设计；4. 负责产品研发过程中的技术架构设计、数据处理逻辑等方面文档的沉淀与积累；5. 有多云平台的使用经验，熟悉阿里云、华为云等公有云，拥有容灾建设、重大故障恢复、自动化运维建设等项目经验；6. 从架构和技术层面参与建设数据仓库，包括元数据管理、数据质量、数据管理、性能优化和调优。岗位要求：1. 具备8年以上大型互联网公司或大型IT企业大数据开发以及架构运维经验；2. 本科及以上学历，计算机、软件⼯程、信息技术、数学等相关专业；3. 熟悉Hadoop、Spark生态开源技术栈，有数据中台、数仓、数据治理能力；4. 熟练使用Flink、Spark等计算框架解决复杂场景计算问题并有性能优化的能力；5. 熟悉云产品大数据组件、开源大数据引擎、主流算法包，以及ToB业务数据开发经验优先；6. 了解云原生技术，对k8S、Docker等容器技术有实际使用经验优先。
String 简介 String 是一家决策智能公司，旨在用自然语言的交互形式完成从取数，根因分析到预测等 80%常见的分析工作。我们的创始团队来自 CMU 、浙大、Google 、Facebook （ Meta ）、Uber 、Salesforce 、Amazon 、腾讯等名校名企，自创立之初便获得了知名基金数百万美元的融资。 为什么数据架构对于我们尤其重要？ 作为一个面向业务人员决策的数据分析系统，我们不仅需要鲁棒的数据连接来实现大数据上的 data pipelining ，还要为学术界 state of art 的算法提供稳健的数据支持。 职责与要求 熟悉Go 、Rust、Python 、Spark 、Apache Arrow 、GraphQL ，CDC, 向量化执行引擎，各种 OLAP 数据仓库等等。 为什么这份工作充满挑战？ 1. 将最前沿的学术成果，和工业界先进的架构理念投入生产，需要极强的工程能力和极高的知识密度（或解决问题 /知识搜索的能力）。 2. 你将不仅仅是一个工程师，还将是一个产品经理，甚至是一个设计师，把用户广泛的需求过滤到精巧的工程设计中。 3. 你将独立负责重要的工程模块，像打磨产品一样打磨架构。 为什么是加入我们而不是大厂？ 1. 自由的工作时间。 2. 不打卡、崇尚效率、结果导向的硅谷文化。 3. 极其平等的公司文化，以及把产品 deliver 给客户的一手经验。 4. 业内有竞争力的薪资。海外的类似产品已经成长为了估值数十亿美元的公司，成为我们的前 15 号员工，享受风口赛道中丰厚的股权回报 我们怎么面试？ 我们不要求现场写代码，但是可能希望能够看到你过往项目的 sample code ，以及 github 上的 activities ；我们也不考察刁钻的基础知识，但是希望能从我们的对话中看出你对过往项目的热忱，以及使用过的技术深度和广度；我们也没有硬性的学历要求，相信 cultural fit 是最大的 fit ，我们希望你有着强大的创业初心、自驱且愿意跟随一家创业公司的愿景一起成长。 我们现在的团队组成是什么？ 在我们不到十人的团队中，既有来自国内外大厂和独角兽的工程经理，也有活跃在开源社区的技术大牛，在我们的努力下，营造了一个技术驱动产品，而产品驱动增长的公司文化。 那么最后？ String 诚邀各色背景的小伙伴们加入我们！我们不对过往的技术经历有硬性要求，但希望你对技术挑战充满热爱，对解决客户的问题充满热忱，最重要的是，我们希望你对世界永葆好奇心，能够和我们一起探索技术改变世界的边界。 我们为什么叫 String ？ String 取自 String theory ，弦理论设想了高维宇宙蜷缩在三维空间里，正如高维数据蜷缩在 manual analysis 可以探索的低维空间中一样。 我们的愿景？ Decision making with the blessing of dimensionality. Curse of dimensionality （维度灾难）是一个机器学习中常见的概念，它指随着空间维度增加时，高维空间内的分析会遇到低维空间中难以遇到的问题。我们借用了这个短语，却把”Curse“（诅咒）改成了”Blessing“（祈福），因为我们相信：借由最前沿的技术，高维数据可以充分地发挥自身的魔法，把更全面、更精准的分析普及到企业日常的决策当中。
【岗位职责】1、管理大数据平台研发团队，制定团队目标，对团队产出负责；2、关注大数据平台前沿方向。基于业务方需求，对大数据基础设施进行架构设计调整、功能开发，提升集群稳定性、性能和效率；3、协调团队与数据治理、数据应用等部门的协作流程，提升集团整体数据研发效率。【任职要求】1、全日制本科及以上学历，计算机相关专业；2、8年以上开发工作经验，3年以上大数据平台（Hadoop集群、实时计算引擎、OLAP引擎等）相关工作经验；3、熟悉敏捷开发体系，管理过8人以上研发团队，并有跨团队协作经验；4、精通大数据主流框架(如Hadoop、hive、ClickHouse等)，有集群性能调优经验；5、熟悉数据治理流程，有数据应用经验者优先；6、有集群性能调优经验。
大数据架构师职位描述：职位职责：1、负责小码王大数据体系建设，在理解在线教育业务场景基础上，赋能业务；2、负责小码王数据仓库、实时计算等系统设计与研发。职位要求：1、本科及以上学历，计算机、通信等相关专业，5年以上工作经验；2、有扎实的编程能力，有优秀的设计和代码品位，有独立的代码实现能力 ；3、熟悉Hadoop/YARN、Hive、Spark、Kafka 等，有Flink实时处理经验优先，有ClickHouse 使用经验优先；4、优秀的理解沟通能力，能快速理解业务背景，责任心强，具有良好的团队沟通与协作能力；5、有大数据处理、数据平台、数据仓库从0到1经验者或数据挖掘算法优先。
岗位职责1、负责数据库、缓存等在线数据存储、计算、检索相关组件的选型、架构设计和运维保障工作2、负责离线大数据ETL、实时指标报表计算等工作涉及的大数据技术的选型、架构设计和运维保障工作3、负责大数据一站式开发平台（集数据抽取、数据加工、数据建模、数据服务管理等功能为一体）相关的产品规划、设计和研发工作任职资格1、深入理解数据库、缓存的原理，熟悉其在互联网行业的架构设计并具备实战经验2、深入理解Hadoop生态各组件的原理和优缺点，具备优秀的大数据技术架构设计和运维能力3、熟悉离线大数据开发平台、实时计算平台等大数据开发产品的设计4、熟悉异地多活IDC、混合云环境下的数据库、大数据集群的技术架构5、具备优秀的业务理解能力，能运用大数据技术并结合业务特点，为业务提供合理的大数据技术解决方案6、主动学习、善于沟通、勤于思考、乐于分享7、有大数据平台管理经验者优先
岗位要求：1、计算机相关专业，本科及以上学历，具备3年以上大数据系统开发设计经验;2、对数据仓库、数据平台、数据分析、数据挖掘等领域有深刻的理解，丰富的数据架构经验，精通数据建模及ETL设计开发；3、有较为系统的海量数据性能处理经验；有前瞻性的整套数据管理、数据服务等解决方案的规划和落地经验；4、对公司业务有整体的理解，对数据业务场景非常敏感，能够有效结合业务和技术创新，全局地规划或完善数据服务体系以解决业务/产品的问题；5、具有大型跨部门的复杂项目或者技术领域的管理经验，有成熟的团队梯队建设经验和技能储备的思路。岗位职责：1、负责公司数据中台建设，业务领域核心数据体系的规划设计；2、规划设计数据服务工具，提升数据研发的工作效率，搭建数据服务的工具，赋能业务产品，灵活支撑业务的创新和探索。
岗位职责：1、负责大数据产品设计工作，负责产品的核心模块开发、关键问题处理等工作2、参与项目需求分析、系统架构设计、方案评审等工作3、参与基础框架研究、输出技术分享和培训、提升团队技能等相关工作岗位要求：1、本科及以上学历，计算机相关专业，5年及以上实际Java开发经验，985/211优先2、具有3年及以上的架构设计经验，熟悉分布式系统、负载均衡的设计和应用，对消息服务、负载均衡、高可用机制等有深入理解3、精通Java语言，熟悉多线程、网络编程，对JVM有深入理解，具有设计实现高并发、高可用的Java应用的能力并对现有系统进行调优4、熟悉常用中间件，理解其设计原理5、熟悉大数据基础组件技术原理，有Spark、Flink引擎开发经验者优先6、熟悉数据治理相关理论，有数据数据治理工作经验者优先7、具有较好的开源项目学习能力，良好的英文文档阅读能力，具有修改开源项目源码实际经验者优先8、良好的沟通经验和团队合作能力，优秀的文档编写能力，热爱技术，良好的学习习惯，并勇于承担风险和挑战
岗位职责：1、参与调研，对客户方组织架构、业务架构、IT架构及数据架构等进行调研分析；2、基于客户实际情况制定数据治理方案与规划，协同项目经理制定项目计划与实施方案；3、制定相关数据标准，基础数据标准、指标数据标准等，协助客户推进数据标准化；4、负责专题治理，如元数据、主数据、数据质量、数据资产、数据安全等；5、协助公司完善产品体系。任职要求：1、本科以上学历，5年以上有主数据项目、数仓类，数据开发等项目经验者2、有数据治理实施或咨询经验；3、了解业内常用治理标准或框架；4、了解制造业常见业务系统如ERP、MES、PDM等优先；5、需要出差。其他：公司酌情配优质单身公寓
岗位职责：1、根据各类数据组建，结合公司内部数据处理全过程，梳理整合公司现有业财、行政等系统，搭建公司整体系统，并及时发现系统和流程痛点并予以完善；2、负责大数据平台的基础技术规划，编制相关规范文档，分析和解决公司大数据平台运行中的性能、通用和吞吐优化问题；3、通过数据、算法和工程化能力，挖掘系统运维数据、研发数据、代码数据中的价值，提升工作效率；4、通过根据公司和部门发展战略，梳理各类系统运行架构，明确系统整体运行策略；4、根据各业务职能的需求确定公司整体系统逻辑和业务板块系统蓝图；5、完成公司安排的其他工作。任职要求：1、全日制本科及以上学历，计算机相关专业；2、5年以上系统搭建、开发经验，有建筑、房地产系统搭建经验者优先；3、较为丰富的数据平台的架构经验，精通数据建模理念和具备实战能力，有较为系统的海量数据性能处理经验4、具备项目规划和决策能力，善于捕捉需求、架构设计存在的问题，并给出有效的解决措施和方法。4、熟悉SAP、WMS、SRM、LES、DPS、ERP、OA等系统，会运用数据库Access、SQL、Oracal或Java等编程软件。
工作职责1、负责企业内、外部相关中台应用系统技术项目管理及架构设计工作；2、参与相关应用系统建设的技术评审工作；3、参与或指导企业中台服务化建设开发工作；4、能够指导项目技术开发，发现模块中潜在的问题，并做出优化或改进，具备重构模块代码的能力5、理解模块的概要设计文档，并能根据概要设计进行模块的详细设计6、对自己负责的模块及领域，可以进行全方位的支持，并可以对模块提出优化，整改建议7、分析测试结果，并能根据结果对模块的性能，功能等进行分析任职要求1、3年及以上开发经验，JAVA基础扎实，熟悉常用的设计模式，理解IO/NIO、多线程、集合等基础框架，对JVM原理有一定的了解。2、掌握Java Web方面常用框架，如Spring boot、Spring MVC、MyBatis等。3、掌握Tomcat/Nginx/Apache服务的安装配置及故障排查。4、掌握MySql，Redis等数据库,对sql使用和优化有一定的经验。5、对前后端分离开发有一定的了解，有Vue前端框架开发经验优先考虑。6、掌握常用的RPC框架，有dubbo开发经验优先7、熟悉分布式系统的设计和应用，熟悉缓存、消息等机制；8、负责过至少1个微服务项目开发经验9、有数据中台项目开发经验优先10、熟悉Hadoop，Spark，Flink等生态圈的离线处理和实时处理优先
职位描述1.打造禾观电商全域的数据架构设计与研发；2.负责数据开发体系与在离线平台能力建设，通过数据技术给业务带来持续增量，提升平台交易转化率，洞察业务行为，挖掘客户诉求；3.为团队引入创新的技术和方案，用创新的思路解决问题，能对现存或未来系统进行宏观的思考，规划形成统一的框架、平台或组件。职位要求1.具有丰富的数据建模实践经验及分布式平台数据处理相关工作经验；2.具备扎实的理论基础和数据技术，具备大数据平台实时和离线ETL开发能力，参与或负责过线上业务的数据仓库建设；3.技术或业务理解上有亮点，自我学习，对新技术敏感；4.良好的思维逻辑性、语言表达能力；5.具备一定的JAVA或Python的开发能力，熟悉机器学习算法能力优先。
岗位职责：1、负责腾讯云大数据相关产品的研发；2、负责与客户进行持续需求沟通，通过完善产品功能服务好企业客户。岗位要求：1、计算机、通信等相关专业，本科及以上学历，3年以上大型互联网产品或分布式系统开发设计经验；2、扎实的java技术基础，对linux，分布式系统，高并发等技术经验丰富；3、对大数据领域相关组件如（spark, airflow,es,fate等）有丰富的使用经验；4、在企业内部或云，有大数据领域相关组件如（spark, airflow,es,fate等）产品化经验优先；5、在企业内部或云，有大数据开发平台、数据湖等产品的研发经验优先；6、有联邦学习或多方安全计算相关领域经验优先
职位：JAVA/SCALA开发工程师 / 大数据研发工程师工作职责1. 根据开发进度和任务分配，完成相应模块的开发、编程任务，并在开发过程中解决关键问题和技术难题；2. 主导技术难题攻关，重构系统确保高性能处理和系统的稳定性，应对海量数据与高并发；3. 实践规范的软件工程（例如测试、code review等）；4. 参与大数据分析的核心算法开发与设计，提供显著的用户价值；5. 与其他后端工程师、前端工程师一同协作，共同打造中国最好的大数据分析产品；岗位要求1. 精通Java编程以及常用的Java框架2. 熟悉服务器的架构设计、开发流程及规范3. 丰富的项目经验4. 快速学习的能力及意愿加分项1. 熟悉Scala、Python2. 有过Apache Spark等开源系统的实际项目经验3. 熟悉Apache Cassandra或HBase等NoSQL数据库4. 了解大数据分析、商业智能（BI），有过实际项目经验更佳5.有相关工作经验或优秀应届毕业生
大数据开发岗位职责:1、参与产品功能的独立设计2、完成代码编写测试及bug修复工作3、参与各类开发文档编写任职要求：1、熟练使用mysql、Oracle等关系数据库，熟悉SQL语法，SQL优化2、熟悉 spring、springmvc、springboot、springcloud 等框架3、了解Linux操作系统4、具有良好的编码风格，责任心强、富有团队协作和敬业精神5、精通java核心以及J2EE，熟练掌握ZK dubbo MQ  redis Memcached 等应用中间件6、熟悉Hadoop生态圈，熟悉Hive，HBase，Spark ，SQL，Flink等大数据技术，熟悉基于大数据的数据质量管理、元数据管理、数据安全管理7：了解 DataWorks/Dataphin/等流行的数据中台产品工作原理及应用工具；8：具备DW/BI项目实施和开发经验，有数据中台项目实施落地经验及oneData建模理论优先；9：本科及以上学历，具备政务行业背景经验优先
岗位职责：1、负责大数据平台的设计、建模、代码开发和测试；2、规划大数据平台的架构和部署需求，把握系统的高可用、扩展、安全、性能、伸缩性等；3、及时与产品经理/项目经理沟通需求，分析梳理业务场景，协助需求侧解决各种业务实现 问题；4、负责核心技术难题的攻关，攻克团队遇到的技术难题，持续对线上系统进行性能优化及稳定性提升；5、参与对平台的运维和运营的支撑体系的制定和实施，对线上突发问题进行及时响应并解决；职位要求：1、统招计算机、工程类、数学、财务等方面相关专业本科及以上学历并取得相应学位；2、2年以上数据分析工作经历；熟悉使用mysql、oracle等数据库，并有相关项目经验；3、掌握复杂SQL语句的编写，具备SQL优化的能力，熟悉etl工具如kettle等操作；4、热衷于产品研发和技术创新， 具有很强的学习能力并有强烈的责任意识和开放的心态， 工作态度好，积极向上者为先；5、有良好的沟通能力及自我驱动能力，强烈的责任感，以及优秀的自我学习能力。
岗位职责：1.将解决方案沉淀成可复用、可配置的灵活平台，降低技术产品复用的成本，提升技术输出效率2.能够组织跨团队协作、推动甚至直接负责项目优质如期落地；熟悉数据及数据技术并能与业务和技术人员很好的沟通与协作3.持续关注大数据领域动态和前沿技术，合理地引入到工作中，提升大数据能力4.深入业务场景，发现业务痛点，设计数据化、智能化解决方案；岗位要求：1.熟悉业界主流大数据处理技术，有丰富的分布式计算平台模型架构（Hadoop, Hive, HBase, ZooKeeper, Spark, Cassandra, MapReduce, MPP等）经验2.具有2年以上大数据架构工作经验；3.如何使数据 以及技术产生价值 有独特的见解
岗位职责：1. 负责售前POC测试工作，包括但不限于功能测试验证、性能测试验证、同类产品对比测试验证等；2. 根据客户需求，形成合理的解决方案；3. 快速解决客户试用和POC测试过程中的技术问题；4. 总结过往问题，撰写高质量的技术教程；5. 给客户进行技术培训。岗位要求：1. 985/211本科及以上学历优先，理工科背景；2. 一流的动手能力和技术问题解决能力；3. 优秀的沟通能力，善于聆听，洞察需求，简洁表述；4. 可接受短期出差；5. 熟悉大数据、数据库、分布式计算、机器学习相关领域知识；6. 优异的脚本语言阅读和开发能力，熟悉向量化和函数化编程为加分项；7. 至少掌握c++/JAVA/Python一门编程语言，熟悉Linux操作系统； 8. 善于总结问题，热爱撰写技术文档；有良好的表达能力，能给客户进行技术培训者优先。
岗位职责：1. 负责轨迹云平台的建设和维护，数据ETL的设计、开发与性能优化;2. 建立实时和离线大数据处理流程，负责数据产品平台化和系统化;3. 负责轨迹数据、业务数据等类型的治理工作，提升数据易用性及数据质量;4. 理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作;任职要求：1、计算机及相关专业本科以上学历2、负责业务条线数据仓库基础平台的建设和维护，数据ETL的设计、开发与性能优化3、具备较强的编码能力，对代码风格自我要求严格，熟练掌握Java、Shell、Python等至少其中一门语言4、熟悉大数据的存储/计算相关技术Hadoop/Hive/Spark/ElasticSearch/HBase/Kafka/Flume/Flink等大数据生态圈常用组件;5、有Geomesa、PostGIS使用经验优先； 6、参与过地理信息数据仓库、时空大数据平台建设者优先;7、有地图行业经验优先;8、有实时数仓设计、开发经验者优先;9、熟悉业内主流BI产品，有使用经验者优先;10、善于从数据中发现疑点，用系统化思维解决问题;
"大数据(高级)研发工程师：上海/北京/杭州职位描述	1、负责头条系产品短视频用户体验的持续优化；	2、构建短视频相关数据仓库，分析和报表系统；	3、设计并优化视频播放QoS数据上报机制，构建面向用户体验的APM系统；	4、通过建设实时数据分析，构建智能播放调度策略和自动报警归因系统；职位要求	1、本科及以上学历，计算机、通信等相关专业，两年及以上全职工作经验；	2、有扎实的编程能力，有优秀的设计和代码品位，有独立的代码实现能力 ；	3、深刻理解计算机原理，有良好的数据结构和算法基础；	4、熟悉数据采集、清洗入库、统计计算、Web展示核心要点，可实现指标计算需求；	5、熟悉至少一个分布式框架，如 Hadoop/YARN、Hive、Spark、Storm、Kafka 等，有Flink实时处理经验优先；	6、优秀的理解沟通能力，能快速理解业务背景，责任心强，具有良好的团队沟通与协作能力；；	7、有大数据处理、数据平台、数据仓库经验者或数据挖掘算法优先;"
岗位职责：1. 负责公司大数据平台（离线/实时）的架构设计及开发，支撑数据和算法在游戏业务的应用；2. 负责大数据平台的架构设计、系统开发、组件调优和运维部署，搭建包括数据采集、数据集成、任务调度、元数据管理、数据血缘、DQC等系统；3.负责搭建数据开发和治理平台，为数据分析和数据开发人员提供稳定、高效的数据。任职要求：1. 本科及以上学历，3年以上大数据相关工作经验，有完整的分布式数据存储计算平台项目实施经验；2. 熟悉Hadoop生态圈和数据库相关技术，有Hive/Iceberg/Spark/Flink/HBase/Elasticsearch/Clickhouse等经验者优先；3. 熟悉Linux开发环境，能使用Python/Java/Scala/Go一种或多种编程语言进行工程实现；4. 在机器学习、推荐算法、图计算等领域有实际项目经验者为佳；5. 沟通能力强，有出色的业务理解力和解决问题的能力。
岗位职责：1. 负责公司大数据离线数仓、实时数仓建设、维护2. 参与大数据基础架构和技术体系的规划建设，包括数据采集、数据处理、数据治理、数据应用等岗位要求：1. 大专及以上学历，对数据处理、数据建模等有一定的认识和实战经验2. 精通数据仓库理论，具备复杂业务需求梳理能力，3年以上的大数据数仓建设维护经验3. 具备良好的团队协同、沟通交流及抗压能力，善于独立分析和解决问题，有强烈的责任心和集体荣誉感4. 熟练使用Linux系统、熟练编写Shell脚本5. 精通SQL，熟练使用常用的关系型数据库、非关系性数据库，具有HQL性能优化经验6. 熟悉常用的大数据生态技术，包括但不限于：Flume，Kafka、Hive、hdfs、yarn、sqoop等
岗位职责：1、负责系统的分析与设计工作，参与重点模块的编码工作；2、负责大数据平台的对接，数据中间件开发；3、负责系统维护、故障解决，保障系统的正常、稳定运行岗位要求：1、计算机/通信/数学相关专业，本科及以上学历；2、熟悉java语言，熟悉分布式、多线程及高性能的设计与编码及性能调优 ；3、熟悉Hive/HBase/Spark/ClickHouse/ES等其中一种或多种开源系统应用和性能优化者优先；4、熟悉mysql等常见数据库，有mysql binlog 数据实时同步经验者优先5、熟练使用LINUX，能进行shell编程；
岗位职责：1. 基于hadoop/flink/spark等开源技术，完成企业业务流程的建模和实时分析；2. 参与建设和输出企业数字大脑解决方案，探索流批一体等前沿领域，输出标准化的流计算平台服务。任职要求：1. 熟悉java、scala、python一种或多种，有jvm调优经验；2. 熟悉流计算原理，熟悉spark、flink一种或多种；3. 熟悉hadoop生态；4. 计算中的容错、事务、可靠性、状态有深入理解，熟悉数据挖掘算法优先；5. 有海量数据处理经验，有调优或内核开发经验优先；6. 熟悉或了解统计机器学习者优先。
职位描述1. 负责安全云大数据分析框架搭建，ETL搭建；2. 负责大数据框架安全方案背后的智能算法引擎研发；3. 负责大数据实时风控平台研发。任职要求1. 具有丰富的C/C++/ Scala系统的开发经验，熟悉Linux操作系统；2. 负责过网络安全、效率类模型算法研究与实现；3. 负责过分布式大数据系统搭建，包括系统结构设计、应用场景分析等；4. 负责相关应用/项目的需求分析、设计等工作；5. 有以下经验优先考虑：具备智能网络安全项目背景，具有时序模型构建经验，熟悉XGBoost，Random Forest等基础算法。
岗位职责：- 负责研发大数据平台和工具- 负责数据接入和存储，保障数据通道的可靠性、一致性- 负责数据平台的大数据基础架构规划、运维保障、数据监控等，为海量数据和业务系统提供可靠的基础设施- 参与大数据生态相关技术的前瞻性研究和调研落地，持续扩充大数据能力，优化大数据服务的性能和效率岗位要求：- 熟练掌握Hadoop、Hive、canal、datax、Presto/Impala、Kudu/Hudi、Sentry/Ranger、HBase、Es、Spark、Flink等大数据平台组件或开发工具中的若干种,有部署和优化经验，实际解决过线上问题- 熟悉Linux系统，熟悉Java/Python/Shell等语言，具备良好的编程能力，具备源码级问题解决和集群优化改造能力- 有自研平台经验者优先，包括但不限于离线开发平台、数据质量中心、元数据管理、数据资产管理、日志埋点平台、实时流平台等；- 对大数据行业富有热情；有较强的责任心，执行能力强；具有优秀沟通能力及团队精神
岗位职责：    1、负责大数据平台的设计与开发实现；    2、负责大数据应用相关产品需求分析、架构设计以及开发实现；    3、负责数据产品的服务接口开发和维护。岗位要求：    1、本科及以上学历，2年及以上大数据相关技术背景；    2、熟练进行Java的代码编写，良好的代码编写素养，良好的数据结构算法技能；    3、熟悉Spring boot、Mbatis、Dubbo等开发框架，熟悉前后端分离开发流程；    4、有数据平台开发经验，包括但不限于离线开发平台、数据质量中心、元数据管理、数据资产管理，实时流平台等；    5、熟悉数据仓库理论，对多维数据建模有深入理解和实际经验；    6、熟悉开源大数据组件如HBase、ES、Kylin、Druid等，有实际的报表平台、多维度分析工具、ETL平台、调度平台中至少一种工具的实际建设经验；
负责或者参与如下工作的一种或者几种：1.负责数据产品的研发，包括但是不限于数据的收集，转化，存储，展示；2.负责数据仓库的设计和维护，开发可靠，高效准确的数据集市，并提供技术支持；3.维护和升级大数据基础设施，解决海量数据存储，计算，监控等问题；
岗位职责：1、参与数据仓库(离线、实时)工具建设、开发和维护2、有数据仓库经验以及数据工具平台开发经验3、熟悉数据仓库建模、ETL设计开发，有数据质量与数据治理相关经验4、负责数据仓库设计，数据ETL的设计、开发和性能优化；5、负责大数据平台（Hadoop，HBase，Spark等）集群环境的性能调优和日常维护；6、熟练掌握Hadoop,Spark,Hbase，Hive，Storm、ZK、Kafka、Flume、Sqoop等一种以上的大数据处理工具和技术，有实际大数据处理经验；7、熟练掌握Java，并熟悉Shell，Python等一种以上的脚本语言，并灵活运用到实际工作中及解决技术问题；8、熟练掌握Linux操作系统；任职要求1、计算机、统计、数学等相关专业，本科及以上学历，有至少一年的大数据行业实践经验；2、熟练使用大数据生态中的常用组件。hadoop、zookeeper、kafka等。有ambari实际使用、二次开发经验者优先；3、熟练掌握一门或多门编程语言，Java、Python、Scala等，java开发至少两年以上经验，java基础扎实。会Scala更佳；4、良好的语言表达能力和自我驱动力，以及优秀的沟通协调能力。
岗位职责1、负责公司物联网平台大数据开发，负责大数据平台各子系统中的系统设计/模块设计，并承担其中核心框架和模块的开发工作；2、负责ETL及数据仓库构建;3、负责大数据集群管理、搭建和运维；4、负责按计划高质量地完成系统的开发落地实现，保证系统的各项质量属性顺利达成；5、负责与大数据平台其他相关系统开发团队的进行开发联调、配合完成系统测试/集成测试；任职要求：1、熟练掌握 java 编程语言；2、熟悉流式处理组件Storm/Jstrom/Flink;3、熟悉大数据处理相关产品架构和技术（如Hadoop/Hive/HBase/Spark/Kafka/Storm/Flume等），对内部实现机制深入了解，对其中的部分组件能进行源代码级的研究和优化；优选项：1、熟悉数据仓库模型设计和精通ETL开发经验,具备海量数据加工处理（ETL）相关经验 2、掌握至少一种数据库开发技术：Oracle、Teradata、DB2、Mysql等，精通并灵活运用SQL实现海量数据ETL加工处理 ；3、5年以上大数据平台实际的相关产品和项目开发经验；或熟悉平台各组件的应用开发接口并有3年以上实际的相关应用软件开发经验； 4、了解各种互联网常用开源软件（如Zookeeper/Redis等），有知名互联网/软件/通信厂商大型项目经验者优先；  5、熟悉Linux系统常规shell处理命令，灵活运用shell做的文本处理和系统操作；6、熟悉数据仓库领域知识和技能者优先，包括但不局限于：数据开发测试工具与方法、数据质量等。
1、负责华为云EI智能体大数据的开发和维护，确保平台高效、稳定的运行；2、与行业专家一道，深刻洞悉人工智能在城市生活各领域应用和发展趋势，打造华为云智慧城市生态品牌。【岗位要求】：1、编程能力突出，具有良好的编程风格，熟悉常用设计模式；2、熟悉Java/Scala/python语言，了解Spark/Hadoop分布式框架；3、拥有数据治理、清洗、判重、融合、存储、计算等数据开发经验；4、有大数据平台服务分层框架，数据中台设计开发经验者更佳；
一、职位描述：1.负责供应链全链路的分析优化，包括但不限于业务分析、数据建模、数据开发、数据质量等；2.参与供应链的数据研发，与产品技术团队一起打造数据产品；3.研究业界数据建设模式，跟进大数据领域新技术，建设PB级数据应用；4.参与供应链数字化控制台产品，对外的商业化；二、职位要求：1）本科以上学历，2年以上相关工作经验，熟悉数据仓库模型设计与数据开发经验，如数据集市设计、数据质量管控等，具备海量数据加工处理相关经验2）熟练运用大数据计算平台来处理数据，包括但不限于ODPS、Flink、Hadoop、Spark等，掌握一门或多门编程语言，如Java、Python等；3）良好的数据敏感度，能从海量数据提炼核心结果，需要具备数据统计的基础知识，能够在数据探索上有自己的洞见分析能力，（加分项）掌握常用的数据分析方法和函数库，如分类、偏差分析；4）有良好的业务及产品感觉，能够超越需求，有自己独到的见解和思考。可以主动并乐于了解日常业务，具备从日常业务中发现问题并解决问题的能力；5）（加分项）对数据挖掘和机器学习有所了解，包括常用的机器学习算法和数据建模过程的优先，有供应链应用场景实践的优先。
岗位职责：1、核心后端技术团队大数据技术组的java开发岗位。2、主要参与数据治理、数据安全等相关服务开发。3、可参与大数据相关技术及服务的研发、维护，包括但不局限数据采集、实时处理、数据开发、数据分析等服务。岗位要求：1、本科以上学历，3年以上工作经验，对技术有强烈热情，关注互联网发展趋势，勤于思考，动手能力强。2、熟悉java，熟练使用线程、锁、队列等，对并发集合框架，异步模型等有一定理解，有JVM问题处理经验。3、熟悉常见的java开源框架，如Spring、Spring MVC、MyBatis等； 4、熟悉http、ftp、tcp等网络协议，熟悉数据加密算法、IO编程等。5、了解大数据、消息中间件、nosql数据库等，有大数据开发经验，可加分。6、熟悉常用的设计模式，对业务有良好的抽象能力和架构设计能力，可加分；7、熟悉linux环境，掌握常用命令； 8、具有良好的团队合作精神、沟通技能，能承担一定工作压力。
数据研发职位描述1、参与行云集团跨境数据仓库架构设计与数据开发 ；2、负责数据平台相关数据管理工作，如研发规范、质量规范、保障规范的制定与推动实施落地 ；3、负责来自业务团队数据需求的研发支撑和数据产品落地。职位要求1、熟悉数据仓库模型设计方法论，并有实际模型设计及ETL开发经验；2、掌握大型数据库开发技术，如Oracle、Teradata、DB2、Mysql等等掌握至少其中一种，灵活运用SQL实现海量数据ETL加工处理；3、 熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等；4、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop/MaxCompute生态相关技术并有相关实践经验；5、掌握一门或多门编程语言，如Java、Python、Perl、shell等；6、熟悉常用的实时数据处理技术，如Flink、Storm、Spark Streaming等；7、良好的语言沟通与表达能力和自我驱动动力。8、有电商行业背景、数据应用经验者优先
1、从事态势感知产品大数据分析平台的开发；2、负责软件项目、模块的需求分析、设计、编码实现、验证；3、参与相关质量活动，确保软件设计及实现工作按时保质完成。职位要求：1、计算机相关专业，本科及以上学历，具备3年及以上大数据系统开发经验；2、具有Hadoop、Spark、kafka、hbase、zookeeper等大数据生态圈实际开发经验，并深入了解它们的工作原理及应用场景；3、拥有实时流处理经验，掌握Storm等实时处理框架，熟悉Solr或ElasticSearch等搜索引擎；4、热爱技术，喜欢专研，并且具备较强的数据分析、问题分析和逻辑思维能力，以及良好的沟通，团队协作能力。
工作内容：基于大数据场景，进行系统性能优化。要求：1.熟悉使用Java python c 其中一门语言，熟悉spark MySQL redies等平台和应用。2.具有独立解决问题和学习能力。
岗位描述 1.负责公司大数据产品、项目的后台研发，参与大数据的运维保障工作； 2.参与大数据相关的算法和模型分析实现； 3.参与大数据的数据治理和数据处理相关java开发工作。 4.负责技术预研，产品设计以及文档编写等工作；  任职资格： 1、本科及以上学历，计算机、软件工程师及其他理工类专业； 2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具； 3、对开源大数据系统有相关经验者优先，包括但不限于Hadoop/Spark/Hive/Flink/Kafka/Kylin/ClickHouse 等； 4、对数据敏感，掌握量化分析方法，善于从数据中发现问题者优先； 5、具备良好的分析问题和解决问题的能力，有较强的责任心，具有良好的学习、沟通能力，注重团队合作，有创新精神。
工作内容：1、 构建基于行业的数据仓库体系，支撑上下游业务；2、 离线数仓开发及实时流数据处理；3、 根据业务需求，开发相应产品；4、 处理大数据平台异常，保证系统平台稳定运行。岗位需求：1、 掌握数据库应用并熟练掌握SQL开发，并有SQL调优经验；2、 熟悉数据仓库的基本理论体系并有个人的想法和见解；3、 具备实时流数据处理能力，有Flink，Spark实操经验更优；4、 积极主动，学习能力强，能接受长期驻场出差。优先条件：1、 熟练掌握Python，Java，Scala一种或多种开发语言；2、 有数据仓库搭建的实战经验，熟悉面向行业的数据标准体系。
1. 工作内容：a.负责数据研发平台的各组件的线上问题排查, 保障基础设施稳定运行。b.已有系统的梳理和架构/性能优化工作，提高线上服务的稳定性和高效性c.有技术反哺业务实践者优先（通过技术改造、提升，来影响业务、产生价值）2. 任职要求a. 掌握Java, 熟悉Spring相关框架;b. 熟悉hadoop/spark/Hive/Presto等分布式计算技术，熟悉其运行机制和体系结构；c. 熟悉Mysql，ES，HBase，Redis等存储引擎的数据存储及使用方法；d. 良好的开发习惯和团队协作意愿;e. 对数据敏感，有良好的沟通表达能力和跨团队协调能力，乐于寻求挑战和突破自我。
1、参与大数据平台建设，承担大数据平台研发职责。2、构建大数据质量体系，持续提升数据质量；3、在传统大数据开发和数仓建模的基础上，探索创新的方案，构建自动化、智能化的建模引擎4、 促进跨业务线的数据融合，通过技术和业务场景的紧密结合，让数据发挥最大业务价值。岗位要求：1、5年以上大数据处理研发经验；2、扎实的JAVA开发能力，熟悉shell、python或其他脚本语言中的任意一门；3、熟练使用数据库同步、日志采集工具；4、精通hadoop、HDFS、Hbase、Hive等技术；5、精通flink、storm或spark streaming等流式或流批一体处理框架中的一种或多种；6、熟练掌握数据仓库建模和ETL设计方法论；7、有基于数据分析推动业务提升或优化的实际案例；8、有数据挖掘、机器学习经验者优先考虑；
要求本科211学历及以上，可以选择base杭州或武汉。岗位职责：1.负责数据仓库平台的建设与维护，数据ETL的设计、开发与性能优化2.建立实时和离线大数据处理流程，负责数据产品平台化和系统化3.负责大数据平台数据挖掘、清洗、建模、分析4.理解业务需求，完成技术选型和技术难点攻关任职要求：1.理解大数据的存储和计算相关技术和原理：Hadoop、Hive，Spark，ElasticSearch,Hbase,Kafka,Flink、ClickHouse等组件，有性能调优经验者优先2.参与过大型数据仓库建设者优先。有实时数据仓库设计、开发经验者优先3.熟练掌握java、scala、Python等至少其中一门语言4.熟悉Linux相关命令，熟悉分布式系统架构设计和运维设计，能独立部署大数据相关集群环境5.熟悉并行计算或者分布式计算原理，熟悉高并发、高稳定性、可线性扩展6.丰富的PaaS项目开发经验，良好的团队协作能力，热爱开发工作
1. 参与数据仓库的长期架构规划与数据开发，建设大数据平台 2. 负责数据平台相关数据管理工作，元数据管理、研发规范、质量规范、保障规范的制定与推动实施落地 3. 对数据ETL任务进行性能调优及性能瓶颈分析 4. 负责业务功能数据开发，包括（数据统计实现、数据测试，发布上线等）5. 学习新技术，提高整个平台的计算能力和效率
岗位职责：1、 负责大数据平台架构的开发、设计和布局 ；2、 完成系统框架的设计和核心代码的编写；3、 针对海量的用户行为数据进行统计、分析与挖掘，不断提高系统运行效率；4、 负责对数据进行分析，为项目组提供大数据技术指导及分析手段支撑；5、 负责大数据平台的性能监控和持续优化；针对需求提供大数据分析技术解决方案 ；6、 大数据平台的运维工作，持续完善大数据平台，保证稳定性、安全性。 任职资格：1、 5 年互联网行业开发经验，计算机或相关专业本科及以上学历；2、 精通 Hadoop 大数据平台架构，具有扎实的 Java/Python 等开发语言；并可以开发高效可靠的代码；3、 具有较强的数据分析、数据挖掘的能力；4、 熟悉 spark、Hive、storm 等计算框架者优先，对分布式存储和计算原理有较深的理解；5、 严密的数学思维、突出的分析和归纳能力、优秀的沟通表达能；6、 个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神
岗位职责：1、参与数据中台项目需求调研、数据建模等前期架构设计工作；2、负责数据中台项目数据采集、数据开发等相关开发工作；3、负责数据中台项目接口开发工作；4、负责数据中台项目可视化开发工作； 基本技能要求：1、熟悉Linux操作系统基础命令2、熟悉Java、Pyhton、Scala其中一种编程语言，具备良好的编程能力3、熟悉数据库Mysql、SQLServer、HiveSql中至少一种，熟练掌握常用数据库命令3、熟练使用Dataworks、DataQ、DataV等阿里云大数据产品集4、熟悉Spark、Hive、Hbase、Flume、Mapreduce、Kafka等大数据组件5、较好的沟通能力；6、熟悉安全生产的相关规定并遵守；7、1年以上大数据项目经验
职位职责： 1.结合业务情况进行大数据平台的开发和设计，数据产品的落地。包括但不限于：数据采集、调度引擎、开发平台、数据治理、数据服务等； 2.参与离线、实时的数据存储和加工处理，保证数据质量，保障集群高效稳定运行，保障数据平台稳定高效； 3.参与数据分析平台的大数据架构、方案和核心代码研发，系统优化； 4.参与大数据组件的选型，新技术的预研，包括但不限于：存储、流/批计算引擎，协助团队解决开发过程中的技术难题； 5.参与数据服务项目开发，为其他部门提供数据支持。  岗位要求： 1.全日制本科及以上学历,三年以上工作经验，计算机、通信、数学等专业优先； 2.精通Java或Scala, 熟悉Python，热爱技术钻研探索，精读hadoop生态内开源组件源码者优先； 3.基于Hadoop的大数据体系有深入认识，具备相关组件（Hadoop、Hive、HBase、Spark、Flink、Flume、Kafka、ES等）项目应用研发经验，参与过spark或Flink实时数据分析项目，有性能优化经验优先； 4.熟练使用Spring Boot、Spring Cloud进行项目开发； 5.有数据平台开发、海量数据处理经验者优先。
岗位描述（校招！！！）1、负责蚂蚁实时数据体系建设，包括业务领域核心模型的规划设计及实时资产沉淀，并能结合业界技术探索数据服务的增量，在数据化运营和数据能力产品化上，制定数据技术和服务的策略。包括用户标签体系、数据智能化和自动化体系和实时数据体系的建设；2、规划设计数据服务工具，提升数据研发的工作效率，搭建数据服务的工具/产品，赋能业务同学和业务产品，灵活支撑业务的创新和探索，让数据价值更浸透；3、负责数据质量、稳定性等数据管理，数据内部共享融通的数据平台，让数据标准更规范、数据获取更高效。岗位要求：1、计算机等相关专业本科以上学历 ，具备扎实的数据开发能力；2、掌握大数据计算技术体系，至少熟悉hadoop/storm/spark/flink中的一种引擎3、良好的思维逻辑性和语言表达能力，以及良好的项目沟通和协调能力。
职位职责：1、基于海量物联网数据和大数据计算平台，深入理解业务，负责行业大数据应用模型设计、建模、研发实现2、负责解决并实现大数据（离线+实时）计算分析需求3、根据业务需求进行数据模型的调研、设计、开发及验证工作，并持续进行模型的优化；4、探索数据产品化的机会，让业务具备数据化驱动的工具和能力，推动业务发展。岗位要求：1、3年以上大数据开发工作经验，计算机、数学或相关专业本科及以上学历；2、熟练使用Flink、Spark、Elastic Search、Impala等大数据框架，熟悉Kafka配置，熟悉基于Kafka的实时应用编程。3、有扎实的Java开发基础，熟悉scala，HiveSQL等编程语言4、熟悉Linux操作系统和开发环境；5、熟悉Postgresql数据库熟练掌握sql的使用6、了解数据挖掘、机器学习的概念和算法优先。
岗位职责：1、承担建设基于Hadoop/Spark生态的大数据离线/实时处理平台；2、负责日常的数据任务维护和支持，参与业务数据、生产日志的抽取、转储、检索等相关工作；。3、跟进大数据前沿技术的发展，将合适的技术方案适时引入业务场景；任职要求：1、计算机及相关专业本科以上学历，具备优秀的编程能力和良好的开发习惯，2~3年互联网大数据处理经验；2、熟悉大数据开源技术，包含（不限于）Hadoop/Spark/Spark Streaming/Hive/Hbase/Impala/Flume/Kafka/Es/Azkaban等；有实时处理工作经历并有一定解决方案者优先；3、精通java、Scala语言，熟悉Linux，熟练使用Python，Shell脚本；4、掌握SQL，SparkSQL进行数据开发；较好的SQL性能调优经验；5、具有认真的技术态度，良好的团队沟通和协作能力。
1.熟悉掌握SQL或HQL，具备一定的SQL调优能力，并有数据分析或数据挖掘相关经验，对数据工作有着浓厚的兴趣；2.了解数据仓库建模，有任意数据或大数据开发实战经验；3.熟悉Python开发语言以及numpy、pandas、mlib等常用的工具包，能够使用机器学习、深度学习等数据挖掘常用的算法，对数据进行分类、聚类、预测等项目经验着优先注：华为od岗位
需要实时计算机方向，flink,redis,hbase外包电网岗位。
1、熟练掌握Mysql，DB2等关系型数据库2、熟悉hive、hbase 有项目开发使用经验  3、熟悉linux常用命令能编写简单的shell脚本4、使用过TDH大数据平台优先5、熟悉银行业务，有过银行业务系统数据开发经验优先6、良好的沟通能力7、熟悉银行风险系统业务，如资金流向异常，违规交易等
岗位职责：参与数仓平台建设，包括ETL设计，建模，数仓搭建，监控体系搭建参与数据产品，数据分析需求的开发负责数据管控，操作审计等数据安全保障工作负责集群扩容，备份等运维工作任职资格：本科及以上学历，计算机或相关专业本科或以上学历，工作细致、善于思考，有很强的数据分析和问题解决能力2年以上工作经验，精通linux操作系统，对系统性能相关问题有较深刻理解精通shell编程，熟练常用命令精通Hadoop，spark，kafka, hive,flink，ES等相关架构及运维熟悉大数据集群运行基本原理及集群高可用性方案熟悉TCP/IP协议，能够定位linux网络下普通的网络异常强烈的责任心、良好的沟通和协调能力有devops实践经验优先
职位描述1、负责快手电商数据仓库的建设，构建各垂直应用的数据集市；2、负责快手电商新产品数据统计、报表产出、效果监测、归因分析和商务支持； 3、定义并开发业务核心指标数据，负责垂直业务数据建模；4、根据业务需求，提供大数据计算应用服务，并持续优化改进； 5、参与埋点设计、数据生产全流程等技术体系建设和保障工作； 任职要求1、本科以上学历，两年以上大数据相关开发经验； 2、熟悉Linux平台，熟练使用Java、Python编程语言，编码基本功扎实；3、有Hive、Kafka、Spark、Flink、HBase等两种以上两年以上使用经验；4、熟悉数据仓库理论方法，并有实际模型设计及ETL开发经验，对于数据的架构和设计有一定的思考，具备良好的数学思维和建模思维； 5、熟悉分布式计算框架，掌握分布式计算的设计与优化能力，对Hadoop生态其他组件有一定了解，比如 HBase，Hadoop, Hive, Druid等6、了解流式计算，熟悉至少一种实时计算引擎：Storm, Spark, Flink；7、有很强的学习、分析和解决问题的能力，良好的团队合作意识，较强的沟通能力。加分项：有电商数据开发经验优先。
工作职责1.配合项目总监，现场与客户技术负责人.技术合作伙伴.架构师对接，带领和管理技术团队；2.了解业务场景，评估项目需求，制定技术实施方案；3.带领技术团队完成项目开发和实施任务，包括需求分析.原型开发.技术评估.POC.项目开发.阶段演示及验收。任职资格1.统招本科及以上学历，计算机.通信工程.软件工程等相关专业，3年以上编程工作经验；2.具有大数据类的项目团队或者开发团队管理经验；3.精通Java/Python语言，熟悉linux操作系统；4.精通大数据相关技术，具备数仓主流组件开发经验；5.精通数据模型设计与ETL开发经验，熟悉Kettle，Sqoop等ETL组件，精通SQL，6.精通数据仓库建设；7.了解能源 政务等行业或领域业务，具有相关项目交付经验优先；8.有强烈的责任心及团队合作精神，能够承担工作压力。
1数据开发，海量hc,欢迎来撩
• 岗位描述：1、 负责电商业务的离线or实时数据仓库的构建；2、负责数据模型的设计，ETL实施，ETL性能优化，ETL数据监控以及相关技术问题的解决；3、负责指标体系建设与维护；4、深入业务，理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作；5、参与大数据应用规划，为数据产品、挖掘团队提供应用指导；6、参与数据治理工作，提升数据易用性及数据质量。• 岗位要求：1、熟悉数据仓库实施方法论、深入了解数据仓库体系，并支撑过实际业务场景；2、熟练使用Hadoop及Hive，熟悉SQL、Java、Python等编程语言；3、善于沟通，对业务敏感，能快速理解业务背景，具备优秀的技术与业务结合能力。
岗位描述：专业：计算机或相关专业；年限：一年以上Java大数据开发经验；1、有较强的责任心并具有一定的抗压能力，具备良好的团队合作精神，较强的沟通协调能力；2、善于学习，对业务有浓厚的兴趣，能够快速理解业务，能够独立与业务人员进行有效沟通；3、熟悉Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境，具有扎实的j2se基础，注重代码规范、代码执行效率，善用设计模式；4、熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，熟练掌握主流Spark框架，熟悉主流NoSQL数据库；5、熟悉Hadoop、流式计算、任务协同管理、YARN资源管理、多线程并发及通讯编程；6、熟悉数据仓库原理，熟悉SQL语言。7、熟悉机器学习常用相关开源框架，如Mahout、MLlib、Trident等优先；
职责描述：1.负责业务数据调研、数据ETL；2.负责建立数据模型，根据业务设计数据主题；3.参与团队ETL流程的优化及解决ETL相关技术问题；4.理解数据需求，提供面向业务的OLAP、报表、数据提取等数据服务；5.基于行业数据仓库标准进行数据开发和模型开发支撑业务应用。任职资格：1、掌握数据库应用并熟练掌握SQL开发，并有SQL调优经验；2、熟悉数据仓库模型设计，具备海量数据处理经验，拥有数仓设计或建设的实战经验；3、熟悉数据仓库领域知识和技能者优先，包括但不局限于：数据治理、元数据管理、数据质量监控；4、熟悉Mysql,Clickhouse,Doris,Hive，Hbase， 等离线框架基本原理，能够将技术与业务很好的结合；5、有BI系统项目和JAVA开发经验者优先；6、对大数据技术有很强的兴趣，不断自我学习，对新技术热衷热爱
岗位职责：1、基于hadoop/flink/spark等开源技术，完成企业业务流程的数据建模；2、负责大数据数据仓库、多维分析系统、分布式关系型数据库的设计与研发工作3、深入理解大数据平台架构，负责大数据平台建设、性能分析与优化4、参与平台大数据采集、清洗、传输、存储、实时计算、建模等设计与落地5、跟进大数据前沿技术，不断优化数据集群。任职要求：1、全日制本科及以上学历，计算机等相关专业毕业，5年以上相关工作经验；2、工作思路清晰，较好的沟通能力和技术学习能力，拥有良好的编码习惯，有很强的自学能力和自我提高的愿望；3、计算机和JAVA基础扎实，熟悉JVM、IO、多线程、并发、网络、数据库等，理解面向对象、设计模式、分布式等相关技术；4、熟练使用主流JAVA技术栈框架，如Spring、SpringBoot、MyBatis、Netty等；5、熟悉一种或多种大数据相关技术如：Hadoop、Flink、Spark、Hive、Storm、搜索引擎技术等优先。
岗位职责： 1、参与基于大数据的数据仓库项目前期业务调研、数据调研工作； 2、参与数据仓库搭建、离线/实时计算开发任务；3、基于阿里云体系规划离线/实时数仓数据流转,数据主题建设.4、保证数据质量及开发进度，参与编写交付文档； 任职要求： 1.计算机、数学、统计等相关专业本科以上学历;2.精通Sql/Java/Python等常见的开发语言，并能够独立进行大数据相关任务的开发和落地实施,了解相关的开发模式.3.有Flink开发经验者优先考虑；4.熟悉 Hive/Spark/Hbase/ES/ClickHouse/Kylin 等常见大数据组件的应用开发和性能调优，有Dataworks经验加分； 5.熟悉数据仓库架构及数仓方法论,熟悉数仓开发过程，有数据架构的设计能力加分；6.沟通能力强，有责任心，能够接受省外出差； 7.工作主动性强,能够独立思考，具备业务理解能力；
岗位职责：1.深入理解业务逻辑，进行数据分析从而把需要解决的业务问题转化为机器学习/数据挖掘问题；2.对海量数据清洗、分析、挖掘、建模，参与模型的维护、部署、评估工作，并形成相应的模型产品；3.深入研究各类数据源，整理和发掘数据价值，形成数据产品并推动落地；4.参与模型应用策略的开发、系统测试、验证和修改更新工作，提供必要的专家经验和使用信息等；5.对模型的表现进行监控和评估，对业务风险指标进行跟踪分析及优化；6.整理编写模型分析报告，及时发现和分析其中的变化和问题，为业务发展提供决策支持。任职要求：1.本科以上学历，统计学，应用数学，计算机，金融数学等相关专业，较好工程能力优先考虑；2.两年以上数据建模经验，具有逻辑回归、决策树、随机森林、GBDT、GLM、深度学习等算法实际使用经验，具有较强的数据整合，数据分析/挖掘，和解决业务问题的能力；3.熟练使用SQL，Python进行数据分析和模型开发；4.能够整体搭建数据架构，构建高质量的特征，建立完善的特征体系；5.有机器学习相关工作经验优先；6.熟悉Hadoop和Spark平台，熟悉相关工具来处理海量数据，具有政府行业数据分析经验优先。
职位描述：1. 负责公司实时流引擎的日常建设与维护；2. 配合公司其他同事进行实时应用的研发与落地；3. 支持公司实时处理技术的演进。岗位要求：1. 3年及以上实时流引擎开发或者数据平台开发经验；2. 熟练掌握Java语言以及常见中间件框架，熟悉面向对象、多线程、反射、JVM调优、类加载机制等；3. 对实时计算体系有自己的见解，深入了解Flink、Spark Streaming或Storm等流式处理框架4. 掌握Hadoop，Spark，HBase，Kafka等大数据组件者优先；5. 深入了解Flink运行机制，有实时流计算开发经验者优先。
岗位职责：1、参与数据中台的建设。2、参与数据仓库平台的建设与维护，数据ETL的设计、开发与性能优化。3、参与部分数据服务接口的开发。岗位要求：1、熟悉Linux操作系统基础命令。2、具有扎实的Java基础、熟练使用springboot+mybatis框架​3、熟悉Flink、Kafka、Doris等大数据组件4、了解数据仓库、数据中台等产品、有相关相关经验者优先​4、第一学历为本科及以上学历
【急聘】【中国移动杭州研发中心】大型央企平台，工作稳定，待遇丰厚，拒绝焦虑不内卷！base：杭州，职等你来[勾引][勾引][勾引] 【高级大数据研发工程师】工作职责1. 从事大数据计算和存储平台的架构设计与搭建、技术方案设计，参与系统研发协作，为后续数据产品提供高效的系统支持。2. 参与产品的架构规划、性能优化、稳定性保障建设、数据安全建设、技术难题攻坚。 任职资格1. 本科及以上学历，3年以上平台研发设计经验，有良好的技术积累，能独立负责技术架构规划与演进；2. 熟练掌握Java/C/C++至少一种开发语言，基础知识扎实，熟悉io、并发编程、数据结构、设计模式等技术，可以深入代码一线；3. 熟悉常用的开源分布式系统，对MySQL/Hive/Spark/Flink/MQ/Redis中的某项或多项有深入了解，并有实际开发经验;4. 具备图数据库相关产品（如Nebula/Neo4J/HugeGraph等）应用研发经验者优先；5. 具备知识图谱、图计算分析引擎、图神经网络、机器学习算法等相关开发经验者优先;6. 具备强烈的责任感和团队合作精神，学习能力强，工作热情、主动、踏实、严谨，有较强的抗压能力；
1、8年以上大型数据仓库/数据开发相关经验；2、熟悉Hadoop生态，包括Spark、HBase、Hive、Kafka、Flink等，有海量数据处理经验，熟悉数据仓库建模理论，精通维度建模设计开发，对数据采集及集成、数据建模、数据开发、数据资产管理、数据分析等大数据处理领域有丰富实战经验；3、能在复杂问题中快速找到解决方案，良好的技术和产品嗅觉，能从技术角度解决业务问题，赋能业务与产品；4、具备一定的Java开发能力，了解基础机器学习算法知识尤佳；5、有财务经验优先，良好的逻辑思维、语言表达能力；职位描述：1、针对财务域场景和制造行业属性，沉淀数据解决方案；2、引导用户需求，完成用户设计场景，进行数据清洗，特征挖掘，统计分析，并结合应用场景落地；3、参与财务数据中心的规划建设，包括数据采集、数据治理、数据质量与稳定性保障；4、深度理解财务域的数据诉求，负责财务数据体系建设；5、负责针对财务领域数据方向遇到的问题攻坚和数据技术挑战，开放性的解决数据分析等多维度数据问题，高效赋能业务（无财务专业领域经验亦可）
【岗位职责】1. 参与奇点云⼤数据实时计算平台的发展规划、设计及落地实现，围绕稳定性、易⽤性、性能；2. 负责Flink/Yarn等大数据组件的问题定位、技术治理、性能优化；3. 负责建设实时计算平台相关衍生产品的开发与维护；4. 根据业务发展，积极参与平台建设，不仅限于产品建设、业务流程改造、技术调研落地等；5. 构建基于 SQL 的批流统一计算引擎，支撑部分核心业务实时/离线统一的应用场景6. 熟悉Flink SQL, State&Checkpoint, Runtime者优先【任职要求】1. 本科及以上学历2. 3年以上java开发经验，熟悉java知识体系（5年以上⼯作经验）；3. 熟悉并行计算或者分布式计算原理，熟悉高并发、高稳定性、可线性扩展、海量数据的系统特点和技术方案4. 熟悉常⻅的开源分布式系统，具备系统开发、维护经验以及故障处理能⼒；5. 有Flink/kudu/Yarn等组件的源码级优化实践者优先；6. 有良好的⼤数据知识体系，对技术、业务流程、产品建设的有较好的理解。
1.负责业务数据和用户行为日志的实时采集、计算、存储、服务，为业务团队提供直接数据决策;2.负责部门实时计算体系架构建设及实时计算平台开发改进。3.负责即时分析相关技术方案的探索4.负责实时数据仓库的建设，完善实时计算方案任职要求1.本科以上学历，三年以上工作经验；2.深入了解离线计算及相关开发，掌握实时计算技术体系包括数据采集、计算引擎flink等,对实时计算所涉及的事务、容错、可靠性有深入理解 并有实际项目经验；3.熟悉 hadoop 生态包括 hdfs/mapreduce/hive/hbase,熟悉 kafka 等实时开源工具并有项目经验；4.熟悉 mysql 等关系型数据库,熟悉 redis 内存数据库,熟悉 linux 系统;5.掌握Java或Scala语言，如并发编程和JVM等，追求高标准的工程质量；6.有flink实时计算开发经验,熟悉olap的相关技术。7.有良好的沟通能力和自我驱动动力，具备出色的规划、执行力,强烈的责任感,以及优秀的学习能力,对技术有热情，愿意不断尝试新技术和业务挑战。
职位描述：1、阿里云数据库团队职位要求：1、从事数据仓库领域工作至少2年以上，熟悉数据仓库模型设计方法论，并有实际模型设计及ETL开发经验；2、掌握离线大数据开发技术，如Hive、Spark、Impala等等至少其中一种，灵活运用SQL实现海量数据ETL加工处理；3、 熟悉数据仓库领域知识和管理技能，包括但不局限于：元数据管理、数据质量、性能调优等；4、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验者优先；5、掌握一门或多门编程语言优先，如Java、Python、shell等；6、熟悉常用的实时数据处理技术者优先，如Flink、Storm、Spark Streaming等；7、良好的语言沟通与表达能力和自我驱动动力。
岗位职责：1.负责研发大数据平台和数据治理工具；2.负责进行大数据产品的离线与实时计算；3.负责数据平台的大数据基础架构规划、运维保障、数据监控等，为海量数据和业务系统提供可靠的基础设施；4.参与大数据生态相关技术的前瞻性研究和调研落地，持续扩充大数据能力，优化大数据服务的性能和效率 。岗位要求：1.熟练进行Java的代码编写，良好的代码编写素养，良好的数据结构算法技能；2.熟悉Java/Python/Shell等语言，具备良好的编程能力，具备源码级问题解决和集群优化改造能力；3.有数据平台开发经验，包括但不限于离线开发平台、数据质量中心、元数据管理、数据权限管理、数据资产管理，实时流平台等；4.熟悉开源大数据组件如Hadoop，Spark，Flink，Hive，Kafka,  Elasticsearch, Clickhouse, Dolphinscheduler等，有实际的报表平台、多维度分析工具、ETL平台、调度平台中至少一种工具的实际建设经验；5.具有很强的团队意识、沟通能力和独立解决问题的能力，学习能力和主动性强，具有钻研精神，充满激情，乐于接受挑战。
岗位职责：1、参与大数据应用设计和研发，解决实时和离线计算流程中性能、功能等多方面的挑战，打造高性能、高可用、可扩展的系统，支撑多项目多场景的通用接入。2、参与数据仓库的设计、开发与实施工作，对数据库模型进行设计、开发、验证、监控、优化。3、在传统大数据开发和数仓建模的基础上，探索创新的方案，构建自动化、智能化的建模引擎岗位要求：1、3年以上大数据处理研发经验；2、扎实的JAVA开发能力，熟悉shell、python或其他脚本语言中的任意一门；3、熟练使用数据库同步、日志采集工具；4、掌握Hadoop生态圈的主流技术及产品，精通Flink/Spark/HDFS/HBase/Hive/ES/Kafka/ClickHouse等大数据组件的原理和开发调优；熟悉数据仓库、ETL的工作原理，能够对ETL过程进行性能优化；5、有基于数据分析推动业务提升或优化的实际案例；6、有数据挖掘、机器学习经验者优先考虑；
岗位职责：1、参与公司项目的需求分析、业务设计、编码实现开发过程； 2、完成单元测试、参与技术讨论、编写技术文档；3、负责子系统模块的设计与实现； 4、负责完成领导安排下来的工作任务。任职条件：1、***本科及以上学历，计算机相关专业,有2年以上的大数据技术实践经验；2、精通掌握Java编程，熟悉IO、多线程、集合等基础知识，有性能调优能力；有Python、Scale，Go等编程经验者优先；3、熟练掌握常用设计模式，对面向接口编程、面向服务编程有一定的认识；4、熟悉Hadoop框架体系，掌握kafka等消息中间件知识，有Spark，Kylin，Flink等分布式计算相关开发经验者优先；5、掌握MySQL、Redis、MongoDB等知识，熟悉NoSQL框架，有Hive，Sparksql，Elasticsearch、ClickHouse等数据应用开发经验者优先；6、熟悉Linux下的常用命令，能够熟练使用shell语言进行脚本开发。7、良好的团队协作能力和沟通能力以及极高的项目责任精神，性格成熟沉稳，能够接受工作压力和迎接挑战；加分项：   有数据仓库产品实战经验，对海量数据的存储处理、维度建模、数据分析、数据挖掘等有深刻认识者优先；福利待遇：公司老板是华为出来的，员工很多来自武汉大学，浙江大学，东南大学等211，985高校，薪资待遇福利都不错，周末双休，加班也没有那么严重，加班可调休。
1.  具备扎实的计算机理论基础, 在操作系统、数据结构及算法方面有较强的功底，有很强的学习能力和自驱力。这是我们最为看重的一点。2. 精通Java或者C++，具备优秀的系统Debug/Profiling能力和经验，熟悉常见的面向对象设计模式，具备优秀的系统架构设计能力。3. 熟悉Hadoop/HBase/Flink/Spark等开源大数据技术，有大数据工程开发经验，有开源社区开发经验优先。
【岗位职责】在这里，你将与业界大数据专家一起工作，有机会与来自全球的大数据领域牛人交流，参与华为业界领先的大数据平台的核心产品设计、研发、交付。你将会1、深度参与到华为大数据Hadoop, Yarn, Spark, Hive，HBase, Kalfa, Zookeeper，Flume, AI品牌平台等组件的研发，交付及解决方案支撑2、探索云服务化实现的前沿技术，并负责华为云大数据服务的架构设计，开发，测试及运维【岗位要求】1、计算机，软件相关专业本科及以上学历2、精通JAVA软件开发，有软件开发项目经验，并至少熟练掌握以下语言中的一种：C/C++/GO/Python/PHP/Shell等编程语言及脚本语言3、熟悉大数据相关开源软件，有应用大数据组件的解决问题的实战经验，有开源设计代码贡献者优先4、具备团队意识，与他人合作良好，最好具有团队协作的经验
关于我们：- 初创公司，我们致力于打造新一代云原生实时数仓- 数仓内核团队，公司的核心部门- 基于share disk + share nothing架构、读写分离的、支持多workloads的实时数仓我们将为您提供：- 数仓部门技术核心研发岗位，与您匹配的待遇，畅通的技术提升与岗位晋升通道；- 参与从0到1的产品开发过程， 公司业务快速发展和技术转型带来的技术挑战和业绩红利；我们需要您：- 完成数仓与大数据生态的集成，包括flink、spark等- 参与数仓的核心设计与开发工作，包括编写执行器、存储、索引构建等- 参与支撑数仓上层云平台的建设，包括任务调度、编排、治理、数据服务等您必须具备：- 3年（含）以上的大数据开发经验，对海量数据处理和快速计算有浓厚兴趣- 计算机相关专业，基础扎实，能够深入理解代码或者有较强的学习能力与意愿- 良好的英文阅读能力和资料查找能力，能快速地查阅资料、深入分析并解决问题- 精通Java、rust、c，熟练使用Linux操作系统- 熟悉Hadoop生态，可熟练使用Spark进行开发- 良好的团队合作精神，逻辑严谨，责任心强具备以下条件尤佳：- 有较好的数据结构、算法基础，对排序索引、倒排索引、文本检索索引了解优先- 有数据中台、平台开发经验，大数据计算引擎相关的研发经验最好欢迎广大大数据从业人员了解并投递简历，薪资可谈不设限，本岗位非数据ETL和业务开发，如果能力够强，有意愿转到大数据平台开发也可。
岗位职责1、参与数据模型的设计，ETL实施、性能优化、数据监控以及相关技术问题的解决2、参与公司相关数据仓库建设，参与数据建模和开发工作岗位要求1：计算机、数据统计、数据科学相关专业，熟练使用SQL，有python经验加分； 2：计算机基础扎实，掌握大数据领域核心技术，包括但不限于：MaxCompute，Hadoop、Hive、Kafka,flink3：对数据开发、仓库、分析有兴趣和热情，有志在大数据领域持续发展4：思维敏捷清晰，性格open，自我驱动，有一定的吃苦抗压能力，具备良好的学习能力和沟通能力
岗位职责1、负责华为大数据平台设计和核心代码开发，软件架构看护；2、负责Hadoop/Flink/Spark/数仓/流处理/搜索引擎/协同计算等产品设计和开发；3、负责Hadoop/Flink生态圈组件维护，开源社区动态跟踪、竞争力分析和规划技术演进；岗位要求1、3年以上Java/Scala/Python开发经验，熟悉Linux/Unix操作系统原来，熟练掌握常用设计模式；2、有分布式系统设计开发经验，能独立承担软件模块设计和开发工作；3、熟悉大数据相关组件Hadoop/HBase/Spark/Sqoop/Oozie/Flume/Kafka/Flink /Storm/Hive/Elasticsearch内核源码，系统性能调优和分布式架构经验优先；4、熟练掌握Spring MVC、容器等技术，理解SOA、微服务等关键理念与技术，并有实践应用经验；岗位亮点华为云 全球网络监控告警平台在世界云计算厂商评估中居于领先位置。已服务 60+个国家和地区，3,000+客户，覆盖政府、金融、运营商、电力、传媒、医疗、教育、交通、油气、物流、零售、制造、互联网等行业。项目部门情况：1、华为云全球网络监控告警大数据团队，负责大数据平台端到端的开发、测试、运维2、目前80人+团队3、有国内顶级的大数据专家团队，注重培养人选的复合型能力，拥有国内领先的开发、维护、测试等团队；
职位描述：1、围绕公司业务域相关数据，负责数据仓库及数据应用系统的架构设计，技术方案设计，技术难点攻关；2、挑战大数据，高稳定的业务场景，支撑业务方对于线上不同数据的各种使用场景；3、与业务，产品紧密协作沟通，满足业务数据需求，发掘业务数据价值，提供应用指导；4、参与数据治理工作，提升数据易用性及数据质量；5、负责系统指标体系建设与维护。职位要求：1、计算机及大数据科学相关专业，本科以上学历，有相关行业经验优先；2、有扎实的编程能力，深入了解SQL、Python、Java等至少一门语言编程；3、熟悉MySQL、消息队列等常用组件，并了解其底层运行原理以及技术要点；4、了解大数据相关技术：Hive/Flink/Spark/HBase/Clickhouse/Hudi 等；5、善于沟通，对业务敏感，能快速理解业务背景，具备优秀的技术与业务结合能力；6、有供应链/交易/财务/风控/CRM/CDP/人群等电商相关成熟数仓经验为加分项。
职责描述：  1、负责大数据应用的架构设计、核心代码开发等任务；根据项目要求编写相关技术文档 2、负责大数据应用的架构评审，代码评审，上线评审；参与数据应用需求、设计、审核和评审 3、负责大数据平台、数据中台产品架构设计、核心模块开发、产品上线技术支持与运维 4、负责建立和维护大数据平台技术标准规范，指导数据开发人员编写代码 5、负责大数据应用开发，提供数据应用项目技术支持，参与数据应用类项目 任职要求：  1、本科及以上计算机、数学相关专业毕业；具有2年及以上相关工作经验 2、熟悉大数据技术生态圈，精通大数据技术架构，有大数据平台建设经验 3、精通离线和实时数据处理流程，掌握离线数据处理框架hive、impala、spark等，掌握实时数据处理常用技术工具flink、spark streaming等 4、掌握常见数据集成工具，如sqoop、datax、flume、kafka等，并熟悉其架构原理 5、熟练掌握基本的Linux操作系统或某种脚本语言编程 6、掌握JAVA、SCALA编程语言，且从事过java web开发优先 7、有1年以上生产系统大规模数据（TB级以上）处理经验，具备大规模数据存储、集成、计算性能优化的能力 8、有华为云MRS/DWS、阿里云ODPS/DATAHUB/BLINK等数据中台产品架构设计、二次开发经验者优先 9、有能源行业、物联网行业等大数据架构及开发经验者优先
1. 负责数据产品开发，承担实时、离线大数据处理组件等功能开发与优化2.负责业务条线数据仓库基础平台的建设和维护，数据ETL的设计、开发与性能优化3.负责数据治理工作，提升数据易用性及数据质量。4.理解并合理抽象业务需求，发挥数据价值，与业务团队紧密合作
【工作职责】1、负责华为大数据平台设计和核心代码开发，软件架构看护；2、负责企业级大数据集群管理平台FusionInsight Manager的设计和开发；3、负责Hadoop/流处理/批处理/实时风控/搜索引擎/HetuEngine/Hudi/CarbonData/ClickHouse等产品设计和开发；4、负责大数据组件开源社区动态跟踪、竞争力分析和规划技术演进。【任职要求】1.掌握Java/Scala/Python/C/C++语言，熟悉Linux/Unix操作系统，熟练掌握常用设计模式；2、有分布式系统设计开发经验，能独立承担软件模块设计和开发工作；3、熟悉大数据相关组件Hadoop/Flink/HBase/Spark/Sqoop/Oozie/Flume/Kafka/Storm/Hive/Elasticsearch/Presto/CarbonData/Hudi/ClickHouse内核源码，系统性能调优和分布式架构经验优先；4、有云服务化开发经验，DevOps实践经验，开源社区项目代码贡献者优先；【团队介绍】：华为云大数据团队，在中国大数据管理平台厂商评估中居于领导者位置，已服务 60+个国家和地区，3,000+客户，覆盖政府、金融、运营商、电力、传媒、医疗、教育、交通、油气、物流、零售、制造、互联网等行业。华为云大数据拥有自主知识产权，获取专利 500+；培养了 20+开源 Committer 专家，为社区贡献了 CarbonData和openLooKeng 等，并持续在开源社区保持影响力。​【职位类型】OD【工作地点】深圳/西安/武汉/杭州/北京/南京
"1.岗位职责:1).完成大数据分析平台的设计、开发、测试和部署;2).大数据平台数据采集、处理、转换、分析建模、服务集成的相关开发和优化工作;3).提供海量数据存储、分布并行计算、搜索系统、4）用户行为数据挖掘和大数据可视化展现;5）.理解和分析数据挖掘需求和数据特点，开发中间数据层及策略中间件。6）.将产品和运营的需求转化成数据的思维，设计面向业务的OLAP，集市模型,完成企业级数据仓库的设计,落实和维护。7).大数据环境下的软件开发，数据应用分析;2.任职要求:基本要求1、计算机或者相关专业本科及以上学历，三年以上分布式处理系统的设计开发工作经验；2、熟练掌握Java或C/C++或scala，熟练掌握Java集合类、并发编程和熟悉JVM原理及内存管理,对数据结构、算法有深刻理解；3、熟悉Spark、Kafka/Flume、Zookeeper等主流大数据开源组件；4、熟悉Hadoop、Hive、Hbase等分布式搜索开源项目及工作原理，懂得SQL优化；5、具有较强的团队意识与良好的沟通能力，高度的责任感，对工作积极严谨，勇于承担压力，较强的学习能力以及快速解决问题的能力。优先条件（满足至少一项）1、	有过基于大数据平台的数据采集、处理、转换、存储的实际应用经验；有丰富的集群部署、开发和维护管理经验； 2、具有搭建数据仓库，OLAP数据库设计与建设经验，企业级数据仓库的设计,落实和维护经验。3.有过基于大数据平台开展数据挖掘工作，并能够较好的应用于特定行业；对spark熟练,对scala熟练."
职业描述：1.参与公司数据仓库架构设计与研发,建设PB级的公共数据平台和服务系统,实现高质量数据的互通与共享2.参与数据产品与应用的数据研发,发掘数据商业价值,打造**体验的数据产品任职要求：1.从事数据仓库领域至少2年以上,熟悉数据仓库模型设计与数据研发经验,掌握维度建模设计方法等思想,具备海量数据加工处理相关经验2.掌握至少一种分布式平台开发技术:Maxcompute、Hadoop、Spark、Teradata等,灵活运用MR、SQL、UDF实现海量数据加工处理3.熟悉Linux系统常规shell处理命令,灵活运用shell做的文本处理和系统操作4.熟练掌握一门或多门编程语言,并有大型项目建设经验者优先,重点考察Java、Python5.熟悉数据仓库领域知识和技能者优先,包括但不局限于:元数据管理、数据开发测试工具与方法、数据质量、主数据管理6.既能掌握大规模离线数据处理又能掌握实时流计算技术优先,如Storm、Flink、SparkStreaming、Streamcompute等7.良好的语言沟通与表达能力和自我驱动动力
岗位职责:1、负责实时数据产品化的开发和架构工作。通过不断完善数据产品来降低数据的使用成本，提升数据的可维护性。2、深入业务，通过数据化产品看清业务现状、推动数据决策闭环。3、对数据工程方向的稳定性负责。任职资格:1、计算机或数学相关专业，本科以上学历；2、熟练掌握 Java 语言，精通 Spring 生态技术栈，有微服务开发经验，熟练掌握脚本语言 Shell/Python 之一；3、熟悉 SQL，具有丰富的数据开发经验，对数据处理、数据仓库建模、数据分析等有深刻认识和实战经验；4、熟悉常用开源分布式系统，深入研究 Hadoop/Hive/Spark/Flink/HBase 一项或多项相关技术；5、有OLAP、海量数据处理、实时计算等相关开发经验者优先；有地理信息索引建设经验优先。6、积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神。7、良好的横向沟通能力和学习能力，对业务有好奇心。8、能独立搭建数据环境，并负责团队招聘和管理相关经验者优先。
基于 flink 系统的分布式大数据处理和分析平台的二次开发与实施；参与项目的需求分析、概要设计、详细设计，技术文档的编写；负责开发框架的搭建、改进；协助完成项目的测试、系统交付工作，对项目实施提供支持。负责跟进软件系统安全、稳定、维护和性能优化等工作;分布式技术研究，及关键技术的开发工作；相关数据平台系统的开发与调试；负责搭建行业产品大数据的存储、计算等框架以及主要代码编写5年大数据开发经验，熟悉各个大数据组件，对es，hbase，titan，hive，spark，yarn能够熟练编写代码，对大数据各个组件原理有清晰深刻理解2 熟悉掌握java，web框架，数据库设计等基本web开发工具及技巧3 有处理高并发，高吞吐数据量的经验。4 精通Linux环境，常用指令操作5 能够承担大数据平台运维工作，对大数据平台出问题后的调试有一定经验。
【职位描述】1. 负责当贝业务数据资产的设计与研发，包括架构和内容设计，项目计划，开发测试部署等。构建行业标杆级的操作系统领域核心数据资产池；2. 打造先进的大数据平台，包括实时数据流、数据仓库、调度系统、查询引擎，用户行为分析，abtest 实验系统等，降低数据的使用门槛，实现数据的最大价值；3. 建设适合业务的大数据存储、计算等分布式系统，为海量数据和大规模业务系统提供可靠的基础设施。【职位要求】1. 本科以上学历，3年以上工作经验，有团队管理经验2. 有3年以上的大数据仓库构建和数据分析经验3. 有很强的架构设计能力, 编码能力扎实，熟悉Java，SQL及常用工具 4. 熟悉主流分布式计算引擎，中间件，NoSQL数据库，如hadoop，hive，flink，kafka，hbase，redis等，并熟悉运行原理5. 有Github等开源社区贡献者优先6. 具备大规模分布式服务设计能力和经验优先
职位描述：1. 负责网商银行风险管理部数据应用集市的设计与研发，包含离线和实时，支持风控策略和模型部署，稳定运行。助力万亿级规模的信贷业务高速且稳健的发展；2. 负责网商银行风险管理部核心数据资产的设计与研发，包括架构和内容设计，项目计划，开发测试部署等。构建行业标杆级的信贷风控领域核心数据资产池；3. 负责数据平台产品的设计与建设，赋能风控和业务，提高团队整体效能。职位要求：1. 数据仓库领域至少5年以上经验，有丰富的数据仓库模型设计与ETL、实时数据研发经验 ，掌握常用的数仓建模方法，具备大数据处理经验和相关项目经验。能独立完成复杂数据架构/模型的设计并推动落地；2. 精通常用关系型数据库Oracle、Teradata、DB2、Mysql等开发；精通hadoop/hive/hbase等大数据研发体系，且了解其底层实现原理；有实时数据研发经验，精通RocketMq/Kafka（任一）等中间件，Blink/Flink/SparkStreaming（任一）等流计算引擎开发；有数据质量管理与数据治理经验；具有超大规模数据研发项目经验更佳；3. 熟练掌握一门或多门编程语言，Java、Python、Perl等，有数据挖掘/分析能力更佳；4. 对信贷风控领域的数据建模有一定了解，对数据驱动业务有深刻理解；5. 良好的语言表达能力和自我驱动力，以及优秀的沟通协调能力。
参与公司数据处理逻辑、数据模型的设计、优化和开发；3年以上的TB级别数据平台开发经验，至少2种分布式计算引擎的实现原理； 名校毕业或高学历者优先、有开源社区贡献如 apache Committer 优先、有海量数据处理经验优先。
岗位职责: 1、负责客户业务数据分析需求，理解业务逻辑，并根据业务需求设计相应主题的数据模型；2、参与BI报表开发；岗位要求：1、对数据处理、数据分析和关联等有较深的认识； 2、熟练掌握SQL查询技术、性能优化; 3、熟悉mysql、sqlserver、oracle等主流数据库系统，有使用Hadoop、hive、 Spark、clickhouse、Antdb等经验者优先；5、具有BI数据分析工具经验者优先；6、有一定的java开发经验者优先；
1、参与数据中台及相关中间件的设计及研发工作；2、负责调研竞品、相关开源工具的架构、源码3、参与解决分布式系统性能、安全、可靠、稳定性等方面的问题；4、参与相关业务功能的设计及研发任职要求：1、本科及以上学历，计算机、软件相关专业，3年以上Java开发经验，有技术深度；2、精通Java/Java Web，对JVM、多线程、NIO等技术有较深的理解；3、熟练掌握MySQL、ORACLE数据库，有数据库调优经验，熟悉hadoop/hbase/spark/storm相关技术者优先；4、熟悉Linux系统，熟悉Linux高性能服务器开发的优先；5、具备良好的算法能力；6、具备优秀的架构经验，熟悉分布式架构，了解常见的分布式问题并能给出解决方案，了解kafka/rocketmq等消息队列技术的优先。7、有知名开源软件源码阅读经验优先

岗位职责1. 研究大数据领域相关业务、产品、技术情况；2. 负责企业项目的运维平台大数据设计开发，带领团队实现大数据相关业务；3. 设计大数据运维产品，包括产出需求，原型与相关的配套文档；4. 与各产品研发团队合作，推动产品的发布；5. 与项目团队合作，推动产品的交付； 任职要求1. 4-10年工作经验，精通Kafka、Flink、ElasticSearch等大数据相关技术；2. 具有较好的沟通能力，组织、协调、团队管理及解决问题的能力3. 熟悉软件产品生命周期及生产过程，有与研发团队配合的经验；4. 具有较好的方案能力，能设计与编写产品原型、需求与方案配套文档；5. 具有强烈的学习、成长意愿；有责任心，能承受较大的工作压力；有团队协作精神，善于挑战；6. 加分项：拥有运维平台、数仓建模、数据治理
1.深入业务场景，发现业务痛点，设计数据化、智能化解决方案；2.持续关注大数据领域动态和前沿技术，合理地引入到工作中，提升大数据能力；3. 将解决方案沉淀成可复用、可配置的灵活平台，降低技术产品复用的成本，提升技术输出效率；4.能够组织跨团队协作、推动甚至直接负责项目优质如期落地；熟悉数据及数据技术并能与业务和技术人员很好的沟通与协作。职位要求1、能快速掌握业务需求，善于系统性思考并使用创新性思维解决问题；2、有云计算，大数据，人工智能，物联网经验者优先；3、了解常见的大数据平台和常用的机器学习算法，熟悉数据统计与挖掘相关方案；4、具备丰富的跨团队整合经验与协作意识，乐观积极，有较强的协调和组织能力，表达能力强，面对各种场合不卑不亢；5、眼界开阔，关注业界新兴流行的技术应用，具有创新性的思维和方法。
职位描述1.负责数据基础架构和数据处理体系的建设与优化。2.负责大数据平台的架构设计，参与数据应用需求、设计、审核和评审。3.负责大数据 ETL 的研发工作。4.负责建立和维护大数据平台技术标准规范，指导开发人员编写代码。职位要求1.本科及以上学历，有5年以上的工作经验，大数据相关产品设计及开发至少经验3年以上；2.熟悉大数据开发框架及业界主流技术框架，如Hadoop、Spark、Hbase、Storm、Flink、SparkStreaming等；3.熟悉Clickhouse/Greenplum/Presto/Druid等OLAP计算引擎的一种或多种。4.熟悉JAVA、Scala中的至少一种，掌握常见的数据结构、算法；5.对数据质量管理、数据应用等有独到见解的优先。
职位描述1、负责字节跳动抖音电商相关业务数据仓库的开发与优化；2、基于Hive/Flink等平台建设数据仓库，实时数仓建设；3、负责数据模型的设计，etl实施，etl性能优化以及相关技术问题的解决；4、负责面向业务的olap，报表，数据提取工具等开发工作。职位要求1、熟悉大数据相关技术：Kafka/Flink/Hadoop/Druid/HBase/Hive 等；2、熟练使用 Java、Go、Python语言中的一种或者多种；3、具备数据库系统理论知识，掌握主流数据库管理和应用，精通SQL；4、了解统计以及数据挖掘、机器学习、人工智能技术，会使用关联分析、分类预测、聚类分析等常用分析方法；5、有高性能分布式平台开发经验，有电商行业经验优先。
团队介绍阿里巴巴拥有世界上规模最大的电商搜索和推荐系统，其中搜索推荐引擎支撑着每天数以百亿计的海量用户访问请求，并产生大量的用户行为日志。搜索AI大数据处理平台承担着商品信息变更、用户行为日志等海量数据处理的职责，其产出的数据除了导入引擎供用户的检索访问，也会产出训练样本供算法同学生产更加优异的算法模型，并提升搜索推荐的业务效果。随着阿里巴巴业务的高速发展，如何在数据量/业务量不断增长的情况下，满足海量吞吐与高实时性两个性能目标，并在此基础上稳定高效的支持大量业务需求，越来越成为巨大的挑战。为了应对这些挑战，我们基于Flink、Hologres等技术开发了AI大数据平台，支持了阿里集团几乎所有业务搜索推荐数据处理相关工作，除此之外团队还直接支持淘宝天猫搜索推荐、拍立淘、Aliexpress等集团电商核心业务。岗位描述：1. 参与搜索推荐AI大数据平台的开发，解决实时和离线计算流程中性能、功能等多方面的挑战，支持搜索推荐场景下特征处理、样本生产等流程的开发和高效迭代，支持集团算法和业务同学在平台上开发业务需求。2. 与Flink、Hologres等生态深度结合，挖掘计算和存储引擎的潜力，开发相关的组件，推进流批计算的一体化。3. 支持淘宝天猫搜索、拍立淘、AliExpress搜索广告等业务，优化性能和迭代效率。智能引擎事业部-AI大数据开发工程师-杭州职位描述1.  具备扎实的计算机理论基础, 在操作系统、数据结构及算法方面有较强的功底，有很强的学习能力和自驱力。这是我们最为看重的一点。2. 精通Java或者C++，具备优秀的系统Debug/Profiling能力和经验，熟悉常见的面向对象设计模式，具备优秀的系统架构设计能力。3. 熟悉Hadoop/HBase/Flink/Spark等开源大数据技术，有大数据工程开发经验，有开源社区开发经验优先。
计算机或相关专业本科以上学历；有3-5年大数据平台开发方面相关工作经验；熟悉数据仓库和数据建模的相关技术细节，有编程经验，熟悉JAVA或者SCALE语言；熟悉SQL/Hadoop/Hive/Hbase/Spark/KFK/flink等大数据工具具有海量数据处理经验，或有互联网行业数据挖掘工作经验者优先；有电商,个性化推荐经历者优先考虑;
职位诱惑：周末双休 绩效奖金 核心产品开发 行业前景好 上升机会多岗位职责：1.参与数据中台团队系统需求分析和设计开发工作；2.利用大数据相关技术实现对数据的分析、挖掘、加工、处理、及数据可视化等相关工作。3.参与推动团队内技术经验分享，前沿技术研究，技术演进。职位要求：1.本科及以上学历，3年及以上Java开发经验，扎实的java基础知识；2.3年以上大数据开发、数据分析相关工作经验，熟悉Flink、Kafka、Doris/StarRocks、ClickHose、Spark、ES等相关大数据技术；3.了解数据仓库建模理论，对数据仓库、数据平台、数据分析、数据治理等有理解，具备的数据加工处理和优化经验；4.熟悉Hadoop、HDFS、Hive、HBase等常用组件的一种或几种，了解其中的架构与技术原理； 5.熟悉Linux操作系统，计算机网络，大数据应用性能调优经验者优先；6.个性乐观开朗，沟通能力强，具备良好的团队协作精神，能利用自身技术能力提升团队整体研发效率。7.有0-1搭建离线/实时数仓经验，熟悉flink，有flink二次开发经验者优先；8.熟悉Java基础，spring框架，k8s者优先；
大数据平台开发，偏底层工作职责1、构建分布式大数据服务平台，参与构建公司海量数据存储、离线/实时计算系统；2、负责Hadoop/spark集群稳定和推广,为业务应用提供平台级支持和服务；3、深入Hadoop/spark源码内核改进优化开源项目；任职要求：1、计算机或相关专业本科以上学历；2、具备3年以上后端开发工作经历，具备3~5年以上大数据相关工作经验。3、熟悉Java/Scala程序开发，熟悉Linux/Unix开发环境。4、熟悉linux操作系统，具备一定的操作系统问题定位解决能力。5、熟悉docker容器技术，对K8S有一定的了解和使用。6. 熟悉Hadoop\Spark\Hive\Hbase\Flink等开源生态技术的体系结构和运行原理
岗位职责：1.负责大数据平台组件、数据中台、大数据应用等领域的开发工作。2.参与大数据技术验证、方案选型、架构设计。3.负责大数据领域的技术应用趋势跟踪，促进大数据应用能力提升。职位要求：1.本科以上学历，计算机及相关专业毕业。2.对大数据处理有强烈兴趣，掌握至少一种主流开源技术方案，如PostgreSQL、Hadoop、Spark、Flink、Hbase，ES等，熟悉开源组件开发、系统调优、高可用等技术。3.具备2年以上Java开发经验，同时具备Python，Scala开发经验者优先。4.具备较好的行业英语能力。5.具备大数据基础架构设计实际经验者优先录取。6.自主学习能力强，善于沟通和解决问题，有高度责任心和团队精神，能够承担压力、接受挑战。
1.负责大数据平台的建设与开发工作，包括不限于数据接入，数据清洗，数据挖掘，业务主题建模，基础组件的二次开发，新模块的集成等。2.对系统存在的技术问题和性能问题进行跟踪发现，并给出解决方案。3.能独立完成业务需求的技术设计和开发。4.能带领团队攻坚克难，高效完成任务。任职要求：1.计算机相关专业，本科以上学历2.对数据架构和业务架构有深刻的认识3.精通离线和实时数据处理相关组件和流程，组件包括datax、hive、hdfs、greenplum、kafka、spark、flink、hbase，流程包括数据采集、数据传输、数据计算和存储等4.熟悉传统的数据库，如oracle、mysql等5.能熟练使用hivesql和传统sql解决业务问题6.有大数据量性能优化的实践经验7.至少精通一门编程语言，如java、python8.具备金融行业数据类项目经验优先考虑
"职位描述	1. 负责数据平台开发工作, 离线调度、执行服务、限流服务等需求调研、方案设计、开发和运维工作, 提升整体任务开发调度平台的稳定性和灵活性	2. 参与实时、离线、机器学习相关平台组件开发工作	3. 参与数据平台基础服务架构设计、开发、测试以及文档编写等工作；职位要求	1. 具有3年以上开发经验，本科及以上学历，计算机软件或相关专业（或具备同等水平的实践经验）	2. 理解Java运行时工作原理，熟悉jvm性能调优，熟练掌握并发编程，并熟练掌握Java相关开发技术和工具;	3. 熟练掌握Spring/Spring Boot/MyBatis等主流开发框架及其运行机制；	4. 熟练掌握MySQL/Redis/HBase等至少一种存储服务的使用和查询调优；	5. 熟练使用Linux，能够利用常用的工具对程序进行跟踪诊断;	6. 具备良好学习、沟通能力及团队协作精神，对工作积极严谨负责。	具备以下条件者优先：	1. 熟悉Azkaban/DolphinScheduler/Zeppelin/Livy/Hadoop/Spark/Flink等开源组件者优先	2. 有Netty开发经验；	3. 有分布式任务调度服务、执行服务开发经验；     4. 有k8s相关使用、开发经验。     5. 了解机器学习相关技术流程，有相关经验"
一、工作内容1、参与需求评审，基于PRD和交互设计完成功能设计及编码实现，并完成代码评审、自测和联调，确保代码交付质量；2、参与关键技术的前期调研和方案选型，参与日常技术难点的攻关；3、熟悉所负责的业务，分析和发现系统的优化点，推动产品性能、稳定性、易用性提升，持续进行架构优化和技术创新；二、职位要求1、本科及以上学历，从事java开发3年及以上；2、对java面向对象软件结构有深入理解以及很强的应用能力，精通OO、AOP、设计模式、熟悉多线程并发，网络编程技术。熟练掌握Spring等主流的开发框架；3、熟练使用MySQL，有良好的SQL编写和调优能力；4、有分布式开发经验，熟练使用分布式服务框架、消息中间件和分布式存储系统等；5、对技术有强烈的兴趣，喜欢钻研，具有良好的学习能力，沟通能力和团队合作能力6、熟悉hive datax hbase clickhouse spark并有实际开发经验的最佳
